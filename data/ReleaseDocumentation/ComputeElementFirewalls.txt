%META:TOPICINFO{author="SuchandraThapa" date="1274474066" format="1.1" version="1.30"}%
%META:TOPICPARENT{name="ComputeElementPostInstall"}%
---+!! *<nop>%SPACEOUT{ "%TOPIC%" }%*
%DOC_STATUS_TABLE%
%TOC{depth="2"}%

%STARTINCLUDE%
%BR%
---+ _%INCLUDEHEADING%  %SPACEOUT{ "%TOPIC%" }%_
%EDITTHIS%
%BR%

---++ Introduction

Grid components are distributed throughout the network, and services such as gatekeepers and data movement utilities are required to be accessible to the dynamic cloud of clients and peer services. This distributed and dynamic requirement places the burden of the security on the implementation of the application.

Due to the discovery of significant vulnerabilities in recent years, network-based applications are untrusted by default. To solve the application problem, effort has focused on developing and deploying firewalls, which restricts full and free network access.  (You might say that this is analogous to building a house with no doors. Is it safe? Yes. Is it useful? No.)

Some essential network-based applications have been "hardened," such as mail relay services, web servers, and secure shell daemons. These are further protected further by IP address  filtering to prevent access from unknown hosts or domains.

Grid components which are located behind a network firewall face special challenges for Grid setup and operations. 

There are two styles of firewalls usually encountered. 
   * A network firewall which is upstream from your server  (usually centrally maintained). This blocks all traffic to your host. 
   * Host-based firewalls which are set up and maintained  by individual host administrators. These are usually set up and configured by the =iptables= program which filters incoming network packets which arrive for the host.

 In addition to host-based firewalls, hosts can choose to implement host based access rules (usually set up with the =tcp_wrapper= or =hosts_allow= utilities).

Network traffic can be blocked at the firewall for both incoming and outgoing dataflow depending on hostnames, ip addresses, ports and protocols. 

A common setup is to allow any outgoing connection, while significantly (if not completely) restricting incoming connections.  The Globus project provides thorough documentation, including but not limited to the [[http://www.globus.org/toolkit/security/firewalls/][Globus Toolkit firewall requirements]] document. 

%IMPORTANT% You may need to open ports on your firewall for your batch system (Condor, LSF, etc.), too! See, for example, [[http://www.cs.wisc.edu/condor/manual/v6.8.6/3_7Networking.html#SECTION00471000000000000000][information about Condor's use of ports]].

---++ Port ranges

Port usage which may require firewall updates:
   * Inbound:
      * GRAM: 2119/tcp inbound
      * [[http://www.globus.org/grid_software/data/gridftp.php][GridFTP]]: 2811/tcp inbound
      * MDS: 2135/tcp inbound  (obsolete)
      * Web Services: 9443/tcp inbound
      * GRAM callback: user-defined contiguous range (set via the environment variable =GLOBUS_TCP_PORT_RANGE=beginport,endport=). 
      * Monalisa: 9000/udp (for ABping measurements).  These are specified in the file =$VDT_LOCATION/MonaLisa/Service/VDTFarm/ml.properties=
   * Outbound:
      * GRAM callback: user-defined contiguous range (set via the environment variable =GLOBUS_TCP_SOURCE_RANGE=beginport,endport=). 
   
GRAM and [[http://www.globus.org/grid_software/data/gridftp.php][GridFTP]] need to know the port range that you've opened up via environment variables.  You need to set the =GLOBUS_TCP_PORT_RANGE=beginport,endport= for inbound ports.  If you restrict outbound connections, you will also need to set =GLOBUS_TCP_SOURCE_RANGE=beginport,endport=. 

The size of these ranges is very dependent on the size of your cluster. As a rule of thumb, each job slot requires between 6 and 8 ports, so be sure to provide a large enough range for your cluster, otherwise jobs may start to hang randomly as your site fills up, and that may be very difficult to track down.

These ranges may be set in =$VDT_LOCATION/vdt/etc/vdt-local-setup.[c]sh=. You should NOT set the allowed port ranges by editing the xinetd configuration files &mdash; the examples below do imply such editing, but will not survive a vdt-control off and on cycle.  

The variables applied in the local setup as above will be used by GRAM, Integration.GridFTP, and any clients that require them.

The above ports and protocols <em>must be open</em> to and from all grid clients and server machines participating in the grid in order to provide minimal functionality.

In addition to the above, port 9443 must be open for both incoming and outgoing connections in order to test the web-services capabilities of the most recent versions of the VDT.

You also may need to open the following optional incoming ports for additional Grid services.  Note that unlike the ones listed above, the following are <em>optional</em> and are only needed if you are running those specific services or if required by your specific virtual organization.

   * GIIS: 2136/tcp (obsolete)
   * GSISSH: 22/tcp
   * [[http://grid.ncsa.uiuc.edu/myproxy/][MyProxy]]: 7512/tcp
   * VOMS-Admin and/or GUMS: 8443/tcp
   * VOMS 15001/tcp  (ports start at 15001 and increment by 1 for each VO you support, used for voms-proxy-init service).
   * RLS server: 39281/tcp
   * Squid server: 3128/tcp

Here is a sample of the a =/etc/hosts.allow= with the GLOBUS services opened:
<pre class="programlisting">
  #
  # hosts.allow   This file describes the names of the hosts which are
  #               allowed to use the local INET services, as decided
  #               by the '/usr/sbin/tcpd' server.
  #
  sshd: 129.79.6.113 
  ALL : localhost
  vdt-run-gsiftp.sh : ALL
  vdt-run-globus-gatekeeper.sh : ALL</i>
</pre>

---++ iptables for RHEL or compatible systems

The default firewall configuration for Red Hat's iptables sets the system up with a stateful packet filter. This is different than some legacy RH7 systems as by default no ports that are not explicitly opened by the iptables script will be open. This includes high numbered ports that are often used by grid services. 

If your preference is to leave as much of the stateful packet filtering in place but enable just those grid services you want to deploy, then you can use the following instructions. 

Two changes need to be made to an OSG gateway with a host based iptables stateful firewall. 

First is the configuration of the firewall itself. On RHEL or similar systems this is done in =/etc/sysconfig/iptables=.

The Chain RH-Firewall-1-INPUT is a default chain for RHEL3. This chain is also sometimes called INPUT. Make sure the following rules use the chain that other rules in =/etc/sysconfig/iptables= do. 

%NOTE% For GSISSH this port is often already open for systems. You can use either this rule or the default rule setup at install time if you selected custom firewall and enabled ssh. 

<noautolink><pre class="programlisting">
# Globus: Requires addition configuration in /etc/xinetd.d/globus-gatekeeper
# set: env = GLOBUS_TCP_PORT_RANGE=40000,50000
# This allows up to 10,000 ports and matches the globus config.
# How globus is configured to use these ports is subject to change in an upcoming
# release
-A RH-Firewall-1-INPUT  -m state --state NEW -p tcp -m tcp --dport 40000:50000 -j ACCEPT
# Monalisa, grabs 3 ports from the following range
-A RH-Firewall-1-INPUT  -m state --state NEW -p tcp -m tcp --dport 9000:9010 -j ACCEPT
-A RH-Firewall-1-INPUT  -m state --state NEW -p ucp -m ucp --dport 9000 -j ACCEPT
# GRAM
-A RH-Firewall-1-INPUT  -m state --state NEW -p tcp -m tcp --dport 2119 -j ACCEPT
# Gridftp
-A RH-Firewall-1-INPUT  -m state --state NEW -p tcp -m tcp --dport 2811 -j ACCEPT

# Optional Services
# RLS Server
-A RH-Firewall-1-INPUT  -m state --state NEW -p tcp -m tcp --dport 39281 -j ACCEPT
# MyProxy
-A RH-Firewall-1-INPUT  -m state --state NEW -p tcp -m tcp --dport 7512 -j ACCEPT
# GSISSH/SSH
-A RH-Firewall-1-INPUT  -m state --state NEW -p tcp -m tcp --dport 22 -j ACCEPT
# MDS
-A RH-Firewall-1-INPUT  -m state --state NEW -p tcp -m tcp --dport 2135 -j ACCEPT
# GIIS
-A RH-Firewall-1-INPUT  -m state --state NEW -p tcp -m tcp --dport 2136 -j ACCEPT
# GUMS/VOMS
-A RH-Firewall-1-INPUT  -m state --state NEW -p tcp -m tcp --dport 8443 -j ACCEPT
# WebServices
-A RH-Firewall-1-INPUT  -m state --state NEW -p tcp -m tcp --dport 9443 -j ACCEPT
</pre></noautolink>

Second, we configure Globus to use the allowed inbound port range.  Do NOT do this by hand-editing the xinetd.d files in versions equal to or later than VDT 1.6.x (ITB 0.5.x), as these will not survive a vdt-control off and on cycle (the xinetd.d files are rewritten by such a cycle).   Instead, set them in the =vdt-local-setup.[c]sh= files.  
=$VDT_LOCATION/vdt/etc/vdt-local-setup.sh=
<noautolink><pre class="programlisting">
GLOBUS_TCP_SOURCE_RANGE=49000,49150
GLOBUS_TCP_PORT_RANGE=49000,49150
export GLOBUS_TCP_SOURCE_RANGE
export GLOBUS_TCP_PORT_RANGE
</pre>
=$VDT_LOCATION/vdt/etc/vdt-local-setup.csh=
<noautolink><pre class="programlisting">
setenv GLOBUS_TCP_SOURCE_RANGE 40000,49150
setenv GLOBUS_TCP_PORT_RANGE 49000,49150
</pre>
<!-- Old samples now commented out.  SCT
The following are shown for historical reference and for older versions that do not include vdt-control, although the local setup method will work in earlier versions also.

=/etc/xinetd.d/globus-gatekeeper=
<noautolink><pre class="programlisting">
  service globus-gatekeeper
  {
         socket_type = stream
         protocol = tcp
         wait = no
         user = root
         instances = UNLIMITED
         cps = 400 10
         server = $VDT_LOCATION/vdt/services/vdt-run-globus-gatekeeper.sh
         env    = GLOBUS_TCP_PORT_RANGE=40000,50000
         disable = no
  }
</pre></noautolink>

%IMPORTANT% <b>If</b> you restrict outbound connections (to the same port range, for example), you should also modify the gsiftp config file.

=/etc/xinetd.d/globus-gsiftp=
<pre class="programlisting">
service gsiftp
{
         socket_type = stream
         protocol = tcp
         wait = no
         user = root
         instances = UNLIMITED
         cps = 400 10
         server = $VDT_LOCATION/vdt/services/vdt-run-gsiftp.sh
         env += GLOBUS_TCP_SOURCE_RANGE=40000,50000
         disable = no
}
</pre>

Finally, add the port range(s) to =$VDT_LOCATION/globus/etc/globus-job-manager.conf= to ensure that it is picked up by other services by adding the following lines (omit the globus-tcp-source-range line if you do not restrict outbound connections):

<verbatim>
        -globus-tcp-port-range 40000,50000
</verbatim>

If you intend to use this installation also for grid client submissions, you should also set (=export= or =setenv=) =GLOBUS_TCP_PORT_RANGE=beginport,endport= and =GLOBUS_TCP_SOURCE_RANGE=beginport,endport= in =$VDT_LOCATION/globus/etc/globus-user-env.[c]sh=.

%NOTE% The pacman installer should set =$VDT_LOCATION=.
-->

If you limit the globus-related port range to certain values, it may be necessary to adjust the Linux ephemeral port range to avoid these values.  If this has not already been done, check the =/etc/sysctl.conf= for the following lines and insert if needed:

<pre class="programlisting">
# Limit ephemeral ports to avoid globus tcp port range
# See OSG CE install guide
net.ipv4.ip_local_port_range = 10240 39999
</pre>

Save and exit if edited.  Then, if you changed it, apply the changes by doing: =sysctl -p=


After editing the above files run the following commands
<pre class="screen">
# <b>/etc/rc.d/init.d/iptables restart </b>
  Flushing firewall rules:                                   [  OK  ]
  Setting chains to policy ACCEPT: filter                    [  OK  ]
  Unloading iptables modules:                                [  OK  ]
  Applying iptables firewall rules:                          [  OK  ]
# <b>/etc/rc.d/init.d/xinetd reload </b>
  Reloading configuration:                                   [  OK  ] 
</pre>

---++ Stateful firewalls

If you have a stateful firewall, you need to provide Globus with configuration in addition to GLOBUS_TCP_SOURCE_RANGE. (There is no need to do this if you do not have a stateful firewall. For instance, you do not need to do this for iptables.) You should also specify the GLOBUS_TCP_PORT_RANGE_STATE_FILE. This is also an environment variable, and it should be the name of a file where Globus can store information about what ports have been recently used. Wherever you set GLOBUS_TCP_SOURCE_RANGE, you should also set GLOBUS_TCP_PORT_RANGE_STATE_FILE, and it should be set to a consistent value so that different Globus services can share this information.

This file should not be on a shared filesystem (there is no need to share it, and Globus relies on reliable file locking to access the file). For example, one possibility is:

<pre>
GLOBUS_TCP_PORT_RANGE_STATE_FILE=/tmp/globus-port-range
</pre>

_Background:_ If you're curious about the need for this, sometimes a TCP connection is closed unexpectedly and a stateful firewall will not know that it has been closed. The operating system may allow programs to reuse the port number, but the firewall will not. This environment variable will point to a file where Globus keeps track of the most recently used port, and when Globus needs a new port, it will start searching sequentially from the last port. This will allow Globus components to avoid using the same ports too quickly, and hopefully avoid the situation where a stateful firewall will not allow a port to be reused. 

---++ More information about Globus firewall requirements

Please look on the [[http://www.globus.org/toolkit/security/firewalls/][Globus]] website for more information on firewalls.

%STOPINCLUDE%
%BR%

---++ *Comments*
%COMMENT{type="tableappend"}%

<!-- CONTENT MANAGEMENT PROJECT
############################################################################################################
 DEAR DOCUMENT OWNER
 ===================

 Thank you for claiming ownership for this document! Please fill in your FirstLast name here:
   * Local OWNER = StevenTimm

 Please define the document area, choose one of the defined areas from the next line
 DOC_AREA = (ComputeElement|Storage|VO|Security|User|Monitoring|General|Integration|Operations|Tier3)
   * Local DOC_AREA       = ComputeElement

 define the primary role the document serves, choose one of the defined roles from the next line
 DOC_ROLE = (EndUser|Student|Developer|SysAdmin|VOManager)
   * Local DOC_ROLE       = SysAdmin

 Please define the document type, choose one of the defined types from the next line
 DOC_TYPE = (Troubleshooting|Training|Installation|HowTo|Planning|Navigation|Knowledge)
   * Local DOC_TYPE       = Knowledge
  Please define if this document in general needs to be reviewed before release ( %YES% | %NO% )
   * Local INCLUDE_REVIEW = %YES%

 Please define if this document in general needs to be tested before release ( %YES% | %NO% )
   * Local INCLUDE_TEST   = %NO%

 change to %YES% once the document is ready to be reviewed and back to %NO% if that is not the case
   * Local REVIEW_READY   = %YES%


 change to %YES% only if the document has passed the review and the test (if applicable) and is ready for release
   * Local RELEASE_READY  = %YES%


 DEAR DOCUMENT REVIEWER
 ======================

 Thank for reviewing this document! Please fill in your FirstLast name here:
   * Local REVIEWER       = AlainRoy
 Please define the review status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local REVIEW_PASSED  = %YES%


############################################################################################################
-->

%META:TOPICMOVED{by="RobGardner" date="1192750453" from="Integration/ITB_0_7.ComputeElementFireWalls" to="Integration/ITB_0_7.ComputeElementFirewalls"}%
