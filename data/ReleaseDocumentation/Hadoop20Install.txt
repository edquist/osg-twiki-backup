%META:TOPICINFO{author="JeffDost" date="1309307017" format="1.1" reprev="1.13" version="1.13"}%
%META:TOPICPARENT{name="WebHome"}%
---+!! *<nop>%SPACEOUT{%TOPIC%}%*
%DOC_STATUS_TABLE%
%TOC{depth="2"}%

*Purpose*: The purpose of this document is to provide Hadoop based SE administrators the information on how to prepare, install and validate the SE.

%INCLUDE{"Documentation/DocumentationTeam/DocConventions" section="Header"}%
%INCLUDE{"Documentation/DocumentationTeam/DocConventions" section="CommandLine"}%

---+ Preparation
---++ Introduction

[[http://hadoop.apache.org/hdfs/][Hadoop Distributed File System]] (HDFS) is a scalable reliable distributed file system developed in the Apache project. It is based on map-reduce framework and design of the Google file system. The VDT distribution of Hadoop includes all components needed to operate a multi-terabyte storage site. Included are:

   * An [[https://sdm.lbl.gov/srm-wg/doc/SRM.v2.2.html][SRM interface]] for grid access; 
   * !GridFTP-HDFS as transport layer; and  
   * A FUSE interface for localized POSIX access.
   * Apache Hadoop.

The VDT packaging and distribution of Hadoop is based on YUM. All components are packaged as RPMs. Two YUM repositories are available: 
   * [[http://vdt.cs.wisc.edu/hadoop/stable/2.0/][Stable repository]] for wider deployments and production usage.
   * [[http://vdt.cs.wisc.edu/hadoop/stable/2.0/][Testing repository]] for limited deployments and pre-release evaluation.

The *stable YUM repository* is enabled by default through the *osg-hadoop-20 RPM*, and contains the *golden release* supported by OSG for LHC operations. 

---+++ VDT Downloads webpage

The VDT Downloads webpage is http://vdt.cs.wisc.edu/components/hadoop.html

---+++ VDT Release notes webpage

The VDT Release notes are available at http://vdt.cs.wisc.edu/hadoop/release-notes.html

---++ Architecture

This diagram shows the suggested topology and distribution of services at a Hadoop site. Major service components and modules which need to be deployed on the various nodes are listed. Please use this as a recommendation to prepare for the Hadoop deployment procedure at your site.

<img src="%ATTACHURLPATH%/Hadoop-site-architecture.png">

---+!!Engineering Considerations

Please read the [[Storage.HadoopUnderstanding][planning document]] to understand different components of the system. 

---+!!Help!
Total installation time, on an average, should not exceed 8 to 24 man-hours. If your site needs further assistance to help expedite, please email osg-storage@opensciencegrid.org and osg-hadoop@opensciencegrid.org.

---+ Installation Procedure

Main server components can be divided in 3 categories: 
   * HDFS core: Namenode, Datanode.
   * Grid extensions: !BeStMan2 SRM, Globus !GridFTP, Gratia probe, and Xrootd server plugin, etc.
   * HDFS auxiliary: Secondary Namenode, Hadoop Balancer.

Main client components are FUSE and Hadoop command line client.

---+ Initializer RPM

|Target |On all nodes:|

---++ Initializing the YUM Repository

Download and install the =osg-hadoop-20= RPM on *all* nodes. This will initialize the OSG YUM repository for Hadoop.

<pre class="rootscreen">
%UCL_PROMPT_ROOT% rpm -Uvh http://vdt.cs.wisc.edu/hadoop/osg-hadoop-20-2.el5.noarch.rpm
</pre>

This initializes YUM repository configuration in =/etc/yum.repos.d/osg-hadoop.repo=. 

---++ Choosing Stable or ITB Repository

%NOTE% %RED% *For Integration Testbed (ITB) Sites:* %ENDCOLOR% 
   * By default, *Stable Repository* is enabled (=enabled=1=) in the YUM configuration. Production sites should use the default setting.
   * ITB sites doing testing can enable the *Testing Repository* to fetch pre-release packages. 

Simply set =enabled=0= in =[hadoop]= section and =enabled=1= in =[hadoop-testing]= section of =/etc/yum.repos.d/osg-hadoop.repo=.

*YUM Repository types in /etc/yum.repos.d/osg-hadoop.repo*

<table>
<tr colspan=2>
<td>
*Production Sites:*
<pre class="file">
[hadoop]
... ...
enabled=1
... ...

[hadoop-testing]
... ...
enabled=0
... ...

[hadoop-unstable]
... ...
enabled=0
... ...
</pre>
</td>
<td>
*Integration Sites:*
<pre class="file">
[hadoop]
... ...
enabled=0
... ...

[hadoop-testing]
... ...
enabled=1
... ...

[hadoop-unstable]
... ...
enabled=0
... ...
</pre>
</td>
</tr>
</table>

---+ Installing Hadoop

---++ Prerequisites

%INCLUDE{"Storage/Hadoop20Installation" section="Prereqs"}%

---++ Installation

%INCLUDE{"Storage/Hadoop20Installation" section="Prep"}%

To install hadoop, run:

%INCLUDE{"Storage/Hadoop20Installation" section="Install"}%

---++ Configuration

%INCLUDE{"Storage/Hadoop20Installation" section="Config" TOC_SHIFT="+"}%

---++ Running Hadoop

%INCLUDE{"Storage/Hadoop20Installation" section="Running" TOC_SHIFT="+"}%

---++ Mounting fuse at boot time 

%INCLUDE{"Storage/Hadoop20Installation" section="Fuse"}%

---++ Validation

Get familiar with Hadoop commands.

<pre class="screen">
%UCL_PROMPT% hadoop -h
</pre>

An online guide is also available at [[http://hadoop.apache.org/common/docs/current/commands_manual.html][Apache Hadoop commands manual]].
You can use Hadoop commands to perform filesystem operations with more consistency.

Example, to look into the internal hadoop namespace:

<pre class="screen">
%UCL_PROMPT% hadoop fs -ls /
</pre>

Example, to adjust ownership of filesystem areas (there is usually no need to specify the mount itself =/mnt/hadoop= in Hadoop commands):

<pre class="rootscreen">
%UCL_PROMPT_ROOT% hadoop fs -chown -R cms:cms /cms
%UCL_PROMPT_ROOT% hadoop fs -chown -R sam:sam /dzero

%UCL_PROMPT_ROOT% hadoop fs -chown -R michaelthomas:cms /cms/store/user/michaelthomas
</pre>

Check HDFS and FUSE:
<pre class="screen">
%UCL_PROMPT% hadoop fs -ls /
%UCL_PROMPT% ls /mnt/hadoop
</pre>

---++ Creating VO and User filesystem areas

Prior to starting basic day-to-day operations, it is important to create dedicated areas for each VO and/or user. This is similar to user management in simple UNIX filesystems. 

%NOTE% Create (and maintain) usernames and groups with UIDs and GIDs on all nodes. These are maintained in basic system files such as =/etc/passwd= and =/etc/group=.

For clean HDFS operations and filesystem management:

(a) Create top-level VO subdirectories under =/mnt/hadoop=.

Example: 

<pre class="rootscreen">
%UCL_PROMPT_ROOT% mkdir /mnt/hadoop/cms
%UCL_PROMPT_ROOT% mkdir /mnt/hadoop/dzero
%UCL_PROMPT_ROOT% mkdir /mnt/hadoop/sbgrid
%UCL_PROMPT_ROOT% mkdir /mnt/hadoop/fermigrid
%UCL_PROMPT_ROOT% mkdir /mnt/hadoop/cmstest
%UCL_PROMPT_ROOT% mkdir /mnt/hadoop/osg
</pre>

(b) Create individual top-level user areas, under each VO area, as needed.

<pre class="rootscreen">
%UCL_PROMPT_ROOT% mkdir -p /mnt/hadoop/cms/store/user/tanyalevshina
%UCL_PROMPT_ROOT% mkdir -p /mnt/hadoop/cms/store/user/michaelthomas
%UCL_PROMPT_ROOT% mkdir -p /mnt/hadoop/cms/store/user/brianbockelman
%UCL_PROMPT_ROOT% mkdir -p /mnt/hadoop/cms/store/user/douglasstrain
%UCL_PROMPT_ROOT% mkdir -p /mnt/hadoop/cms/store/user/abhisheksinghrana
</pre>

(c) Adjust username:group ownership of each area. 

<pre class="rootscreen">
%UCL_PROMPT_ROOT% chown -R cms:cms /mnt/hadoop/cms
%UCL_PROMPT_ROOT% chown -R sam:sam /mnt/hadoop/dzero

%UCL_PROMPT_ROOT% chown -R michaelthomas:cms /mnt/hadoop/cms/store/user/michaelthomas
</pre>

---+ Installing !GridFTP

---++ Prerequisites

   1. %INCLUDE{"Storage/Hadoop20GridFTP" section="HadoopReq"}%
   1. %INCLUDE{"Storage/Hadoop20GridFTP" section="GumsReq"}%

%INCLUDE{"Storage/Hadoop20GridFTP" section="Prereqs"}%

---++ Installation

To install gridftp-hdfs server, run:

%INCLUDE{"Storage/Hadoop20GridFTP" section="Install"}%

---++ Configuration

%INCLUDE{"Storage/Hadoop20GridFTP" section="Config"}%

---++ Running !GridFTP 

%INCLUDE{"Storage/Hadoop20GridFTP" section="Running"}%

---++ Validation

<pre class="screen">
%UCL_PROMPT% globus-url-copy file:///home/user/testfile gsiftp://GRIDFTP.SERVER.FQDN:2811/mnt/hadoop/user/testfile
</pre>

---+ Installing !BeStMan2

---++ Prerequisites
   1. You must also have already installed and mounted Hadoop using FUSE.
   1.  A !GridFTP-HDFS server must also be installed, but this does not need to be on the same server as the !BeStMan2 server.  A larger site will prefer to have their !GridFTP and !BeStMan2 servers installed on separate hosts.

%INCLUDE{"Storage/Hadoop20SRM" section="Prereqs"}%

---++ Installation

%INCLUDE{"Storage/Hadoop20SRM" section="Install"}%

---++ Configuration

%INCLUDE{"Storage/Hadoop20SRM" section="Config1"}%

!BeStMan2 SRM uses the Hadoop FUSE mount to perform namespace operations, such as mkdir, rm, and ls.  As per the Hadoop install instructions, edit =/etc/sysconfig/hadoop= and run =service hadoop-firstboot start=.  It is *not* necessary (or even recommended) to start any hadoop services with =service hadoop start=.

%INCLUDE{"Storage/Hadoop20SRM" section="Config2"}%

---++ Running !BeStMan2

%INCLUDE{"Storage/Hadoop20SRM" section="Running"}%

---++ Validation

Check SRM server ping response:
<pre class="screen">
%UCL_PROMPT% srm-ping  srm://SRM.SERVER.FQDN:8443
</pre>

Check SRM based remote directory listing:
<pre class="screen">
%UCL_PROMPT% lcg-ls  -l -b -D srmv2 srm://SRM.SERVER.FQDN:8443/srm/v2/server?SFN=/mnt/hadoop
%UCL_PROMPT% lcg-ls  -l -b -D srmv2 srm://SRM.SERVER.FQDN:8443/srm/v2/server?SFN=/mnt/hadoop/user
</pre>

Check SRM copy using !GridFTP underneath:
<pre class="screen">
%UCL_PROMPT% lcg-cp -v -b -D srmv2 file:/home/user/testfile  srm://SRM.SERVER.FQDN:8443/srm/v2/server?SFN=/mnt/hadoop/user/testfile
</pre>

---+ Installing Gratia Probes

#DebugInfo
---+ Debugging Information

---++!!Debugging Procedure
What are the first things to check, step-by-step instructions to determine source of problem for this service

---++!!Caveats/Known Issues
Restrictions and/or work around for known issues 

---++!!References
---+++ Benchmarking

   * [[http://www.iop.org/EJ/article/1742-6596/180/1/012047/jpconf9_180_012047.pdf][Using Hadoop as a Grid Storage Element]], <i>Journal of Physics Conference Series, 2009</i>.
   * [[http://osg-docdb.opensciencegrid.org/0009/000911/001/Hadoop.pdf][Hadoop Distributed File System for the Grid]], <i>IEEE Nuclear Science Symposium, 2009</i>.

---+ *Comments*
%COMMENT{type="tableappend"}%

<!-- CONTENT MANAGEMENT PROJECT
############################################################################################################
 DEAR DOCUMENT OWNER
 ===================

 Thank you for claiming ownership for this document! Please fill in your FirstLast name here:
   * Local OWNER = JeffDost

 Please define the document area, choose one of the defined areas from the next line
 DOC_AREA = (ComputeElement|Storage|VO|Security|User|Monitoring|General|Integration|Operations|Tier3)
   * Local DOC_AREA       = Storage

 define the primary role the document serves, choose one of the defined roles from the next line
 DOC_ROLE = (EndUser|Student|Developer|SysAdmin|VOManager)
   * Local DOC_ROLE       = SysAdmin

 Please define the document type, choose one of the defined types from the next line
 DOC_TYPE = (Troubleshooting|Training|Installation|HowTo|Planning|Navigation|Knowledge)
   * Local DOC_TYPE       = Installation
  Please define if this document in general needs to be reviewed before release ( %YES% | %NO% )
   * Local INCLUDE_REVIEW = %YES%

 Please define if this document in general needs to be tested before release ( %YES% | %NO% )
   * Local INCLUDE_TEST   = %YES%

 change to %YES% once the document is ready to be reviewed and back to %NO% if that is not the case
   * Local REVIEW_READY   = %NO%

 change to %YES% once the document is ready to be tested and back to %NO% if that is not the case
   * Local TEST_READY     = %NO%

 change to %YES% only if the document has passed the review and the test (if applicable) and is ready for release
   * Local RELEASE_READY  = %NO%


 DEAR DOCUMENT REVIEWER
 ======================

 Thank for reviewing this document! Please fill in your FirstLast name here:
   * Local REVIEWER       =  TanyaLevshina
 Please define the review status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local REVIEW_PASSED  = %IN_PROGRESS%


 DEAR DOCUMENT TESTER
 ====================

 Thank for testing this document! Please fill in your FirstLast name here:
   * Local TESTER         = NehaSharma
 Please define the test status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local TEST_PASSED    = %IN_PROGRESS%
############################################################################################################
-->

%META:FILEATTACHMENT{name="Hadoop-site-architecture.png" attachment="Hadoop-site-architecture.png" attr="h" comment="" date="1306345934" path="Hadoop-site-architecture.png" size="23565" stream="Hadoop-site-architecture.png" tmpFilename="/usr/tmp/CGItemp37821" user="JeffDost" version="1"}%
