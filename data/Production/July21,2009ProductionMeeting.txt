%META:TOPICINFO{author="BurtHolzman" date="1248206431" format="1.1" version="1.12"}%
%META:TOPICPARENT{name="WeeklyProductionMeetings"}%
-- Main.DanFraser - 09 Jul 2009
---++ Action/Significant Items

---++ Attendees (to be updated after meeting):
   * Xin, Armen, Britta, Mats, Brian, Suchandra, Burt, Marco, Abhishek, Rob Q., Mine, Chander, Miron, Dan
---++ CMS (Burt)
   * Last week: 107 khour/day, 85% success.  CPU/wallclock at 45% (excluding FNAL skims: 56%).
   * STEP09 post-mortem details:
      * High-level summary: STEP09 went well. T0 performance good, might want more monitoring. T1 tape performance overall good (FZK and IN2P3 had downtimes), problems addressed at FNAL -- will use results to design pre-stage system.  T1 batch slots pledged met.  Analysis went well but error rates above 10% at 3 US sites (problems with data access)
      * Twiki: https://twiki.cern.ch/twiki/bin/view/CMS/Step09PostMortem
      * Overview talk: http://indico.cern.ch/getFile.py/access?contribId=2&sessionId=0&resId=0&materialId=slides&confId=56580
      * STEP09 analysis: http://indico.cern.ch/getFile.py/access?contribId=25&sessionId=11&resId=0&materialId=slides&confId=58153

---++ Atlas (Armen & Xin)

   * job statistics for last week. 
      * Last week production continued on all USATLAS sites, keeping 6k~7k jobs running all the time, with high success rate.
      * Gratia report: USATLAS ran 651K jobs, with CPU/Walltime ratio of 83%. 
      * PanDA world-wide production report (real jobs):
         * completed successfully 635K managed MC production, validation jobs
         * average  91K jobs per day
         * failed   40K  jobs
         * average efficiency: 94% for jobs and 96% for walltime

   * Site issues
         * BNL T1 is preparing to move all worker nodes to SLC5/64bit platform. At least 0.5 PB dCache pool disk space will be removed from the worker nodes, replaced by new dedicated storage with more space.  Testing is ongoing. 

   * condor-g issues
      * waiting for globus bug fix for a memory leak  
      * about to start the stress test on WISC condor pool, results expected in a couple of weeks. 


---++ LIGO (Britta)

*  Issues with LIGO voms server (07/19 -- 07/20)

* Condor Issue on submit host  osg-job  (07/19 -- 07/20)

* ITB validation: 
   * E@OSG 
      * 5 ITB sites validated, CIT_ITB_1 needs admin attention
   * BINARY INSPIRAL
      * FNAL_FERMIGRID_ITB, LIGO_CIT  validated
      * Problems at remaining 4 sites:

https://twiki.grid.iu.edu/bin/view/ReleaseDocumentation/OSG12LIGOComments#LBNL_DSD_ITB_grolsch_lbl_gov_Las


* Gratia Reports:

   * No LIGO metrics this week (used to be Monday morning)?
      * 13,960 jobs
      * 46,216 wall clock hours
      * CPU/WALL: 89.3
   * Last week's total usage: 3 users utilized 17 sites;
      * 9491 jobs total (8438 / 1053 = 88.9% success)
      * 34250.4 wall clock hours total (29988.9 / 4261.5 = 87.6% success);

---++ Integration (Suchandra)
   * Currently trying to finish testing
   * Most issues look like they're resolved
   * Waiting for vo validation results and documentation changes

---++ Site Coordination (Marco)


---++ Engagement (Mats)

10 users utilized 32 sites;


54606 jobs total (49690 / 4916 = 91.0% success);


206417.7 wall clock hours total (110519.6 / 95898.1 = 53.5% success);


Low wall clock success due to a user submitting jobs with too short wall time limit.
Because these were long jobs, we did not notice until the run had already claimed
a lot of resources.



---++ Metrics (Brian)

   * Gathering measurements for upcoming Metrics document, to be presented at the August 10 meeting.  If you're on this call and owe me measurements, please do not forget!  You will be getting at least 2 more emails.
   * After working with the Gratia team, we think we are moving through the backlog in the Gratia transfer collector.  FNAL is *still* > 1 week behind.
   * In the last 2 weeks, Engage has been able to start running on a large scale at Nebraska; they have been able to utilize up to 2,000 CPUs (limited by their submission infrastructure).  This makes a noticeable difference in the Engage VO  weekly hours for the last 100 days: http://t2.unl.edu/gratia/bar_graphs/facility_hours_bar_smry?vo=engage&span=604800&starttime=time.time()-100*86400 but not yet in the overall non-HEP VO monthly plots http://t2.unl.edu/gratia/xml/monthly_non_hep.  Hopefully, NYSGrid and/or DOSAR might want to someday also run at Firefly.

---++ Virtual Organizations Group (Abhishek)

   * OSG 1.2 pre-release validation by VOs -- ALICE, ATLAS, CDF, CMS, DES, Dzero, DOSAR, Engage, Fermilab-VO, LIGO, nanoHUB, SBGrid/NEBioGrid, and STAR are participating.
      * URL: https://twiki.grid.iu.edu/bin/view/ReleaseDocumentation/SiteValidationOSG12#VO_validation   
      * Dzero, DES, DOSAR, Engage-VO, Fermilab-VO, nanoHUB have successfully completed validation, and have officially given green flags toward OSG 1.2.
      * ATLAS and CMS are validating workflows on 1 site each. Work is in progress.
      * LIGO has succeeded on 2 sites; is in progress on 4 sites. Failures are being noted and worked upon.
      * STAR has succeeded on 1 site; is in progress on 2 sites.
      * ALICE is in progress on 1 site.
      * CDF has succeeded on 2 sites; is in progress on 3 sites.
      * SBGrid has succeeded on 2 sites; and !NEBioGrid on 0 sites so far.

---++ Grid Operations Center (Rob Q.)

---+++ This Week in Operations
   * We will be continuing to test contact information update reminders for OIM with select testers; expect release sometime soon. 
   * Root Cause Analysis of Top Level BDII with IP Move at the GOC [[https://twiki.grid.iu.edu/bin/view/Operations/BDIIRootCauseAnalysis][Link]] 

---+++ Future Operations Events
   * VORS Turn Down Scheduled for August 3rd - If you know anyone who uses VORS, please remind them. (Need LIGO Update)
   * August 6th and 7th - Site Administrators Meeting in Indianapolis -- Please register if you have not already done so!
   * September Machine Room Move in Bloomington September 19 2009 - All GOC Services in Bloomington are expected to be down. IUPUI will still be handling BDII traffic. GOC will attempt to install as many other services on an Indianapolis based server/VM as possible, especially other critical ones like !MyOSG?. 

---++ Security (Mine)