%META:TOPICINFO{author="BrittaDaudert" date="1274212180" format="1.1" version="1.8"}%
%META:TOPICPARENT{name="WeeklyProductionMeetings"}%
-- Main.DanFraser - 30 Apr 2010
---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings

---++ Action/Significant Items:
   * 

---++ Attendees:
   * (to be updated after the meeting) John, Chris, Mats, Xin, Armen, Britta, Rob E., Brian, Suchandra, Burt, Marco, Abhishek, Rob Q., Mine, Chander, Miron, Dan
 
---++ CMS (Burt)
   * Another excellent weekend of LHC running - again doubled integrated luminosity
   * Moved from 4x4 bunches to 6x6 bunches
      * Only 3x3 bunches were previously colliding
   * Job statistics for last week
      * 45 khours/day
      * 168759 Jobs/day
      * 93% success
   * Transfer statisics for last week
      * ~50 TB/day

---++ Atlas (Armen & Xin)

   * General production status
      * For quiet some time last week, USATLAS sites ran out of production jobs. That explained why the number of pilot jobs went up but the number of real jobs dropped. 
         Late last week May 2010 reprocessing campaign started. 
   * Job statistics for last week. 
      * Gratia report: USATLAS ran 2.5M jobs, with CPU/Walltime ratio of 74%. 
      * Panda world-wide production report (real jobs): 
         * completed successfully 679k managed MC production, validation and reprocessing jobs 
         * average 97K jobs per day
         * failed 120K jobs
         * average efficiency:  jobs  - 85%,  walltime - 96%
   * Data Transfer statistics for last week
      * BNL T1 data transfer rate was 150~200TB/day last week. 
   * Issues
      * Opportunistic SE usage for D0 : 

---++ LIGO (Britta, Rob E.)
--+++ Gratia Reports
   * This week's total usage: 5 users utilized 38 sites
      * 59792 jobs total (23165 / 36627 = 38.7% success)
      * 590568.1 wall clock hours total (460984.9 / 129583.3 = 78.1% success)
   * Last week's total usage: 5 users utilized 35 sites
      * 62680 jobs total (26174 / 36506 = 41.8% success);
      * 895682.0 wall clock hours total (672090.6 / 223591.4 = 75.0% success);

---+++ LIGO / E@H
   * Recent Average Credit (RAC):1,169,942.99571,  Last Week: 1,288,948.61025
   * E@H rank based on RAC: 2 (+-0)
   * E@H rank based on accumulated Credits: 4 (+-0) 

---+++LIGO/E@OSG
   * Troubleshooting s6 code on ITB cluster
   * RLS server move from ISI to Caltech - in progress
---++ OSG Operations (Rob Q.)


---+++ Operations Last Week 
      * Reliability/Availability Last Week of [[http://tinyurl.com/36v63tq][GOC Services]]
      * Reliability/Availability Last Week of [[http://tinyurl.com/33qdatk][Security Services]]
   * BDII Issues 
      * [[https://ticket.grid.iu.edu/goc/viewer?id=8530][Ticket]]
      * [[http://osggoc.blogspot.com/2010/05/scheduled-maintenance-is2gridiuedu-goc.html][Maintenance Announcement]]
   * !TWiki Issues on Friday
      * [[http://osggoc.blogspot.com/2010/05/osg-twiki-brief-outage.html][Notification One]]
      * [[http://osggoc.blogspot.com/2010/05/osg-twiki-brief-outage.html][Notification Two]]    
      * The TWiki experienced problems due to heavy load queries from the documentation team. We have asked them to suspend these queries while we investigate.
   * Meeting with FNAL Remedy, May 13th
      * FNAL has given the GOC a script for testing. Work will continue...

---+++ Operations This Week

   * BDII Issues 
      * [[https://ticket.grid.iu.edu/goc/viewer?id=8530][Ticket]]
      * [[http://osggoc.blogspot.com/2010/05/scheduled-maintenance-is2gridiuedu-goc.html][Maintenance Announcement]]
      * NSCD Bug Fix in place and is2 online (though not in RR) all weekend without any issues. 
         * We'd like to start running NSCD in "Paranoid" mode to prevent other reported issues in the near future. 
      * is2.grid.iu.edu will be returned to production at 2pm EDT today. 
         * There is now monitoring that to warn us if more than 10% of the resources drop out of either BDII. 
   * !TWiki 
      * Set up mirror non-production instance to allow docs group to do testing. 

---++ Engage (Mats, John, Chris)


---++ Integration (Suchandra)
   * Working on documentation efforts with Doc Team
   * Working on further ITB Robot enhancements / bringing up myproxy server

---++ Site Coordination (Marco)
Note that this report lists the currently active resources in OSG.
If a site is down or not reporting it will not be counted.
Therefore there may be fluctuations.
Each line has the current number and variation from last week in parenthesis.
You can find a table with current OSG and VDT versions at http://www.mwt2.org/~marco/myosgldr.php
   * Site update status (from !MyOSG as of today):
      * Most recent production version is OSG 1.2.9
      *       77 (-3) OSG 1.2.X resources (       9 are 1.2.9)
      *        6 (0) OSG 1.0.X resources (       1 are 1.0.6)
      *        7 (0) OSG 1.0.0 resources
      *        1 (0) OSG 0.8.0 resources
Minutes from last week site coordination meeting are available at SiteCoordination.SitesCoord100513 . Few key items:
   * special topic was Job workflows in OSG and presentations are available
   * OSG operation is providing special support to sites interested in deploying a local Gratia collector
      * some information will be dropped by the OSG collector (individual file transfers)
      * sites can query easily their data
      * central reporting is more efficient

---++ Metrics (Brian)


---++ Virtual Organizations Group (Abhishek)


---++ Security (Mine)