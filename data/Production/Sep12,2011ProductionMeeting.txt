%META:TOPICINFO{author="RobQ" date="1315936368" format="1.1" reprev="1.4" version="1.4"}%
%META:TOPICPARENT{name="WeeklyProductionMeetings"}%
-- Main.BrittaDaudert - 12 Sep 2011
---++ Action/Significant Items:
   * 

---++ Attendees:
   * (to be updated after the meeting) Mats, Xin, Armen, Britta, Robert E., Brian, Suchandra, Burt, Marco, Rob Q., Scott T., Mine, Chander, Dan
 
---++ CMS (Burt)


---++ Atlas (Armen & Xin)

   * General production status
      * 
   * Job statistics for last week.      
      * Gratia report: USATLAS ran 2.67M pilot jobs, with cpu/walltime ratio of 87% 
      * Real Jobs processed by US sites for last week, reported from PanDA monitor 
         * 960K 
   * Data Transfer statistics for last week
      * Data transfer rate was 300TB~530TB last week at BNL T1. 
   * Issues
      * Cancelled downtime still affects site availability calculation
         * GOC ticket https://ticket.grid.iu.edu/goc/10984
         * results need to be corrected, so that the monthly report won't be affected. 
         * GOC is helping trace it with SAM folks now. 

---++ LIGO (Britta, Robert E.)
   
---+++ Gratia Reports
   * No metrics report received this week

    | VO        |   Cores |     Njobs |     Delta |      Wall |      Delta | CpuToWall |     Delta | %Effi | Delta |
    | ligo        |       1 |   126,540 |    46,547 | 600,012.8 |    155,661 |      0.66 |      0.01 |    66 |     1|

---+++ LIGO/E@OSG

   * Recent Average Credit (RAC):734,416.17222, Last Week: 808,022.63851
   * E@H rank based on RAC: 2 (+-0) 
   * E@H rank based on accumulated Credits: 2 (+-0)

---+++LIGO/Pulsar Powerflux   
   * Monitoring 10GB data dags at 5 OSG sites via corral glidein service
      * Investigating error at UCSDT2: found faulty machine, issue resolved by system admin
      * Investigating hangup error at Purdue
   * Monitoring 50.000 job dag running via local glidein factory
      * Investigating dagman error: ERROR: Failed to connect to local queue manager
            * scheduler overloaded, changed condor configuration to ease load

---++ Grid Operations Center (Rob Q.)
---+++ Announcements
   * Rob and Scott at CERN, EGI Technical Forum 15-29/Sep (Geneva and Lyon, France)
      * Unless there is an emergency that requires our attendance Operations will not be in attendance at the next two Production Meetings.

---+++ Operations Last Week 
   * [[http://tinyurl.com/3k3lqjh][GOC Services Availability/Reliability]]
   * [[http://myosg.grid.iu.edu/miscstatus/index?datasource=status&count_sg_1=on&count_active=on&count_enabled=on][Current Status]]
   * ITB release, [[http://osggoc.blogspot.com/2011/09/goc-service-update-september-13th-at.html][release notes]] are available
   * Gratia slowness reported on GRATIA-OSG-PROD twice on Thurs 9/1 eventually traced to bad disk.  Disk was replaced, OK by afternoon of 9/2.
   * Massive power outage in San Diego Thursday 9/8 3:30 pm (PT) until around Friday 9/9 12 am (PT)
      * Radius spanned from Orange County down to Baja Californa, and east to Arizona.
      * Believed to be caused by a problem during a utility repair job in Yuma, AZ.
      * Our machines and equipment were brought back up around 10:00 am (PT) on Friday 9/9
         * No damage to hardware
      * The UCSD Factory was up and running again by Friday 9/9 10:30 am (PT)
      * Effects of outage on UCSD Factory
         * Only negative effect is new glideins cannot be submitted
         * Glideins already running on grid are not effected
         * User jobs running on grid are not effected and should complete normally
         * Glideins already running can continue to accept new user jobs until they reach their retire time
      * Attached below are plots of monitoring during outage from UCSD factory
         * note the frontend monitoring depends on the factory being up to accurately report, during the outage the number of jobs running did *not* go to zero.
         * [[https://twiki.grid.iu.edu/twiki/pub/Operations/Minutes2011September12/outage_cms.png][Graph of CMS Frontend during power cut.]]
   * ITB Factory machine has high load due to insufficient CPU

---+++ Operations This Week
   * Production release, [[http://osggoc.blogspot.com/2011/09/goc-service-update-september-13th-at.html][release notes]] are available
   * OIM will move to Bloomington, service will be unavailable for a short period during the move.
   * We expect a Middleware Release from VDT containing the Apache DoS patch. 
   * New VO Package Release with LBNE expected. 

---++ Engage (Mats, John)


---++ Integration (Suchandra)


---++ Site Coordination (Marco)


---++ Virtual Organizations Group (Chander)


---++ Security (Mine)

---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings
