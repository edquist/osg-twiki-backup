%META:TOPICINFO{author="XinZhao" date="1398797227" format="1.1" version="1.5"}%
%META:TOPICPARENT{name="WeeklyProductionMeetings"}%
---++ Coordinates
   * 4:00 PM Eastern (3:00 PM Central)
   * Phone: +1-866-740-1260, code 8266135 

---++ Announcements:

---++ Action/Significant Items: 
   * OSG PKI Host Cert Revocation Issue
      * GOC is informed that there was a long delay on CRLs updates
      * Inquiry about CRLs update was sent to DigiCert
      * DigiCert reports revoked host certs request were in the pending status
      * It was determined that a 2nd API was need to approve revocation requests
      * Revocation request in the "pending" state were manually approved by OSG RA via the online web interface
      * API is implemented and tested in ITB before releasing to production
      * API is released to production
      * A weekly check will be performed for any outstanding revocation request that may be stuck  in the "pending" state 
   * Gratia DB Outage

---++ Attendees:

---++ CMS (Tony)

---++ Atlas (Armen & Xin)

   * General production status.
      * 
   * Job statistics for last week.      
      * Gratia report: (gratia DB outage)
      * 1.8M real Jobs processed by US sites for last week, reported from the Atlas dashboard.
   * Data Transfer statistics for last week (Gratia DB outage)
   * BNL will have a downtime on May 6th, all day long.  

---++ Grid Operations Center (Scott T.)
---+++ Operations Last Week
   * [[http://tinyurl.com/ct2mfy6][GOC Services Availability/Reliability]]
   * [[http://myosg.grid.iu.edu/miscstatus/index?datasource=status&count_sg_1=on&count_active=on&count_enabled=on][Current Status]]
   * gratia issues prevent putting the hours/week plot here...
   * Grid Operations Center
      * Production release, [[http://osggoc.blogspot.com/2014/04/goc-service-update-tuesday-april-22nd.html][Release note]]
      * gratiaweb updates
      * TX housekeeping
      * OS updates with reboots.
   * !FermiGrid Ops
      * We had a disk fail on the OSG gratia database machine.  It was a raid10 mirror and within a couple of hours of that disk failing the mirrored disk start getting errors reading sectors on the disk.  This caused database corruption and we lost the filesystem.
      * We provisioned a new SLF6 mysql 5.1 machine and restored the database to it.  There were a few issues initially getting this setup to work but we did get that up by Thursday.  It became clear that there were performance issues and we tried tuning a few variables related to memory heap sizes but by Friday evening the database was backed up again.
      * The database group here at Fermilab is working with Mysql consultants at the RDX consulting company to optimize the performance so queries don't pile up as they're doing now.  We're hoping these guys are expert enough that we'll get fast results.
   * WMS Glide In Factory
      * Applied Tony's patch to fix HTCondorCE support for glideinWMS v3_2_4 on GOC-ITB, confirmed it works.
  
---++ Operations This Week
   * Fifth Tuesday, special release. [[http://osggoc.blogspot.com/2014/04/goc-service-update-tuesday-april-29th.html][Release note]]
      * Version update for oasis-replica (One of three strata-1)
   * Gratiaweb currently running single instance. Will return redundant instances in coordination with FNAL. Gratiaweb-itb is shutdown.

---++ Campus Infrastructures Community (Rob G)


---++ Software (Tim C.)


---++ Release (Tim T.)

---++ User Support (Chander, Mats)

---++ Security (Mine)

---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings




-- Main.ScottTeige - 25 Feb 2014





-- Main.RobQ - 25 Feb 2014