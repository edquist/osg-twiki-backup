%META:TOPICINFO{author="AbhishekSinghRana" date="1262726889" format="1.1" reprev="1.6" version="1.6"}%
%META:TOPICPARENT{name="WeeklyProductionMeetings"}%
-- Main.BrittaDaudert - 04 Jan 2010
---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings

---++ Action/Significant Items:

---++ Attendees:
   * 
 
---++ CMS (Burt)
   * CRL bug affected UCSD and Florida
      - Somehow some CRLs became zero-length on two different CMS sites.  CRL update then does not update those CRLs anymore.
   * LIGO jobs filled $OSG_DATA at Florida; LIGO user was informed.
   * Computing: 84 khour/day, 95% success. CPU/wallclock at 68%.
   * Storage: 276 TB xfer (T1), 42 TB (others)
   * OSG: Nearly all at 1.2 (only Rutgers and OSU @ 1.0)
   * Non-CMS/CDF preemption issue @ MIT_CMS: second suggested fix not yet implemented at MIT.
   * D0 opportunistic storage -- no recruits yet (could only make the tail end of the T2 mtg today).

---++ Atlas (Armen & Xin)

   * General production status
      * During the last two weeks USATLAS production was quite stable at the level of 8K running jobs. Reprocessing was finished by the end of 2009, as planned. BNL T1 processed ~50% of all jobs.  The reprocessing jobs are short in CPU but long in stage-in and stage-out, making cpu/walltime ratio lower, reflected in the following job stats. 
   * Job statistics for last two weeks. 
      * Gratia report: USATLAS ran 2.9M jobs, with CPU/Walltime ratio of 31 for the last week of 2009, and 81% for the first week of 2010. 
      * Panda world-wide production report (real jobs): 
         * completed successfully 2M managed MC production, validation and reprocessing jobs 
         * average 291K jobs per day
         * failed 226K jobs
         * average efficiency:  jobs  - 89%,  walltime - 90%       
   * Data Transfer statistics for last week
      * Transfer rate stays the same as previous weeks. BNL T1 transferred ~75 TB/day data last week, with peak at 150 TB/day.  
   * Issues and GOC Tickets
      * GOC ticket 7772: Issues with WLCG BDII periodically loses information about some USATLAS Tier2 sites. Got the new ldap query from Burt, running it now on ganglia.
      * Opening more USATLAS T2 sites to D0 VO as opportunistic storage:  We will try to contact Joel from D0, figuring out details about configuration etc.

---++ LIGO (Britta)

   * Gratia reports:
   * Current week's total usage: 4 users utilized 30 sites;
      * 2424 jobs total (2372 / 52 = 97.9% success);
      * 30.4 wall clock hours total (25.7 / 4.7 = 84.5% success);
   * Previous week's total usage: 4 users utilized 33 sites;
      * 2641 jobs total (2571 / 70 = 97.3% success);
      * 87.8 wall clock hours total (64.7 / 23.1 = 73.7% success);
 
   * E@H reports
      * Recent Average Credit (RAC): 170,585.60004
      * E@H rank based on RAC: 10 (-7)
      * E@H rank based on accumulated Credits: 11 (+0)
   
   * Robert is working on code changes required to expand to Fermilab sites and Sprace

 
---+++ Binary Inspiral
    * 3 day test work-flow on Firefly: Gap in data error

---++ Engage (John, Chris)


---++ Integration (Suchandra)
   * OSG 1.2.5 release delayed due to last minute issues
   * Considering making an interim release of xrootd/bestman components for ATLAS
  
 
---++ Site Coordination (Marco)
Note that this report lists the currently active resources in OSG.
If a site is down or not reporting it will not be counted.
Therefore there may be fluctuations.
   * Site update status (from !MyOSG as of today):
      * Most recent production version is OSG 1.2.4
      *       58 OSG 1.2.X resources (      23 are 1.2.4)
      *       10 OSG 1.0.X resources (       0 are 1.0.5)
      *       19 OSG 1.0.0 resources
      *        2 OSG 0.8.0 resources
         * OU_OCHEP_SWT2, tier2-01.ochep.ou.edu , Contact: Horst Severini
         * UIC_PHYSICS mstr1.cluster.phy.uic.edu , Contact: John Wolosuk

---++ Metrics (Brian)

---++ Grid Operations Center (Rob Q.)


---++ Virtual Organizations Group (Abhishek)

---+++ VOs with High Activity

   * D0 MC reported good production in mid-Dec, followed by a drop. 
      * Workload very low in past 2 weeks; 3 M, 0.5 M Evts/week.
      * Nearly 11.4 M Evts in mid of Dec'09; was new 6-month peak; OSG view was 9 M Evts; discrepancy was resolved.
      * MIT issue fixed, as reported by D0 in late Dec'09.
      * [Carried over items:
         * ATLAS: Need for more SEs.
            * D0 can benefit from more opportunistic SEs at ATLAS T2 sites. 
            * Currently 2 SEs: MSU, MWT2-IU.
         * CMS: CE's rate of preemption. 
            * Possibly, MIT T2 applied the fix to CE. (Burt may have more accurate status).
            * Dan Bradley's solution: use <u> !LastHeardFrom </u> instead of the more popular <u> !CurrentTime </u>.
            * https://ticket.grid.iu.edu/goc/viewer?id=7814
         * CMS: Need for more SEs.
            * D0 can benefit from more opportunistic SEs at CMS T2 sites. 
            * Currently 3 SEs: Purdue, UCSD, UNL]
           
   * SBGrid/NEBioGrid 
      * Meeting and plan discussed on Dec 16 '09.
      * Immediate goal: 
         * To increase job efficiency at moderate job volume. Then, increase job volume. 
         * Target sustained peak 3000 jobs running simultaneously. Increase to 6000 later. Target 1-2 times jobs queued as running. 
      * Full details: https://twiki.grid.iu.edu/bin/view/VirtualOrganizations/SBGrid_NEBioGrid_OSG  
      * Immediate issue: Possibly, SBGrid submit infrastructure is co-located on same hardware as CE/Gatekeeper headnode. 
      * Current status:
         * ~200 simultaneous jobs. 
         * Working with Mats to resolve OSG-MM issues.
         * New version of MM v0.8 is now being installed, rank calculation to be tweaked.
      
   * GEANT4
      * Biannual EGEE-based exercise ran on OSG in Dec'09. 
      * Scale was low; more analysis and report later this month. 
      * Problem: Discrepancy in wasted wall hours due to Pilots.
         * 50% in OSG resource-view, 0% (full success) in Geant4-view.
         * Reason likely to be OSG-side issue: Exit-code discrepancy due to Pilots.

   * CDF 
      * Successfully upgraded new portal to !GlideinWMS; working well.

   * Fermi-VO
      * Communication channel in Dec'09 site upgrade; not discussed beforehand.
   
---+++ VOs with Limited Activity
      
   * !GridUNESP / DOSAR
      * Brought up !GridUNESP as community grid VO.
      * Infrastructure configured with OSG software stack (site side, then VO side).
      * Charter for !GridUNESP made public.  
      * Experiences: https://twiki.grid.iu.edu/bin/view/VirtualOrganizations/DOSAR_GridUNESP_OSG
      * First !GridUNESP researchers submitted MPI jobs through full infrastructure, running on OSG.

         
   * !IceCube
      * Proof of principle completed in Oct'09. Limited data-access model.
      * Total usage across 6 sites; 4,000 wall hours; 600 jobs at 50% efficiency.
      * Progress in Oct-Dec'09 slow; !IceCube team was on travel to South Pole.
      * Work restarted in Dec'09 to integrate HTTP cache / Squid for data staging.
 
---++ Security (Mine)
