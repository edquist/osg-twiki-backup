%META:TOPICINFO{author="AbhishekSinghRana" date="1265144360" format="1.1" version="1.8"}%
%META:TOPICPARENT{name="WeeklyProductionMeetings"}%
-- Main.DanFraser - 19 Jan 2010
---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings

---++ Action/Significant Items:
   * 

---++ Attendees:
   * (to be updated after the meeting) John, Chris, Mats, Xin, Armen, Britta, Rob E., Brian, Suchandra, Burt, Marco, Abhishek, Rob Q., Mine, Chander, Miron, Dan
 
---++ CMS (Burt)
   *  Computing: 100 khour/day, 90% success. CPU/wallclock at 59% (excluding T1: 68%).
   * Storage: 1.8 PB xfer (T1), 75 TB (others)
   * Continued to run intense skim runs at the Tier 1 to test dCache/network congestion issues.
   * LIGO seems to be running full-out at the CMS T1 (slots are limited by Condor 7.3 bug; we hope to upgrade to 7.4 soon).

---++ Atlas (Armen & Xin)


---++ LIGO (Britta, Rob E.)

 * Gratia reports:
   * Last week's total usage: 5 users utilized 34 sites
     * 91942 jobs total (63184 / 28758 = 68.7% success)
     * 854231.0 wall clock hours total (700689.1 / 153541.8 = 82.0% success)
   * Last week's total usage: 5 users utilized 38 sites;
     * 74974 jobs total (51987 / 22987 = 69.3% success);
     * 640336.3 wall clock hours total (593458.9 / 46877.4 = 92.7% success);
 
   * E@H reports
      * Recent Average Credit (RAC): 1,670,211.09593
      * E@H rank based on RAC: 3 (+0)
      * E@H rank based on accumulated Credits: 10 (+0)
 
   * Robert is working on code changes required to expand to Fermilab sites and Sprace

 
---+++ Binary Inspiral
   * Work-flow comparison:
      * 1) Firefly
      * 2) LIGO_CIT  (local ITB cluster)
      * 3) ldas-grid (local LIGO cluster)
   * Compared queue times and execution  times of different job types in the work-flow
   * Summary and plots can be found here:  http://www.ligo.caltech.edu/~bdaudert/INSPIRAL

   * Testing clustering capabilities of Pegasus

---++ Engage (Mats, John, Chris)

10 users utilized 37 sites;

35227 jobs total (29198 / 6029 = 82.9% success);

148639.9 wall clock hours total (133903.4 / 14736.6 = 90.1% success);

No production issues this week. We will not be able to make the call this week.


---++ Integration (Suchandra)


---++ Site Coordination (Marco)


---++ Metrics (Brian)


---++ Grid Operations Center (Rob Q.)

---+++ Operations Last Week 
   * Last week's availability metrics
      * [[http://tinyurl.com/yl6pb7a][GOC Services: BDII, MyOSG, RSV Collector, OSG Display]] 
      * [[http://tinyurl.com/yjkchjp][GOC hosted Security services managed by OSG security team]]
   * *[[http://osggoc.blogspot.com/2010/01/goc-service-update-tuesday-january-26th.html][Production release completed on Tuesday - Jan 26th 14:00 UTC]]* -- there was no known outage.
   * [[http://osggoc.blogspot.com/2010/01/new-vo-package-available.html][VO package v30 released]] -- change in ordering requested by cdf and addition of grid unesp
   * [[http://osggoc.blogspot.com/2010/01/myosg-url-registration.html][MyOSG URL usage registration]] -- GOC requested MyOSG XML users to register URLs they are using so those users could be contacted to ensure continued success in use following update releases.
   * [[http://osggoc.blogspot.com/2010/01/osg-126-release-announcement.html][OSG 1.2.6]] released last week
   * GOC-GGUS ticket exchange was successfully moved to using a web-service based ticket exchange system.
      * GOC also attempting to setup prototype exchange with RT ticketing system (ATLAS ticket system)

---+++ Operations This Week
   * *GOC Service ITB release Tuesday - Feb 2nd 14:00 UTC* 
   * Continue new web service based GOC-FNAL ticket exchange work
      * Continue discussion re: web service based ATLAS RT ticket exchange as well
   * Continue final testing of Debian repository deployment for CA distribution (requested by LIGO VO), then announce release.
   * GOC working on collating VOMS monitoring metric results into a table, possibly with limited history ([[https://ticket.grid.iu.edu/goc/viewer?id=7983][related ticket]])
   * Minor update to GIP validator tool - necessitates changes to way results are parsed by MyOSG's GIP Validation results view
   * SAMS broker outages - I've gotten word directly from WLCG that all availability and reliability will be recalculated due to these outages.

---+++ Future Events
   * RSV Collector upgrade to be done on Feb 9th (production release Tuesday); ITB collector already successfully upgraded to 1.06.14 two weeks ago.
   * New member of the Support Group starting Feb 15th. 


---++ Virtual Organizations Group (Abhishek)

   * D0 MC production picking up; remains low. Last week's average 3 M Evts/week.

   * CDF production running smoothly; opportunistic expansion plan awaited.
   
   * SBGrid 
      * Provided with detailed Gratia logs of sites that give high failures. Investigation goal is to improve overall job success rate at sustained moderate scale (1000-1500 jobs); results awaited. 
      * Last week's average: Successfully used 70,000 wall hours. 35,000 hours/day at 28% wall efficiency; 40,000 jobs in week at 34% efficiency.    
      * SBGrid trying to find a good storage solution. Suggestion from ATLAS site at UChicago is PCache, an unsupported client-side tool; OSG Storage is open to add it as a partly supported tool in Operations-toolkit if needed.
      * SBGrid investigating PANDA WMS. Meeting between SBGrid and BNL teams today. Abhishek dialing in.

   * ALICE to make NERSC site production-ready on small scale. Work in progress. 

   * !GlueX's site UCONN_OSG is not visible in !ReSS. Available in RSV. To remedy, Richard/GlueX working to resolve system-level !CentOS 5 issues. Aim is to make CE more stable before fixing CEMon/ReSS.
 
   * !CompBioGrid's site issue with firewall on site upgrade from OSG 1.2.3 to 1.2.4; investigation currently on hold; trying to re-install and evaluate if issue is resolved by itself. VDT team in loop. Ticket -- https://ticket.grid.iu.edu/goc/viewer?id=7870      
   
   * !IceCube evaluating HTTP cache/Squid for data staging; had phone meeting last week to expedite work.


---++ Security (Mine)