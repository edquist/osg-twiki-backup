%META:TOPICINFO{author="BrianBockelman" date="1264540092" format="1.1" version="1.10"}%
%META:TOPICPARENT{name="WeeklyProductionMeetings"}%
-- Main.DanFraser - 19 Jan 2010
---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings

---++ Action/Significant Items:
   * 

---++ Attendees:
   * (to be updated after the meeting) John, Chris, Mats, Xin, Armen, Britta, Rob E., Brian, Suchandra, Burt, Marco, Abhishek, Rob Q., Mine, Chander, Miron, Dan
 
---++ CMS (Burt)
   * Computing: 175 khour/day, 88% success.  CPU/wallclock at 47% (excluding T1: 68%).
   * Storage: 2.9 PB xfer (T1), 65 TB (others)
   * Continue to run intense skim runs at the Tier 1 to test dCache/network congestion issues.
   * Had to discontinue LIGO support at MIT_CMS.  Their workflow is too much I/O for the NFS configuration there.  (Good news: I did see roughly 3k concurrent LIGO jobs over the weekend at the FNAL T1).

---++ Atlas (Armen & Xin)

   * General production status
      * During the last week USATLAS production was quite stable at the level of 8~10K running jobs, mainly MC jobs. Starting this weekend, we run out of real jobs, so number of running jobs/pilots drops a lot. 
   * Job statistics for last week. 
      * Gratia report: USATLAS ran 1.8M jobs, with CPU/Walltime ratio of 81%. 
      * Panda world-wide production report (real jobs): 
         * completed successfully 600K managed MC production, validation and reprocessing jobs 
         * average 84K jobs per day
         * failed 64K jobs
         * average efficiency:  jobs  - 90%,  walltime - 96%       
   * Data Transfer statistics for last week
      * Transfer rate stays the same as previous weeks. BNL T1 transferred ~75 TB/day data last week, with peak at 150 TB/day.  
   * USATLAS sites are asked to finish the upgrade to SL5 and OSG 1.2 by the end of January. 
   * Issues and GOC Tickets
      * GOC ticket 7772: Issues with WLCG BDII periodically loses information about some USATLAS Tier2 sites
      * Opening more USATLAS T2 sites to D0 VO as opportunistic storage:  no update this week. 

---++ LIGO (Britta, Rob E.)

 * Gratia reports:
   * Current week's total usage: 5 users utilized 38 sites;
     * 74974 jobs total (51987 / 22987 = 69.3% success);
     * 640336.3 wall clock hours total (593458.9 / 46877.4 = 92.7% success);
   * Previous week's total usage: 5 users utilized 38 sites;
     * 39880 jobs total (34908 / 4972 = 87.5% success);
     * 395944.2 wall clock hours total (383453.3 / 12490.9 = 96.8% success);

   * E@H reports
      * 90k cpu hours / day on 28 resources
      * Recent Average Credit (RAC):  1.8M,  Last week: 992k
      * E@H rank based on RAC: 3 (+-0)
      * E@H rank based on accumulated Credits: 10 (+1)
 
   * Robert is working on code changes required to expand to Fermilab sites and Sprace

 
---+++ Binary Inspiral
    
      * Gap in data error ticket remains open

      * Test run on one week of data succeeded  on Firefly
      
      * Two month of LIGO data transferred into Firefly SE


---++ Engage (Mats, John, Chris)


9 users utilized 39 sites;

38278 jobs total (33574 / 4704 = 87.7% success);

175688.0 wall clock hours total (165122.9 / 10565.1 = 94.0% success);

Normal week. We have more jobs in the queue, but they require either long wall time or a lot of memory which makes it more difficult to match. 

What is the status of the RSV ReSS probe?


---++ Integration (Suchandra)
   * ITB 1.1.17 / OSG 1.2.6 testing still ongoing
      * ATLAS VO testing completed successfully
      * Discovered an issue with gip 1.1.8 , investigating currently
      * Otherwise all ready for a release   
   * ITB / Panda framework
      * BNL and UC_ITB up
      * Still resolving issues on LBNL and VDT site

---++ Site Coordination (Marco)


---++ Metrics (Brian)
   * We've been working with Dan on the deployment of new Gratia.  We would like to contact sites for two things, below.  Instructions and tickets verbage are being prepared for both.
      * (Medium priority) Point to the correct Gratia collector hostname.
      * (Low priority) Upgrade the Gratia client library.
   * Consistency work is ongoing; John Weigand currently holds the token on this as he is investigating the best way to upload Gratia data to WLCG.  Basically, we want to make sure we can automate consistency checks from end-to-end.  Right now, there's no "right" or "wrong" configuration, just a configuration.
      * Need feedback from Burt and Xin because the changes as proposed would affect rows in the T1 WLCG reports.  Need/want explicit check-off.
   * We (maybe just I?) need to understand the mechanism for getting OSG Operations to stay on top of both consistency and non-reporting sites.
   * Considering some options for further Gratia work.

---++ Grid Operations Center (Rob Q.)
---+++ Operations Last Week 
   * Last week's availability metrics
      * [[http://tinyurl.com/yek7kob][GOC Services: BDII, MyOSG, RSV Collector, OSG Display]] - NOTE: High Level OSG Display added to monitoring per Brian Bockelman's request, SLA expected soon.
      * [[http://tinyurl.com/ybp3w7z][GOC hosted Security services managed by OSG security team]]
   * Relevant to only WLCG Interop sites: SAM team indicated a couple more instances of a broker problem.

---+++ Operations This Week
   * *[[http://osggoc.blogspot.com/2010/01/goc-service-update-tuesday-january-26th.html][Production release Tuesday - Jan 26th 14:00 UTC]]*
      * MyOSG 1.14, Ticket 1.13, OIM 2.13 
   * *GOC-FNAL ticket exchange*: A meeting was held this morning between the GOC and Fermilab/Fermigrid/CMS about progressing with testing on web service ticket exchange. A few technical hurdles need to be overcome before testing web services can continue. 
      * GOC will also attempt to setup prototype exchange with RT ticketing system, possibly development ATLAS ticket system
   * Next [[http://indico.fnal.gov/conferenceDisplay.py?confId=2871][Registration for OSG All-Hands meeting (March 8th - 11th @ FNAL) is now open]] - hope to see you all there!
   * vo package release for change in ordering requested by cdf and addition of grid unesp

---+++ Future Events
   * RSV Collector upgrade coming up in the next couple of weeks -- waiting for VDT to release change to their production cache; ITB collector already successfully upgraded to 1.06.14 last week.
   * Migration from error-prone email-based ticket exchange to new TicketExchanger (TX) based GOC-GGUS setup to likely be released to production on Feb 3rd assuming all tests are successful - GOC is working with GGUS to ensure smooth transition

---+++ Tickets and WLCG
   * [[https://ticket.grid.iu.edu/goc/viewer?id=7772][7772]] 
      * Number of tests VS the OSG BDII: 124168
      * Number of failures VS OSG BDII: 53 (Excluding the WT2 Scheduled Maintenance)
      * Percentage of Failures: 0.04%
      * Number of tests VS the EGEE BDII: 124168
      * Number of failures VS EGEE BDII: 113 (Excluding the WT2 Scheduled Maintenance)
      * Percentage of Failures: 0.09%

   * [[https://ticket.grid.iu.edu/goc/viewer?id=8001][8001]] - ATLAS VO member unable to dq2-get dataset from BNL-OSG2_USERDISK
   * [[https://ticket.grid.iu.edu/goc/viewer?id=7980][7980]] - Remote and local file sizes do not match for an ESD file on BNL
   * Recalculation of Availability Numbers for CMS Tier 1


---++ Virtual Organizations Group (Abhishek)

   * D0 MC production remains low. Last week's average 3 M Evts/week.

   * CDF production running smoothly; opportunistic expansion plan awaited.
   
   * SBGrid was provided with detailed Gratia logs of sites that were giving high failures. Investigation goal is to improve overall job success rate at sustained moderate scale (1000-1500 jobs); results awaited. BNL site-specific ticket - https://ticket.grid.iu.edu/goc/viewer?id=7748

   * ALICE to make NERSC site production-ready (on small scale). Work in progress. 

   * !GlueX's site to follow similar !ReSS advertisement procedure as !FermiGrid. Richard/GlueX expects to resolve system-level !CentOS 5 issues, to make CE more stable before fixing CEMon/ReSS.
 
   * !CompBioGrid's site issue with firewall on site upgrade from OSG 1.2.3 to 1.2.4; investigation ongoing with VDT team. Ticket -- https://ticket.grid.iu.edu/goc/viewer?id=7870

---++ Security (Mine)