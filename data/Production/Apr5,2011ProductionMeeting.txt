%META:TOPICINFO{author="RobQ" date="1302030109" format="1.1" version="1.4"}%
%META:TOPICPARENT{name="WeeklyProductionMeetings"}%
-- Main.DanFraser - 10 Mar 2011
---++ Action/Significant Items:
   * 

---++ Attendees:
   * (to be updated after the meeting) Mats, Xin, Armen, Britta, Robert E., Brian, Suchandra, Burt, Marco, Rob Q., Scott T., Mine, Chander, Dan
 
---++ CMS (Burt)


---++ Atlas (Armen & Xin)

   * General production status
      * LHC is recovering from the technical stop, and preparing for the collisions (no collisions since last Monday). 
      * US ATLAS production level still not very high. Waiting for new MC tasks to be defined, as well as reprocessing of cosmic ray data, which may start today. 
   * Job statistics for last week. 
      * Gratia report: USATLAS ran 3.2M jobs, with CPU/Walltime ratio of 74%. 
      * Panda world-wide production report (real jobs): 
         * completed 619K managed group, MC production, validation and reprocessing jobs 
         * average 88K jobs per day
         * failed 72K jobs 
         * average efficiency:  jobs - 90%, walltime - 95%
   * Data Transfer statistics for last week
      * BNL T1 data transfer rate was around 200~400TB/day in last week. 
   * Issues

---++ LIGO (Britta, Robert E.)

---+++ Gratia Reports
   * Last week's total usage: 3 users utilized 26 sites
      * 34232 jobs total (32649 / 1583 = 95.4% success)
      * 421768.8 wall clock hours total (415895.9 / 5872.9 = 98.6% success)
   * This week's total usage: 3 users utilized 32 sites
      * 26466 jobs total (20288 / 6178 = 76.7% success)
      * 284804.2 wall clock hours total (244272.9 / 40531.2 = 85.8% success)


---+++ LIGO / E@OSG
   * Recent Average Credit (RAC): 461,452.67363, Last Week: 653,802.55289 
   * E@H rank based on RAC: 3 (+-0)
   * E@H rank based on accumulated credits: 3 (+-0)


---+++ LIGO / INSPIRAL
   * transferred 1 week of data (0.14) TB to Nebraska
   * work-flow submitted

---+++ LIGO/PULSAR
   * running two large work-flows (>10000 jobs) via GlideinWMS on OSG (4 sites, pre staged data)

---++ Grid Operations Center (Rob Q.)

---+++ Operations Last Week 
   * [[http://tinyurl.com/27fknc6][GOC Services Availability/Reliability]]
   * [[http://myosg.grid.iu.edu/miscstatus/index?datasource=status&count_sg_1=on&count_active=on&count_enabled=on][Current Status]]
   *  Fifth Tuesday, no release.
   * New VO Package to production
      * CSIU Addition, CMS Requested Change, and Engage Group Add
   * Rebooted ReSS servers, everything went well
   * WMS Glide In Factory
      * New Frontend Status
         * NWICG (Stephen Harrel - Purdue) - Is now set up to submit glideins to 20 entries. These have not yet been used.
      * Derek the HCC frontend admin at UNL reported that numbers are not correctly adding up in the daily analyze_entries reports e-mail we send to our frontends.  Igor found wrote a patch and submitted it to glideinWMS.  It was due to inadequate exception handling when parsing the condor logs
      * Discovered an edge case when glideins are preempted on sites they may incorrectly be reported as failing to start even though they have run jobs.  GlideinWMS development team was notified and Burt and Parag are troubleshooting it.

---+++ Operations This Week
   * DOEGrids CA Services Down Friday - [[http://osggoc.blogspot.com/2011/04/doegrids-services-outage-update-goc.html][Notification]]
      * Services were restored late Friday evening (about 22:30 EST). OSG was not notified until Monday that this service was stable. [[http://osggoc.blogspot.com/2011/04/doegrids-services-outage-update-goc_04.html][Notification]]
      * Please resubmit any cert requests made during this period.
      * Mike Helm wants to perform a maintenance this week and perhaps a subsequent regular scheduled maintenance window.
   * ITB Services release Tuesday
      * State Optional in OIM
      * MyOSG / Gip Validator Consolidator
      * Made changes to the top level wlcg bdii monitor script so that BDII entries are loaded one at a time instead of all at once in order to prevent timeout issue caused during low throughput events of IU network.
   * BDII at is4.grid.iu.edu was reinstalled with a 32-bit OS. 
      * Our testing shows the seg faults have gone away, however we will watch closely when this is returned to RR next Tuesday. 
   * All services to be moved outside IU institutional firewall.
      * Testing has proven that the institutional firewall substantially slows service.
   * Gratia and !ReSS (Represented by !FermiGrid Ops)
      * Short network maintenance today, HA services will mean no effect.

---++ Engage (Mats, John)


---++ Integration (Suchandra)


---++ Site Coordination (Marco)


---++ Virtual Organizations Group (Chander)


---++ Security (Mine)

---++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Production/WeeklyProductionMeetings