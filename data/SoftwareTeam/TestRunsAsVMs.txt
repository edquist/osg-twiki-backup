%META:TOPICINFO{author="BrianLin" date="1386188225" format="1.1" reprev="1.17" version="1.17"}%
%META:TOPICPARENT{name="TestingHome"}%
---+ Running Tests as VM Jobs

This page is my (cat) collected notes and ideas about running osg-test runs as VM jobs, either locally (e.g., CHTC) or in OSG.


---++ Using VM Universe in HTCondor

For HTCondor 8.0, the documentation for VM universe is in [[http://research.cs.wisc.edu/htcondor/manual/v8.0/2_11Virtual_Machine.html][section 2.11]] of [[http://research.cs.wisc.edu/htcondor/manual/v8.0/ the manual]].

Some quick notes:

   * =universe = vm=
   * =executable= is just a label
   * Omit =input=, =output=, and =error=, as they are not used and will cause submit failures
   * Must select a =vm_type= of =vmware=, =xen=, or =kvm=


---++ Using VM Universe in CHTC

The only VM universe support in CHTC was using a now-archaic version of [[http://www.vmware.com VMware]]; this was set up in support of the Thomas Jahns lab. Essentially, in July 2013, there is no current support. However, the CHTC infrastructure team is interested in adding real support for at least kvm.

On 3 July 2013, Nate Yehle proposed working with us to add kvm support in stages. Roughly:

   1. Nate will set up kvm on =osghost.chtc.wisc.edu= to create a playground
   1. Nate will show !TimC how to run an arbitrary image on =osghost=
   1. !TimC will iterate on a basic SL6 VM image (probably using !BoxGrinder, see below) until it starts, runs a simple process, and exits cleanly
   1. Nate and !TimC will work together to identify and solve any issues with the test VM image, especially concerning networking
   1. Nate will set up one CHTC node with kvm support
   1. !TimC will try to run the test VM image on the CHTC node using HTCondor
   1. Iterate and grow as needed and possible


---++ Selecting a VM Type

On 2 July 2013, Jaime and !ToddM suggested focusing on kvm as the VM type. People on the team have the most experience with kvm. Avoid !VMware (no reasons recorded).

To run our test code, use the =rc.local= system (file? directory?). It should run last in the startup sequence, after all other services are running. Ask !ToddM for help, if needed. Once the tests are done, shut down the VM from the same script.


---++ Creating VM Images

At the heart of each test run will be a base OS image, containing a relatively bare-bones OS installation along with a few key files to set up networking, users, certificates, etc.

The base images, one for each platform on which we wish to test, will need to be recreated periodically, say once a week, and reused many times. Thus, the process of creating a base OS image must be scriptable. There are tools to create Linux installations on VM images:

   * John Hover has used [[http://boxgrinder.org BoxGrinder]] to do his virtualization work. It has not received an update since mid-2012, but has been sufficient for his needs.
   * [[https://github.com/clalancette/oz/wiki Oz]] is newer and support some but not all of !BoxGrinder’s features. Tony Tiradani at Fermi uses it.
   * [[http://imgfac.org Image Factory]] builds on Oz by adding features to prepare and install VM images for cloud deployment. It is available via RPM on EL 6, Fedora 16, and Fedora 17 platforms from their own repository, as described in [[http://imgfac.org/documentation/install.html the installation documentation]].

John H. (11 July 2013) noted that !BoxGrinder may run only on the latest Fedora releases, such as 17 and 18; I did not check whether this is true. Also, John noted that he had some problems with !BoxGrinder: He could not install both x86-64 and i386 RPMs at the same time, due to limitations in the tool; and there were some issues with EC2, but they would not affect us. John’s !BoxGrinder patches are available in his source code repository.

One other thing to think about: !BoxGrinder appliance files are fairly simple to understand and reference files contained in the same directory. However, imagefactory uses one giant XML file, with all installed files inlined. Yuck!

Tony Tiradani at Fermi also has experience with creating VM images. He uses Oz, and [[https://github.com/holzman/gwms-cloud-vms/tree/development has a Subversion repository]] with an example of his TDL file.

[[http://docs.openstack.org/trunk/openstack-image/content/ch_creating_images_automatically.html Another document]], on the !OpenStack site, gives an example of using Oz with EPEL.

If there are performance issues with transferring this image, likely to be 4GB or so, the CHTC infrastructure folks could set up some kind of caching, possibly via the Ken Hahn Filesystem.

---+++ Commands

---++++ Oz

<pre class="screen">oz-install -d 4 -p -u -x oz-generated-libvirt.xml sl64.tdl</pre>

   * The =-d 4= option yields maximum debugging output
   * The =-p= option removes the existing guest image file
   * The =-u= option runs the image customization steps (after installation is done)
   * The argument is the name of the TDL XML file

---++++ Virsh

To load the definition of the guest into virsh:

<pre class="screen">virsh define cat-libvirt.xml</pre>

   * The second argument is the name of the libvirt domain definition file, as documented [[http://libvirt.org/formatdomain.html on the libvirt website]]. It is an XML file that defines what the VM guest configuration, including things like the guest name, memory size, VM image(s), networking configuration, etc.

To start the guest:

<pre class="screen">virsh start cat.chtc.wisc.edu</pre>

   * The second argument is the guest name, as defined in the domain definition file.

To stop the guest, as though disconnecting the power:

<pre class="screen">virsh destroy cat.chtc.wisc.edu</pre>

   * The second argument is the guest name, as defined in the domain definition file.

To remove the definition of the guest from virsh:

<pre class="screen">virsh undefine cat.chtc.wisc.edu</pre>

   * The second argument is the guest name, as defined in the domain definition file.

---+++ Configuring for a Static IP Address

To make an image that will run as cat.chtc.wisc.edu, I need to tell both kvm (externally, on the host) and the image the same fixed MAC address. From within the original cat.chtc.wisc.edu machine, I found that =ifconfg= reports =eth0= as the primary interface. So this file:

<pre>/etc/sysconfig/network-scripts/ifcfg-eth0</pre>

needs to contain:

<pre>DEVICE=eth0
ONBOOT=yes
HWADDR=00:16:3E:45:66:99
TYPE=Ethernet
BOOTPROTO=dhcp</pre>

---+++ Hostname and Host Certificates

The test runs will need a valid host certificate. How to accomplish this?

Jaime and !ToddM suggested getting a single, static hostname from the CSL. Then, the networking system in the base OS images would be set up such that this name would resolve, but only on the VM itself, not going out to the network. Then, we could request a host certificate from !DigiCert for this fixed hostname, and that host certificate would be shipped with the base OS VM image. Jaime and !ToddM know how to set up the fake hostname lookups in the VM configuration.


---++ Handling Input and Output

To handle input and output, Jaime and !ToddM recommended having separate, small image files for them. Thus, two extra images, beyond the OS base install itself, may be needed:

   * An input image, containing only a single text file with test run conditions.
   * An output image, initially empty and for saving the output log file(s). This image would be the only file transferred back from the run.

The =qemu-img= tool make images and may be sufficient for the input and output images.

Alternatively, John (11 July 2013) noted that there are tools designed for supplying a limited amount of input to an otherwise static VM image. He called this the “HEPIX contextualization approach”, although the HEPIX system is just one implementation. One possibility is the =cloud-init= package from Ubuntu, available on all Linux systems that we care about. I found [[https://launchpad.net/cloud-init a project page]] and [[http://cloudinit.readthedocs.org/en/latest/ some documentation]].

---+++ libguestfs

To get =guestfish= and other tools, I had to install an extra package:

<pre class="screen">yum install libguestfs-tools-c</pre>

This brought along another package:

<pre class="screen">Installed:
  libguestfs-tools-c.x86_64 1:1.16.34-2.el6

Dependency Installed:
  libconfig.x86_64 0:1.3.2-1.1.el6</pre>

To get =virt-make-fs= (recommended by Dave B.), there was another install:

<pre class="screen">yum install libguestfs-tools</pre>

More packages:

<pre class="screen">Installed:
  libguestfs-tools.x86_64 1:1.16.34-2.el6

Dependency Installed:
  perl-Sys-Guestfs.x86_64 1:1.16.34-2.el6
  perl-Sys-Virt.x86_64 0:0.9.10-4.el6
  perl-XML-Parser.x86_64 0:2.36-7.el6
  perl-XML-Writer.noarch 0:0.606-6.el6
  perl-XML-XPath.noarch 0:1.13-10.el6
  perl-libintl.x86_64 0:1.20-1.el6</pre>

---++++ Creating the Input/Output Image

   1. Create an input directory:<pre class="screen">mkdir input</pre>
   1. Create an input options file in =input/options.txt=:<pre class="file">--add-user --dump-output --verbose --install=ndt</pre>
   1. Make the input/output image file (raw format): <pre class="screen">virt-make-fs --size=1M input /var/lib/libvirt/images/vm-io-disk.raw</pre>

---++++ Getting Files from the Image Manually

   1. Create a mount point:<pre class="screen">mkdir /mnt/output</pre>
   1. Mount the input/output image locally:<pre class="screen">mount -o loop /var/lib/libvirt/images/vm-io-disk.raw /mnt/stuff</pre>
   1. Copy files to local disk:<pre class="screen">cp -p /mnt/output/*.log output/</pre>
   1. Unmount the input/output image:<pre class="screen">umount /mnt/stuff</pre>

---++++ Getting Files from the Image Automatically

<pre class="screen">guestfish --ro --add vm-io-disk.raw --mount /dev/vda:/ download /osg-test-20130802.log osg-test-20130802.log</pre>

---++ Interactively connecting to a VM

Unfortunately, VM Universe jobs don't have the ssh_to_job capacity that's available to other Condor jobs so if we need to investigate test failures in VMU, we'll have to spin up our own VM's. We can do this by taking the images that Neil automatically generates and create new ones from them that don't automatically run osg-test (Right now, Neil has to manually copy over the updated images. Eventually, we should have an automated way to get the most updated VMU images). Here are the steps you need to follow to set up your own VM:

   1. Grab the make-interactive-image from SVN:<pre class="screen">svn co https://vdt.cs.wisc.edu/svn/new-test/trunk/vm-test-runs/</pre>
   1. Run =make-interactive-image= using the flavor and version of Linux you need, VMU images are in =/kvm= (NOTE: the output image needs to be in a directory that's readable by the =qemu= user): <pre class="screen">vm-test-runs/make-interactive-image /kvm/%RED%&lt;input image&gt;%ENDCOLOR% %RED%&lt;output image&gt;%ENDCOLOR%</pre>
   1. Make a copy of =/kvm/libvirt-template.xml= and edit the @DOMAIN@ and @IMAGEPATH@ to a name that will be used by virsh and the path to the output file you created in the previous step. %TWISTY{%TWISTY_OPTS_OUTPUT% showlink="Click to show libvirt-template.xml..."}% <verbatim>
<domain type='kvm'>
  <name>@DOMAIN@</name>
  <uuid>f737df49-5323-088f-922b-9e4aef5a100d</uuid>
  <memory unit='KiB'>4145152</memory>
  <currentMemory unit='KiB'>4145152</currentMemory>
  <vcpu placement='static'>8</vcpu>
  <os>
    <type arch='x86_64' machine='rhel6.4.0'>hvm</type>
    <boot dev='hd'/>
  </os>
  <features>
    <acpi/>
    <apic/>
    <pae/>
  </features>
  <clock offset='utc'/>
  <on_poweroff>destroy</on_poweroff>
  <on_reboot>restart</on_reboot>
  <on_crash>restart</on_crash>
  <devices>
    <emulator>/usr/libexec/qemu-kvm</emulator>
    <disk type='file' device='disk'>
      <driver name='qemu' type='raw' cache='none'/>
      <source file='@IMAGEPATH@'/>
      <target dev='hda' bus='ide'/>
      <address type='drive' controller='0' bus='0' target='0' unit='0'/>
    </disk>
    <controller type='usb' index='0'>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x01' function='0x2'/>
    </controller>
    <controller type='ide' index='0'>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x01' function='0x1'/>
    </controller>
    <interface type='bridge'>
      <mac address='00:16:3e:45:66:99'/>
      <source bridge='br0'/>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x03' function='0x0'/>
    </interface>
    <serial type='pty'>
      <target port='0'/>
    </serial>
    <console type='pty'>
      <target type='serial' port='0'/>
    </console>
    <input type='mouse' bus='ps2'/>
    <graphics type='vnc' port='-1' autoport='yes' listen='128.105.244.224'>
      <listen type='address' address='128.105.244.224'/>
    </graphics>
    <video>
      <model type='cirrus' vram='9216' heads='1'/>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0'/>
    </video>
    <memballoon model='virtio'>
      <address type='pci' domain='0x0000' bus='0x00' slot='0x04' function='0x0'/>
    </memballoon>
  </devices>
</domain>
</verbatim> %ENDTWISTY%
   1. Define and start the VM with your copy of the xml file: <pre class="screen">virsh create %RED%&lt;xml file&gt;%ENDCOLOR%</pre>
   1. Connect to the VM (consult BrianL, Mat or Carl for the password):<pre class="screen">virsh console %RED%&lt;DOMAIN&gt;%ENDCOLOR%</pre>
   1. Cleanup the VM:<pre class="screen">virsh destroy %RED%&lt;DOMAIN&gt;%ENDCOLOR%</pre>
