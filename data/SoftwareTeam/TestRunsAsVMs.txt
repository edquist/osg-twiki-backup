%META:TOPICINFO{author="TimCartwright" date="1374674451" format="1.1" version="1.7"}%
%META:TOPICPARENT{name="TestingHome"}%
---+ Running Tests as VM Jobs

This page is my (cat) collected notes and ideas about running osg-test runs as VM jobs, either locally (e.g., CHTC) or in OSG.


---++ Using VM Universe in HTCondor

For HTCondor 8.0, the documentation for VM universe is in [[http://research.cs.wisc.edu/htcondor/manual/v8.0/2_11Virtual_Machine.html][section 2.11]] of [[http://research.cs.wisc.edu/htcondor/manual/v8.0/ the manual]].

Some quick notes:

   * =universe = vm=
   * =executable= is just a label
   * Omit =input=, =output=, and =error=, as they are not used and will cause submit failures
   * Must select a =vm_type= of =vmware=, =xen=, or =kvm=


---++ Using VM Universe in CHTC

The only VM universe support in CHTC was using a now-archaic version of [[http://www.vmware.com VMware]]; this was set up in support of the Thomas Jahns lab. Essentially, in July 2013, there is no current support. However, the CHTC infrastructure team is interested in adding real support for at least kvm.

On 3 July 2013, Nate Yehle proposed working with us to add kvm support in stages. Roughly:

   1. Nate will set up kvm on =osghost.chtc.wisc.edu= to create a playground
   1. Nate will show !TimC how to run an arbitrary image on =osghost=
   1. !TimC will iterate on a basic SL6 VM image (probably using !BoxGrinder, see below) until it starts, runs a simple process, and exits cleanly
   1. Nate and !TimC will work together to identify and solve any issues with the test VM image, especially concerning networking
   1. Nate will set up one CHTC node with kvm support
   1. !TimC will try to run the test VM image on the CHTC node using HTCondor
   1. Iterate and grow as needed and possible


---++ Selecting a VM Type

On 2 July 2013, Jaime and !ToddM suggested focusing on kvm as the VM type. People on the team have the most experience with kvm. Avoid !VMware (no reasons recorded).

To run our test code, use the =rc.local= system (file? directory?). It should run last in the startup sequence, after all other services are running. Ask !ToddM for help, if needed. Once the tests are done, shut down the VM from the same script.


---++ Creating VM Images

At the heart of each test run will be a base OS image, containing a relatively bare-bones OS installation along with a few key files to set up networking, users, certificates, etc.

The base images, one for each platform on which we wish to test, will need to be recreated periodically, say once a week, and reused many times. Thus, the process of creating a base OS image must be scriptable. There are tools to create Linux installations on VM images:

   * John Hover has used [[http://boxgrinder.org BoxGrinder]] to do his virtualization work. It has not received an update since mid-2012, but has been sufficient for his needs.
   * [[https://github.com/clalancette/oz/wiki Oz]] is newer and support some but not all of !BoxGrinder’s features. Tony Tiradani at Fermi uses it.
   * [[http://imgfac.org Image Factory]] builds on Oz by adding features to prepare and install VM images for cloud deployment. It is available via RPM on EL 6, Fedora 16, and Fedora 17 platforms from their own repository, as described in [[http://imgfac.org/documentation/install.html the installation documentation]].

John H. (11 July 2013) noted that !BoxGrinder may run only on the latest Fedora releases, such as 17 and 18; I did not check whether this is true. Also, John noted that he had some problems with !BoxGrinder: He could not install both x86-64 and i386 RPMs at the same time, due to limitations in the tool; and there were some issues with EC2, but they would not affect us. John’s !BoxGrinder patches are available in his source code repository.

One other thing to think about: !BoxGrinder appliance files are fairly simple to understand and reference files contained in the same directory. However, imagefactory uses one giant XML file, with all installed files inlined. Yuck!

Tony Tiradani at Fermi also has experience with creating VM images. He uses Oz, and [[https://github.com/holzman/gwms-cloud-vms/tree/development has a Subversion repository]] with an example of his TDL file.

If there are performance issues with transferring this image, likely to be 4GB or so, the CHTC infrastructure folks could set up some kind of caching, possibly via the Ken Hahn Filesystem.

---+++ Hostname and Host Certificates

The test runs will need a valid host certificate. How to accomplish this?

Jaime and !ToddM suggested getting a single, static hostname from the CSL. Then, the networking system in the base OS images would be set up such that this name would resolve, but only on the VM itself, not going out to the network. Then, we could request a host certificate from !DigiCert for this fixed hostname, and that host certificate would be shipped with the base OS VM image. Jaime and !ToddM know how to set up the fake hostname lookups in the VM configuration.


---++ Handling Input and Output

To handle input and output, Jaime and !ToddM recommended having separate, small image files for them. Thus, two extra images, beyond the OS base install itself, may be needed:

   * An input image, containing only a single text file with test run conditions.
   * An output image, initially empty and for saving the output log file(s). This image would be the only file transferred back from the run.

The =qemu-img= tool make images and may be sufficient for the input and output images.

Alternatively, John (11 July 2013) noted that there are tools designed for supplying a limited amount of input to an otherwise static VM image. He called this the “HEPIX contextualization approach”, although the HEPIX system is just one implementation. One possibility is the =cloud-init= package from Ubuntu, available on all Linux systems that we care about. I found [[https://launchpad.net/cloud-init a project page]] and [[http://cloudinit.readthedocs.org/en/latest/ some documentation]].