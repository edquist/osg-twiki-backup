%META:TOPICINFO{author="AlainRoy" date="1307663707" format="1.1" version="1.13"}%
%META:TOPICPARENT{name="Projects"}%
---+ A transition to native packages

Summary: This document contains the details of how we will transition away from Pacman to native packages (RPMs and debs)

%RED% _Please note_: %ENDCOLOR% There are many incomplete details here, and they are likely to change _significantly_ in the first three weeks of June.

---++ 0.0 State of this document

This document is a draft. 

---+++ 0.1 Known issues that will be addressed in future versions of this document. 

   * What needs to change in order to make the transition? 
   * A survey of packages that need to be provided.
   * Testing infrastructure needs to change how?
   * Assess where the work is? Configuration? 
   * What do we expect from the sysadmins? How do they convert?To update easily? 
   * CA Certs: only from GOC? Also from VDT? IGTF vs. non-IGTF? Different packaging so you can choose subset? (Note from BB: I integrated these below).
   * How do LIGO's requests for SL6 and Debian 6 support mesh?
   * Mirrors of yum repos
   * What packages might need significant work to fit into RPM world? Gratia? 
   * Target dates: Site Admin Meeting in August, LHC shutdown in December...

---+++ 0.2 Open questions for readers

   * Sysadmins: how do you feel about the requirement that we depend on EPEL? 

---++ 1.0 General Approach

Our general approach is documented in our [[CommunityPackagingProposal][Community Packaging Proposal]]. 

Here is a brief summary of our approach, as quoted from that document:

<blockquote>
*Proposed Principle of Community Packaging:* <br>
The OSG Software Team should be a good community citizen when it comes to packaging: When possible, we should use packages from existing and/or broader communities; when that is not possible, we should make our own packaging but contribute them back to the broader communities. Therefore, we should package software only when one of the following is true:

   1. The software is not already packaged; or 
   1. The software is packaged but needs significant changes to be acceptable to our users. (Different version, extra patches, etc...)

Otherwise we should use the existing packaging provided by external developers or software repositories.
</blockquote>

While this does not mention native packages, that is the implication: we can only use packages from a larger community effectively if we are using the same packaging mechanism with the same standards. 

---++ 2.0 Outline of timeline

There are two portions to our current timeline. 

   1. Finish pending work on Pacman-based releases, then stop any non-critical work on the Pacman-based releases.
   1. Immediately begin work on transitioning our infrastructure and products to RPMs for Red Hat Enterprise Linux 5. 

---+++ 2.1 Finish pending work on Pacman-based releases.

We want to stop new work on Pacman packages as soon as possible, but we have some lingering work to finish up to ensure that we are well-positioned to provide our users with a working VDT while we make the transition to RPMs. We plan for the following.

|  *Date*  |  *Effort*  |  *What*  |
|  June 10  |  | As of June 10, we won't accept any new requests for changes to the Pacman cache. |
| June  |  2-3 FTE Days  | Release [[http://vdt.cs.wisc.edu/releases/2.0.0/release-p27.html][OSG 1.2.20 (VDT 2.0.0.p27)]], which is currently in testing in the ITB. This provides some long-requested changes to GRAM for CMS, among other minor updates. This release will not require much effort from the OSG Software Team: perhaps a day or two to deal with minor problems and the release process. |
|  July  |  1 FTE Week  | Minor update to address low priority security issues and a GIP update from CMS. While the security updates are low priority, we want to ensure they are addressed because some of our users may be using the Pacman-based releases for a long time, and it's best to have these resolved. (To be precise, we need to update Squid, !MySQL-JDBC.) This should take less than a week of one person in the OSG Software Team. |

After these releases, we will not make any plans to do updates to the Pacman-based packaging of the VDT unless there are critical updates. By "critical update", we mean a moderate or high priority security update, or anything approved by the OSG Executive Team. 


*Please note:* This means that the requested VOMS/VOMS-Admin upgrade will not be provided in Pacman-based packaging. 
---+++ 2.2 Immediately begin work on RPMs for RHEL 5

We will immediately begin the transition to producing the OSG Software Stack as RPMs for Red Hat Enterprise Linux 5 and variants (especially Scientific Linux 5). 

---+++ 2.2.1 Order of packages to release

Starter packages:
   1. *vdt-system-profiler*: We will first ship an updated version of the <code>vdt-system-profiler</code>. This is a simple script that allows users to collect debugging information to be sent to VDT support when help is needed. This is our first target because the package itself is simple, but it will allow us to make sure our infrastructure is in place. (Building RPMs, yum repositories, etc.)
   1. *Xrootd*: Xrootd (without the DSI Plugin) will be our next target. This is already mostly done, so the goal is to make sure that our infrastructure works properly.
   1. *Xrootd DSI Plugin*: This will require us to use Globus, so we will be forced to address questions about how we get Globus. Do we refer to it from EPEL? Do we copy it from EPEL?
      * Note from BB: We have already done this for the Hadoop DSI plugin.
   1. *glexec*: CMS wants an upgraded version of glexec. While it is not difficult to build, there are several dependencies (lcas, lcmaps, VOMS, and Globus) that need to be addressed.
      * Note from BB: VOMS is an interesting issue, as (last I checked) the VOMS in EPEL doesn't have the "--dont-verify" flag.  This is possibly the first place where we'll have to decide between "copy and maintain a patch" versus "work with upstream".  This is based on 9-month-old information; may have changed.
   1. *Worker Node Client*: This is "low-hanging fruit". Many of these packages have already been done by CMS and we can use the results. They also require minimum configuration to get working.
      * Note from BB: We have proof of concept source packages for all of the WN-client *except* Fermi-SRM-Client.
   1. *OSG Client*: Probably falls under the "starter" package category in complexity, but it does possibly affect end-users.  (Added by BB)

Complex packages:
   1. VOMS Admin: This is the first Tomcat+MySQL application we'll need to support.  This would be the first test of our ability to port complex configuration scripts over. (Added by BB)
   1. OSG-CE: This is the most complex software we offer.  It's going to be necessary to start very early, as it will take much longer than any other software, and will require coordination with several pieces of software that have never had native packaging.  (Added by BB)
   1. CREAM: EMI is also doing source packages for this; it might benefit to let them shake-out bugs.
      * Note from BB: The following software will be in both OSG-CE and CREAM, and have never had native packages made: Gratia probes, GIP, OSG-RSV, Configure-OSG, Fermi-SRM-Client.

TBD:
   1. Gratia Collector.  Small user base (5-6).  Requires MySQL+Tomcat; might be easy after VOMS Admin.  (Added by BB)
   1. VDT-CA-Manage.  This is to manage the set of CAs; while we have RPMs for CAs right now, they're far less powerful than VDT-CA-Manage.  We probably don't want to regress on these capabilities, as they were strongly desired by the OSG Technical Director.  (Added by BB)
   1. Mostly-unused-packages: dccp, bwctl, ndt, npad, MonaLisa, owamp.  These packages all provide some level of functionality to a small crowd.  I don't think we should consider removing them (for now), but we might want to state they won't happen for the initial release. (Added by BB)
   1. Pegasus client: Last I checked with the Pegasus folks, they now glide-in their own client.  We should check to see if this is still necessary.  (Added by BB)
   1. CA certs.  Who defines the starting set of CA certs?  Can it be only GOC?

What do we say about timeline? Goal of X, Y, and Z by... August 31? 

---+++ 2.2.2 Supported operating systems

Initially we plan to support Red Hat Enterprise Linux 5 and variants (particularly Scientific Linux 5) in both 32 and 64-bit architectures. 

Note the absence of other platforms, at least initially: No RHEL 4, no SuSE, no Debian. More will come later, but unspecified as to what and when. (The software we provide to LIGO on Debian will continue to exist.)

---++ 3.0 Technical details

Below we have a lot of technical details about our approach. We expect the details to change significantly over the next few weeks as our understanding of the problems becomes more clear. However, we are guided by a few principles. 

*Principles*

   1. For supported packages, we must be able to reproduce the complete build from data in the VDT infrastructure. That is, if we rely on software/files that are not from us, we must make a copy of them into our local infrastructure before we distribute anything based on them. (Local infrastructure means "version control system + 'extra stuff' as needed.) We don't want our future builds to break because we've lost them. For example, we will make a local checkout from a software provider's source code repository instead of relying on the repository's continued existence. 
   1. We must provide clear distinctions between what comes from external sources and what is the VDT's work. You'll see this distinction in the source code repository layout below. 
   1. We must have a straightforward, unambiguous conversion from the files in our source code repository into source rpm. We must have a tool that can drive this process as well as the build. 
   1. We should make it easy for external people to make contributions. 
   1. We should rely on standard tools provided by the larger packaging/development community wherever appropriate. 
   1. We will follow the OS vendor packaging guidelines as closely as possible. 

%RED%Warning:%ENDCOLOR% Many technical details follow. Gloss over parts you don't care about.

---+++ 3.1 Adherence to Fedora Packaging Guidelines?

_Tenatative_: Our packages will adhere to as many [[http://fedoraproject.org/wiki/PackagingGuidelines][Fedora Packaging Guidelines]] as possible, but we will not require all packages to meet all guidelines. However, we may require all packages that do not meet all guidelines to install a file (perhaps in <code>/usr/share/doc/<i>package</i>/</code>) that documents major deviations from the guidelines that may be significant to end-users. 

---+++ 3.2 Approach to building

We have a few conflicting desires. We want to use community-accepted tools (such as mock and Koji), we want to take advantage of the Batlab at the University of Wisconsin-Madison, and we want to make it easy for external contributors to provide RPMs. How do we balance these?

---++++ 3.2.1 Officially supported packages

   1. All necessary information to create the package will be committed to the VDT source code repository. (See Section 3.3.)
   1. A tool will be provided that will take those files, create a source RPM, and submit it to a build system. Initially we will have three possible underlying build systems. 
      1. rpmbuild
      1. mock
      1. Metronome (the Batlab build system). This build will use mock, so it's very similar to option 2. 

All official builds will be done via option 3, but contributors can work with options 1 or 2 to develop their build before they contribute it to the VDT.

Initially this will be all we support. In the near future, we will likely have our Metronome builds provide build information to a VDT-owned Koji instance. As we gain expertise with Koji, we may add support for directly using Koji. 

We will implement these build options in the order they are presented. This will allow us to quickly get up to speed in producing !RPMs.

---++++ 3.2.2 Unsupported contributed packages

Unsupported contributed packages have two build options. They will be provided via a separate yum repository for unsupported contributions.

   1. Build exactly like the supported packages (above). 
   1. The RPM can be built by the contributor in their own environment and shared with the OSG Software Team for manual staging into the yum repository. 

Should we support Koji in the future, we'll allow Koji submissions for trusted contributors. 

---+++ 3.3 VDT source code repository

All packages that are built by the VDT will be checked into our source code repository (currently Subversion). We will allow collaborators to commit to the repository. 

Within the repository, each source package will be a single directory from which we can derive a single source RPM. Within that directory, we will have two sub-directories:

   * <code>original</code>: Anything we've copied from another source. We do not modify, except for trivial file name changes.
   * <code>osg</code>: Anything provided by the OSG. This may be modifications to the original directory, or completely new files.

---++++ 3.3.1 Original directory
Within the original directory, we conceptually provide everything that comes from a source RPM, but with the individual files (not the source RPM itself). For example, if you examined the RPM for commonly-used "<code>less</code>" utility, you would see something like (simplified a bit):

<blockquote>
<pre>
% rpm -qpl unzip-5.52-3.el5.src.rpm 
unzip-5.52-long-filename.patch
unzip.spec
unzip552.tar.gz
</pre>
</blockquote>

The original directory would contain:

<blockquote>
<pre>
     original/
     original/unzip.spec
     original/unzip-5.52-long-filename.patch
     original/%RED%SOURCES%ENDCOLOR%
</pre>
</blockquote>

*Open Question:* We're not sure how to specify the source code. Options include: 
   1. Check it into the repo as-is (or perhaps renamed to eliminate the version number so there is easier history
   1. Do something koji-like where there is a makefile that can fetch the source code.
   1. A file with a URL to the source code. 

I think we want to keep the source code cached somewhere for reproducibility. 

---++++ 3.3.1 OSG directory

The "osg" directory may contain a few things:

   1. A "root" directory that contains files to be installed as part of the RPM. This can only be used if the sources are not specified in the original directory.
   1. A spec file. If there is a spec file in the original directory, the OSG-provided one is used.
   1. Any OSG-specific patches. 

---++++ 3.3.2 Example 1: A VDT-provided utility script, vdt-system-profiler

We will provide a debugging utility named <code>vdt-system-profiler</code> to collect system information that can be sent to the OSG Software Team to aid in debugging. Within the source code repository, it would like this:

<blockquote>
<pre>
vdt-system-profiler/
     osg/
     osg/root/usr/bin/vdt-system-profiler
     osg/vdt-system-profiler.spec
</pre>
</blockquote>

---++++ 3.3.3 Example 2: The VDT creates the RPM for a package without one

As of today, the OSG RSV software does not provide an RPM. The source code repository would have:

<blockquote>
<pre>
osg-rsv/
     original/
     original/%RED%SOURCES%ENDCOLOR%
     osg/
     osg/osg-rsv.spec
</pre>
</blockquote>

---++++ 3.3.4 Example 3: The VDT copies an RPM 

Here is an example of how we might copy an RPM. We would copy the RPM in order to freeze the version and/or provide a minor patch. We might do this for Xrootd, for example.

<blockquote>
<pre>
xrootd/
     original/
     original/%RED%SOURCES%ENDCOLOR%
     original/xrootd.spec
     osg/
     osg/fix-init-script.patch
</pre>
</blockquote>

---++++ 3.3.5 VDT tool to build RPMs

We will provide a VDT tool in our source code repository that will create !RPMs. The options will look something like this:

*Option 1: Build with rpmbuild*

<pre>
make-vdt --rpmbuild PACKAGE-NAME
</pre>

   1. Create the source rpm
      1. Combine original and osg directories to create input needed to make source RPM
      1. Make source RPM with <code>rpmbuild -bs --nodeps</code>
   1. rpmbuild ...
   1. Copy RPM to some local directory

*Option 2: Build with with*

<pre>
make-vdt --mock PACKAGE-NAME
</pre>

   1. Create the source rpm
      1. Combine original and osg directories to create input needed to make source RPM
      1. Make source RPM with <code>rpmbuild -bs --nodeps</code>
   1. Set up mock
   1. mock build 32 & 64 bit
   1. Stage to yum repo if specified in config

*Option 3: Build with Metronome*

<pre>
make-vdt --batlab PACKAGE-NAME
</pre>

   1. Create the source rpm
      1. Combine original and osg directories to create input needed to make source RPM
      1. Make source RPM with <code>rpmbuild -bs --nodeps</code>
   1. Submit build to Metronome
      1. mock build 32 & 64 bit
      1. Stage to yum repo via ssh if specified in config ... or ...
      1. Stage to yum repo via Koji

*Option 4: Look at build input*

<pre>
make-vdt --generate PACKAGE-NAME
</pre>

   1. Combine original and osg directories to create input needed to make source RPM
   1. Make source RPM
   1. Tell user where to find these. 

---+++ 3.4 EPEL & Globus & VOMS

We will tell our users that they have to use/enable the EPEL repository.

Initially, we will only copy Globus from EPEL when we need to patch it. We expect that we only need to patch a small subset of the Globus packages, so most will come from EPEL. We don't yet have a good feeling for whether or not we can rely on EPEL, so we reserve the right to copy more RPMs from EPEL in the future, if necessary.

When we copy packages, we will add a VDT repotag to distinguish them from the ones that come from EPEL. We will also recommend using yum priorities to prefer the VDT versions. 

---+++ 3.5 EMI

EMI 1.0 is very new. We expect to use many of their packages, but we will prefer to copy the packages to our repository instead of relying directly on the EMI repository. This will allow us to control the versions of the critical grid software our stakeholders need. 

---+++ 3.6 RPM signing

How we sign: one key for team vs. key for individuals. How does koji handle this?

---+++ 3.7 Testing

Pre-release and after-release against updated versions

---+++ 3.8 Repositories

VDT supported packages will be in three repositories per major version. 

   1. *dev:* Packages that are not ready for release to anyone outside the VDT. They are bleeding-edge and may be changed at any time. This should only be used by contributors to the VDT (both VDT team and external contributors). 
   1. *test:* Packages that are being tested for imminent release. The ITB and other testers will use this repository. Only a OSG Software Team member may promote packages from _dev_ to _test_. 
   1. *release*: Packages that have been released to our users. Only an OSG Software Team member may promote packages from _test_ to _release_. In most cases this will only happen after ITB testing.

Unlike the past where there were separate repositories for "the VDT" and "the OSG software cache", we will have a single shared repository. The GOC will continue to maintain the packages they have maintained (such as the VO configuration information), but will provide it via our mechanisms. 

There will also be a "contrib" repository for unsupported software that may be of interest to VDT stakeholders. 

---++ 4.0 Versioning

%RED%Warning:%ENDCOLOR% This whole section was added by BB and not yet reviewed by Alain.

We've previously said the minor version number transitions (as in, OSG 1.2 -> 1.3) are only incremented when upgrades aren't possible.  This makes the major version number mostly meaningless, and leads to a very large patch-level (1.2.19) and major changes happen between patch levels.  I'd like to fix this while we are doing a clean sweep.

The point of making versioning changes is to communicate *within the version number* the amount of risk one takes in performing the upgrade.

We use the traditional MAJOR.MINOR.PATCH numbering scheme.  By "version number", we are referring to the version number of any OSG meta-package RPMs. 

---+++ Major version number

   * Significant new services will only be added on major releases.
   * We don't guarantee configuration file compatibility across major releases (although we will keep the existing policy of making configuration files as backward compatible as possible).  We are allowed to obsolete, remove, or semantically change configuration options.  We will avoid semantic changes if at all possible.
   * We don't guarantee ABI compatibility across major releases.
   * We don't guarantee protocol compatibility across major releases.
   * Major version changes will be ITB-tested.
   * We support the previous two major versions (i.e., about 18 months of support for a release).
   * Each major release will have a separate repository to prevent inadvertent upgrades.  To upgrade across a release, we can use yum plugins to do something like "yum updateosg 3" to switch to the OSG 3.0 repository.  We expect the upgrade process to be:
      1 Switch yum repository using custom yum command.
      1 Run "yum update".
      1 Edit configuration files.
   The average major release is thus far, far simpler than major release in the past.
   * The contents of the MAJOR release repository will contain version MAJOR.0.0 of the RPMs.

Note that, while we have a significant leeway for change at each major release, we aren't necessarily going to change things.  We will continue to be conservative in breaking things - but this will provide a predefined point when we need to.

Also note that previous minor releases would now be considered major releases due to the configuration option changes.

---+++ Minor version number
   * Configuration files will be backward, but not necessarily forward compatible.  A configuration file working with minor version X will work with minor version Y if X<Y.
   * Minor version changes will be ITB-tested.  We may change this item in the future if ITB effort is reduced.
   * Minor updates will be available in an -updates repo.
   * We expect updating across minor version numbers to be "safe", but admins are advised to not do them automatically.
   * Forward and backward ABI and protocol compatibility is expected.
   * Services may have new capabilities or versions in minor releases.
      * New packages may be added in a minor release if the upgrade of an existing service requires it.
   * Releases will happen on the 1st or 3rd Tuesday of the month (TODO: check to verify this jives with the current policy)
   * Packages in the MAJOR updates repository will contain the RPMs corresponding to the latest MAJOR.MINOR.VERSION.

---+++ Patch-levels
   * Configuration variables may not change.
   * Reserved only for bugfixes or security fixes.
   * ABI compatibility is guaranteed.
   * Patch-level fixes may skip ITB if necessary.
   * It is expected to patch-level upgrades to be completely safe.
   * We expect updates should be safe to be done automatically.
   * Patch-level fixes will go into the -updates repo.

---+++ Exceptions

There cases where we make exceptions to the versioning and release policy outlined above.
   * If we find a compelling reason to break the above process, the OSG-ET must approve it.  It will be noted in the release nodes, and separately emailed to osg-sites.
   * The OSG 2.0 release cycle will be special because we will not transition all OSG 1.2 services in one release. OSG 2.0 might start with only the worker node client (or less).
      * Services existing in OSG 1.2 will be added in minor releases of OSG 2.0.  The new services will go into the *release*, not the *updates* repository.  Compatibility guarantees are unchanged. The minor updates of OSG 2.0 will be tested by ITB.
      * Services not in OSG 1.2 will wait for OSG 3.0.

---+++ Repository Content Examples

Suppose OSG 2.0 has an RPM called foo.  OSG 2.0.0 released with foo-4.0.3, OSG 2.1.0 released foo-4.0.4, and OSG 2.1.1 released foo-4.0.5.  According to the above policy, the OSG2 release repo will contain foo-4.0.3 and the OSG2 updates repo will contain foo-4.0.5.  foo-4.0.4 will be available from Koji, but not from the release or updates repository.