%META:TOPICINFO{author="BrooklinGore" date="1330370114" format="1.1" version="1.5"}%
%META:TOPICPARENT{name="Projects"}%
<!--
   * Set NOT_STARTED = Not Started
   * Set NOT_RELEASED = Not Released
   * Set ON_TRACK = <div style="background-color: #3366FF; color:white">&nbsp;On Track&nbsp;</div>
   * Set BEHIND = <div style="background-color: #CCFF00;">&nbsp;Behind&nbsp;</div>
   * Set AT_RISK = <div style="background-color: #CC0000; color:white">&nbsp;At risk&nbsp;</div>
   * Set ACHIEVED = <div style="background-color: #00FF66;">&nbsp;Achieved&nbsp;</div>
   * Set RELEASED = <div style="background-color: #00FF66;">&nbsp;Released&nbsp;</div>
   * Set TWISTY_OPTS_DETAILS = mode="div" showlink="Details" hidelink="Hide" showimgleft="/twiki/pub/TWiki/TWikiDocGraphics/toggleopen-small.gif" hideimgleft="/twiki/pub/TWiki/TWikiDocGraphics/toggleclose-small.gif" remember="on" start="hide" 
-->

---+!! Plan for Usability Testing of Bosco Version 0

---# What is usability?

From [1]:

<blockquote>
Usability is not a quality that exists in any real of absolute sense. Perhaps it can be best summed up as being a general quality of the <i>appropriateness to a purpose</i> of any particular artefact.
</blockquote>

---# Limits to current phase of usability testing

Thorough usability testing is an art and a science. Given the short time-frame and lack of in-house experience, we are going to limit the scope of usability testing. Good usability testing should include a fair number of candidate subjects, multiple rounds of testing, etc. Our goal is to gain insight into the usability we have in a cost-effective way.

---# Inputs for the usability testing

Our usability testing requires a few things to be in place before it can begin:

   1. The software must be ready for usability testing.
   1. An initial round of beta testing should be complete. The goal of usability testing is not to find bugs (though we welcome bug reports) but to understand the usability. Therefore basic bug fixing should be complete before usability testing begins. 
   1. There must be sufficient documentation for the user to be able to do all of the tasks required for the usability testing. 
   1. Dan will provide a set of testers for usability testing. These should not be the same as the beta testers. We would like 5 independent testers, but we'll take whatever Dan can find. (We realize that five might be optimisitic).

---# Plan

---## Target audience

Our target audience is composed of scientists and researchers who:
   * Have access to a cluster of computers using PBSPro or Torque. 
   * Have need for high-throughput computing
   * Are comfortable with the basics of using Linux and the command-line. 

---## Task

We will ask our testers to spend about one hour doing the following two tasks:
   1. Install Bosco and connect it to their PBS/Torque cluster.
   1. Run one job via Bosco.

---## Usability testing
Our usability testing will consist of three parts. All three are desirable, but due to time constraints we may only be able to do the second and third parts.

   1. Have an OSG staff member (preferably a Bosco team member) watch the tester complete the task. The staff member will not interfere with the task. Specifically, we will not provide any guidance or help. We will take extensive notes on what happened. In particular, we will note what parts of the task were hard or confusing and whether the users used the recommended workflow. (i.e. do they use the software differently than we expected?) <br>This task will require someone to be present. In future usability testing, we may find appropriate remote collaboration testing to do this remotely.
   1. Ask the user to fill out the System Usability Scale survey (below) and mail it to Alain
   1. Ask the user to provide any extra comments on the usability of the software and ways it can be made better.

---## Timeline: External dependencies
%TABLE{ sort="off" valign="top" }%
| *Task* | *State* | *Owner* | *Target Start* | *Target Finish* | *Actual Finish* | *Notes* |
| BOSCO v0 complete | %ON_TRACK% | Fraser/Gore | - | 27-Feb-2012 | |  |
| Documentation/web site complete | %ON_TRACK% | Mambelli/Fraser | - | 27-Feb-2012 | | |
| Beta testing complete | %NOT_STARTED% | Fraser/Gore | - | 5-Mar-2012 | | |
| Find usability testers | %NOT_STARTED% | Fraser | 20-Feb-2012 | 5-Mar-2012 | | |

----## Timeline: Usability testing
%TABLE{ sort="off" valign="top" }%
| *Task* | *State* | *Owner* | *Target Start* | *Target Finish* | *Actual Finish* | *Notes* |
| Determine impact of Human Subjects Research | %ON_TRACK% | Alain | 16-Feb-2012 | 24-Feb-2012 | | |
| Update plan to reflect Human Subjects Research | %NOT_STARTED% | Alain | 24-Feb-2012 | 28-Feb-2012 | | | 
| Work with tester #1 and #2 | %NOT_STARTED% | Alain | 5-Mar-2012 | 9-Mar-2012 | | |
| Work with testers #3 and #4 | %NOT_STARTED% | Alain | 12-Mar-2012 | 16-Mar-2012 | | |
| Write up usability testing results | %NOT_STARTED% | Alain | 16-Mar-2012 | 19-Mar-2012 | | | 

---# Appendices
---## System Usability Scale

I read about the System Usability Scale in [1] and [2], and it seems likely to be an excellent tool in our arsenal. It's a ten question questionnaire that can be used to determine the usability of an artifact. According to [2], it's been well studied and people have found it to consistently be a reliable measure of usability. Given that people more expert than me have studied it and agreed on it's utility, we should use it if we want to use a survey. 

   1. I think that I would like to use this system frequently	
   1. I found the system unnecessarily complex
   1. I thought the system was easy to use                      	
   1. I think that I would need the support of a technical person to be able to use this system	
   1. I found the various functions in this system were well integrated
   1. I thought there was too much inconsistency in this system
   1. I would imagine that most people would learn to use this system very quickly			
   1. I found the system very cumbersome to use
   1. I felt very confident using the system
   1. I needed to learn a lot of things before I could get going with this system 	

This can be converted into a single number (0-100) to rate the usability. 

---## Human Subjects Research

Miron advised Alain to check out rules governing Human Subjects Research, and ensure that we follow appropriate guidelines. 

After some research, he communicated with the directory of the relevant Institutional Research Board at the UW-Madison, who said:

<blockquote>
If these people are only commenting on the software, it is evaluation, not human subjects research.  If you are getting details that are personal or identifiable-- it becomes research.

To avoid moving into the research realm-- your questions should focus on  a "reporting" nature (tell me what you see)  rather than, for example, "Compare this to another software and give me your opinion."

Its a gray area, but so far, what you have described is not human subjects research.  It involves human subjects-- but what you are doing so far is not human subjects research.
</blockquote>

So if we are careful not to collect personal information, we will be fine. 

Some other background:

   * [[http://www.grad.wisc.edu/research/policyrp/rcr/humansubjects.html][UW information on Human Subjects Research]]
   * [[http://my.gradsch.wisc.edu/hrpp/10018.htm][Defining _Human Subjects Research:_]]
   * [[http://www.grad.wisc.edu/research/hrpp/submissioninstructions.html][Step by Step Instructions for Obtaining IRB Approval for Human Subjects Research]]

---## References

[1] Brooke, J. (1996). "SUS: a "quick and dirty" usability scale". In P. W. Jordan, B. Thomas, B. A. Weerdmeester, & A. L. McClelland. Usability Evaluation in Industry. London: Taylor and Francis. [[http://www.usabilitynet.org/trump/documents/Suschapt.doc][Word]]

[2] Lewis, J.R. & Sauro, J. (2009). The factor structure of the system usability scale. international conference (HCII 2009), San Diego CA, USA. [[http://www.measuringusability.com/papers/Lewis_Sauro_HCII2009.pdf][PDF]]