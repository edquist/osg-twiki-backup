%META:TOPICINFO{author="TimCartwright" date="1329774310" format="1.1" reprev="1.6" version="1.6"}%
%META:TOPICPARENT{name="TestingHome"}%
<!--
   * Set NOT_STARTED = Not Started
   * Set NOT_RELEASED = Not Released
   * Set ON_TRACK = <div style="background-color: #3366FF; color:white">&nbsp;On Track&nbsp;</div>
   * Set BEHIND = <div style="background-color: #CCFF00;">&nbsp;Behind&nbsp;</div>
   * Set AT_RISK = <div style="background-color: #CC0000; color:white">&nbsp;At risk&nbsp;</div>
   * Set ACHIEVED = <div style="background-color: #00FF66;">&nbsp;Achieved&nbsp;</div>
   * Set RELEASED = <div style="background-color: #00FF66;">&nbsp;Released&nbsp;</div>
-->

---+ Plans for Development of Automated Testing

---++ Basic Architecture

The proposed test framework comes in three parts. The *Driver* is the main script that is invoked to find, run, and report on tests. Ideally, it knows nothing about what the tests do or how they do it; instead, it just knows how to find tests, sequence them, run them, evaluate their outcomes, and report on the results. The *Tests* are intended to be divided into many files (Python modules) and should be small, be relatively independent, and clearly state their requirements. The underlying *Support Library* contains utility functions common to a variety of tests, a means for accessing global state information across tests, and (future work) a means for accessing global test environment information.

<table cellpadding="0" cellspacing="0" style="font-size: 150%;">
  <tr>
    <td>
      <table cellpadding="10" cellspacing="0" style="background-color: #BFB; border: 1px solid black; width: 100%;">
        <tr>
          <td colspan="3" style="text-align: center; font-weight: bold;">Driver</td>
        </tr>
        <tr>
          <td style="text-align: center;">Find&nbsp;Tests</td>
          <td style="text-align: center;">Run&nbsp;Tests</td>
          <td style="text-align: center;">Reporting</td>
        </tr>
      </table>
    </td>
  </tr>
  <tr><td style="height: 10px"></td></tr>
  <tr>
    <td>
      <table cellpadding="10" cellspacing="0" style="background-color: #BFB; border: 1px solid black; width: 100%;">
        <tr>
          <td style="text-align: center; font-weight: bold;">Tests</td>
        </tr>
      </table>
    </td>
  </tr>
  <tr><td style="height: 10px"></td></tr>
  <tr>
    <td>
      <table cellpadding="10" cellspacing="0" style="background-color: #BFB; border: 1px solid black; width: 100%;">
        <tr>
          <td style="text-align: center; font-weight: bold;">Support Library</td>
        </tr>
      </table>
    </td>
  </tr>
</table>

---++ Milestones

Effort estimates are actual effort, not calendar time, and are given by order-of-magnitude only at this time. See below the table for notes on particular items.

%TABLE{ sort="off" valign="top" }%
| # | *Milestone* | *State* | *Owner* | *Effort* | *Start* | *Target Finish* | *Actual Finish* | *Notes* |
| 1.1 | Separate support library from tests | 0.0.11 | Tim |  week  |  2012-01-12  | |  2012-01-20  | |
| 1.2 | Add global state to library; separate test files | 0.0.11 | Tim |  day  |  2012-01-20  | |  2012-01-24  | |
| 1.3 | Add a few useful functions to support library | 0.0.11 | Tim |  week  |  2012-01-25  | |  2012-02-02  | |
| 1.4 | Release osg-test with new features & gLExec | 0.0.11 | Tim |  hour  |  2012-02-14  | |  2012-02-20  | |
| 1.5 | Test Fest | | Tim |  day  | | | | Doug, Maxim, Neha, Scot |
| 2.1 | Replace nose with simplest possible driver | | Tim |  week  | | | | |
| 2.2 | Add sequence metadata and ordering algorithm | | Tim |  week  | | | | |
| 2.3 | Add state requirements and refactor runtime algorithm | | Tim |  week  | | | | |
| 2.4 | Expand possible test outcomes and reporting | | Tim |  week  | | | | |

Notes on milestone tasks:

   * *Separate support library from tests.* Originally, all modules (i.e., Python files) that supported the =osg-test= script were in a single module directory (=osgtest=). The goal of this change is to create two subdirectories of =osgtest=, one for the support library (in =library=) and one for the actual test files (in =tests=). As a result of the filesystem reorganization, all references to the support library were changed.

   * *Add global state to library.* Right now, each test module (i.e., Python file) tracks its own state, as far as setting up services and so forth. Also, the library itself has some shared state, implemented in a very ad hoc way. The goal of this task is to design and implement a simple, consistent, central mechanism for all global state, so that each test module could be smaller and a bit simpler to understand and sequence. The task also includes refactoring existing tests to use the new global state, possibly breaking up some of the longer test files (VOMS!) in the process.

   * *Add state requirements and refactor runtime algorithm.* Still under design. Each test (or small set of tests) may have two different kinds of requirements: ones that impose a sequence on the tests, and then "state requirements" that describe what state the system must be in for the tests to be run (as opposed to being skipped). This task will include brief analysis of what is needed, a bit of design, and then, if still needed, implementation.

---++ Possible Future Features

   * External file to define test environment (e.g., location of services, client user name and cert)
   * Test categories (e.g., client vs. server, light vs. heavy)
   * Support services on external systems (requires test environment, test categories)
