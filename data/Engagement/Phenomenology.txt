%META:TOPICINFO{author="MarkoSlyz" date="1324077532" format="1.1" version="1.2"}%
---+!! Running Phenomenology Codes on OSG

The [[http://www.slac.stanford.edu/grp/th/th.html][SLAC Theory Group]]
has started working with OSG User
Support to try running some phenomenology codes on OSG
as a proof-of-principle.

The theory group works with
the following experiments within SLAC:
[[http://atlas.web.cern.ch/][ATLAS]],
[[http://www-public.slac.stanford.edu/babar/][BaBar]],
[[http://cdms.berkeley.edu/][CDMS]],
[[http://fgst.slac.stanford.edu/][FGST]],
BICEP/SPUD,
and Super-B. More broadly, it works with
[[http://cms.web.cern.ch/][CMS]],
[[http://lhcb.web.cern.ch/][LHCb]],
[[http://www-cdf.fnal.gov/][CDF]],
[[http://www-d0.fnal.gov/][D0]],
[[http://h1.desy.de/][H1]],
[[http://www.lnf.infn.it/kloe/][Kloe]],
[[http://www.rssd.esa.int/index.php?project=Planck][Planck]],
PAMELA/HESS,
[[http://www.gsi.de/][GSI]],
[[https://www.jlab.org/][Jlab]], and
[[http://www.bnl.gov/rhic/][RHIC]].


%TOC%

---++ Job Requirements

We will initially be running a pair of applications,
[[http://projects.hepforge.org/sherpa/dokuwiki/][Sherpa]]
and
[[http://today.slac.stanford.edu/feature/2008/theory-one-loop-computations.asp][Blackhat]],
that do multiparticle QCD calculations.

In actual use they will produce about 2 or 3 GB of data
stored in a root NTuple, and take about 8 to 12 hours
to run.

They are independent Monte Carlo jobs whose output
files will record the random number seed, so no special
parallelization is needed. If some jobs fail, we don't
have to resubmit them.

There will be very roughly 500 jobs submitted at
one time for the proof-of-principle phase.

The executables will be 2 or 3 GB also, and should
be prestaged at the sites. The executable
shouldn't change too often--on the order of once
per year.

For testing, the output data will be more like
160KB, and the executable and input data are in a
50MB file.

Ideally we should be able to do a single
exploration ("pilot") run to figure out how many
jobs will be needed, and then submit all the jobs.
The variable number of jobs may be difficult to
handle with Condor DAGMAN.

---++ Basic Idea for Data Handling

We would direct jobs to sites that have a hadoop
file system available. Each job can copy its output
data to its site's file system, usually via a POSIX
interface, before exiting. Then, later, the user can
retrieve and delete the data from the site using srm
or gridftp.

There are
[[https://twiki.grid.iu.edu/bin/view/ReleaseDocumentation/OSGStorageDiscoveryTool][OSG Discovery Tools]] 
that indicate which sites have storage elements and (at least nominally) how much room
they have.

As an example
<pre class="screen">
   get_srm_storage_element_id --vo engage --free_online_size 100000 --show_site_name
</pre>


---++ Current Todo Items

   a. Put together a small test case. -- Done.
   a. Get the full executable compiled. -- In progress.
   a. Fix OSGMM to transfer the executable
      everywhere it's needed. --
   a. Test ability to find storage elements, transfer
      data to them from the worker node, and independently
      transfer the data to a third site. -- Done.
   a. Write script to produce a list that that has the hadoop
        engage directory for each site. If the directory is
        not mounted from the worker node, then instead there
        should be an srm command that will copy data there. -- Started
   a. Write a wrapper script to (eventually) run the
      job that copies the data to the correct SE
      directory after the program is done. -- In progress.
   a. Write a script that will copy the data from
      all (?) the storage elements to the ultimate
      destination. --
   a. Write scripts to clean up and list the
      directories where we are keeping data. --

We hope to be running after the new year.


-- OSG User Support - 15 Dec 2011
