%META:TOPICINFO{author="MarkoSlyz" date="1329376640" format="1.1" reprev="1.1" version="1.1"}%
%META:TOPICPARENT{name="WebHome"}%
---+ Running !SuperB  Jobs on OSG

---++Introduction

Members of the !SuperB VO would like to start running
jobs on OSG. To talk about this, there was a
meeting on 1/17/12 including Armando Fella (INFN
Padova), Luca Tomassetti (INFN Ferrara), Steffen Luitz
(SLAC), Marko, Tanya, and Gabriele.

---++History

In the past !SuperB has run at SLAC and Caltech on
RH5/SL5 x86_64 using the gLite suite to submit jobs via
an EGI WMS system. This is a push-based system.  The
system submits to the sites using a CE hostname list
(GRAM URL: CE / Hostname / port).

The !SuperB VOMS servers are
  https://voms2.cnaf.infn.it:8443/voms/superbvo.org
and
  voms-2.pd.infn.it
These should interoperate with OSG.

---++Requirements

Input and Output data: Applications need to access 10GB
to 50GB of common input data.  Either POSIX or SRM
access has been used in that past and is ok.
  There is about 200MB of output data per job now. Not
expected to be over 1GB. Use lcg-utils to register and
send output data back.
  Access to the !SuperB storage should be controlled by
VOMS Roles. For example, only users with a
!ProductionManager role may have read/write access to
storage.

Application: The main application is Monte Carlo using
geant4. The application is ~50MB. This is prestaged as
a tar ball in advance of the runs, then each run
sends a small amount of data.

Amount of compute time: The last production used 400
dedicated cores at SLAC which amounted to 8% of
production. [How long are the jobs?]

!SuperB does not need to recover failed jobs. Can just
resubmit.


Other framework software:

   * Use GANGA for job management.  Ports are the same as
     before.
   * Use Nagios to get information on how many jobs are
     running, pending, or failed.
   * !SuperB jobs communicate using curl to a bookkeeping
     DB at CNAF. On CNAF side there is an apache server
     listening on 8443 and 8080. On job side the curl command
    just chooses the first available high port on WN and
    use that.

The following URL includes the ports used per EGI
service and LHC experiment on the worker nodes:
  https://twiki.cern.ch/twiki/bin/view/LCG/LCGPortTable

---++ Status of Work

* superbvo.org is a recognized OSG VO. According to
  the command
     get_os_versions --vo superbvo.org
  it has access to CIT_CMS_T2, CIT_HEP,
  !GridUNESP_CENTRAL, SPRACE, WT2. There is some
  question about at least SPRACE access which is being
  checked.

* There was a problem with !GridUNESP_CENTRAL reporting
  which has been solved. !GRIDUNESP_CENTRAL is now
  showing up at
     http://is.grid.iu.edu/cgi-bin/status.cgi

  The !SuperB jobs access information about the CE and
  SE's from BDII in order to move data to and from the
  worker nodes using lcg-utils tools. There is a
  failover method in the job wrapper that allows the
  jobs to return data even if BDII is not working.

* We have asked that Production request wider support
  for the !SuperB VO. The Ohio Supercomputing Center may
  be good to contact.

* Have found out from OSG Sites that we could put in a
  request for sites to map each VOMS role, like
  !ProductionManager, into a separate unix account. Then
  it's up to the VO to set up the directories and
  permissions as needed. At least CMS and Atlas already
  use roles this way at OSG sites.

* The next !SuperB production run should be around June.


-- OSG User Support
