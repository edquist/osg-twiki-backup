%META:TOPICINFO{author="GabrieleGarzoglio" date="1279837719" format="1.1" reprev="1.8" version="1.8"}%
%META:TOPICPARENT{name="EngageLSST"}%
%TOC%

---+!! LSST Image Simulation on OSG Phase 2

---++ Introduction.

The Phase 2 is starting in Jun 2010 with the goal of simulating one entire night of data taking by LSST.

This is the [[EngageLSST][documentation for the phase 1 of the project]]

---++ Requirements

<b>DRAFT</b><br>
These requirements need to be vetted with LSST. <br>
Items marked with question marks (??) are the most uncertain.<br>

---+++ Application requirements

The LSST detector consists of 189 adjacent chips. The LSST Simulation application simulates as independent jobs the 189 chips of the LSST detector to create one simulated observation of the sky i.e. an image. The output of the 189 jobs can be optionally merged to generate the complete simulated image (does LSST want this step done on OSG for phase II ??).
   * Workflow: 189 simulation jobs --> 1 (optional) merge job

There are two main modes in which to run the simulation:
   * deep drill: simulate small region of the sky continuously imaged
   * wide field survey: simulate as much sky as possible for 1 night of observation

---+++ Platform requirements
Direct experience in job durations, IO requirements, etc. is reported below. This experience comes from running the LSST application on common OSG platforms for Phase I of the project.

The common OSG platforms considered are all combinations of {Scientific Linux sl4,sl5} and {i386,x86_64}. The LSST simluation binaries have been compiled for all these platforms and that were made available at the sites in $OSG_APP (in phase I using the OSG MM).

   * Simulation job duration on common OSG platforms = 2 - 4 hours / job (average over 189 jobs = 140 minutes)
   * Simulation job application = unix binaries
   * Simulation job Memory requirement = 1 GB ?? (some jobs failed w/ out-of-memory)
   * Merging job duration = Estimate 15 minutes (uncompress 10 MB of input * 189 + concatenate the images) ??
   * Merging job application = MatLab (is there a unix binary for this?)
   * Memory requirement = 1 GB ??

---+++ I/O Data requirements

   * Input to the simulation job:
      * Galaxy files: a catalog of the objects in the sky.
         * They are fairly static: it may change once per year.
         * They consists of 4000 files, 46 MB overall compressed, 362 MB overall uncompressed.
         * Each job needs access to all galaxy files
         * In phase I, these were pre-installed in OSG_DATA
      * CAT files: generated from the galaxy files to describe what each chip will see, including effects such as atmospheric aberrations, the direction and speed of the wind, the position of the moon, etc.
         * Each job needs a different and specific CAT file as input. This is true for both deep drill and wide field survey simulation modes.
         * Each file consist of 7MB compressed.
         * In phase I, these were pre-installed in OSG_DATA
      * One random seed per job

   * Output of the simulation job:
      * 1 FITS file per simulation job: an image in the NASA FITS format, which keeps together the image with its metadata
         * These are 10 MB compressed, 1 per chip


   * Input to the merging job
      * 189 FITS files from the simulation jobs
         * 10 MB compressed, 1 per chip

   * Output of the merging job:
      * 1 final image: this is the final output of the workflow. It is an image in FITS format.
         * About 2 GB compressed ??


---+++ Phase 2 specific requirements
The goal of Phase 2 is to simulate 1 night of data collection for LSST. This consists of 500 pairs of focal plane images = 1000 images

This consists of about 200,000 simulation jobs (1 chip at a time) and 1000 merging jobs.

Assuming an upper limits of 4 hours per job, this consists of  800,000 CPU hours

Assuming we can sustain 2000 simultaneous simulation jobs across the grid i.e. 50,000 CPU hours / day, this takes
   * 17 days to complete the production, w/o counting failures
   * 12,000 jobs / day , w/o counting merging jobs
   * 84 GB / day of input CAT files (different for every job); each job also needs access to 46 MB of Galaxy files (same for every job)
   * 120 GB / day of output for the simulation
   * If files are kept in a Storage Element, this workflow requires about 1000 connections per hour (500 for input, 500 for output)
   * Total number of simulation files = 400,000 (200,000 input + 200,000 output)
   * Total output compressed from simulation jobs = 2.0 TB (10 MB per job)

Requirements for the merging jobs (possibly not necessary)
   * 1000 merging jobs
   * 189 FITS files of input, 2 GB of total input per job
   * 1 FITS file of output, 2 GB in size ??
   * Amount of computation for 1 job = 15 minutes (estimate) ??
   * Total amount of computation = 250 CPU h (estimate) ??
   * Total output of final images: 1000 images, with total size of 2TB

Lifetime and access requirements
   * For how long should the storage elements keep the files? = ??
   * Are the output of the simulation jobs valuable after merging? = ??
   * Where should the output be kept? = ??
   * Who should have access to the files ? How often per day ?
   * How much data will be moved per day?


---++ Project Execution Plan

This link shows an [[http://home.fnal.gov/~garzogli/LSST/LSST-on-OSG-Phase-2-plan/LSST-on-OSG-Phase-2-v1.2.html][outline of the project execution plan]], with timeline and associated resources. 

Older versions of the plan are maintained in [[http://home.fnal.gov/~garzogli/LSST/LSST-on-OSG-Phase-2-plan/][the same directory]]


---++ Architecture

---+++ Simple Architecture
     <img src="%ATTACHURLPATH%/LSST-Architecture-Jul22-10.jpg" alt="LSST-Architecture-Jul22-10.jpg" width='960' height='720' />    

In this architectural configuration, computing resources are allocated via the GlideIn WMS system (OSG Glidein Factory) and are accessible to the user through a submission node running a condor scheduler. Input data is organized "manually" by the user at the submission node (Hadoop disk in the fig) and it is transferred to the worker node with the job by condor. Output is also returned to the submission node by condor. Binaries and common input file (Galaxy files) are pre-installed at all sites using the OSG Match Maker. The bookkeeping of the computational tasks (what jobs have failed, what need to be resubmitted, what percentage of the jobs have produced output, etc.) is done manually through condor.

More in detail, in reference to the figure

   1. The OSG Factory submit Glidein jobs to OSG clusters. When running, Glideins report the availability of computing resources (worker nodes) to the condor collector. As jobs are submitted to the user scheduler (step 3 below), the Glidein VO frontend adjusts the number of glidein submitted to OSG to respond dynamically to the demand for computing cycles. 
   2. An LSST user logs into the Glidein submission machine (HCC at Nebraska). Using a command line user interface, she submits jobs with the granularity of a group of 189 jobs at the time (1 simulated LSST image). The user interface requires a seed, unique for the group of jobs (each job will then have its own unique seed), and a path to a directory containing the 189 input catalog files. In this model, these files can be organized in individual directories in the Hadoop file system 
   3. In a unique local directory, the user interface generates a DAGMan description, a job description file for the 189 jobs, and a post-completion evaluation job.  The user interface then submits the DAG and the jobs to the scheduler. 
      The DAG consist of 
      * an initial job that creates the context for the monitoring process
      * the 189 simulation jobs
      * a post-completion job that gather statistics, such as the distribution of job resubmission, total job duration, job duration when successful, condor "goodput", etc.</br>
      * <img src="%ATTACHURLPATH%/LSST-DAG-Jul22-10.jpg" alt="LSST-DAG-Jul22-10.jpg" width='385' height='252' />    
   4. The scheduler interacts with the condor collector to find an appropriate resource match for each job. The input file and the job are then dispatched directly from the hadoop storage to the selected worker node. As opposed to other grid submission systems (e.g. OSG MM), user jobs submitted through the glidein WMS system start immediately i.e. without waiting in any remote batch system queue. The output is then transferred back using condor mechanisms.
   5. A periodic monitoring process publish on the web operationally-oriented characteristics of each job group, such as the number of completed output files, the link to post-completion statistics (see point 3), the related input and run directory, submission and modified time, etc. 

The system is designed to be fault tolerant. If a job fails because of problems with the resource (e.g. network connection problems, job pre-emption, etc.) the job is automatically resubmitted by the system indefinitely. If the job fails because of application errors (missing binaries at the remote location, bug in the code, etc.), DAGMan resubmits the job up to 5 times. After this process, if the job did NOT succeed (exit with status 0), DAGMan creates a "rescue" DAG description file, which can be manually resubmitted to rerun only failed jobs. 

---+++ Data Handling-enabled Architecture

In parallel to the simple architecture describe above, we have considered the use of IRODS as a candidate OSG data handling solution. A data handling system would enable file cataloging, access of input and storage of output from / to multiple (redundant) storage elements, output file-oriented bookkeeping of the computation. At this time (Jul 1, 2010), it is unclear that IRODS will be deployed to OSG in time for the integration with the LSST Phase 2 project. 


---+++ VO Workload Management (possibly useful for Phase 3 and beyond)
Node requirements for GlideIn frontend

   * Frontend:
      * Fast Multicore CPU
      * Webspace for monitoring
      * 1GB memory

   * User Pool + Schedd:
      * Medium fast CPU
      * Large Memory (16GB recommended). The memory requirement for the Schedd are 4 MB / jobs (in detail, the shadow process requires 8M Virt; 4M Res). For LSST it would be at least 4M * 2000+ = 8+GB.

Examples of current production setups -

   * Minos: Frontend+User Pool and WMS Collector+ User and WMS Schedd + Factory  ( 8 core server, 16 GB Memory)
   * Samgrid: minor difference w.r.t. the Minos setup
   * CMS Setup1: Frontend+User Pool Collector (32GB, 8CPU) ; User Schedd (32GB, 8CPU)
   * CMS Setup2: Frontend (8GB, 8CPU); User Pool Collector + User Schedd (32GB, 8CPU)

For LSST, we recommend 1 machine with Frontend + User Pool Collector + User Schedd (16GB, 8CPU)

---++ Commissioning

---+++ Results from 61 job groups

The infrastructure has been initially tested submitting 61 job group, corresponding to 61 simulated images. Each job group consists of 189 individual jobs, each simulating a CCD chip. Considering the upper limit of an individual job using 4 CPU hours (an over-estimate), 60 job groups made of 189 individual jobs is the computation available with 2000 nodes used 100% efficiently for 24 hours i.e. ~ 50,000 CPU hours.

   * 61jobs_on_2010-07-13.png: <br />
     <img src="%ATTACHURLPATH%/61jobs_on_2010-07-13.png" alt="61jobs_on_2010-07-13.png" width='507' height='310' />    

   * 61jobs_CPUhours_on_2010-07-13.png: <br />
     <img src="%ATTACHURLPATH%/61jobs_CPUhours_on_2010-07-13.png" alt="61jobs_CPUhours_on_2010-07-13.png" width='1161' height='734' />    

%META:FILEATTACHMENT{name="LSST-Architecture.jpg" attachment="LSST-Architecture.jpg" attr="h" comment="Simple Architecture" date="1277921754" path="LSST-Architecture.jpg" size="110770" stream="LSST-Architecture.jpg" tmpFilename="/usr/tmp/CGItemp18593" user="GabrieleGarzoglio" version="1"}%
%META:FILEATTACHMENT{name="LSST-Architecture-Jul22-10.jpg" attachment="LSST-Architecture-Jul22-10.jpg" attr="" comment="" date="1279831240" path="LSST-Architecture-Jul22-10.jpg" size="77671" stream="LSST-Architecture-Jul22-10.jpg" tmpFilename="/usr/tmp/CGItemp18740" user="GabrieleGarzoglio" version="1"}%
%META:FILEATTACHMENT{name="LSST-DAG-Jul22-10.jpg" attachment="LSST-DAG-Jul22-10.jpg" attr="" comment="" date="1279832593" path="LSST-DAG-Jul22-10.jpg" size="28669" stream="LSST-DAG-Jul22-10.jpg" tmpFilename="/usr/tmp/CGItemp18744" user="GabrieleGarzoglio" version="1"}%
%META:FILEATTACHMENT{name="61jobs_on_2010-07-13.png" attachment="61jobs_on_2010-07-13.png" attr="" comment="" date="1279835838" path="61jobs on 2010-07-13.png" size="41321" stream="61jobs on 2010-07-13.png" tmpFilename="/usr/tmp/CGItemp18664" user="GabrieleGarzoglio" version="1"}%
%META:FILEATTACHMENT{name="61jobs_CPUhours_on_2010-07-13.png" attachment="61jobs_CPUhours_on_2010-07-13.png" attr="" comment="" date="1279835864" path="61jobs CPUhours on 2010-07-13.png" size="97518" stream="61jobs CPUhours on 2010-07-13.png" tmpFilename="/usr/tmp/CGItemp18830" user="GabrieleGarzoglio" version="1"}%
