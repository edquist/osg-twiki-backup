%META:TOPICINFO{author="GabrieleGarzoglio" date="1304437245" format="1.1" version="1.3"}%
%META:TOPICPARENT{name="EngageOpenSeesB"}%
---+ Production-demo Phase of Integration of the Network for Earthquake Engineering Simulation (NEES) running !OpenSees on the Open Science Grid

<b>
This page describes the production-demo phase of integration of NEES on OSG.<br>
The [[EngageOpenSeesB][proof-of-principle phase of integration of NEES with OSG is described at this link]].<br>
</b>

---++ Introduction

%TOC%

During the  [[EngageOpenSeesB][proof-of-principle phase of integration of NEES with OSG]], the OSG User Support team has worked with NEES to enable a proof-of-principle of direct job submission as well as of portal-based job submission.

For the case of direct job subssion, NEES ran 300 !OpenSEES jobs for an estimated 2400 hours to analyze the response of a structure called the Self-Centering Steel Plate Shear Wall (SC-SPSW) system.

The OSG User Support team is now helping NEES scale up its workload on OSG by about 2 orders of magnitude. This activity is considered a demo of production computations for NEES. This work is done in support of Andre' Barbosa, a graduate student from UCSD.

---++1. Requirements for Direct Job Submission

   * Computational needs:
      1. Resource needs: RAM < 1 GB; Scratch disk: 20 GB
      1. Number of jobs per simulation: 180 (corresponds to 180 different earthquake records)
      1. Number of parameter sets to simulate: 21 (10 strength/stiffness parameters * 2 different percentile values + 1 mean value)
      1. Total number of jobs = 3780 (180 * 21)
      1. Job duration: 6-12 hours
      1. Measured CPU hours per simulation (180 jobs): ~40 cores * ~4 days = ~3840 CPU hours
      1. Total estimated CPU hours = 80640 CPU hours (~4 days on OSG @ 1000 CPU / day)

   * Data needs:
      1. Input per job: 60 MB
      1. Output per job: 2 GB ASCII uncompressed = ~1 GB compressed.
      1. Total output: ~ 4 TB

   * Network needs:
      1. Assume: 1 GB output, 8 hours / job, 1000 jobs continuously = 1000 (MB/s per job) / (8 h * 3600 s/h) * 1000 jobs = 35 MB/s average bandwidth. If we transfer data to the storage repository while running jobs, we'll need twice as much bandwidth. Note: this is a calculation of average, but this bandwidth will be required in bursts. The submit node has 2 * 1 Gbit eth interfaces, which should satisfy this requirement.

   * Calendar time:
      1. Need results in a few weeks (by June?)

---++2. Division of Responsibilities

The OSG User Support team will be responsible for:
   * Build a version of !OpenSEES that does not depend on MPI. Our goal is to eventually transfer this responsibility to the maintainers of the code.
   * Help Andre' adapt his application to work on the WAN. The main potential issues are data handling and operation monitoring. In particular, to transport the job output (1 GB per job) we'll initially use condor and evaluate if a different solution is needed.
   * Help Andre' set up a data transferring infrastructure to move his output from the Engage submit node to his storage repository. We expect that this activity will produce ~4 TB of data, more than the current available space on the submit node.

Andre' Barbosa will be responsible for:
   * Andre' has been running his simulation on a 5 nodes condor cluster. On the WAN we recommended to organize his input and output as single *compressed* archives. Andre' has changed his jobs and input preparation process to support this.
   * Andre' will need to validate the results obtained on OSG. In particular, he'll need to validate the results generated by the MPI-less build of !OpenSEES.
   * Andre' will run his operations on OSG via the Engage Glidein WMS front end. Andre' is responsible for deciding what jobs to run, for monitoring their progress, for maintaining enough disk space to accept the output of the jobs, and for cataloging the output.

Our goal is to enable Andre' to run his operations by the 1st week of May.


-- Main.GabrieleGarzoglio - 02 May 2011