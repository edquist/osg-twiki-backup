%META:TOPICINFO{author="KyleGross" date="1225985976" format="1.1" version="1.4"}%
%META:TOPICPARENT{name="MeetingMinutes"}%
---+!!<nop>%TOPIC%
%TOC%
%STARTINCLUDE%


---++Introduction
Minutes of the Integration meeting, November 10, 2005.

   * Last meeting, MinutesNov3
   * Previous meetings: MeetingMinutes
   * Coordinates: 2:30pm Central, 1-510-665-5437 #1212
   * This weeks osg-int [[http://listserv.fnal.gov/scripts/wa.exe?A1=ind0511b&L=osg-int][archive]]

---++ Attending

Leigh, Neha, Xin, Greg, Marco, Rob, John, Burt, Eric, David Meyers, Doug, Michael, Horst, Dane, Mike, 
Fred, Mark, Frank, Alan, Ruth, Bockjoo, Iosif


---++ Agenda

   * Storage discussion (Neha)
   * Monalisa issue (John, Iosif)
   * Validation
   * Worker node environmnent in OSG 0.4
   * ITB 0.3.0 sites status update
   * Sign-off on next face-to-face meeting, November 30-Dec 1, Fermilab


---++ Storage Focus

Neha will lead a walk-through of storage documents :

   * http://osg.ivdgl.org/twiki/bin/view/Storage/WebHome
      * StorageElementAdmins information for Integration
      * SRMClientTools - srmcp client tools and such
   * LocalStorageRequirements  - notes from the "ad-hoc CE storage group"

It is important that all OSG site administrators and application
developers understand the changes these might imply for the next release of
OSG 0.4.  It is important to have read these before the meeting so we can provide 
meaninful feedback.

---+++ Neha

   * Has been coordinating with Ruth the various SE efforts, see links.
   * General lack of documentation for instructions. Primary goal is to set the twiki pages.
   * "What is a SE?" - Going over the definition, and will include the "local CE storage", that is storage as viewed from within the CE, LocalStorageRequirements.   Xin points out that many sites will have only local storage.
   * Next section discusses development of instructions for various types of SE installation and configuration. Neha is providing pointers to existing documentation, and will be sending feedback to the original documents.
Hope is to add value to existing documents developed elsewhere. 
   * Add a section for Gridftp-based/NFS only SE?
   * Anyone expecting to use the CERN SRM? Ans: from Ruth, not for OSG 0.4.
   * Alex Sim is helping with some of the documentation, and a couple of people at Fermilab.
   * Marco will help with the instructions for the local storage part (take agreements from LocalStorageRequirements and turn into instructions).
   * Suggest to Neha contacting Jane Liu for dCache
   * What about GIP's?  Reference rather than duplicating text.
   * Bockjoo is working with Shaowen on getting srm/SE attributes correctly stored (" =--srm= ").  Large amounts of information is missing for SE's.  Will these be added? (Both Neha and Shaowen will be at SC05, perhaps resolve there.) What needs to be added? From scratch? There are questions asked (site name, access protocol, ...).  Frank notes that there are large differences between the LCG versions, and the current version from Shaowen. Bockjoo will take a pass at resolving the attributes and send what he finds to Shaowen.
   * Hope to get this document completed by November 30 meeting at Fermilab.

---+++ Local Storage Issues - Marco

   * Document defines names and variables, and how they are provided.  (Two ways: either through the Globus jobmanager and local scheduler scripts, and from the information system.)
   * The variables define paths to local disk from the point of view of the CE (visible from the cluster).
   * "CE Storage" might be confusing (fkw).   Marco's point is that these definitions are properties of the compute element.  *Note*: they are not necessarily implemented on the same hardware.  Whenever a job lands at a site, it sees these storage spaces.  We should make this clear to the site admins what the site setup options. Note- jobs that land on worker node, whatever the method, still have to see the same spaces.
   * Other issue: the $GRID directory - left unresolved in the discussion.  Should grid install directory be visible from the worker nodes or not. Frank: yes. For example, an =srm-cp= client available in my path, and in a standard way, no matter where I land.  Do we want this to be the same package? (has client and server packages). What should, and should not be exposed? Would need to review carefully. 
   * Three packages?
      * OSG-Server
      * OSG-Client (for job submission, includes Condor-G) 
      * OSG-WN-Client (has stuff needed by landed jobs on compute nodes) - served from $GRID.
   * There is also the static grid3-info.conf script, its needed for GIP, and should be maintained for backwards compatibility for some time. (Mark notes there is a character limitation for passing environmental variables via PBS.)  This could be a problem for sites that do not want to run an NFS server on the gatekeeper.
   * Franks comments. Addressed in points above.
   * Propagation of the grid proxy.
      * Normally requires shared directory
      * LCG doesn't have shared directory, propagates via the job manager.  What about OSG?
      * For OSG, we will require a shared directory for the time being (OSG 0.4).
      * Need to articulate, separately, where we store the user proxy certificate and gass cache. (eg. $HOME) -- but the site must be responsible for this.
      * The documentation has to describe these types of CE storage spaces (so far): $GRID, $APP, $DATA.
   * Minimum requirement for an OSG site has four options, see: LocalStorageRequirements#Minimum_requirements
   * How does DRM map into these four options? Have they implemented Posix I/O?
   * What changes for OSG will site admins need to be advised of?
   * Applications perspective.
   * *Note* Marco will provide a new link which articulates the agreements. This will be linked to Neha's page.
   * Xin: How does an application developer find out which scenario is in use?  GIP, grid3-info.conf, and GridCat.

And then?:

   * Identify components of OSG-WN-Client.  Supposed to be "universal" tools.  Ruth believes the VirtualOrganizations/VOInfo's should be responsible for this, stored by the VO. 
   * =configure-osg.sh= asks the questions for the variables.  This would have have to be re-written (Leigh and Marco will collaborate).  What about unused (empty) variables?  Leave empty.



---++ Monalisa and Vojobs Issue (John, Iosif)

This might have been discussed at length in the VDT meeting this morning. If so, can
we have a brief report here?  Not discussed there.

   * In OSG 0.3.0, VDT 1.3.7, the configuration script doesn't work.
   * The new one from Iosif is an improvement, but there remains a descrepancy in the variable names.
   * John will test another version, and will pass to Leigh to overwrite.


---++ Validation

   * ValidationPage, in particular USCMS Daily validation of the ITB, [[http://www.uscms.org/SoftwareComputing/Grid/Validation/][here]].  Burt and John have setup a page to validate the production releases. For the ITB it is under production.

   * From John, http://home.fnal.gov/~weigand/osg/osg-030.html


---++ Face to Face Meeting

   * The ITB signed off on November 30, December 1 @ Fermilab

---++ MEETING ENDED HERE...

---++ Workernode environment setup

   * Follow up on last week's discussion (Alain was to discuss with Stu)
   * Relevant for VDT 1.3.8 and therefore next ITB release


---++ ITB Installations as of last week (tbu: "to be udpated" during meeting)

   * Status of testbed installaions of ITB 0.3.0:
      * UC - [[http://pgl.uchicago.edu/twiki/bin/view/Tier2/DevITB][in progress]].  
      * IU - OSG 0.3.0-ws up, WS-GRAM working, MDS4 opened Bug [[http://bugzilla.globus.org/bugzilla/show_bug.cgi?id=3856][3856]]. Resource is in  GridCat with the shortname of [[http://osg-itb.grid.iu.edu/index.php?view=sitename&whichmap=us&numentries=100&sortval=services&id=16][IUPUI]]
      * TTU - not here
      * UB - not here
      * BNL - not here: from Xin via email: _Yes, I have done the pacman install part on gridtest01, our new ITB GK. There was a problem in VDT that couldn't handle the globus user account home dir if it's on NFS (root squash), Alain said that will be fixed in VDT 1.3.8. We got around it yesterday and now I am about to configure it, but get distracted to many other things today..._
      * FNAL - no success - 
         * Burt was having problems with grid exerciser.  need to confirm with another site.  Alain consulted.  
         * John is having trouble with the configure monalisa script (this comes from VDT).  Alain is aware of this - needs a pretty big update - will be targeted for 1.3.8.  This was re-written to fit into the VDT environment better.  John has a URL describing the problem.  Some of this is VDT specific, not easily integrated back into VDT.  Iosif is helping, hope to provide a new version by tomorrow. 
      * IOWA - Have installed ITB release, and still have to configure Condor.  Could submit fork jobs just fine (pre-webservices version).  Hope to fix by end week. 
      * PU - was able to sort out issues with ws-gram not finding pbs logs.  Problem was with how local installation organizes its logfiles. Fixed with a symlink. Allow a site to designate a filename rather than a directory location (this is for ws-gram)?  Alain doesn't think its configurable at the moment (confirms later that the piece of gram that reads logfiles).  Submitting simple jobs from another box with gt4 client tools. Note - these are available separately in the VDT (for those that want to test).  Question comes up as to whether GridCat can develop a status check of these WS gatekeepers?  Suggestion is to whether this could be presented into the Discovery service.  (Aside - can the interface to the discovery service documented some place? Michael says is really meant as proof of concept rather than a designed interface for users. Can this be captured on a readiness plan? 
      * Caltech - Suresh is starting to work on upgrading their Opteron cluster.  Probably delayed till after SC05.
      * Kent - ligo will install after SC05.  Also want to upgrade with FC4.  (John is installing on FC4).  Alain - thought FC4 was already supported.  (Note will be trying to run on 0.3.0 sites.) Have tried on FSU.  Let Kent know when a site is ready, will send a LIGO application.
      * Horst - will also install when Panda work cools down.

   * Other comments - many of the questions are now gone.  Possible issue with Condor and Monalisa configuration. 



---++ AOB

   * 

-- Main.RobGardner - 10 Nov 2005

%STOPINCLUDE%