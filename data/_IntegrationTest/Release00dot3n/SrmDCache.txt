%META:TOPICINFO{author="ElizabethChism" date="1466010183" format="1.1" version="1.6"}%
<!-- This is the default OSG Trash/Integration template. 
Please modify it in the sections indicated to create your topic!
If you have any comments/complaints about this template, then please email me:
rwg@hep.uchicago.edu.  (Adapted from Atlas wiki template, Ed Moyse)
--> 

<!-- By default the title is the WikiWord used to create this topic !-->
<!-- if you want to modify it to something more meaningful, just replace %TOPIC% below with i.e "My Topic"!-->

---+!!<nop>Srm/dCache

%STARTINCLUDE%

---++ Introduction

For information on dCache, see [[http://www.dcache.org/manuals/index.shtml][dCache documentation]].

---++ Hardware/Software Requirements

There is no official list of supported platforms for dCache. 

Java 1.4 or 1.5 must be present. 

A <nop>PostgreSQL installation is needed. Version 8.0 is the "required" version. Though the latest dCache will run with 7.4, future versions may not. 

<nop>PostgreSQL 7.3 is known to not work. If you need to install Postgres, see PostgresInstallRPMS.

The software installation of pnfs and dCache only takes about 40 MB, but the database for a very large number of files can consume several gigabytes.

---++ Large Systems

For very large storage systems (20 to 100 TB), adequate performance requires installation over several nodes. There are many possibilities. For example, a large storage service may be configured as follows:

Behind the NAT/Firewall:
-----------------------

   * Node 1: PNFS Server using local postgres databases, and PNFS Manager
   * Node 2: <nop>AdminDoor, Replica manager using local postgres database
   * Node 3: 5 DCAP doors domains, each with a max login of ~500
   * Optional - More nodes like Node 3 (5 DCAP doors), if LAN load requires
   * Optional - Monitoring and pnfs backup node

   * CE Nodes: 2nd disk on CE should be deployed as resilient pools

   * SE Nodes: Optional - some sites are choosing to purchase separate high quality data servers to act as Storage Elements. If you choose to do this, these nodes should be configured to act as write pools, and your resilient pools on the CE should be configured to act as read pools.

On the public Network:
---------------------

   * Node A: dCache core: dCache, lm, httpd using local postgres database
   * Node B: SRM, space manager and pin manager - each using a local postgres database
   * Node C: gridftpdoor
   * Optional - More nodes like Node C (gridftpdoor), as WAN load requires


Use the same deployment if you do not have a NAT/firewall.


-- Main.TedHesselroth - 28 Nov 2005

