%META:TOPICINFO{author="guest" date="1109429199" format="1.0" version="1.1"}%
%META:TOPICPARENT{name="LeighGrund"}%
<html><head><title>OSG Quick Installation Guide</title>

<meta name="description" content="OSG">
<meta name="keywords" content="OSG-Quick-Install">
<meta name="resource-type" content="document">
<meta name="distribution" content="global"></head>
<body>
<div align="center">
<br>
<br>
<br>
<br>	 <span class="textbf">
		<big class="XXLARGE">OSG Quick Installation 
	 </big></span> <br>

<br>
<br>
<br>  
</div>
  
  <table cellpadding="3">
<tbody><tr><td align="left">Document identifier:</td>
<th align="left"><span class="textbf">OSG-DOC124</span></th>
</tr>
</tbody><tbody><tr><td align="left">Document Version:</td>
<th align="left"><span class="textbf"> 0.1.2 </span></th>
</tr>

<tr><td align="left">Date:</td>
<td align="left"><span class="textbf">16 February 2005</span></td>
</tr>
<tr><td align="left">Author:</td>
<td align="left"><span class="textbf">Leigh Grundhoefer, Greg Cross</span></td>
</tr>
</tbody></table>
  <span id="txt49">Abstract</span>: OSG Quick Installation 
  <br>

<h2><a name="SECTION000000"> Contents</a>

</h2>
<!--Table of Contents-->

<ul class="TofC">
<li>
<a name="tex2html54" href="http://igoc.ivdgl.indiana.edu/grid-install/documentation/OSG-step.html#SECTION000010">Pre-installation checklist </a>
</li>
<li><a name="tex2html57" href="http://igoc.ivdgl.indiana.edu/grid-install/documentation/OSG-step.html#SECTION000300">Getting Pacman</a>
</li><li><a name="tex2html59" href="http://igoc.ivdgl.indiana.edu/grid-install/documentation/OSG-step.html#SECTION000500">Installing the OSG software</a>
</li><li><a name="tex2html60" href="http://igoc.ivdgl.indiana.edu/grid-install/documentation/OSG-step.html#SECTION000600">Compute Element Middleware Setup</a>
</li> <li> <a name="tex2html60" href="http://sdm.lbl.gov/srm-dist/DRM-VDT-UserGuide.html">Storage Element Setup </a>

</li><li> Optional VO-level services Setup
<ul>
<li><a name="tex2html60" href="http://www.cs.wisc.edu/vdt/VOMS-documentation.html">VOMS (Authorization)</a>
</li></ul>
</li><li><a name="tex2html61" href="http://igoc.ivdgl.indiana.edu/grid-install/documentation/OSG-step.html#SECTION000700">Certification Authorities</a>
</li><li><a name="tex2html62" href="http://igoc.ivdgl.indiana.edu/grid-install/documentation/OSG-step.html#SECTION000800">Host Certificates</a>
</li><li><a name="tex2html62" href="http://igoc.ivdgl.indiana.edu/grid-install/documentation/OSG-step.html#SECTION000810">Authorizing VO users</a>
</li>
<li><a name="tex2html63" href="http://igoc.ivdgl.indiana.edu/grid-install/documentation/OSG-step.html#SECTION000900">Site Verify</a>
</li><li><a name="tex2html64" href="http://igoc.ivdgl.indiana.edu/grid-install/documentation/OSG-step.html#SECTION001000">Firewalls</a>

</li><li><a name="tex2html65" href="http://igoc.ivdgl.indiana.edu/grid-install/documentation/OSG-step.html#SECTION001100">Contacts</a>
</li><li><a name="tex2html66" href="http://igoc.ivdgl.indiana.edu/grid-install/documentation/OSG-step.html#SECTION001200">About this document ...</a>

</li></ul>

<h1> Introduction </h1>
This document is addressed to Site Administrators in charge of the OSG 
middleware installation and configuration.
<br>It is a rough guide to the installation.

<br>It provides a method to install and configure the OSG middleware on the 
on the top of the many Linux distributions. 

<ul>
<li>RedHat 7.x,</li><li> RedHat 9.0, </li><li> RedHat Enterprise Linux 3, </li><li>Fedora Core 3 and </li><li> Debian Linux 3.1 (sarge). </li></ul>

It may work on other Linux releases but we do not test them. 

The proposed installation and configuration method is based on <a href="http://physics.bu.edu/pacman/">Pacman</a>.  Pacman is a package manager like RPM or dpkg, but is able to work on and support multiple platforms.

<br>
<p> 
Questions, problems and support may be obtained from the Grid
Operations Center before, during and after the installation.
</p><p>
<b> Contacting Support </b>
</p><ul>
  <li>iGOC phone number : +1 317 278 9699 </li>
  <li>Email address : igoc at ivdgl.org. </li>

  <li> <a href="http://igoc.ivdgl.indiana.edu/test/index.php"> Web
form </a> </li>
</ul>
<h1><a name="SECTION000010">
Pre-installation Checklist</a>
</h1>
<ol>
<li> <b>System or cluster already installed.</b>
  It is assumed that your hardware is already running one of the operating 
  systems previously mentioned. If your system is a cluster, 
  the batch queuing system should be likewise previously installed and 
  configured, unless you intend to use the Condor system that will be 
  installed with the grid middleware.  

</p><p>
<b>Preserving a pre-existing Condor installation</b>
</p><p>
If you would like to preserve your 
Condor installation 
you can setup the installer to recognize it by setting
two environment variables.
</p>
<p>

Doing so will produce the following effects:
</p><ul>
<li>Condor will be installed but not configured. 
</li><li>The Grid middleware will point to the necessary locations in your 
	 external Condor installation.
</li></ul>
<p></p>
<p>
To specify an external Condor installation you need to set the
following two environment variables before starting the installation:
</p><ul>

  <li><b>VDTSETUP_CONDOR_LOCATION</b> - the location of your Condor installation 
(e.g. <i>/opt/condor</i>). The Condor <i>bin/</i>, <i>sbin/</i>, <i>etc/</i>, <i>lib/</i>...
 directories should be directly under this location.
  </li><li><b>VDTSETUP_CONDOR_CONFIG</b> (optional): The location of your Condor configuration
  file (if non-standard). Default is <i>$VDTSETUP_CONDOR_LOCATION/etc/condor_config</i>.

</li></ul>

<p>
</p></li><li> <b>Existing reliable network.</b>
It is assumed that your hardware is connected to a reliable network
connection by which the software may be retrieved and from which
services may contact your system.
</p></li><li> <b>Time synchronization (NTP) and reverse name lookups (DNS).</b>
	Each system should be setup to support network time protocol.
	Lack of synchronization generally complicates troubleshooting 
	and can cause problems with the security 
	infrastructures evaluation of eg. proxy lifetimes.
</p><p>
	Also for the middleware to correctly function both the forward and
	reverse lookups as configured through a local DNS service are required
	for the IP address of the system.
</p>
</li><li> <b>Unique OSG site name.</b>

  Each OSG site will need to designate a <b>unique name</b>
by which services and resources may refer to the site. This name will
be displayed on the Site Catalog and used in tables for other
monitoring and accounting.  For example, the University of New Mexico has a
unique name of UNM_HPC; the University of Buffalo is Buffalo_CCR.
</p></li><li> <b>Previous Grid3 installations.</b>
 If there is <b>previous installation</b> of the Grid3 environment or 
 other Globus middleware please <b>stop the processes</b> which are currently running.
 This includes the Globus Resource Information Service, MonaLisa and other 
 services configured to start upon initialization on your system.
 More information is provided in the <a href="http://igoc.ivdgl.indiana.edu/grid-install/documentation/grid3-shutdown.html"> 
 Grid3 shutdown document</A>.

</p>
</li><li> <b>Creation and setup of VO accounts.</b>

VO accounts need to be created by the system administrator. 
The accounts are: 
<ul> <li>"cdf"</li><li> "grase"</li><li> "fmri",</li><li> "gadu",</li><li> "btev",</li><li> "uscms01",</li><li> "uscms02", </li><li>"usatlas1",</li><li> "sdss",</li><li> "lsc01" and,</li><li> "ivdgl". </li></ul><p></p>

<p> Ensure that the users are enabled to use the batch queuing system.
</p></li></ol>
<p></p><h1><a name="SECTION000300">
Getting Pacman</a>
</h1>
The Pacman tool downloads a local copy and then installs the software needed for
 the installation. During the installation, scripts are run
to specially configure the local node. More about using Pacman
can be found from the <a href="http://physics.bu.edu/pacman"> Pacman Documentation. </a> 

<ol>

  <li><b>Download Pacman.</b> <a href="http://physics.bu.edu/%7Eyoussef/pacman/sample_cache/tarballs/pacman-2.126.tar.gz">Pacman 2.126</a> is the most recent version
  tested with VDT 1.3.2.  <a href="http://physics.bu.edu/pacman/sample_cache/tarballs/pacman-latest.tar.gz">

  Pacman 3.x</a> also works well with VDT 1.3.2. You can choose
  either version, but our directions are phrased in terms of Pacman
  2. You will find small differences in command-line options between
  the two versions.  Future versions of the VDT will require Pacman
  3.x. If you will be using Pacman version 3 ensure the correct python version 
  is installed and available (2.3.x or newer).
<p>
  To download Pacman 2.126 via wget:
  </p><pre>&gt; <b>wget http://physics.bu.edu/pacman/sample_cache/tarballs/pacman-2.126.tar.gz </b>
</pre>
  For Pacman 3.x:
  <pre>&gt; <b>wget http://physics.bu.edu/pacman/sample_cache/tarballs/pacman-latest.tar.gz </b>
  </li><li><b>Unpack the tarball.</b>  Note that Pacman does not need to 
reside in your VDT directory.

<p>
For Pacman 2.126:
<pre>&gt; <b>tar xzvf pacman-2.126.tar.gz</b></pre>
For Pacman 3.x:
<pre>&gt; <b>tar xzvf pacman.latest.tar.gz</b></pre>
  </li><li><b>Setup your environment to use Pacman.</b> 
<pre>&gt; <b>cd pacman-*</b></pre>

For sh and bash:

<pre>$ <b>source setup.sh</b></pre>
For csh and tcsh:
<pre>% <b>source setup.csh</b></pre>
</pre>
</li></ol>
<p>


</p><h1><a name="SECTION000500">
Installing the OSG software</a>
</h1>

<ol><li>
	 <p> <b>Decide on an installation directory for the software.</b>
This is typically <b>/usr/local/grid</b>, but whatever suits the
local resource structure is fine. If you are installing on a
cluster, this directory must be available on all the nodes. 
If this directory is not shared additional installation of
software will be required on each of the worker nodes. Nearly all of
the software to be installed is from the Virtual Data Toolkit (VDT).
They maintain complete and detailed installation instructions for the
software at the following location <b> <a href="http://www.cs.wisc.edu/vdt/installation-1.3.2.html">
http://www.cs.wisc.edu/vdt/installation-1.3.2.html. </a> </b>
</p><p> The installation described here is done as root.  However, non-root
installs are supported.  Not all services will run as root; Condor, 
MonALISA and the GRIS will run as the user "daemon". If you prefer to run
MonALISA and/or Condor with its own UID, you need only to create a 
<b>monalisa</b> and/or <b>condor</b> user before proceeding with installation the VDT will configure the daemons appropriately. 

</p>
<p>Create and change into your VDT directory.  For the purposes of this document,
the directory will be <b>/usr/local/grid</b>.  It is suggested that you set 
assign the variable <b>$VDT_LOCATION</b> to the VDT directory.</p>
<p>For sh and bash:
<pre>$ <b>VDT_LOCATION=/usr/local/grid; export VDT_LOCATION; cd $VDT_LOCATION</b></pre>
<p>For csh and tcsh:
<pre>% <b>setenv VDT_LOCATION /usr/local/grid; cd $VDT_LOCATION</b></pre>
<p> A few questions regarding trust of the caches from which the software is
downloaded will be displayed. Please answer <b>y</b> (yes) so that the
software can be retrieved. </p>

<pre>
# <b>pacman -get iVDGL:osg-0.1.2</B> 
Do you want to add [iVDGL] to [trusted.caches]? (y or n): <b>y</b>
Package [osg] found in [iVDGL]...
Package [osg-auto] found in [iVDGL]...
Package [VDT_132] found in [iVDGL]...
Do you want to add [http://www.cs.wisc.edu/vdt/vdt_132_cache] to [trusted.caches]? (y or n): <b>y</b>
...
...
...
</pre>
If you plan to use Condor, answer <b>y</b> (yes) to the question posed regarding setting up the Condor JobManger.  <br>

<pre>If you would like, we can set up a Globus jobmanager interface
to Condor.

This will allow Globus Gatekeeper to run jobs on Condor.

Would you like to enable Globus jobmanager for Condor?
Choices: y (yes), n(no), s (skip this question) <b>y</b>
</pre>
<p>
 Other questions may be asked it is safe to answer <b>n</b> (no).
</p>

<p><b>This will take between 10 and 60 minutes to complete, depending
upon the system and network connection.</b> The installation should complete
with the following message. During this time you may open a second 
terminal and watch the progress by monitoring the vdt-install.log file.</p>
</li>

<li>
  <b>Set up your environment.  Assuming the Pacman install completed without
fatal errors, you should now be able to source the OSG setup environment.</b>
<pre>  $ <b>cd $VDT_LOCATION; source setup.sh</b>
</pre> 
or
<pre>  % <b>cd $VDT_LOCATION; source setup.csh</b>
</pre> 
</li>
  <li> <b><i>Optional extra packages for PBS, LSF, or FBSng setup</i></b><br>

	 <p> An extra package will be required to setup access to an
existing PBS, LSF, or FBSng installation. 
<b>Ensure that that the command-line utilities for your batch system 
are in your path,</b> then install the appropriate package (for PBS, LSF, or 
FBSng, respectively): </p>
<pre># <b>pacman -get http://www.cs.wisc.edu/vdt/vdt_132_cache:Globus-PBS-Setup</b><br><br>
# <b>pacman -get http://www.cs.wisc.edu/vdt/vdt_132_cache:Globus-LSF-Setup</b><br><br>
# <b>pacman -get http://www.cs.wisc.edu/vdt/vdt_132_cache:Globus-FBSNG-Setup</b><br>	</pre>

  </li>
</ol>
<h1><a name="SECTION000600"></a>
<a name="Compute Element Middleware Setup"></a><br>
Compute Element Middleware Setup
</h1>
<ol>
<li> <b>Globus configuration.</b> 
Globus has been pre-configured for this installation. If you wish
reconfigure it, please review the <a href="http://www.cs.wisc.edu/vdt/globus_config.html">
Globus Configuration Script</a> document on using
the <b>$VDT_LOCATION/vdt/setup/configure_globus.sh</b> script. </p>

<p> Check that the xinetd daemon is running, or restarted it and
  review the configuration files /etc/xinetd.d/globus-gatekeeper and
  /etc/xinetd.d/gsiftp. Additionally these services must be listing 
  in the "/etc/services" file.
</p>

</li><li>
<b>Configuring the Grid3 information provider.</b>
The setup of Grid3 Information Provider is partly accomplished with the
assistance of the configuration script, configure-grid3.sh and partly
by modifying a few files with detailed information. Enter the <b>unique name</b> when asked for the Grid3 SITE NAME</p>
<p>
If you are upgrading your site <b> save the $APP/etc/grid3-locations.txt file before running the configure-grid3 script</b> Please restore it after completing the configuration.

</p>
<pre># <b>cd $VDT_LOCATION</b><br># <b>. ./setup.sh</b><br># <b>cd monitoring</b> <br># <b>./configure-grid3.sh</b><br><br>Please specify your GRID3 SITE NAME [shagbark.ucs.indiana.edu]: IU-CE0<br><br>Please specify your GRID3 BASE_DIR [/opt/osg/]: <br><br>Please specify your GRID3 APP_DIR [/app]: <br><br>Please specify your GRID3 DATA_DIR [/data]: <br><br>Please specify your GRID3 TMP_DIR [/scratch]: <br><br>Please specify your GRID3 TMP_WN_DIR [/tmp]: <br><br>Please specify your GRID3 VO [iVDGL]: <br><br>Please specify the Batch Queuing to be used [condor]: <br><br><br>Please review the information:<br>Grid Site Name: IU-CE0<br>Grid3 Location: /opt/grid3v2.4/<br>Application: /app<br>Data /data<br>Shared Temp: /scratch<br>WorkerNode Temp: /tmp<br>JOB Manager: condor<br><br>Is this information correct (y/n)? [n]: y<br>#<br></pre>

<p> Start the information service daemon&gt;
</p><pre>  # /etc/init.d/gris start
</pre> 
</li><li>
<b>Job Policy and the Batch Queuing System </b>
	 <p>A queuing manager is used to execute the incoming grid jobs.
The configuration of a queue manager is beyond the scope of this
document. </p>
</li><li>
<b>Configuring MonaLisa </b>
	 <p> The setup of MonaLisa is done with the assistance of the
configuration script. However there are two files which need editting.
The site_env script must be modified by-hand to set the location of 
the batch queue. Also the VDTFarm/vdtFarm.conf file must be updated
for the new TracePath module</p>

	 <ul>
		<li> Run the configuration script <a href="http://www.cs.wisc.edu/vdt/releases/1.3.2/configure_monalisa.html">/$VDT_LOCATION/vdt/setup/configure_monalisa.sh</a> to setup MonaLisa. 
<b> The OSG-ITB group should be enter when queried for the group.  </b>
	  </li>
		<li>Edit the site_env file:
	  <p> To have  MonaLisa interact with the local batch queuing system, 
			the file site_env will need to specify the location of the local 
			installation directories. </p>

<pre>	 # cd $VDT_LOCATION/MonaLisa/Service/CMD
	 # vi site_env
</pre>

 <p> Make sure the location variable for your batch system is setup and 
	  exported, eg:
 </p>
 <p> PBS_LOCATION or LSF_LOCATION or FBNSG_LOCATION as appropriate. </p>
 <pre>	 PBS_LOCATION="/usr/local/pbs";
	 export PBS_LOCATION;
 </pre>
</li>

<li> Edit the vdtFarm.conf file:

	  <p> To have  MonaLisa use the Tracepath module the vdtFarm.conf
			will need to be edited with the following line added.

</p><pre>	*Tracepath{monTracepath, localhost, " "}
</pre>
<p></p>
</li> <li> Start MonaLisa:
 <pre>  # /etc/init.d/MLD start
 </pre> 
</li>
</ul>
</li></ol>

<p></p><h1><a name="SECTION000700">
Certification Authorities</a>
</h1>
<h3>Setup and maintenance of Certificate Authority connection </h3>
	 <p> The default Certificate Authority should be configured to be
the DOEGrids CA. Here is the list of <a href="http://www.cs.wisc.edu/vdt/releases/1.3.2/certificate_authorities.html"> CA's </a>
which were added as authorized CA's on your system. Please review the list of authorized CA's.  The VDT installed
the daemon script (/etc/init.d/edg-crl-upgraded)
which should be running at all times. This program checks for and
updates the certificate revocation lists (CRL's) for each of the
Certificate Authorities (CA's) installed. If CRLs are not kept current
incoming connections will fail. </p>
	 <ul>
		<li> Configure the DOEGrids CA to be used by default by running
 the utility below. If there is an option given <b> choose the option 
 which matches "1c3f2ca8 : ..." then "q" </b> at the prompts.
		  <pre> # $YOUR-VDT_LOCATION/vdt/setup/setup-cert-request
Reading from /g3dev/globus/TRUSTED_CA
Using hash: 1c3f2ca8
Setting up grid-cert-request
Running grid-security-config...

<br>...<br></pre>
	 </ul>
<p></p><p>

</p><h1><a name="SECTION000800">
Host Certificates</a>
</h1>

<h3>Request and install the host certificate for the resource </h3>
	 <p>To authorize this resource for use, a host certificate needs to
be
requested from an appropriate Certificate Authority. Currently the
<a href="http://igoc.ivdgl.indiana.edu/grid-install/documentation/www.doegrids.org"> DOEGrids CA </a>is in use.
iVDGL and PPDG project instructions for getting a certificate are available at the <a href="http://igoc.ivdgl.indiana.edu/RAinfo/newra/"> iVDGL RA </a>

and <a href="http://www.ppdg.net/RA"> PPDG RA </a> pages </p>
	 <p> Here is a brief guide to the process assuming you have a valid
User Certificate. </p>
	 <ul>
		<li> Run grid-cert-request to generate your host's private key -
hostkey.pem,
and the certificate request.
		  <pre># cd $VDT_LOCATION<br># . ./setup.sh<br># ./globus/bin/grid-cert-request -host YOUR_HOSTNAME_AND_DOMAIN<br>Using configuration from /usr/local/grid3v2.4/globus/etc/globus-host-ssl.conf<br>Generating a 1024 bit RSA private key<br>.++++++<br>.........................................................++++++<br>writing new private key to '/usr/local/grid3v2.4/globus/etc/hostkey.pem'<br>-----<br>...<br></pre>

The certificate request is stored in the file hostcert_request.pem The
important part refereed to as the PKCS#10 request, is as below:
		  <pre>-----BEGIN CERTIFICATE REQUEST-----<br>MIIBmzCCAQQCAQAwWzETMBEGCgmSJomT8ixkARkTA29yZzEYMBYGCgmSJomT8ixk<br>ARkTCGRvZWdyaWRzMREwDwYDVQQLEwhTZXJ2aWNlczEXMBUGA1UEAxMObXlob3N0<br>ZS5pdS5lZHUwgZ8wDQYJKoZIhvcNAQEBBQADgY0AMIGJAoGBALMM/3jhhkGUA3uz<br>5h4dzUzluDbCdBonv3UjeWbBFyh1JUA3d2148WBTtHAfQuB+f61tRcia2j5eEQEg<br>TwQnx86VaG8mAOk6gKe/zZlfhVkYR6OY1ssmc3dtkFoIprVoUUJCviq9DUp3DRO/<br>57/AtDAJsPhAl/UY5d2jFWl9jYGtAgMBAAGgADANBgkqhkiG9w0BAQQFAAOBgQAr<br>ZS88q8AgsOJ3n0EJoiAvr6dws4mr94Xg9uohNogmGsdjsdM3LG6Q+Qb22YdPPEH9<br>3HeLtcBlsjEnBq/a+M4IsfnPCn/6hvJs0HS7PxSR98bE116Ik4zuM1dtQ1Ce8Q/h<br>YtfstZj7FRZPZP1Lg2uftazDst4dkuu0msBP7dUAZw==<br>-----END CERTIFICATE REQUEST-----<br></pre>
		  <p>Copy the hostkey.pem, in $VDT_LOCATION/globus/etc/, to the
/etc/grid-security directory preserving
the read only for root permissions. </p>
		</li>

		<li> Connect to the DOEGrids CA server and paste this into the
area provided in the form at this link. <a href="https://pki1.doegrids.org/ManServerEnroll.html">https://pki1.doegrids.org/ManServerEnroll.html</a>
		  <b> All of the information must be filled out and in the
additional comments
section add the institutional <a href="http://igoc.ivdgl.indiana.edu/RAinfo/newra/rastaff.php">
sponsor </a> </b> </li>
		<li> Then email will be received indicating a link to retrieve
the Host
certificate, hostcert.pem. Goto the link and download it on the host. </li>

		<li>After obtaining the host certificate install it into the
directory
/etc/grid-security as hostcert.pem. Use the following openssl command
to verify the certificate.
		  <pre> # openssl x509 -text -noout -in /etc/grid-security/hostcert.pem <br>[kileh@worldgrid g3]$ openssl x509 -text -noout -in /etc/grid-security/hostcert.pem<br>Certificate:<br>	 Data:<br>		  Version: 3 (0x2)<br>		  Serial Number: 1578 (0x62a)<br>		  Signature Algorithm: sha1WithRSAEncryption<br>		  Issuer: DC=org, DC=DOEGrids, OU=Certificate Authorities, CN=DOEGrids CA 1<br>		  Validity<br>				Not Before: Mar 19 14:48:32 2004 GMT<br>				Not After : Mar 19 14:48:32 2005 GMT<br>		  Subject: DC=org, DC=doegrids, OU=Services, CN=worldgrid.iu.edu<br>.....<br></pre>

		</li>
	 </ul>
<p>
</p><h1><a name="SECTION000810">Authorizing VO users </a>
</h1>Each of the Virtual Organizations maintains a secure Membership
service which may be queried with the utility
$VDT_LOCATION/edg/sbin/edg-mkgridmap utility.
To create a gridmapfile containing an entry for every
member of the VO start the edg-gridmapfile-upgraded daemon.
<pre>  # /etc/init.d/edg-gridmapfile-upgraded start
</pre>

<h3> Setup and testing access to VOMS services</h3>

  After the installation has finished email must be sent to the 
  VO administrator to request that your site be given access to the 
  VOMS database. This access depends upon knowledge of the Distinguished 
  Name (DN) of the host and the CA which issued the host certificate.  

<p></p><p> The site should test the edg-mkgridmap script to ensure
there are no connection errors to the VOMS services. This needs to be
executed as root so that the host certificate can be used.
</p><pre>		# cd YOUR_VDT_LOCATION/edg/sbin
		# ./edg-mkgridmap --verbose --output=test.out
</pre>
	
  The most common error is "Internal Server Error" which indicates 
  that access to the VOMS DB has not been completed.
<p></p>
<h3> <B>Optional</b>Setting up edg-mkgridmap for Local Users </h3><p>

  The edg-mkgridmap script uses a configuration file to dictate 
  it's behavior. This is distributed with the Grid3 parameters
  YOUR_VDT_LOCATION/edg/etc/edg-mkgridmap.conf.

</p><p>
  The edg-gridmapfile-upgrade daemon has a similar configuration
  file YOUR_VDT_LOCATION/edg/etc/edg-gridmapfile-upgrade.conf.
  

</p><p>
  One of the parameters specifies a LOCAL grid-mapfile that
  will be added to the output of the edg-mkgridmap command.
</p><pre>  There are two steps to make this work:

  1) Set the GRIDMAP_LOCAL_FILE in 
	 YOUR_VDT_LOCATION/edg/etc/edg-gridmapfile-upgrade.conf

GRIDMAP_LOCAL_FILE=/YOUR-PREFERRED-PATH/grid-mapfile-local}

	2) Add a new directive to the end of the
		YOUR_VDT_LOCATION/edg/etc/edg-mkgridmap.conf 

gmf_local /YOUR-PREFERRED-PATH/grid-mapfile-local
 
</pre>
  
  Now local grid-mapfile entries to this file will be 
  added every time the script is executed.


<p></p><h1><a name="SECTION000900">
Site Verification</a>
</h1>

<h3>Site Verify script checks<br>
	 </h3>

  
To verify many of the software installed by OSG download and
execute the site_verify perl script. Download the <a href="http://griddev.uchicago.edu/download/grid3/doc.pkg/WIP/site_verify.pl">Site
Verify script</a> and Click or go to <a href="http://griddev.uchicago.edu/download/grid3/doc.pkg/WIP/site_verify_pl.html"> http://griddev.uchicago.edu/downl
oad/grid3/doc.pkg/WIP/site_verify_pl.html </a> for Site Verify documentation. Here is how:
  <p> # wget
http://griddev.uchicago.edu/download/grid3/doc.pkg/WIP/site_verify.pl <br>
# cd $VDT_LOCATION <br>
# . ./setup.sh <br>
# grid-proxy-init "enter your pass phrase" <br>

# perl site_verify.pl --host=YOUR_HOSTNAME<br clear="all">
  <br>
The Grid Exerciser application will attempt to execute on this site. </p>
<h4>MonALISA and its information providers </h4>
<p>
Launch the MonALISA client tool from the page a <a href="http://gocmon.uits.iupui.edu:8888/index.html">http://gocmon.uits.iupui.edu:8888/index.html</a>
The client is launched from the "Start MonALISA Client" button on the
top of the left hand menu. On the running MonaALISA (ML) client, check
that your site is reporting to ML and that it is correct geographical
location (mouse over the dot and it will display the site name, make
sure it is the name you picked out that conforms to the naming
convention). To check that the various information providers are
reporting to ML go to the TabPan view (on the left hand menu bar) and
check that all of the table entries for your site are providing
information, compare with other sites. If there are "Unknown" entries
in the fields then most likely there is error in the ML configuration
files you modified.&nbsp; Please go through the instructions and
contact the iGOC if you need help. <br>

</p>
<h1><a name="SECTION001000"> Firewalls</a>
</h1>
<p>
Grid componets are distrubted throughout the network and services 
such as gatekeepers and data movement utilties are required to be 
accessible to the dynamic cloud gof clients and peer services.
This ditributed and dynamic requirement places the burden
of the security on the implementation of the application.
</p><p>
Network based applications in recent years, due to the discovery of
significant vulnerablities, are untrusted. To solve the application
problem effort has focused on developing and deploying firewalls which
restricts full and free network access.  This is analogous to building 
a house with no doors. Is it safe? Yes. Is it useful. No.
</p><p>
Some network based application which are essential have been
"hardened" such as the mail relaying software, web servers and secure
logins daemons. These are further protected further by IP address 
filtering to prevent access from "unknown" IP or domains.
</p><p>
Grid componnets which are located behind network firewall 
face special challenges for the grid setup and operations. 
</p><p>
There are two styles of firewalls usually encountered. 

</p><ul> <li>A network firewall which is "upstream" from your server and 
usually centrally maintained. This blocks all traffic to your 
host. 


</li><li> A "host-based" firewall which are setup and maintained 
by individual host administrators. This is usually setup and configured
by the "iptables" program which filters incoming network packets which 
arrive for the host.

</li></ul>
 In addition to host based firewalls, hosts can choose to 
 implement host based access rules ussually setup with the "tcp_wrapper"
  or hosts_allow utilties.
<p>
Network traffic can be blocked at the firewall for both incoming and outgoing
depending on individual host-names, ip addresses, ranges of 
ip address, individual ports and protocols. 
</p><p>

A common setup is to allow any outgoing connection,
while significantly restricting, if not totally restricting, 
incomping connections.

The Globus project provides a excellant document on this subject which I will
not repeat here. However, you should read and understand the detail provide
therein.

The mosts recent document from the Globus security people on 
"Globus Toolket Firewall Requirements" can be found  via a link on the webpage
http://www.globus.org/security/v2.0/firewalls.html

</p><pre>IP port usage which may require firewall updates:
	MDS		2135/tcp
	GRAM		2119/tcp
	GridFTP		2811/tcp
	GRAM callback	contiguous range if tcp ports as specified by the
			GLOBUS_TCP_PORT_RANGE=start,stop. 
								A minmun range of 100 for a small site. 
	MonAlisa:	9000/udp (for ABping measurements).
			These are specified in the file 
	$VDT_LOCATION/MonaLisa/Service/{assigned cluster name}/ml.properties
	
These ports and protocols must be open to all grid clients and
server machines participating in the grid in order to provide minimal
functionality.

Optional IP ports 

	GIIS	2136/tcp
	GSISSH	22/tcp
	MyProxy	7512/tcp
		  EDG-VOMS-ADMIN	 8443/tcp
		  EDG-VOMS	 15000/tcp
	RLS server 39281/tcp

</pre>
<p>

</p><h1><a name="SECTION001100">
Contacts</a>

</h1>
For questions and suggestions dealing with this document please contact the iGOC. 
<p>
<b> Contacting Support </b>
</p><ul>
  <li>iGOC phone number : 1-317 278 9699 </li>
  <li>Email address : igoc at ivdgl.org. </li>
  <li> <a href="http://igoc.ivdgl.indiana.edu/test/index.php"> Web
form </a> </li>

</ul>

<p>

</p><h1><a name="SECTION001200">
About this document ...</a>
</h1>
 <strong>OSG Installation &amp; Configuration Guide</strong><p>
</p><p>
</p></body></html>

