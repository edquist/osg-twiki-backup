%META:TOPICINFO{author="BrianBockelman" date="1218812797" format="1.1" version="1.41"}%
---+!! *<noop>%SPACEOUT{ "%TOPIC%" }%*
%TOC%

The Open Science Grid (OSG) Generic Information Provider (OSG-GIP) are a core part of the OSG Information Infrastructure. They should be configured carefully by the resource administrator to correctly publish the information about the site. Information collected by the GIPs is sent through CEMON to a central LDAP (BDII) server. Information selected by request to the GOC is then transferred from the OSG BDII to the EGEE BDII to support interoperability between the grids.

The GIP is a grid information service that aggregates static and dynamic resource information for use with LDAP-based information systems. The GIP produces information based on the [[http://glueschema.forge.cnaf.infn.it/SpecV13/LDAP][GLUE Schema]].

---++ Installation
 The Generic Information Provider is installed with the standard OSG CE installation. To activate it, you must complete the configuration section of this document.

---++ Configuration
 When you run =configure-osg.py= it will create an gip-attributes.conf file that will record all the information needed to run =configure_gip=. The details of the information collected can be found in the [[https://twiki.grid.iu.edu/bin/view/Main/OSGConfigurationParameters#GIP][OSG Configuration Parameter]] twiki. =configure_gip= runs transparently.

---++ Validation Webpage
 A Validator for GIP using information from the OSG BDII can be found at [[http://gip-validate.grid.iu.edu/]].

One can execute:
<pre>ldapsearch -x -LLL -p 2170 -h is-itb.grid.iu.edu -b mds-vo-name=YOUR_SITE_NAME_HERE,mds-vo-name=local,o=grid </pre>

For a complete set of instructions to validate information published to BDII, see the ValidateBDII page.

For instructions to validate information published to !ReSS, see the [[ResourceSelection.WebHome#ValidationLinks][ReSS validation links]].

---++ Adding site specific attributes to GIP output that are not included in Glue schema
%NOTE% This feature is only available in OSG v1.0 (June 11, 2008).

The GIP uses the Glue Schema to publish information about the site; however, the Glue Schema constraints GIP to only publish a fixed set of attributes.

The problem of adding custom information to our sites keeps arising under different circumstances. For example
   1 FNAL uses a grid to fabric requirement forwarding: how to set batch system constraints to submit jobs to a subcluster specified via grid requirements; 
   1 MPI parameters: how to give applications information about MPI library location, version, etc. 

Extending the Glue schema is an option, but the process is time consuming and requires coordination among various Grids. Without this coordination, OSG cannot extend this schema for its own purposes because it breaks interoperability with LCG.

Our solution to this problem is giving a mechanism for administrators to extend the schema published by GIP and filter out these extra attributes before they are published to BDII. This way, the schema available in BDII is still compliant with the Glue Schema and interoperability is maintained. At the same time, other information systems, such as ReSS, will be able to publish the extra custom attributes for the OSG users.

---+++ How do I get my GIP to publish non Glue Schema attributes?
 The procedure in this section is for adding new attributes to existing DNs. 
%NOTE% If you want to add a completely new DN, follow instructions in case 2 ("adding new DNs") in section "[[GenericInformationProviders#Overwriting_attributes_published][Overwriting attributes published by GIP]]" below. 
   1 Add the extra attributes to appropriate GIP templates file.  There are two sets of templates for GIP 1.0, and both must be edited.  Look in $VDT_LOCATION/gip/templates and $VDT_LOCATION/templates/compat.  In the upcoming GIP 1.0.2 bugfix release (slated for September 2008), you do not need to edit *any* templates.  Just add it to alter-attributes.conf, as documented in the next step.
     The only restrictions on the newly added attributes are: 
      * The attribute should not start with the keyword 'Glue' 
      * It should not be called 'dn' 
      * It should not be called 'objectClass' 
   1 Set the value that you want to publish . This can be done in any of the following ways: 
      * Add an entry in the alter-attributes.conf file to change this value. (see how to do this in case 1 in section "[[GenericInformationProviders#Overwriting_attributes_published][Overwriting attributes published by GIP]]" below). 
      * You can set static attribute value in the template file (step 1) 
      * Write a more full-fledged plugin, if the values you need to publish change dynamically. (GIP plugins and providers included in the GIP can be found in $VDT_LOCATION/gip/libexec/) 
   1 Run $VDT_LOCATION/vdt/setup/configure_gip (if you don't, the values will get few hours to get updated, since configure_gip gets run every few hours) 
   1 Run $VDT_LOCATION/gip/libexec/osg-info-wrapper to see the GIP output. 

---++++!! An Example
 Let us say you want to advertise MPI attributes (!MPIInterconnect, !MPICompilerLocation, MPIVendor) that are associated with a particular subcluster. To accomplish this you would do the following 
   * First you will modify the $VDT_LOCATION/gip/etc/GlueCluster.template and add the following entry within the subcluster region <verbatim>MPIInterconnect:
MPIVendor:
MPICompilerLocation: </verbatim> 
   * Next update $VDT_LOCATION/gip/etc/alter-attributes.conf to add the values associated with the cluster. <pre>dn: GlueSubClusterUniqueID=mysubcluster1.univ.edu, GlueClusterUniqueID=mycluster.univ.edu,mds-vo-name=local,o=grid<br />MPIVendor: MPICH<br />MPIInterconnect: Infiniband<br />MPICompilerLocation: /usr/local/mpi/mpi-compiler<br /><br />dn: GlueSubClusterUniqueID=mysubcluster2.univ.edu, GlueClusterUniqueID=mycluster.univ.edu,mds-vo-name=local,o=grid<br />MPIVendor: OpenMPI<br />MPIInterconnect: GigE<br />MPICompilerLocation: /sw/mpi/mpi-compiler </pre> 
   * Next run $VDT_LOCATION/vdt/setup/configure_gip and verify the newly added values are getting propagated by checking the output of $VDT_LOCATION/gip/libexec/osg-info-wrapper, 
---++ Overwriting attributes published by GIP

Since =configure_gip= runs as a cron jobs site admins who used to manually update some values can no longer directly update the ldif files. Instead we have added two files: =alter-attributes.conf= and =add-attributes.conf=. These files are to be located at =$VDT_LOCATION/gip/etc/=. They exploit the plugin and provider mechanism of OSG-GIP to give admins the highest priority to set any values. This approach is particularly useful in case you want to add new dn's. This also makes it easier to preserve changes across software updates.

%IMPORTANT% If you want to alter or add multiple DNs, remember to have two new-line characters between the DNs.

%IMPORTANT% Each override entry has to begin with the line <br /> =dn: Glue...UniqueId=...,...= %BR% This line is crucial to identify where the information you are putting should go. This can be thought of as an hash key, telling GIP what exact attribute should be altered. ([[http://tille.garrels.be/training/ldap/ch01s03.html][More about the ldif format...]])

---++++!! Typical use-case for overwriting attributes

---+++++!! Case 1: Altering values published for attributes for existing DNs

This allows the site admin to alter the values that are being published.

Example 1: Changing the values associated with !GlueHostNetworkAdapterInboundIP and !GlueHostNetworkAdapterOutboundIP By default these attributes are initialized as follows:

<verbatim>GlueHostNetworkAdapterInboundIP: FALSE
GlueHostNetworkAdapterOutboundIP: TRUE </verbatim>

Let us say for example you want to specify that you Worker nodes don't have network access. This can be done as follows:

Edit/Create =$VDT_LOCATION/gip/etc/alter-attributes.conf=, and add lines similar to the example below (You need to change 'grow-test1.its.uiowa.edu' to your sites 'FQDN')

<verbatim>dn: GlueSubClusterUniqueID=grow-test1.its.uiowa.edu, GlueClusterUniqueID=grow-test1.its.uiowa.edu,mds-vo-name=local,o=grid
GlueHostNetworkAdapterOutboundIP: FALSE </verbatim>

Example 2: If you want to state that you have inbound access to your worker node, as well as change the Operating System value being published for this !SubCluster. In this case you will again edit =$VDT_LOCATION/gip/etc/alter-attributes.conf= and add the lines as you see in the illustration below.

<verbatim>dn: GlueSubClusterUniqueID=grow-test1.its.uiowa.edu, GlueClusterUniqueID=grow-test1.its.uiowa.edu,mds-vo-name=local,o=grid
GlueHostNetworkAdapterInboundIP: TRUE
GlueHostOperatingSystemName: My OS
GlueHostOperatingSystemRelease: MY OS RELEASE
GlueHostOperatingSystemVersion: MY-OS_V1 </verbatim>

---+++++!! Case 2: Adding new DNs
 This gives site admin a mechanism to publish new information that are not being published by GIP. This will be most useful if site admins want to publish multiple subclusters.

%NOTE% This is an addition to existing !DNs which are already being published.

Example: Let us say you already have one !SubCluster being published by !GIP and you would like to associate two more sub-clusters (with different architecture, !OS) within the same cluster. Let these be identified by unique IDs grow-subcluster1.its.uiowa.edu and grow-subcluster2.its.uiowa.edu, and let them be associated with the cluster grow-cluster.its.uiowa.edu. Then in order to publish these two new !SubClusters, we will add the following entries to the =$VDT_LOCATION/gip/etc/add-attributes.conf= file.

%IMPORTANT% It is important to get the !UniqueIDs correct since LDAP used them to form its directory structure

%STARTMore%
<verbatim>
dn: GlueSubClusterUniqueID=grow-subcluster1.its.uiowa.edu, GlueClusterUniqueID=grow-cluster.its.uiowa.edu,mds-vo-name=local,o=grid
objectClass: GlueClusterTop
objectClass: GlueSubCluster
objectClass: GlueSchemaVersion
objectClass: GlueHostApplicationSoftware
objectClass: GlueHostArchitecture
objectClass: GlueHostBenchmark
objectClass: GlueHostMainMemory
objectClass: GlueHostNetworkAdapter
objectClass: GlueHostOperatingSystem
objectClass: GlueHostProcessor
objectClass: GlueInformationService
objectClass: GlueKey
GlueChunkKey: GlueClusterUniqueID=grow-cluster.its.uiowa.edu
GlueHostApplicationSoftwareRunTimeEnvironment: OSG-ITB-0.5.2
GlueHostArchitectureSMPSize: 2
GlueHostBenchmarkSF00: 380
GlueHostBenchmarkSI00: 400
GlueHostMainMemoryRAMSize: 512
GlueHostMainMemoryVirtualSize: 1024
GlueHostNetworkAdapterInboundIP: FALSE
GlueHostNetworkAdapterOutboundIP: TRUE
GlueHostOperatingSystemName: MAC OS X
GlueHostOperatingSystemRelease: 10.4.6
GlueHostOperatingSystemVersion: Unknown
GlueHostProcessorClockSpeed: 1000
GlueHostProcessorModel: Mac
GlueHostProcessorVendor: Mac
GlueSubClusterName: grow-subcluster1.its.uiowa.edu
GlueSubClusterUniqueID: grow-subcluster1.its.uiowa.edu
GlueSubClusterPhysicalCPUs: 1
GlueSubClusterLogicalCPUs: 2
GlueSubClusterTmpDir: /grow/data-local/data
GlueSubClusterWNTmpDir: /tmp
GlueInformationServiceURL: ldap://grow-test1.its.uiowa.edu:2135/mds-vo-name=local,o=grid
GlueSchemaVersionMajor: 1
GlueSchemaVersionMinor: 2

dn: GlueSubClusterUniqueID=grow-subcluster2.its.uiowa.edu, GlueClusterUniqueID=grow-cluster.its.uiowa.edu,mds-vo-name=local,o=grid
objectClass: GlueClusterTop
objectClass: GlueSubCluster
objectClass: GlueSchemaVersion
objectClass: GlueHostApplicationSoftware
objectClass: GlueHostArchitecture
objectClass: GlueHostBenchmark
objectClass: GlueHostMainMemory
objectClass: GlueHostNetworkAdapter
objectClass: GlueHostOperatingSystem
objectClass: GlueHostProcessor
objectClass: GlueInformationService
objectClass: GlueKey
GlueChunkKey: GlueClusterUniqueID=grow-cluster.its.uiowa.edu
GlueHostApplicationSoftwareRunTimeEnvironment: OSG-ITB-0.5.2
GlueHostArchitectureSMPSize: 2
GlueHostBenchmarkSF00: 380
GlueHostBenchmarkSI00: 400
GlueHostMainMemoryRAMSize: 512
GlueHostMainMemoryVirtualSize: 1024
GlueHostNetworkAdapterInboundIP: FALSE
GlueHostNetworkAdapterOutboundIP: TRUE
GlueHostOperatingSystemName: RedHat Generic
GlueHostOperatingSystemRelease: RedHat Unknown
GlueHostOperatingSystemVersion: Unknown
GlueHostProcessorClockSpeed: 1000
GlueHostProcessorModel: Intel(R) Pentium(R) D CPU 3.00GHz
GlueHostProcessorVendor: GenuineIntel
GlueSubClusterName: grow-subcluster2.its.uiowa.edu
GlueSubClusterUniqueID: grow-subcluster2.its.uiowa.edu
GlueSubClusterPhysicalCPUs: 1
GlueSubClusterLogicalCPUs: 2
GlueSubClusterTmpDir: /grow/data-local/data
GlueSubClusterWNTmpDir: /tmp
GlueInformationServiceURL: ldap://grow-test1.its.uiowa.edu:2135/mds-vo-name=local,o=grid
GlueSchemaVersionMajor: 1
GlueSchemaVersionMinor: 2 </verbatim> %ENDMore%

---+++!! Configuring to publish GUMS information
 GIP is now automatically configured to to publish GUMS service status information. For more details, please look at [[http://vdt.cs.wisc.edu/releases/1.10.1/notes/GUMS.html]]

If you want to overwride the default behavior (i.e. you do not want GIP to publish status of your GUMS system), then set
<verbatim>
OSG_GIP_GUMS=0;
</verbatim> in $VDT_LOCATION/monitoring/gip-attributes.conf.

---+++ Major Updates for OSG 1.0.0
   1 New d-cache SE provider 
   1 New dynamic PBS provider 
   1 New Timestamp provider 
   1 VO-to-queue mapping for PBS 
   1 Improved local gip testing tools 
   1 Support for preset GIP_LOCATION 
   1 Support for Glue 1.3 
   1 Relaxed Timeout Values 

---+++!! Counting VMs in "Owner" State in Condor Batch system
 By default owner VMs are counted for the total CPU numbers published by GIP. According to Condor defn an Owner state implies "The machine is being used by the machine owner, and/or is not available to run Condor jobs". But technically it could be available in the future, for this purpose, GIP counts this field to determine total CPUs on the system, but it does not count this for the available CPUs or available slots. But some sites have been using this "Owner" state to create shadow pools which will be never available and should not be counted as a part of total CPUs.

In order to tell the GIP not to count the CPUs in "Owner" state for the total CPU count a site administrator should add the following line
<verbatim>
OSG_GIP_SUBTRACT_OWNER=1
</verbatim> to the $VDT_LOCATION/monitoring/gip-attributes.conf

This is available beyond ITB 0.7.0

---+++!! SQUID Monitoring
 Squid monitoring can be enabled by answering 'y' to the question 'Would you like to use the squid caching service?'.

Once enabled the squid monitoring script will advertise the $http_proxy variable or the $OSG_SQUID_LOCATION variable. Squid information will be advertised as a Service in the GLUE schema context.

---+++!! Adding site defined constraints to custom configure condor status commands
 In GIP, it is now possible to add "--constraint" options to condor commands from GIP, to allow for custom configuration of GIP values. This constraint gets passed on to condor_status requests made by the GIP dynamic plugins. The use case for this came from BNL, where they had the nodes being shared between both the ITB and production cluster and they specify constraints in their condor class ads, as to how many nodes are available in each case. By default GIP dynamic plugins get the information about free and total cpus by executing a "condor_status" command without any parameter. So GIP was publishing incorrect information that could potentially affect !ReSS. In order to address this use case we added a new attribute (OSG_GIP_CONDOR_STATUS_CONSTRAINT) can be added to gip-attributes.conf.

In order to enable this functionality (add administrator defined "--constraint" option to condor_status queries made by osg-info-dynamic-condor) add the following lines
<verbatim>
OSG_GIP_CONDOR_STATUS_CONSTRAINT="Your_constraint"
export OSG_GIP_CONDOR_STATUS_CONSTRAINT
</verbatim> to the $VDT_LOCATION/monitoring/gip-attributes.conf

An example constraint
<verbatim>
OSG_GIP_CONDOR_STATUS_CONSTRAINT="'CPU_Type == \"osgitb\"'"
</verbatim>

This feature is available beyond ITB 0.7.1

---++ Troubleshooting
   * Error comparing subject names.: Desired subject and actual subject of certificate do not match. %BR% Desired subject: =/CN=ldap/cmssrv09.fnal.gov= %BR% Actual subject: =/DC=org/DC=doegrids/OU=Services/CN=cmssrv09.fnal.gov= %BR% *Cause:* You are probably using your host certificate for your LDAP certificate. A common shortcut. 

   * Information is NOT sent to BDII or CEMon. Follow [[ResourceSelection.CEMonTroubleshootingGuide][CEMon troubleshooting guide]]. 

*In Progress*

---++ Miscellaneous Info
   * [[http://glueschema.forge.cnaf.infn.it/SpecV13/LDAP][GLUE 1.3 LDAP schema]] 
   * [[http://glueschema.forge.cnaf.infn.it/][Documents about GLUE]] 
   * Links from Laurence Field: 
      * [[http://lfield.home.cern.ch/lfield/cgi-bin/wiki.cgi?area=bdii&page=documentation][BDII]] 
      * [[http://lfield.home.cern.ch/lfield/cgi-bin/wiki.cgi?area=gip&page=documentation][GIP]] 
      * [[http://lfield.home.cern.ch/lfield/cgi-bin/wiki.cgi?area=glue&page=information][GLUE]] 
   * [[http://griddev.uchicago.edu/download/grid3/doc.pkg/GIIS-configuration/][Grid3 era]] 

---++ Useful LDAP Tool

If you run an un-authenticated GRIS / GIP and want to check your results a helpful tool is the [[http://www-unix.mcs.anl.gov/~gawor/ldap/][LDAP browser]].
   1 Download the zip/tar file and unpack it. 
   1 Start it by running the lbe.sh script. A graphical user interface will appear. 
   1 Create a new connection and enter the following properties for the new connection: 

<pre>    Host: your.fully.qualified.hostname     Port: 2135     Base DN: mds-vo-name=local,o=grid </pre>

If you would simply like to see what the GIP looks like when configured, feel free to use rsgrid3.its.uiowa.edu as a hostname.

---++ Explanation of BDii
 BDii is the Berkeley Database Information Index. It consists of two or more standard LDAP databases that are populated by an update process. The OSG-ITB BDii service is collecting GIP information from OSG ITB hosts which are listed in the OSG [[GridCat050][GridCat]] database which have installed OSG 0.1.6 (early version are not compatible).

The connect to the BDii service standard LDAP querying command can be used.

<pre>> *ldapsearch -LLL -x -h is.grid.iu.edu -p 2170 -b "o=grid"* </pre>

The BDii server name is "is.grid.iu.edu" the BDii port to query is 2170.

Other useful query examples follow:

This query returns site information for !FermiGrid. Piping the output of ldapsearch into perl prevents ldapsearch from cutting the output at column 80.

<pre> > ldapsearch -x -l 60 -b mds-vo-name=local,o=grid  -h is.grid.iu.edu -p 2170  "(GlueSiteName=FNAL_FERMIGRID)"  | perl -00pe 's/\r*\n //g' </pre>

This query returns information about all Authorization services.
<pre>> ldapsearch -x -l 60 -b mds-vo-name=local,o=grid  -h is-itb.grid.iu.edu -p 2170  "(&(objectClass=GlueTop)(objectClass=GlueService)(objectClass=GlueKey)(objectClass=GlueSchemaVersion)(GlueServiceName=Authorization))"  | perl -00pe 's/\r*\n //g' </pre>

---++ Explanation of GIP / Glue Attributes

What follows is a large amount of [[http://glueschema.forge.cnaf.infn.it/Spec/V13][Glue attributes]] which are added by the GIP with some notes on what the attributes mean.

%NOTE% Not all the values here have been properly configured; yet, they are just provided as an example.

---+++!! GlueSite

*OSG unique site name* <br /> =GlueSiteName: CIT_CMS_OSG=

*Human readable description of the site* <br /> =GlueSiteDescription: Caltech CMS OSG Site=

*Site email contacts*
<verbatim>
GlueSiteUserSupportContact: mailto: my@email.com
GlueSiteSysAdminContact: mailto: my@email.com
GlueSiteSecurityContact: mailto: my@email.com
</verbatim>

*Geographic location of the site*
<verbatim>
GlueSiteLocation: Pasadena, US 
GlueSiteLatitude: 34
GlueSiteLongitude: 118
</verbatim>

*Web site describing the site, if any*
<verbatim>
GlueSiteWeb: http://www.opensciencegrid.org
</verbatim>

---+++!! GlueCEUniqueID

GlueCEUniqueID defines a gatekeeper combined with a jobmanager and queue. The format for the GlueCEUniqueID is hostname:port/jobmanager-batch-queue .

*Please note that 'jobmanager-condor-atlas' does not exist as a submittable jobmanager. 'jobmanager-condor' is the actual jobmanager that exists while 'atlas' is the queue that the job should be submitted to*

*The idea is that this should express how many CPU's are available at this time to a VO*

<verbatim>
dn: GlueCEUniqueID=rsgrid3.its.uiowa.edu:2119/jobmanager-condor-atlas, mds-vo-name=local,o=grid
GlueCEHostingCluster: rsgrid3.its.uiowa.edu
GlueCEName: atlas
GlueCEUniqueID: rsgrid3.its.uiowa.edu:2119/jobmanager-condor-atlas
GlueCEInfoGatekeeperPort: 2119
GlueCEInfoHostName: rsgrid3.its.uiowa.edu
GlueCEInfoLRMSType: condor
GlueCEInfoLRMSVersion: 6.7.7
</verbatim>

*How many total CPU's (busy or available) are accessible on this queue via Grid interfaces to all VO. This parameter can be customized by site administrators.*
<verbatim>
GlueCEInfoTotalCPUs: 10
GlueCEInfoJobManager: condor
GlueCEInfoContactString: my-ce.my.domain:2119/jobmanager-condor-atlas
</verbatim>

*How many total job slots (busy or available) are accessible by policy via Grid interfaces for a certain VO. For PBS, VO information is not available: the parameter is the total number of job slots for any VO i.e. !GlueCEInfoTotalCPUs*
<verbatim>
GlueCEPolicyAssignedJobSlots: 0
</verbatim>

*How many CPU's are available right now via Grid interfaces to all VO*
<verbatim>
GlueCEStateFreeCPUs: 10
</verbatim>

*How many job slots are available right now via Grid interfaces for a certain VO. For PBS, VO information is not available: the parameter is min( maximum_number_of_queuable_jobs - total_jobs_in_queue , free_cpus_for_the_queue ). In general, maximum_number_of_queuable_jobs may be different from free_cpus_for_the_queue by administrative policy.*
<verbatim>
GlueCEStateFreeJobSlots: 0
</verbatim>

*RunningJobs + WaitingJobs*
<verbatim>
GlueCEStateTotalJobs: 0
</verbatim>

*How many jobs are waiting in the queue*
<verbatim>
GlueCEStateWaitingJobs: 0
GlueCEStateWorstResponseTime: 0
</verbatim>

*How long a VO can expect to wait before being submitted to a machine*
<verbatim>
GlueCEStateEstimatedResponseTime: 0
</verbatim>

*How long a job may remain in the queue before being removed (CPU time)*
<verbatim>
GlueCEPolicyMaxCPUTime: 0
GlueCEPolicyMaxRunningJobs: 0
GlueCEPolicyMaxTotalJobs: 0
</verbatim>

*How long a job may remain in the queue before being removed (Wall time)*
<verbatim>
GlueCEPolicyMaxWallClockTime: 0
GlueCEPolicyPriority: 1
</verbatim>

*Which VO may run jobs on this queue*
<verbatim>
GlueCEAccessControlBaseRule: VO:atlas
GlueForeignKey: GlueClusterUniqueID=rsgrid3.its.uiowa.edu
GlueInformationServiceURL: ldap://rsgrid3.its.uiowa.edu:2135/mds-vo-name=local,o=grid
</verbatim>

---+++!! GlueSubClusterUniqueID

GlueSubClusterUniqueID provides information about what grid software version is installed on the cluster as well as general information about a cluster. It also can hold VO published information about what software has been installed. For example, !GlueHostApplicationSoftwareRunTimeEnvironment: CMKIN could also be added by a VO.

<verbatim>
dn: GlueSubClusterUniqueID=rsgrid3.its.uiowa.edu, GlueClusterUniqueID=rsgrid3.its.uiowa.edu, mds-vo-name=local,o=grid
GlueChunkKey: GlueClusterUniqueID=rsgrid3.its.uiowa.edu
</verbatim>

*GlueHostApplicationSoftwareRunTimeEnvironment lists all the software installed on the cluster*
<verbatim>
GlueHostApplicationSoftwareRunTimeEnvironment: LCG-2
GlueHostApplicationSoftwareRunTimeEnvironment: LCG-2_1_0
GlueHostApplicationSoftwareRunTimeEnvironment: LCG-2_1_1
GlueHostApplicationSoftwareRunTimeEnvironment: LCG-2_2_0
GlueHostApplicationSoftwareRunTimeEnvironment: LCG-2_3_0
GlueHostApplicationSoftwareRunTimeEnvironment: LCG-2_3_1
GlueHostApplicationSoftwareRunTimeEnvironment: LCG-2_4_0
GlueHostApplicationSoftwareRunTimeEnvironment: R-GMA
GlueHostArchitectureSMPSize: 2
</verbatim>

*The SI and SF benchmarks have been used to make sure that a job will finish in a cluster before being removed*
<verbatim>
GlueHostBenchmarkSF00: 0
GlueHostBenchmarkSI00: 381
GlueHostMainMemoryRAMSize: 513
GlueHostMainMemoryVirtualSize: 1025
</verbatim>

*Method of publishing information about whether or not the cluster nodes have inbound / outbound access*
<verbatim>
GlueHostNetworkAdapterInboundIP: FALSE
GlueHostNetworkAdapterOutboundIP: TRUE
GlueHostOperatingSystemName: Redhat
GlueHostOperatingSystemRelease: 7.3
GlueHostOperatingSystemVersion: 3
GlueHostProcessorClockSpeed: 1001
GlueHostProcessorModel: PIII
GlueHostProcessorVendor: intel
GlueSubClusterName: rsgrid3.its.uiowa.edu
GlueSubClusterUniqueID: rsgrid3.its.uiowa.edu
GlueSubClusterPhysicalCPUs: 0
GlueSubClusterLogicalCPUs: 0
GlueSubClusterTmpDir: /tmp
GlueSubClusterWNTmpDir: /tmp
GlueInformationServiceURL: ldap://rsgrid3.its.uiowa.edu:2135/mds-vo-name=local,o=grid
</verbatim>

---+++!! GlueCESEBindGroupCEUniqueID

Defines which storage element is considered close to this Computing Element. This is done on a per VO basis. For example, these attributes can define the default location for Atlas data to go would be to rsgrid3.its.uiowa.edu and into the directory =/storage/atlas=. Another convention on the LCG is that the mount point has a folder in it for each VO that is accepted.

<verbatim>
dn: GlueCESEBindGroupCEUniqueID=rsgrid3.its.uiowa.edu:2119/jobmanager-condor-atlas, mds-vo-name=local,o=grid, GlueCESEBindGroupCEUniqueID: rsgrid3.its.uiowa.edu:2119/jobmanager-condor-atlas
GlueCESEBindGroupSEUniqueID: rsgrid3.its.uiowa.edu

dn: GlueCESEBindSEUniqueID=rsgrid3.its.uiowa.edu, GlueCESEBindGroupCEUniqueID=rsgrid3.its.uiowa.edu:2119/jobmanager-condor-atlas, mds-vo-name=local,o=grid
GlueCESEBindSEUniqueID: rsgrid3.its.uiowa.edu
GlueCESEBindCEAccesspoint: /storage
GlueCESEBindCEUniqueID: rsgrid3.its.uiowa.edu:2119/jobmanager-condor-atlas
GlueCESEBindMountInfo: none
GlueCESEBindWeight: 0
</verbatim>

---+++!! GlueSEUniqueID

Defines an access point of a Storage Element.

<verbatim>
dn: GlueSEUniqueID=rsgrid3.its.uiowa.edu,mds-vo-name=local,o=grid
GlueSEUniqueID: rsgrid3.its.uiowa.edu
GlueSEName: my-site-name:disk
GlueSEPort: 8443
GlueSESizeTotal: 0
GlueSESizeFree: 0
GlueSEArchitecture: disk
GlueInformationServiceURL: ldap://rsgrid3.its.uiowa.edu:2135/mds-vo-name=local,o=grid
</verbatim>

---+++!! GlueSEAccessProtocolLocalID

Defines the protocols that may be used to access this Storage Element. The example below defines gsiftp as the protocol.

<verbatim>
dn: GlueSEAccessProtocolLocalID=gsiftp, GlueSEUniqueID=rsgrid3.its.uiowa.edu,Mds-Vo-name=local,o=grid
GlueSEAccessProtocolLocalID: gsiftp
GlueSEAccessProtocolType: gsiftp
GlueSEAccessProtocolVersion: 1.0.0
GlueSEAccessProtocolPort: 2811
GlueSEAccessProtocolSupportedSecurity: GSI
GlueChunkKey: GlueSEUniqueID=rsgrid3.its.uiowa.edu
</verbatim>

%STOPINCLUDE% 
%BR% 
%COMPLETE3% %BR% 
%RESPONSIBLE% Main.AnthonyTiradani - 12 Jun 2008 %BR% 
%REVIEW% Main.GabrieleGarzoglio - 12 Jun 2008 %BR% %REVFLAG% %Y% %BR%

<!--
 Main.AnandPadmanabhan - 14 Jul 2008
 Main.GabrieleGarzoglio - 12 Jun 2008 
 Main.AnthonyTiradani - 12 Jun 2008
 Main.GabrieleGarzoglio - 11 Jun 2008 
 Main.AnandPadmanabhan - 12 Feb 2007 
 Main.RobGardner - 24 May 2005
 Main.RansomBriggs - 10 Jun 2005
 Main.RansomBriggs - 17 Jun 2005
 Main.JohnWeigand- 12 Jan 2006
 Main.EricShook - 09 Mar 2006
 Main.AnandPadmanabhan - 15 Mar 2006 
 Main.RobQ - 01 May 2006   %BR% 
-->

%META:TOPICMOVED{by="ForrestChristian" date="1166047849" from="Integration.GenericInformationProviders050" to="Integration/ITB_0_5.GenericInformationProviders"}%
