%META:TOPICINFO{author="TomLee" date="1473863979" format="1.1" reprev="1.6" version="1.6"}%
%META:TOPICPARENT{name="WebHome"}%
---+ Root Cause Analysis of Reported Sno+ Issue

---++ Introduction
After the 23-Aug-2016 Maintenance Window the !PerfSONAR datastore at psds failed to restart collecting and sending network metrics.  

---++ Timeline

   * 16 Aug ITB master datastore (psds-itb1) updated and frozen; appears to be functioning properly
   * 23 Aug Normal Maintenance window update on master datastore (psds0)
      * yum update esmond
      * yum update rsv-perfsonar
      * Edgar reports problems with RSV posting
      * ITB master datastore continues to operate without problems
      * Shawn flying to Shanghai and out of contact.
   * 24 Aug Operations restarts Postgres based on Edgar's request
      * Edgar reports there is still a problem
   * 26 Aug Ticket Closed prematurely
      * Ticket reopened same day when Shawn reports there are still problems
   * 31 Aug Operations posts some log contents to ticket
   * 1 Sep ESNet added to ticket for guidence
      * Brian adds this is a problem for a student using the data from UNL
   * 3 Sep Shawn returns from China trip (where he had limited access to email and remote systems)
   * 6 Sep Troubleshooting call determines Apache was not restarted after upgrade attributing to at least some of the issue
      * Service restarted and normal operations for ~4 hours
      * After 4 hours memory swapping begins and service stops publishing
      * Shawn begins the process of discussing data recovery from the outage
   * 7 Sep Full reboot performed and memory available to the VM updated from 12G to 16G
   * 8 Sep 19:05 CEST By request Tom looks in /var/log/rsv/consumers/html-consumer.err and discovers "insecure string pickle" error
   * 8 Sep 21:10 CEST Edgar notices that several RPMs besides the ones updated are out of date compared to ITB
   * 8 Sep 21:15 CEST On advice from both Shawn and Edgar, Tom restarts simplevisor on psds0, which appears to reset the memory usage of stompclt for now, but doesn't restore data flow to CERN
   * 8 Sep 22:17 CEST Tom deletes /usr/share/rsv/www/state.pickle, stops simplevisor and stompclt, and runs stompclt from the command line as a test
   * 8 Sep 22:26 CEST Shawn posts graph showing that data is being published to CERN (Hendrik Borras confirms this)
   * 8 Sep 22:33 CEST On advice from Marian, Tom interrupts command-line stompclt to obtain its stats (and starts simplevisor again), producing the following:
      * =# 2016/09/08-20:31:48 stompclt[47740]: main lingering=
      * =processed 31731 messages in 1636.728 seconds (0.019 k msg/sec)=
      * =throughput is around 0.140 MB/second=
      * Shawn reports additional RPMS that were older on Production vs ITB
      * Tom notes "The version of condor is the same, but production lags behind ITB on condor-cron and rsv."
      * Tom updates all the RPMS on Production that Shawn noted were lagging (this seemed to be an important part of getting back to a working state)
      * stompclt: unexpected ERROR frame received: User CN=OSG Operations Center, OU=People, O=Open Science Grid, DC=DigiCert-Grid, DC=com is not authorized to write to: topic://perfsonar.summary.packet-loss-rate-bidir
   * 8 Sep 23:45 CEST CERN stops receiving data again, according to Hendrik Borras
   * 9 Sep 18:22 CEST Tom deletes /usr/share/rsv/www/state.pickle and restarts simplevisor; Shawn reports that this starts data being published to CERN again (but it doesn't last)
   * 10 Sep Service restarted and memory usage shows signs of returning to normal. 
      * Memory usage visualization in attachments.
      * Memory usage continues to rise and is associated with the "stompclt" process that is supposed to send data to the ActiveMQ at CERN
   * 12 Sep 10:00 CEST Marian reports that the CERN broker was re-configured (at some point in the past, time frame unstated; can someone fill this in?) "to introduce new topics and have per-topic authorisation" but has now been re-configured to accept topic "packet-loss-bidir"
   * 12 Sep 21:31 CEST Tom reports the following stompclt errors were found in syslog:
      * =Sep 12 18:38:21 psds0 stompclt[2911029]: [ERROR] failed to flush outgoing buffer (13469824136 bytes)!=
      * =Sep 12 19:02:08 psds0 stompclt[2589]: [WARNING] removing too old volatile file: /usr/local/rsv-perfsonar//57d6f9c8/57d6f9ef92b9eb.tmp=

---++ Analysis 
      The analysis is ongoing.

---++ Follow Up Actions

One issue noted was that the ITB instance of the OSG network service was not having problems. When we compared the software package versions on the ITB vs Production we noticed that a number of them were (much) older on the Production systems. Another issue was that Production systems were not restarted after updates were applied. Because of the very old version of one of the RPMS a fix (from February) was missing that would have restarted a reconfigured service when the new RPM was installed. Since that fix was missing and the services/system were not restarted, the Production instances were running with a mix of old and new services.  

   * We should have a policy of updating RPMS to match ITB versions on Production as we move updates in place
   * Production updates should be applied before the system is restarted

---++ Reference

[[https://ticket.grid.iu.edu/30823][Primary Ticket]]

-- Main.RobQ - 13 Sep 2016

%META:FILEATTACHMENT{name="Screen_Shot_2016-09-14_at_8.59.55_AM.png" attachment="Screen_Shot_2016-09-14_at_8.59.55_AM.png" attr="" comment="" date="1473858134" path="Screen Shot 2016-09-14 at 8.59.55 AM.png" size="181212" stream="Screen Shot 2016-09-14 at 8.59.55 AM.png" tmpFilename="/usr/tmp/CGItemp38434" user="RobQ" version="1"}%
