%META:TOPICINFO{author="RobQ" date="1218563989" format="1.1" version="1.4"}%
%META:TOPICPARENT{name="WebHome"}%
---+ BDII Plan

The OSG BDII has been determined to be a critical service provided by the GOC. In preparation for the LHC turn on and the increased load expected from the ATLAS and CMS VOs, the GOC plans on taking the following action plan.

---++ Current Issues with the OSG BDII

An explanation of the current BDII/CEMon Aggregator architecture can be found at this [[http://is.grid.iu.edu/documentation.html][link]].

The current version of the BDII is experiencing two known issues. These are a priority to correct for service stability. First, the file system on the machine running the BDII service seems to occasionally (we haven't found the cause) go read only. This does not cause an outage, but prevents new data from being sent to the BDII from the resource CEMon's, resulting in stale GLUE data. We initially believed this was due to a drive going bad, but when the service was moved to a new machine it happened again. Our current guess is a firmware issue, we are working on firmware updates in the near future. Regardless of these firmware updates we need to move to a new version of BDII which includes several bug fixes which may be causing problems. The second issue, is several small ~1-2 minute outages reported by the USCMS support center. When talking to the BDII experts at CERN they point at two recent upgrades that fix this issue...

   * Version 3.8.6: 
      * Wait up to 1 minute for a new slapd to become responsive. 
   * Version 3.8.7: 
      * Try to prevent the slapd ports from getting taken by other processes. 

The GOC is planning on setting up a new BDII service from scratch with new versions. See Time Line section below.

| Component | Responsible | Agency |
| BDII 4.0.0.4 | Laurence Fields, Maarten Litmaath | CERN |
| CEMon Consumer | Luigi Zangrando, Massimo Sgaravatto | ITFN |
| Translation Between CEMon and BDII | Arvind Gopu | OSG GOC |

---++ Stability and Stress Testing

Once the new service is ready for testing, we will use stakeholder knowledge to test the new BDII for possible issue. We have been assured that CERN has done load testing during CCRC08, and don't expect any issue. We will have a slightly different configuration with the OSG CEMon reporting structure, so we will do a full set of tests to assure we will be able to handle the load when the time comes.

Frank has agreed to use USCD OSG researches to help create artificial load on the new GOC BDII. This will come in the form of CRAB and WMS glidins. The GOC will graph result and look for load and I/O problems on the BDII, while UCSD will monitor for issues on the client side. After analysis is completed this document will be released to the CMS and ATLAS stakeholders for comment and input.

We will attempt to get someone with ATLAS to do the same type of testing based on ATLAS' use of the BDII.

---++ Failover and Load Balancing

Longer term, but of no less importance is having a solid failover plan in case of a BDII failure. The IU facilities will be used to create a second BDII service. It has not been determined if this will be used only in emergencies when the main BDII fails, or as a way to balance load. This depends on the results of the stress testing done.

---++ Time Line

| *Date* | *Description* | *GOC Notes* |
| Aug 28th 2008  | Install dev collector for CMS/ATLAS testing | Including load testing as applicable; We don't think the load on the collector and/or the web service (LDAP) will be an issue, neither does Burt. But it's definitely worth testing out. The GOC developer assigned to this project will be on vacation from August 14 to August 22. |

| Sep 11th 2008 | Install production collector, and have friendly testing | including stress testing if applicable (again) (friendly = Tony Tiradani, Terrence Martin, who from ATLAS?)  |

| Sep 18th 2008 (worst case 25th) | Release production BDII collector | This would be the replacement for the current BDII available at is.grid.iu.edu |

| Sep 15th 2008 | Have GOC BDII Documentation Published on the TWiki | This would include any details necessary for use and maintenance of the GOC BDII |

| Oct 2nd 2008 | try to have test failover node... | This will not be a simple hot-swap 'switch the DNS' collector if production collector fails; instead it'd be some sort of load balancing round-robinning sort of collector. I understand this is a lofty goal but we'll try. It'll depend on at least two factors: a) implementation of above critical goals b) how hard/easy BDII is toward allowing seamless failover and/or RR'ing of collectors -- Rob thinks it should allow both since it already has capability to handle CEMon and ReSS collectors. |
---++ Comments:

Following are notes from the Executive Team Meeting where the presented plan was discussed - Ruth Pordes

%COMMENT%
   * I have updated the body of the document with the comments from Frank and Rut -- Main.RobQ - 11 Aug 2008 - 20:59 
   * From FKW: I'm reading/writing this in the plane, and will send whenever I find wireless. In case I am swamped with local issues after my arrival at UCSD, here's my input for 1.) 

Chander, Rob Q. and I talked at the blueprint meeting about this. We arrived at a plan that would have UCSD folks (Sanjay and/or Toni) take the bdii querries that are done in CMS analysis framework (CRAB & glideinWMS), and turn them into an artificial load on the bdii.

Whenever Rob is ready with a bdii for us to point to, we would then run this against it at increasing scales, trying to break the deployed bdii. Rob Q's team will observe the health of bdii server side, while we will do the same client side.

We will then put all the information together, describe the test, and make explicit what was not tested. E.g., Rob suggested that it would be easier for him to make a stale replica of the bdii than a live replica. The difference being that the replica we hit in the test is not accumulating new information from the sites at the same time as it is hit by the client.

This document will be presented to CMS for comment.

Chander, if this is different from your understanding of the plan, then please let me know.

Thanks, frank

   * Feedback from the Executive Team Meeting: 

1. Add following information to the plan: a) Goal to complete in good time for the start of first data taking run ~October 15th. Indicate that developer/integrator on vacation for 1 week between now and September 1. b) Add explicit list of s/w components and who is responsible for them - e.g. BDII s/w, CEMON/BDII adaptor etc. Make sure Alain is in the loop to oversee/understand all s/w components. c) Investigate whether stress testing could/should start in parallel with deployment of new BDII and adaptor code, or whether there is a "cut-off" date where, if the new system is not ready, the fallback is to use the exisitng code-base and system and stress test that instead of the new s/w. d) Ruth will alert WLCG /EGEE support staff of priority need for support during this project. e) An additional activity and delivery date will be added for the documentation task. f) Our understanding is to increase the priority/bring forward the deliverable dates would mean that the CA certificates move from VDT to Operations would be delayed and ongoing operations support work would be compromised. -- Main.RuthPordes - 07 Aug 2008 - 19:21

-- Main.RobQ - 07 Aug 2008