%META:TOPICINFO{author="KyleGross" date="1225985933" format="1.1" version="1.2"}%
%META:TOPICPARENT{name="April-08-2008"}%
---++ Rob Quick's Email (March 13th, 2008 at 7:15AM Pacific)

Subject: Re: [Fwd: [Fwd: RE: OSG MonALISA Turn Down - GOC Ticket # 4740]]

Date: Thu, 13 Mar 2008 10:15:33 -0400

From: Rob Quick <rquick@iupui.edu>

To: Ruth <ruth@fnal.gov>

CC: Harvey Newman <Harvey.Newman@cern.ch>, Frank Wuerthwein <fkw@fnal.gov>, 
 Paul Avery <avery@phys.ufl.edu>, Iosif Legrand <iosif.legrand@cern.ch>, "McKee, Shawn" <smckee@umich.edu>, 
Joel Butler <butler@fnal.gov>, Howard Gordon <gordon@bnl.gov>, Richard Cavanaugh <Richard.Cavanaugh@cern.ch>, "osg-eb@OPENSCIENCEGRID.ORG" <osg-eb@OPENSCIENCEGRID.ORG>

References: <47D84C95.5040007@cern.ch> <47D84E47.3090904@fnal.gov>

Ruth,

Yes, I will send a stay of the MonALISA turn off date dependent on the  
Council's decision.

Let me touch on a few points, there are 81 OSG compute elements and 13  
storage elements for a total of 94 registered resources on the OSG.  
MonALISA is only running on CEs, so I won't include the SEs in the  
next few calculations. 31 resources are reporting to MonALISA as of  
last night, I do not recognize 4 of these resources and 5 reported no  
informaiton. This leaves 22 of 81 resources or ~27%. This graph shows  
DB size and a huge drop off in usage after the 0.6.0 release in March  
of 2007. (http://www.grid.iu.edu/reports/ML_Jan07-Mar08.png)

The effort involved includes maintenance, monitoring, and support of  
MonALISA at the client and server level (aka Trouble Tickets reporting  
problems, inaccuracies, outages, etc.). I agree that MonALISA has  
evolved into be a stable service. But other than a few select  
resources it is largely unused. I would suggest this is a VirtualOrganizations/VOInfo level  
service, and not an OSG Operations infrastructure service. If we would  
like this to be an OSG service we need to think about making it a  
mandatory service so we can use it fully. I am not disputing  
MonALISA's usefulness as a monitoring tool, but until it is more  
widely used, it is not helpful on a OSG-wide operations level.

As I said, I will send a stay of the turn off date this morning  
pending council decision.

Rob

On Mar 12, 2008, at 5:42 PM, Ruth wrote:

> Hi Harvey, Rob Quick
>
> This needs to go through the OSG Council for the longer term  
> decision as I have explained before. It is a matter of effort and  
> priority of course. I am definitely and equially sure we don't need  
> a crisis right now.
>
> However, with this email I am asking Rob Quick to retract from the  
> recent decision to turn off the current ML service at the OSG  
> operations center. I am, with this email, asking him to  let me know  
> the effort it takes to maintain this service as others ramp up.
>
> Rob Quick - will you send the email retracting the decision or would  
> you like me to?
>
> thank you for the email
>
> Ruth
>
>
>
> Harvey Newman wrote:
>>
>>
>> Dear Ruth,
>>
>> I've been informed of this secondhand, but because of the urgency  
>> and import,
>> I am letting you know as OSG Executive Director that the MonALISA  
>> turndown is,
>> as explained in this note, is a strategic mistake of rare  
>> proportions. Also the timing is quite
>> out of synch. with the ramp up to LHC running, and the associated  
>> network
>> developments for managing network resources.
>>
>> As you can see ATLAS is responding to the turn-down immediately, in  
>> recognition
>> of the obvious fact that there is no monitoring system of similar  
>> capability, or
>> indeed in this class. As LHC ramps us, a system with this reach and  
>> capability is
>> required to keep track of what is going on. What it does provide  
>> cannot be replaced
>> by simpler, and in a fundamental way far more basic tools.
>>
>> Unlike many other manual systems, ML can deal with issues  
>> autonomously,
>> or semi-autonomously, and problems do not generate reams of Emails  
>> from
>> users and system managers where the failure is, and what its nature  
>> is. As we've
>> said many times, awareness of both end-systems and networks is a  
>> requirement, and
>> this requirement is increasing; not decreasing in any way.
>>
>> As you know, MonALISA underlies EVO, and you may also be aware
>> that ALICE uses it to provide them with a highly capable autonomous
>> infrastructure (and higher level services that they developed  
>> themselves
>> using its services) which supports computing operations
>> with much reduced manpower.
>>
>> The major networks are transitioning to a new dynamic circuit- 
>> oriented
>> paradigm to support the major network flows of the major science
>> programs, most notably the LHC. In the case of the LHC, it is obvious
>> that the LHC experiments will soon exhaust the affordable bandwidth
>> and so managed services are being built, following a plan exposed to
>> the community, including OSG, starting a few years ago. The  
>> infrastucture
>> to provide this has been installed, throughout the US and across the
>> Atlantic by Internet2 and US LHCNet respectively, within the past  
>> year.
>> A partnership of ESnet, GEANT2, the networks just mentioned,
>> Fermilab, BNL and leading NRENs has begun work on a de facto
>> standard way to build and provision inter-domain circuits.
>>
>> The services to be deployed on this infrastructure for LHC require  
>> an end-to-end
>> view and a true real-time monitoring. This is going to be based on  
>> MonALISA
>> as this is the one system of sufficient power and field proven  
>> stability (over
>> 7 years, around the clock) that exists. Applications, including OSG  
>> middleware
>> [sorry to repeat what I told the OSG management a few years ago]  
>> will have
>> to request network resources and communicate with network-resident  
>> services
>> that will manage and control the allocation of bandwidth. Projects  
>> funded by
>> NSF (UltraLight, PLaNetS) are working with US LHCNet on some of these
>> services as well.
>>
>> The APIs are starting to be developed. The communication will be  
>> real-time in that
>> the allocated network resources will be checked as being well-used,  
>> or not,
>> and resources not well-used will be freed to satisfy competing  
>> requests.
>> The configuration of the end-systems in terms of hardware and  
>> software as
>> well as state (load, traffic levels) will be used to diagnose  
>> throughput problems,
>> together with realtime diagnosis of the network itself, to  
>> demystify what is happening
>> to flows that do not perform in a way that matches (to some degree  
>> of accuracy)
>> what was requested.
>>
>> So OSG, using the ML infrastructure, at least had a start in this  
>> correct direction.
>> If it ML monitoring is turned down, then either much greater effort  
>> will have to be invested
>> by OSG to restore (as well as extend and expand on, as above) this  
>> capability, or OSG's
>> ability to distribute data will be correspondingly reduced, by a  
>> major factor,
>> as the competition for network resources increases with the arrival  
>> of real LHC
>> data. The reason is simply that as a strategic, scarce resource,  
>> Network resources
>> with a guaranteed bandwidth will be assigned to requests where the  
>> requesting application
>> can communicate with the network services, and which are configured  
>> to use the network
>> resources allocated to them at reasonably high efficiency.  
>> Otherwise requests will have
>> go to a catch-all "best effort" class to which a relatively small  
>> amount of bandwidth will
>> be assigned.
>>
>> On a related topic, the above has been presented in some detail at  
>> DOE
>> at the US LHCNet review in mid-January and today at NSF. In the
>> discussion that ensued today, it was clear that OSG needs to re- 
>> engage with
>> these network issues, through the network working group that was  
>> formed
>> a few years ago with the leadership of Don and Shawn, but was not  
>> funded
>> by OSG project management.
>>
>> Best regards
>> Harvey
>>
>>
>>
>>
>> Subject:
>> [Fwd: RE: OSG MonALISA Turn Down - GOC Ticket # 4740]
>> From:
>> Iosif Legrand <Iosif.Legrand@cern.ch>
>> Date:
>> Wed, 12 Mar 2008 21:00:03 +0100
>> To:
>> Harvey Newman <Harvey.Newman@cern.ch>
>> To:
>> Harvey Newman <Harvey.Newman@cern.ch>
>> CC:
>> Iosif Legrand <Iosif.Legrand@cern.ch>
>>
>> Hello Harvey,
>>
>>
>> I received the attached email from the USATLAS , and they want a ML
>> repository to replace the OSG site .
>> I think it will be useful for us to support this... and I hope to  
>> provide a
>> good example for the USCMS.
>> I think  CMS did a big mistake with  the CERN dashboard.
>> In fact the CMS dashboard is totally depended on ML for collecting  
>> all
>> the jobs related information.  As I told you, it is done in a very  
>> inefficient way and
>> is  using now only one  ML service running  at CERN.
>> This ML service collects ~ 200 000 parameters with an average update
>> rate of ~ 1500 parameters per second from all the  CMS jobs running  
>> on all CMS centers
>> This ML service works really fine for more than two years, but this  
>> is not an architecture to monitor the
>> jobs in CMS.
>>
>>
>>
>> Best Regards,
>> ioji
>>
>>
>> -------- Original Message --------
>> Subject:     RE: OSG MonALISA Turn Down - GOC Ticket # 4740
>> Date:     Wed, 12 Mar 2008 13:53:14 -0500 (CDT)
>> From:     Horst Severini <hs@nhn.ou.edu>
>> Reply-To:     Horst Severini <hs@nhn.ou.edu>
>> To:     rwg@hep.uchicago.edu, packardj@rcf.rhic.bnl.gov, smckee@umich.edu
>> CC:     hs@nhn.ou.edu, aglt2-hardware@umich.edu, mernst@bnl.gov, Iosif.Legrand@cern.ch 
>> , Costin.Grigoras@cern.ch
>>
>>
>>
>> Hi Ioji and Costin,
>>
>> we (USATLAS) were talking about this OSG ML Repository shutdown  
>> this morning,
>> and we'd like to migrate/replicate the Repository to/at BNL, since  
>> we really like all the useful features of the Repository and don't  
>> want to lose it.
>>
>> How difficult would that be? Could you help us with the  
>> configuration?
>>
>> Thanks a lot,
>>
>>     Horst
>>
>>


-- Main.KentBlackburn - 01 Apr 2008