%META:TOPICINFO{author="JohnWeigand" date="1211912778" format="1.1" reprev="1.36" version="1.36"}%
%META:TOPICPARENT{name="WebHome"}%
<!--
These are general in nature and should be changed in the this template if the location changes:
   * Set CURRENT_TOMCAT = ==gratia09==
   * Set CURRENT_MYSQL = __gratia06__
   * Set NEW_TOMCAT = ==gratia07==
   * Set NEW_MYSQL = __ gratia07__
   * Set TOMCAT_ALIAS = ==gratia.opensciencegrid.org==
   * Set MYSQL_ALIAS = ==gratia-db01.fnal.gov==
   * Set RELEASE_TAR_REPOSITORY = /afs/fnal.gov/files/expwww/gratia/html/Files

These are specific to a release and require changing:
   * Set RELEASE_DATE = 5/14/08
   * Set CURRENT_RELEASE = v0.34.5
   * Set RELEASE_TAG = v0-34-5
   * Set NEXT_DEVEL_VERSION = v0.35
   * Set BUILD_DIRECTORY = /home/weigand/cdcvs/gratia-%CURRENT_RELEASE%



-->
---+!! Gratia Release v0.34 and %CURRENT_RELEASE% (%RELEASE_DATE%)%BR% 

%TOC%

%STARTINCLUDE%
---+ Overview
The main purpose of this release (%CURRENT_RELEASE%) is the DN/FQAN collection improvements and the requirement for authentication for administrating the Collector.

---++ Reporter Improvements
   * Report displaying those jobs that have been running more than X days by VO. where X is a week and a month (RR23)
   * Report displaying those sites that show 0 Wall Duration for more than X days - where X is a week and a month. (RR24)
   * Update the osg daily report for Birt 2.2
   * Periodically generated (daily, weekly and/or monthly) csv files that are available for immediate view without need to read db records 
      1. CPUday per day for the last month/30 days for each VO
      2. CPUday per day for the last month/30 days for each site
      3. total  CPUweeks per week for the last 52 weeks (year) 
   * Extend User daily report to include VO name.

---++ Collector Improvements
   * Enable authentication in the administration pages
   * Implement looking up the !DN, Role and !VO directly from certificate
   * Update of the record checksum to exclude !DN, Role, !VO"
   * Review and improve the Summary table creation mechanism
   * Update Collector to Collector connection to send more than one record on each connection
   * Add VO to User Summary Table
   * Replace pre-duplicate check by exception handling 

---++ Probe Improvements
   * Collection of FQAN and DN in most cases
   * Document on the issues related to full and complete probe black-out detection.
   * Package dCache probe as RPM. 

<!--   -------------------------------------------- -->
---+ Anticipated downtime
It is expected that this release will require the Gratia services and reporting to be unavailable beginning at:
   * Start: %RELEASE_DATE%  hh:mm CST
   * Available: %RELEASE_DATE% hh:mm CST

The changes affecting downtime  for this release are:
   1 Length of time to make a backup of the database to the backup area using =mysqlhotcopy=
   1 Installation and validation on the 6 Gratia schemas



<!-- BUILD DISTRIBUTION -------------------- -->
---+ Build the %CURRENT_RELEASE% for distribution
This release was done in 2 stages and a couple interim stages when problems were detected:
   * v0.34 - for the VDT 1.10.1 distribution (ITB 0.9.0)
   * v0.34.1 - for local distribution.  Changes were required to the local scripts/configurations for the actual conversion at FNAL on gratia08 and gratia09 collectors.

<ol>
<li>Make sure your build area contains all _committed_ changes.
<ul><li>cvs update</li></ul>
</li>

<li>In _gratia/build-scripts/Makefile_ , change the _version_default_ to:
<ul><li>version_default = %NEXT_DEVEL_VERSION%</li>
       <li>commit the change</li>
</ul>
</li>

<li>Tag the release:
<ul><li>cvs tag -R v0-34 gratia</li></ul>
       This tags everything that is in your build directory and presumably tested.
</li>

<li> _Into a *new* area_, export the tagged release:
<ul><li>cvs export -d gratia-v0.34 -r v0-34 gratia</li></ul>
</li>

<li>Build it for the release (this insures that tar files are produced for VDT):
<ul><li>cd gratia-v0.34/build-scripts</li>
<li>source setup-jdk15.sh</li>
<li>make release</li></ul>
</li>

<li>Copy the build/release area to the _gratia_ home directory for posterity:
   * mkdir /home/gratia/gratia-releases/v0.34
   * cp -pr /home/weigand/cdcvs/gratia-v0.34/* /home/gratia/gratia-releases/v0.34/.

<li>Copy the built tar files to the release area:
<ul><li>scp ../target/*_v0.34.tar   flxi07.fnal.gov:%RELEASE_TAR_REPOSITORY%/</li></ul> </li>

<li>Update the version number on the [[InstallationGuideVDT][services release TWiki page]]:</li>
<ul><li>Edit and update the TWiki variable _<nop>ReleaseVersion_.</li></ul>
</ol>
%GREEN%Status: Completed on 5/10/2008 08:00 CDT%ENDCOLOR%

%BLUE%
<!-- ------------------------------------- -->
<hr width="80%" />
<b>Update: 5/11/2008 14:45 CDT:</b>%BR%
Had to modify Makefile to include the voms_servers and voms-server.sh files in the Gratia-Services 
distribution for VDT.  Re-tagged, rebuilt, moved to the flxi07.fnal.gov site.  


<!-- ------------------------------------- -->
<hr width="80%" />
<b>Update: 5/12/2008 14:15 CDT:</b>%BR%
Problems encountered when working with an _empty_ database.  Previous testing was done with an
existing database.  The following programs required modification:
   * collector/gratia-services/net/sf/gratia/services/ListenerThread.java
   * collector/gratia-services/net/sf/gratia/services/NewVOUpdate.java
   * collector/gratia-services/net/sf/gratia/storage/DatabaseMaintenance.java
   * common/configuration/hibernate.cfg.xml

Steps 3 through 6 were repeated for these modules.
Note: To tag the individual module (example):
   * cvs tag -F v0-34 collector/gratia-services/net/sf/gratia/services/ListenerThread.java 

Provided a new _configure_gratia_ to VDT.  This was tested in a condor environment as best we could especially for the validation of the condor environment relevant to the PER_JOB_HISTORY_DIR that is critical.

This is the v0.34 used in VDT 1.10.1 (ITB 0.9.0).

<!-- ------------------------------------- -->
<hr width="80%" />
<b>Update: 5/14/2008 15:45 CDT:  Tagged as v0-34-1</b>%BR%
The following modules were modified for changes to local (non-VDT) installations/upgrades.  Tests are currently being run by Chris Green and a gratia instance on _gratia07:/test/data/mysqldb/gratia_ using this software:
   * gratia/build-scripts/Makefile
   * gratia/common/configuration/cleanup_server_lib
   * gratia/common/configuration/configure-collector
   * gratia/common/configuration/update-gratia-local

Steps 3 through 6 were repeated for these modules.
Note: The tagging was done as:
   * cvs tag -R v0-34.1 gratia
and the export done as:
   * cvs export -d gratia-v0.34.1 -r v0-34.1 gratia
and the build done as:
   * cd gratia-v0.34.1/build-scripts
   * source setup-jdk15.sh
   * make release
and the copy to the release area:
   * scp ../target/*_v0.34.1.tar   flxi07.fnal.gov:%RELEASE_TAR_REPOSITORY%/.
   * updated the version number on the [[InstallationGuideVDT][services release TWiki page]]

Also note these changes do not affect the current VDT 1.10.1 release of Gratia v0.34.  The latest version was copied in as in step 6 and 7, but VDT does not need to access this version.

<!-- ------------------------------------- -->
<hr width="80%" />
<b>Update: 5/20/2008 14:42 CDT:  Tagged as v0-34-2 </b>%BR%
<verbatim>
U collector/gratia-services/net/sf/gratia/storage/DatabaseMaintenance.java
U collector/gratia-services/net/sf/gratia/storage/JobUsageRecord.java
U collector/gratia-services/net/sf/gratia/storage/SummaryUpdater.java
U collector/gratia-services/net/sf/gratia/storage/Utils.java
U common/configuration/collector-pro.dat
U common/configuration/service-configuration.properties
U probe/build/gratia-probe.spec
U probe/common/Gratia.py
U probe/common/GRAM/JobManagerGratia.pm
U probe/condor/condor_meter.pl
U reporting/summary/PSACCTReport.py
</verbatim>

cvs tag -R v0-34-2 gratia%BR%

<!-- ------------------------------------- -->
<hr width="80%" />
<b>5/20/2008 16:46 CDT</b>
<verbatim>
cvs tag -F v0-34-2  collector/gratia-services/net/sf/gratia/services/CollectorService.java
cvs tag -F v0-34-2  collector/gratia-services/net/sf/gratia/storage/DatabaseMaintenance.java
cvs tag -F v0-34-2  common/configuration/summary-procedures.sql
</verbatim>

<!-- ------------------------------------- -->
<hr width="80%" />
<b>5/21/2008 11:03 CDT</b>
<verbatim>
Since the osg_daily record does not have a jobid or anything similar, we must keep the UserIdentity field in the md5 calculation otherwise we find many false duplicate
U collector/gratia-services/net/sf/gratia/storage/JobUsageRecord.java

Add support for DN comming from cron (/DC=gov/DC=fnal/O=Fermilab/OU=Robots/CN=fermigrid0.fnal.gov/CN=cron/CN=Keith Chadwick/CN=UID:chadwick).  In that case, use the 3rd CN
U collector/gratia-services/net/sf/gratia/storage/JobUsageRecordUpdater.java

Re-add VOName Correction link
U collector/gratia-administration/WebContent/dashboard.jsp

use full md5 for ps accounting too
U common/configuration/collector-pro.dat
</verbatim>

cvs tag -R v0-34-3 gratia%BR%

<!-- ------------------------------------- -->
<hr width="80%" />
<b>5/22/2008 10:45 CDT</b>
Changes:
<verbatim>
Re-add missing Host field lookup needed by psacct
U collector/gratia-services/net/sf/gratia/storage/DatabaseMaintenance.java
U common/configuration/summary-procedures.sql

actually use the common name we just found
U collector/gratia-services/net/sf/gratia/storage/JobUsageRecordUpdater.java

</verbatim>

cvs tag -R v0-34-4 gratia%BR%


<!-- ------------------------------------- -->
<hr width="80%" />
<b>5/27/2008 13:10 CDT</b>
Changes for gratia_psacct
<verbatim>
report library is in production-osg only
  reporting/gratia-reports/WebContent/reports/production-fermi/gratia-lib1.rptlibrary is no longer in the repository
  reporting/gratia-reports/WebContent/reports/production-osgdaily/gratia-lib1.rptlibrary is no longer in the repository
U reporting/gratia-reports/WebContent/reports/production-osg/gratia-lib1.rptlibrary
</verbatim>

cvs tag -R %RELEASE_TAG% gratia%BR%

Steps 3 through 6 were repeated for these modules.%BR%
Note: 
the export done as:
   * cvs export -d gratia-%CURRENT_RELEASE% -r %RELEASE_TAG% gratia
and the build done as:
   * cd gratia-%CURRENT_RELEASE%/build-scripts
   * source setup-jdk15.sh
   * make release
and the copy to the release area:
   * scp ../target/*_%CURRENT_RELEASE%.tar   flxi07.fnal.gov:%RELEASE_TAR_REPOSITORY%/.
   * updated the version number on the [[InstallationGuideVDT][services release TWiki page]]
and make a copy in the /home/gratia/gratia-releases directory
   * cp -pr %BUILD_DIRECTORY%   /home/gratia/gratia-releases/.

%ENDCOLOR%

%GREEN%Status: Finally Completed on %ENDCOLOR%
 



<!--   -------------------------------------------- -->
---+ Collectors and Databases Affected

The following Gratia collectors and databases will be converted with this release:
%TABLE{ tableborder="1" cellpadding="0" cellspacing="1" headerbg="#99CCCC" databg="#FFFFCC, #FFFFFF"}%
%EDITTABLE{  header="|*Schema*|*URL*|*Description*|" format="| text, 20 | text, 20 | text, 20 | text, 7 | text, 15 | text, 15 | text, 8|"  changerows="on" quietsave="on" editbutton="Edit table" }%
|*Schema*|*<nop>MySql port*|*Collector URL*|*Size (bytes)*|*Size (rows)*|*Max dbid*|*Duplicates*|
| fermi_transfer | gratia06.fnal.gov:3320 | gratia08.fnal.gov:8886 |  5.2M |            0 |  0 |  0 |
| gratia_osg_transfer | gratia06.fnal.gov:3320 | gratia09.fnal.org:8886 |  5.2M |            0 |  0 |  0 |
| gratia_osg_daily | gratia06.fnal.gov:3320 | gratia09.fnal.gov:8884 |  89M |  84,437 |   85117 |  0 |
| fermi_itb | gratia06.fnal.gov:3320 | gratia08.fnal.gov:8881 |  558M |  58,082 |  159187 |  92,879 |
| gratia_qcd  | gratia06.fnal.gov:3320 | gratia08.fnal.gov:8883 |  4.3G |  1,210,400 |  1588366 |  0 |
| gratia_osg_integration | gratia06.fnal.gov:3320 | gratia09.fnal.gov:8885 |  8.1G |  1,438,686 |  2561449 |  691,626 |
| gratia_psacct | gratia06.fnal.gov:3320 | gratia08.fnal.gov:8882 |  13G |  7,763,036 |  7792895 |  0 |
| gratia_itb | gratia06.fnal.gov:3320 | gratia09.fnal.gov:8881 |  21G |  8,327,662 |  8958895 |  101,365 |
| fermi_osg | gratia06.fnal.gov:3320 | gratia08.fnal.gov:8880 |  24G |  8,707,956 |  8712636 |  3,652 |
| gratia | gratia06.fnal.gov:3320 | gratia09.fnal.gov:8880 |  117G |  68,418,063 |  70987563 |  2,231,774 |



<!-- ----------------- SHUTDOWN AND DATABASE BACKUP ------------- -->
---+ Shutdown and database backup.
The nightly backups will suffice for this implementation.


<!-- ----------------- UPGRADE AND IMPLEMENTATION ------------- -->
---+ Small DB - Upgrade and implementation
The __upgrades should be single-threaded__ , that is, performed for each database schema one at a time.  

We will perform these upgrades based on the size of the individual database schema, in ascending order.

The _DupRecord_ table (duplicates) should be removed before starting the upgrade.

The general procedure for this upgrade is:
   1 Stop the tomcat service 
      * service TOMCAT_INITD_SERVICE stop
   1 Install the new software on the Gratia tomcat instance:
      * pswd=xxx
      * source=%BUILD_DIRECTORY%
      * pgm=%BUILD_DIRECTORY%/common/configuration/update-gratia-local 
      * $pgm  -d $pswd -S $source -s  DATABASE
   1 Tar the existing log files and save to a backup area.  Then clean the log file directory.
      * date=`date '+<nop>%Y<nop>%m<nop>%d'`
      * cd TOMCAT_LOCATION/logs/
      * tar zcf /data/gratia_tomcat_logs_backups/tomcat-TOMCAT_INITD_SERVICE.$date.tgz *
      * rm -f * 
   1 Effective with this release, there is an administrative login process that, by default, does not allow access to the admin functions.  You will need to update the __TOMCAT_LOCATION/gratia/service-configuration.properties__ file with the following attributes. (Note that if you forget to do this, the administrator can be added at anytime without restarting the tomcat service):
      * service.admin.DN.0=/DC=gov/DC=fnal/O=Fermilab/OU=People/CN=Philippe G. Canal/UID=pcanal
      * service.admin.DN.1=/DC=org/DC=doegrids/OU=People/CN=Christopher H. Green 851859
      * service.admin.DN.2=/DC=org/DC=doegrids/OU=People/CN=John Weigand 458491
      * service.admin.DN.3=/DC=org/DC=doegrids/OU=People/CN=Steven Timm 74183
      * service.admin.DN.4=/DC=gov/DC=fnal/O=Fermilab/OU=People/CN=Steven C. Timm/UID=timm
   1 Start the tomcat service 
      * service TOMCAT_INITD_SERVICE start
   %BR%When the tomcat service initializes, it will detect any schema changes have been effected and a conversion process will begin. 
      * _tail_ the log files in _TOMCAT_LOCATION/logs. When the conversion process completes the log will show the following message:
      - "INFO: Server startup in _xxx_ms"
      * In your browser, access the _gratia-administrative_ web service, select the _System / Administration_ menu option in the left menu, Then scroll down to the _Starting/Stopping Database Update Services_ section and select the _Stop Update Services_ link
   1 __Wait until the schema upgrade is complete__ , then, _start_ the Gratia _update_ services for the database schema just upgraded.
      * In your browser, connect to the Gratia administrative services url for each of the databases.
      * Select the _System / Administration_ menu option in the left menu
      * Then scroll down to the _Starting/Stopping Database Update Services_ section and select the _Start Update Services_ link.
      * As the collector/tomcat host update service is started, monitor the tomcat logs files for any errors.
      * Bring up the gratia _administration_ web interface and verify that the collectors are processing the data on the status page.
      * Bring up the gratia _reporting_ web interface and verify that the reports look reasonable while still _tail'ing_ the log files.
   1 Run the static reports cron as _root_ and verify these reports are generated:
      * 3 pdf files and 3 csv files
   1 If satisifed, you may continue to the next one.

%BLUE%
Did not have to do the stop/start of update service as you those services never got started
%ENDCOLOR%

---++ Status

%TABLE{ tableborder="1" cellpadding="0" cellspacing="1" headerbg="#99CCCC" databg="#FFFFCC, #FFFFFF"}%
%EDITTABLE{  header="|*Schema*|*URL*|*Description*|" format="| text, 20 | text, 20 | text, 20 | text, 15 | text, 5 | text, 10 | text, 18 |"  changerows="on" quietsave="on" editbutton="Edit table" }%
|*Database*|*Tomcat node*|*init.d service*|*tomcat location*|*Size*|*Start*|*Complete*|
| fermi_transfer |  gratia08.fnal.gov:8886 | tomcat-fermi_transfer | /data/tomcat-fermi_transfer |  5.2M | 5/18 09:00 | 5/22 13:05 v0.34.4 |
| fermi_itb |  gratia08.fnal.gov:8881 | tomcat-fermi_itb | /data/tomcat-fermi_itb |  558M | 5/18 10:10 | 5/22 12:54 v0.34.4 |
| gratia_qcd  |  gratia08.fnal.gov:8883 | tomcat-qcd | /data/tomcat-qcd |  4.3G | 5/18 11:20 | 5/22 12:59 v0.34.4 |
| gratia_psacct |  gratia08.fnal.gov:8882 | tomcat-ps | /data/tomcat-ps |  13G | 5/18 11:58 | 5/22 12:00 v0.34.4 |
| fermi_osg |  gratia08.fnal.gov:8880 | fermi_osg | /data/tomcat-fermi_osg |  24G | 5/19 07:51 | 5/22 12:44 v0.34.4 |


%TABLE{ tableborder="1" cellpadding="0" cellspacing="1" headerbg="#99CCCC" databg="#FFFFCC, #FFFFFF"}%
%EDITTABLE{  header="|*Schema*|*URL*|*Description*|" format="| text, 20 | text, 20 | text, 20 | text, 15 | text, 5 | text, 10 | text, 18 |"  changerows="on" quietsave="on" editbutton="Edit table" }%
|*Database*|*Tomcat node*|*init.d service*|*tomcat location*|*Size*|*Start*|*Complete*|
| gratia_osg_transfer |  gratia09.fnal.org:8886 | tomcat-osg_transfer | /data/tomcat-osg_transfer |  5.2M | 5/18 13:55 | 5/22 13:12 v0.34.4 |
| gratia_osg_daily |  gratia09.fnal.gov:8884 | tomcat-osg_daily | /data/tomcat-osg_daily |  89M | 5/18 14:28 | 5/22 13:15 v0.34.4 |
| gratia_osg_integration |  gratia09.fnal.gov:8885 | tomcat-osg_integration | /data/tomcat-osg_integration |  8.1G | 5/18 18:20 | 5/22 13:18 v0.34.4 |
| gratia_itb |  gratia09.fnal.gov:8881 | tomcat-itb | /data/tomcat-itb |  21G | 5/18 18:48 | 5/22 13:26 v0.34.4 |


%RED% 
*Issues/Problems:*
   1 No host certificate.  So administratiion functions disabled.  Will have to wait until Monday to request host and http certificates from Steve.
   1 Static reports not working on fermi_transfer and osg_transfer.  These databases are completely empty (zero records) and this is causing the problem.
   1 The _update_gratia_local_ adds a cron entry for static reports every time it is run.  You have to manually edit the crontab of the old entries.
      * It is also adding it with the ssl port number where in the past it was using the non-ssl port.
      <verbatim>
42 0 * * * '/data/tomcat-fermi_osg/gratia/staticReports.py'
                 '/data/tomcat-fermi_osg' 
                 'http://gratia-fermi.fnal.gov:<b>8880</b>/gratia-reporting/' 
<b>One below added new:</b>
##42 0 * * * '/data/tomcat-fermi_osg/gratia/staticReports.py' 
                 '/data/tomcat-fermi_osg' 
                 'https://gratia-fermi.fnal.gov:<b>8845</b>/gratia-reporting/' 
</verbatim>
   1 osg_daily catalina.out logs
      * May 18, 2008 2:33:26 PM org.eclipse.birt.chart.script.ScriptHandler register%BR%WARNING: An invalid Chart Java event handler class [class net.sf.gratia.reporting.GratiaBirtReportEH] has been detected and ignored.
      * Reporting menu is entirely different.  
      * should the static reports even be run for these
   1 gratia_psacct
      * Appears to be hung in the *post-install.sh summary* . Killed tomcat around 5/19 07:47 with an explicit kill and restart.  It is hung again in the same step.
   1 fermi_osg
      * Encountered this error with *index12* :
      <verbatim>
FINE: Command: Error: alter table ProbeDetails_Meta add unique index index12(md5) : 
com.mysql.jdbc.exceptions.MySQLIntegrityConstraintViolationException: 
     Duplicate entry 'E6A2B4DC7D3C910EF4D584CAEB6F10FA' for key 2
      </verbatim> 
      * This are the *alter table..* statements in the gratia-0.log
      <verbatim>
380:FINE: Executing: alter table MetricRecord_Meta add unique index index12(md5)
382:FINE: Command: OK: alter table MetricRecord_Meta add unique index index12(md5)
388:FINE: Executing: alter table ProbeDetails_Meta add unique index index12(md5)
390:FINE: Command: Error: alter table ProbeDetails_Meta add unique index index12(md5) :
    com.mysql.jdbc.exceptions.MySQLIntegrityConstraintViolationException: 
    Duplicate entry 'E6A2B4DC7D3C910EF4D584CAEB6F10FA' for key 2
470:FINE: Executing: alter table ProbeDetails_Meta add unique index index12(md5)
472:FINE: Command: Error: alter table ProbeDetails_Meta add unique index index12(md5) :
    com.mysql.jdbc.exceptions.MySQLIntegrityConstraintViolationException: 
    Duplicate entry 'E6A2B4DC7D3C910EF4D584CAEB6F10FA' for key 2
590:FINE: Executing: alter table ProbeDetails_Meta add unique index index12(md5)
592:FINE: Command: Error: alter table ProbeDetails_Meta add unique index index12(md5) :
    com.mysql.jdbc.exceptions.MySQLIntegrityConstraintViolationException: 
    Duplicate entry 'E6A2B4DC7D3C910EF4D584CAEB6F10FA' for key 2
618:FINE: Executing: alter table JobUsageRecord_Meta add index index17(md5v2
      </verbatim>
   1 osg_daily
      * 5/20 08:00 noticed java exceptions
      <verbatim>
FINEST: fixDuplicatesOnce: resolving 3 duplicates 
with checksum C7E72574A5A891270BF2F6ECA1127A10
May 20, 2008 9:12:45 AM net.sf.gratia.util.Logging debug
FINEST: fixDuplicatesOnce: deleting record 54646 in favor of record 54704
May 20, 2008 9:12:45 AM net.sf.gratia.util.Logging warning
WARNING: fixDuplicatesOnce: caught exception resolving duplicates 
with checksum C7E72574A5A891270BF2F6ECA1127A10
com.mysql.jdbc.exceptions.MySQLSyntaxErrorException: 
PROCEDURE gratia_osg_daily.del_JUR_from_summary does not exist
      </verbatim>
      * Philippe reports that the checksum calculation is wrong for this instance and is looking into it
      * stopped the instance 5/20 09:12
   1 gratia_itb
      * hibernate got in a deadlock state.  Recycle on 5/20 09:08.  Waiting to see if it occurs again.
      <verbatim>
2008-05-19 08:22:50,075 com.mchange.v2.async.ThreadPoolAsynchronousRunner [WARN]:
 com.mchange.v2.async.ThreadPoolAsynchronousRunner$DeadlockDetector@e39068 
-- APPARENT DEADLOCK!!! Creating emergency threads for unassigned pending tasks!
2008-05-19 08:22:50,091 com.mchange.v2.async.ThreadPoolAsynchronousRunner [WARN]:
 com.mchange.v2.async.ThreadPoolAsynchronousRunner$DeadlockDetector@e39068 
-- APPARENT DEADLOCK!!! Complete Status:
        Managed Threads: 3
        Active Threads: 3
        Active Tasks:

2008-05-20 10:16:50,019 com.mchange.v2.async.ThreadPoolAsynchronousRunner [WARN]:
 com.mchange.v2.async.ThreadPoolAsynchronousRunner$DeadlockDetector@d7f3b9 
-- APPARENT DEADLOCK!!! Creating emergency threads for unassigned pending tasks!
2008-05-20 10:16:50,048 com.mchange.v2.async.ThreadPoolAsynchronousRunner [WARN]:
 com.mchange.v2.async.ThreadPoolAsynchronousRunner$DeadlockDetector@d7f3b9 
-- APPARENT DEADLOCK!!! Complete Status:
        Managed Threads: 3
        Active Threads: 3
        Active Tasks:
      </verbatim>
%ENDCOLOR%


%BLUE%
*Notes*
   1 The tmp directory being used by <nop>MySql on gratia06 is defined on the command line and not by the my.cnf value
   <verbatim>
gratia    6415 14500 42 Apr25 ?        10-01:17:45 
          /fnal/ups/prd/mysql/v5_0_22/Linux-2-4/libexec/mysqld 
         --basedir=/fnal/ups/prd/mysql/v5_0_22/Linux-2-4 
         --datadir=/data/mysqldb/ --user=gratia 
         --pid-file=/data/mysqldb//gratia06.fnal.gov.pid --skip-locking 
         --port=3320 --socket=/data/mysqldb/mysql.sock 
         --tmpdir=/data/mysqltmp/tmp
   </verbatim>
   1 *gratia_psacct* 
      * Had to perform an <nop>InnoDB conversion in the beginning.  (Start 12:59 Completed: 13:09,  elapsed 01:11)
      * Then it had to create the new table for the <nop>JobUsageRecord_Meta table column. (Start 13:11 Complete:14:26 elapsed 01:15)
      * Adding the index (Start 15:21 ).  No clue when it ended
      * At 15:46 running gratia/build-summary-tables.sql
   1 *fermi_osg*
      * Creating the <nop>JobUsageRecord_Meta table column and index (Start 5/19 09:32  Completed: 5/19 11:57 Elapsed: 02:25)
      * Summary table  creation (Start: 11:57  Completed:   Elapsed: )
   1 Philippe changed the creation of the summary tables ( _build-summary-tables.sql_ ) 
      * This was to eliminate glexec records from the tables due to a large number of bad records in the main database when glexec first fired up.
      * Ran from gratia-vm02:/data/tomcat-greenc_test area against the gratia07:/test/data/mysqldb/gratia database
      * Started 5/19 14:40  Completed 5/20 04:52  Elapsed: 12:12
      * Reduced time by 4 hours



*Certificates on gratia08 and graita09*
   1 Installed pacman
      * mkdir /usr/local/pacman
      * cd    /usr/local/pacman
      * wget http://physics.bu.edu/pacman/sample_cache/tarballs/pacman-3.24.tar.gz
      * tar zxf pacman-3.24.tar.gz 
      * cd pacman-3.24
      * source setup.sh
   1 Installed VDT CA-Certifcates
      * mdkir /etc/grid-securtiy
      * mkdir /usr/local/vdt-certificates.1101
      * cd    /usr/local/vdt-certificates.1101
      * pacman -get  VDT:CA-Certificates
      * (answer yes to all questions and "r (root)" when asked where you want to install them.  This puts them directly in /etc/grid-security.
   1 Enable the VDT services (crons in his release) to maintain the certificates and crls
      * source /usr/local/vdt-certificates.1101/setup.sh
      * vdt-control --on
%ENDCOLOR%



---+ Large DB - Upgrade and implementation
---++ Notes on large database <nop>MySql client step
These SQL fragments are intended to ease the pain of upgrading large DBs
to v0.34 (and above) by allowing most of the column addition to take
place while operations continue.

This SQL is for execution before and after updates are stopped on a pre-v0-34
collector prior to upgrading to v0-34.

---+++ v0.34-pre-install-1.sql
Execute this SQL while the OLD collector is still running: *DO NOT*
upgrade the running collector otherwise this script will be rendered
redundant as soon as the collector starts.
<pre>
set autocommit=0;
start transaction;

  drop table if exists NEWJobUsageRecord_Meta;

  create table NEWJobUsageRecord_Meta like JobUsageRecord_Meta;

  alter table NEWJobUsageRecord_Meta 
    add column md5v2 varchar(255), add index index17(md5v2);

commit;

-- initial fill
set autocommit=0;
start transaction; 
  insert into NEWJobUsageRecord_Meta
   select *, null
   from JobUsageRecord_Meta;
commit;
</pre>



---+++ v0.34-pre-install-2.sql
This will do the final catch-up of all updates that have occured while the 
_v0.34-pre-install-1.sql_ sql script was running.  

It will perform the table pivot
by:
   * making a backup of the original <nop>JobUsageRecord_Meta as <nop>OLDJobUsageRecord_Meta
   * putting the new one in effect by renaming<nop>NEWJobUsageRecord_Meta as <nop>JobUsageRecord_Meta

This SQL should be executed AFTER v0.34-pre-install-1.sql. 
   * The OLD collector should still be running
   * DB updates should have been stopped. *VERY IMPORTANT*
<pre>
set autocommit=0;
start transaction;

  set @maxdbid := 0;

  -- Where did we get to last time?
  select @maxdbid:=max(dbid) from NEWJobUsageRecord_Meta;

  -- Catch up newer records  
  insert into NEWJobUsageRecord_Meta
   select *, null
   from JobUsageRecord_Meta M
   where M.dbid > @maxdbid;

  -- Rename tables
  rename table JobUsageRecord_Meta to OLDJobUsageRecord_Meta,
               NEWJobUsageRecord_Meta to JobUsageRecord_Meta;
commit;
</pre>

If this is successful, upgrade the collector and restart.

Pre-"in-service" downtime should therefore be limited to the time required
to re-create the summary tables.

Delete the <nop>OLDJobUsageRecord_Meta table as soon as you are comfortable that
it is not longer required.

---++ Large DB Status

%TABLE{ tableborder="1" cellpadding="0" cellspacing="1" headerbg="#99CCCC" databg="#FFFFCC, #FFFFFF"}%
%EDITTABLE{  header="|*Schema*|*URL*|*Description*|" format="| text, 20 | text, 20 | text, 20 | text, 15 | text, 5 | text, 15 | text, 8 |"  changerows="on" quietsave="on" editbutton="Edit table" }%
|*Database*|*Tomcat node*|*init.d service*|*tomcat location*|*Size*|*Start*|*Complete*|
| gratia |  gratia09.fnal.gov:8880 | tomcat-gratia  | /data/tomcat-gratia  |  117G |   |   |


<!-- ----------------- POST MORTEM  ------------- -->
---+ Post-mortem
At this time, this will appear to be random notes.  After the conversion, they may be organized.

<ol>

</ol>


%STOPINCLUDE%

<!-- MAJOR UPDATES
For significant updates to the topic, consider adding your 'signature' (beneath this editing box) !-->
---++!! Major updates
<!--Future editors should add their signatures beneath yours!-->
-- Main.JohnWeigand - 15 May 2008
