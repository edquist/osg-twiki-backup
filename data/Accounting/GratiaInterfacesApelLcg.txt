%META:TOPICINFO{author="JohnWeigand" date="1377261745" format="1.1" reprev="1.63" version="1.63"}%
%META:TOPICPARENT{name="WebHome"}%
---+!! Gratia Interfaces - APEL/WLCG

<!--
   * Set OIM_HOME= [[http://oim.grid.iu.edu/][OIM (OSG Information Management System)]]
   * Set MYOSG_HOME= [[http://myosg.grid.iu.edu/about][MyOSG]]

   * Set GRATIA_APEL_UI = [[http://gratia-osg-prod-reports.opensciencegrid.org/gratia-data/interfaces/apel-lcg/][Gratia-APEL WLCG Interface]]
   * Set OSG_WLCG_REPORTING = [[http://gratiaweb.grid.iu.edu/gratia/wlcg_reporting][OSG WLCG Reporting]]

   * Set EGI_PORTAL                        = [[http://accounting.egi.eu/osg.php][EGI Accounting Portal]]
   * Set EGI_PORTAL_OSG_VIEW   = [[http://accounting.egi.eu/osg.php][EGI Accounting Portal - OSG view]]
   * Set EGI_PORTAL_TIER1_VIEW = [[http://accounting.egi.eu/tier1.php][EGI Accounting Portal - Tier 1 view]]
   * Set EGI_PORTAL_TIER2_VIEW = [[http://accounting.egi.eu/tier2.php][EGI Accounting Portal - Tier 2 view]]
   * Set EGI_PORTAL_USER_VIEW = [[http://www3.egee.cesga.es/gridsite/accounting/CESGA/user/user_view.html][EGI Accounting Portal - User view]]
   * Set EGI_PORTAL_VOMEMBER_VIEW = [[https://accounting.egi.eu/user/vomem.php][EGI Accounting Portal - VO Member view]]

   * Set APEL_FAQ=[[https://twiki.cern.ch/twiki/bin/view/EMI/APELFAQ][APEL FAQ and Troubleshooting]]
   * Set APEL_SERVER=[[https://wiki.egi.eu/wiki/APEL/Server][APEL Server]]
   * Set APEL_SUMMARY_RECS=[[https://wiki.egi.eu/wiki/APEL/MessageFormat#Summary_Job_Records][APEL Job Summary Records]]

   * Set WLCG_REBUS_TOPOLOGY = [[http://wlcg-rebus.cern.ch/apps/topology/][EGI REBUS topology]]

   * Set REPORTABLE_SITES = [[#Reportable_resource_groups][lcg-reportableSites]] 
   * Set REPORTABLE_VOS    = [[#Reportable_VO_data][lcg-reportableVOs]]
   * Set GRATIA_QUERY    = [[#Gratia_query][Gratia sql query]]
   * Set NORMALIZATION_FACTOR = [[#Normalization_Factor][normalization factor]]
 
   * Set ACCOUNTING_DATA = [[#Accounting_Data][APEL accounting data]]
-->

%TOC%

%STARTINCLUDE%

---++ Description
Accounting records collected by Gratia are forwarded to the EGI accounting system, APEL. This is important for US-LHC Tier1 and Tier2 facilities which have to demonstrate to the LHC project delivered computing resources on behalf of ATLAS, CMS and ALICE collaborations, in accordance with signed Memorandum of Understanding agreements. A service outside the OSG software infrastructure (VDT) runs at Fermilab, parses and analyzes accounting records for a resource, scales wall time and cpu usage into <nop>HepSpec2006 for the processor type, and then forwards this data to the %APEL_SERVER% at the EGI GOC

The APEL Accounting Portal at RAL has been storing CPU accounting results for WLCG.  On behalf on the ATLAS, CMS and ALICE Tier 1 and Tier 2 that are part of OSG, OSG uploads usage information from Gratia to the APEL accounting system.  This OSG data can be viewed in the 
%EGI_PORTAL_OSG_VIEW%.  APEL is using OSG __resource groups__  registered in %OIM_HOME% and viewable in %MYOSG_HOME%



---++ Contact Information
For support issues on this interface, the contacts are:
   * Gratia Operations gratia-operations@opensciencegrid.org
   * APEL-WLCG Operations: apel-support@jiscmail.ac.uk
   * %APEL_FAQ%

For non-support general type issues on this interface, the contacts are:
   * osg-wlcg-reports@opensciencegrid.org


---++ Frequency
The update to APEL from Gratia is performed daily, aggregating usage information for the current month on a per __resource group__  and VO basis (and effective 11/1/2009 by User Distinguished Name).  Each update is a complete refresh of the current month's usage.  

In order to insure completeness of the previous month's usage, a special update is performed for the previous month for the 1st 8 days of the current month.  This special update allows for any late reporting to Gratia that may occur.   In addition, this been set  to coincide with the LCG Accounting Office extract of the data from the EGI accounting portal for the monthly MOU reports.  This occurs on the 8th of each month.

These are cron jobs running between 00:00 and 02:00 Central Time daily. The update is performed by deleting the entire months data and then re-inserting (all using sql dml statements) the new summaries.  

The APEL system then performs an aggregation of all the accounting data collected from all sites (inclusive of OSG) and updates the %EGI_PORTAL% at least once per day.  As this process involves a lot of aggregation over a large database the actual time this occurs can vary.  The last update time can be viewed at the bottom of the %EGI_PORTAL% page.


---++ Accounting Data
Since Gratia handles the collection of detailed accounting data for OSG, this interface sends only monthly summaries for select OSG __resource_groups__ and __VOs__ as shown below:

<blockquote>
%TABLE{ tableborder="1" cellpadding="0" cellspacing="1" headerbg="#99CCCC" databg="#FFFFCC, #FFFFFF"}%
|  *Data*  |  *Description*  |
| Month |  |
| Year   |  |
| Resource Group | APEL/EGI Site is equivalent to OSG's OIM resource group |
| VO                      | VO |
| User Name          | User's DN |
| Number of jobs    | Total jobs for the period |
| CPU time              | Total CPU time (in hours) |
| Wall Time              | Total Wall time (in hours)  |
| Normalized CPU    | CPU Time normalized by the resource group's HEPSPEC06 |
| Normalized Wall       | Wall Time normalized by the resource group's HEPSPEC06 |
| Earliest End Time | End time of the  first job in the month |
| Latest End Time | End time of the last job in the month |
</blockquote>

Details on the complete set of summary data accepted can be found here: %APEL_SUMMARY_RECS%.
It should be noted that APEL/EGI is designed to accept VOMS group and role attributes but, as of this time, we have not been asked to provide them.

---++ The Process
As mentioned earlier, the interface reports Gratia accounting data to APEL/EGI for select  __resource_groups__ and for only specific VO data for those __resource_groups__  using normalization factors at the __resource_group__ level.  Since, at this time, %MYOSG_HOME% does not provide information on this, two manually maintained configuration files are required:
   * %REPORTABLE_SITES% which contains the %NORMALIZATION_FACTOR% for the __resource_group__.
   * %REPORTABLE_VOS%

For each __resource_group__, a %GRATIA_QUERY% will be constructed using the following filters:
   * Using the %REPORTABLE_SITES% file, the process queries %MYOSG_HOME% to determine the  set of __resources__ within each __resource_group__ to determine if that __resource's__ accounting data is to be included.  It uses the !WLCGInformation !InteropAccounting flag (True) for this determination.
   * The %REPORTABLE_SITES% file provides the %NORMALIZATION_FACTOR% to be applied.
   * The %REPORTABLE_VOS% file provides the list of VOs whose data is to be reported.

THE %GRATIA_QUERY% data is then formatted and transmitted  to APEL via the SSM protocal.

The sub-sections that follow provide more detail.


---+++ Reportable resource groups
This is a manually maintained configuration file (__lcg-reportableSites__) identifying  the __resource_groups__ that are interfaced to APEL/WLCG.   This file contains the __resource_group__ and normalization factor used.   
<blockquote><pre>
#--- CMS Tier 1 ----
USCMS-FNAL-WC1   10264
#--- CMS Tier 2 ----
CIT_CMS_T2          12944
GLOW                9632
    :
#--- ATLAS Tier 1 ----
BNL_ATLAS          12372
#--- ATLAS Tier 2 ----
AGLT2               8500
HU_ATLAS_Tier2      8872
    :
#--- ALICE Tier 2 ---- 
NERSC-PDSF          13920
LC-glcc             15680
</blockquote></pre>

---+++ Normalization Factor
As you've seen in the %ACCOUNTING_DATA% section, the data sent to the APEL/WLCG data base contains both a raw and normalized value.  The WLCG requires a normalization factor to be applied.  It is felt that this is the only fair means of comparing data across a wide variety of grid clusters.   Prior to January 2011, the normalization factor was based on <nop>SpecInt2000 benchmark values for a  processor and the monthly MOU reports reflected that.  Starting in January 2011, the MOU reports and Tier 1 spreadsheets reflect <nop>HepSpec2006 benchmarks.

The normalization factor is basically a simple weighted average of a __resource_group's__  sub-cluster configuration.  For example:
%TABLE%
| *Processor* | *Cores* | *Benchmark* | *(Cores * Benchmark)* |
| Intel(R) Pentium(R) 4 CPU 2.60GHz | 120| 978 | 117,360|
| Dual Core AMD Opteron(tm) Processor 270 | 102| 1,452 | 148,104|
| Summary:  (2 Subclusters) - Totals| 222|| 265,464|
| Normalization Factor (265464 / 222) ||| 1,196|

As newer processors were put into production, a problem started to emerge in that <nop>SpecInt benchmarks were unavailable and only <nop>HepSpec benchmarks were. On the other side, there were no <nop>HepSpec values available for the older processors.  In addition, given the current interface, there was no way of distinguishing between a <nop>SpecInt and <nop>HepSpec derived normalization factors and there was really no way to compare the two values, a decision was made by the WLCG to apply a factor of 4 as an arbitrary equalization factor for the two benchmarks.   

However, the interface, as described in the %ACCOUNTING_DATA% section, only provides for normalized data using a <nop>HEPSpec2006 benchmark:
   * if the processor has a <nop>SpecInt2000 value, we mdiultiply by 4 and use that.
   * if the processor has a <nop>HEPSpec2006 value, we use that.

Then, when the data is sent to APEL and subsequently to the EGI portal, the <nop>HEPSpec2006 normalized values are divided by 4 to reflect the <nop>SpecInt200 normalized values.   This can be seen under any of the views in the EGI Accounting portal like %EGI_PORTAL_OSG_VIEW% when you select the _Data to graph_ pull down at the top.  At some point, !SpecInt2000 should be totally deprecated, however, that will be transparent to Gratia and this interface.


---+++ Reportable VO data 
     A manually maintained configuration file (__lcg-reportableVOs__) identifying the VOs whose accounting data is interfaced. Only accounting data for the CMS, ATLAS and ALICE VOs is sent to APEL/WLCG for each of the __resource_groups__ at this time.
<blockquote><pre>
cms
uscms
atlas
usatlas
alice
</blockquote></pre>


---+++ Gratia query
This is the Gratia sql query used for each __resource_group__ defined in the %REPORTABLE_SITES% file.  The criteria, defined in the previous sections, is highlighted in <font color="red">red</font>.
<blockquote><pre>
SELECT '<font color="red">RESOURCE_GROUP</font>'   as Site,
   VOName   as "Group",
   min(UNIX_TIMESTAMP(EndTime))  as EarliestEndTime,
   max(UNIX_TIMESTAMP(EndTime)) as LatestEndTime,
   date_format(min(EndTime),"%m") as Month,
   date_format(min(EndTime),"%Y")  as Year,
   IF(DistinguishedName NOT IN (\"\", \"Unknown\"),
      IF(INSTR(DistinguishedName,\":/\")>0,
      LEFT(DistinguishedName,INSTR(DistinguishedName,\":/\")-1), DistinguishedName),CommonName) as GlobalUserName,
   Round(Sum(WallDuration)/3600)                        as WallDuration,
   Round(Sum(CpuUserDuration+CpuSystemDuration)/3600)   as CpuDuration,
   Round((Sum(WallDuration)/3600) * <font color="red">NORMALIZATION_FACTOR</font> ) as NormalisedWallDuration,
   Round((Sum(CpuUserDuration+CpuSystemDuration)/3600) * <font color="red">NORMALIZATION_FACTOR</font>) as NormalisedCpuDuration,
   Sum(NJobs) as NumberOfJobs
from
     Site,
     Probe,
     VOProbeSummary Main
where
      Site.SiteName in (<font color="red">LIST_OF_MYOSG_RESOURCES_WITH_INTEROPACCOUNTING_FLAG_TRUE</font>)
  and Site.siteid = Probe.siteid
  and Probe.ProbeName  = Main.ProbeName
  and Main.VOName in ( <font color="red">LIST_OF_REPORTABLE_VOS</font> )
  and %(period)s
  and Main.ResourceType = "Batch"
group by Site,
         VOName,
         Month,
         Year,
         GlobalUserName
</pre></blockquote>

The reason for the complexity in extracting <nop>DistinguishedName in Gratia is two-fold:
   1 the check for empty or 'Unknown' is because the <nop>DistinguishedName was not available in Gratia until 11/1/2009
   1 the even more complex exclusion of everything after the first ":/' was  to compensate for a new feature in Condor 7.3.2 and 7.4 that captured the VOMS proxies extended attributes and appended them to the _x509userproxysubject_ attribute which is the source of the data.

The filter on !ResourceType was due to a change in the condor probes (v1.00.3) to distinguish between the actual grid jobs (Batch) and the grid monitoring job (!GridMonitor) when jobs are submitted using condor_submit. Any 'local' job used to submit a job on the CE node will be filtered, but should they at some point be passed to Gratia, these will be identified as 'Local'. 




---+++ Validation/Verification that sites are reporting.
As a part of the interface process, a check is made at the site/resource level (not individual probes) to determine if data is being reported to Gratia every day.  If a site/resource has missing data for any day,  checks are made to see if this is due to planned maintenance or if a site/resource has gone inactive based on OIM/MyOSG data.  If after these checks are made  and a site/resource still has missing data for more than 2 days in the month, an email "WARNING" notification is issued to initiate an OSG GOC ticket.  Example:
<blockquote><pre>
WARNING/ADVISORY: UCSDT2 missing data for more than 2 days: ['2012-05-04', '2012-05-05', '2012-05-06', '2012-05-07', '2012-05-08']
</pre></blockquote>
<b>Note: this is a manual ticket initiation.</b>

If, for whatever reason %MYOSG_HOME% is unavailable, an additional warning message will be generated advising of this.  This is not a critical problem unless it persists for several.  When this occurs, any messages regarding sites not reporting should not be acted upon.
   * WARNING: Unable to determine planned shutdowns 


---+++ Validation/Verification that !MyOSG and %WLCG_REBUS_TOPOLOGY% agree
Since, at the current time, only those __resource_groups__ with MOU agreements are being interfaced to APEL, a validation is made to insure %MYOSG_HOME% and the %WLCG_REBUS_TOPOLOGY% are in sync.  The terminology between the two is slightly different:
<blockquote>
%TABLE%
| *Rebus* | *MyOsg* | 
| Federation Accounting Name | WLCGInformation Accounting Name |
| Site | resource group |
</blockquote>
A query is made to %WLCG_REBUS_TOPOLOGY% and against %MYOSG_HOME% comparing the !MyOSG WLCGInformation !AccountingName with the Rebus !AccountingName to insure that monthly MOU reporting will be accurately for the __resource_group's__ data the interfaced sends to APEL.  This should be investigated and a goc ticket should be generated to take correct the descrepancy.   There are too many combination of conditions to highlight here.  They are self explanatory as to the problem.

<b>Note: this is a manual ticket initiation/process</b>

The following warning can occur and are not immediately critical unless they persist:
   * WARN: The WLCG REBUS topology was not accessible today. We are using a previous days data for validations

---+++ Other warning/error messages
At the end of the process, the xml/dat/html files created in the ./log directory are copied to the Gratia reporting server.  If these fail for whatever reason, the failure should be investigated, but it is not immediately critical to the data being sent to APEL.
   * WARNING: !SendXmlHtmlFiles method: [command] failed rtn code [rtn]

On the first day of each month, a warning message will be generated advising that the current months lcg-reportableSites file should be added to svn as should the txt/dat/xml/html files in the ./logs directory.
   * These files should be checked to see if any updates should be made to SVN/CVS in order to retain their history.


---++ Maintaining the Normalization Factors
Updating of the normalization factor for a __resource_group__ is a manual process.

Information related to the calculation of the normalization factor for each site can be seen at  %OSG_WLCG_REPORTING%
containing the following information:
   * GIP Sub-cluster Data (including the <nop>SpecInt for the processor)
   * Site Normalization Factors (as calculated using the GIP data and as used in the reporting to APEL/WLCG)

It provides a comparison of GIP calculated normalization factor with the actual normalization factor being used in the %REPORTABLE_SITES% file.  However, due to the nature of the GIP interface, it has not proved reliable at any point in time.  In general, a change is made only when requested.

ATLAS maintains their own calculations manually and can be viewed here:
   * http://www.usatlas.bnl.gov/twiki/bin/view/Admins/CapacitySummary.html

The ALICE sites provide their own normalization factor.

---++ Maintaining the Reportable Sites and VOs
This is also a manual process.  As seen in the section on warning messages, there is a process which checks %MYOSG_HOME% at the __resource__ level for the !InteropAccounting flag and warns if a site says it is reporting but has not yet been added to the %REPORTABLE_SITES% file.  Usually, at this time anyway, it is a mistake in updating via OIM.




---++ Would like to have enhancements
---+++ Move the manually maintained configuration files to !MyOsg
Eventually  the %REPORTABLE_SITES% file should be replaced with data in %MYOSG_HOME%.

The areas that would have to be addressed are:
   1 Identification of the __resource_groups__ that are to be reported/interfaced.
   1 Maintenance of the normalization factor at the __resource_group__ level
   1 Identification of the VOs to be reported/interfaced


---++ Open issues / To-Do's

---+++ Synchronization of OIM/MyOSG with Gratia
The intent of this initiative is to align OIM/MyOSG with Gratia and, additionally, extend that to the APEL/WLCG interface. The motivation is to eliminate the manual intervention required when new resources (Gratia sites) are added or removed from service.  Currently, there does not exist any true relationship between resources in OIM/MyOsg and Gratia.  The OIM/MyOSG resource name should correspond to a Gratia site name.  In the following paragraphs, when the term 'resource' is used, it is considered synonymous with Gratia 'site name'.

In OIM/MyOSG, the ability to define resources that are involved in the APEL/WLCG interface currently exists  This data is at the resource level and contained in the WLCG Information section:
   1 Interop Accounting flag - True if the resource is interfaced to APEL/WLCG for accounting purposes
   1 Accounting Name - if the Interop Accounting flag is True, this contains the Tier 1 or 2 WLCG federation name (e.g., T2-US-Caltech)

From an APEL/WLCG perspective, we need to handle the following use cases:
   1 Addition of a new resource for a Tier1/2 Federation
   1 Removal of a resource from a Tier1/2 Federation (aka, disabling a resource in OIM/MyOSG terms).  This requires preserving the historical data for that resource.


---+++ Validation/verification of monthly MOU reports
When the Tier 2 monthly reports are issued by the LCG accounting office (e.g, http://lcg.web.cern.ch/LCG/accounting/Tier-2/2010/january-10/Tier2_Accounting_Report_January2010.pdf), a validation of the OSG federation resource is being performed manually.  It would be "nice" to be able to able perform some form of automated validation and eliminate this manual effort.  I am not sure if this is totally viable.


---+++ Normalization factor issues
<OL>
<LI>As far as Gratia/Accounting is concerned, we would like to get to a point where each job usage record contain the type of cpu  that the job ran on.  This would give Gratia the most flexibility to normalize the result (normalization is required by WLCG and is the only way to fairly compare the result). 

However, at this point the batch system does not gives us enough information (Condor 6.9 might be able to make the information available).   So for now we will rely for  normalization on a rougher estimate.  Currently the estimate comes from the average on one existing farm for which I know the actual hardware.  When the GLUE schema is properly filled, we will use the average for  the Site the job ran on.
</LI>

<LI>
The normalization factor is currently reflecting the latest cluster configuration.  As these clusters are upgraded over time, these factors will change.  In order to be able to re-create the normalized view of past periods, these configurations/factors will need to be keyed by time period somehow.
</LI>
</OL>


---++ History
This section just documents when major changes to the interface took place:
%TABLE{ tableborder="1" cellpadding="0" cellspacing="1" headerbg="#99CCCC" databg="#FFFFCC, #FFFFFF"}%
|  *Date*  |  *Description*  |
| September 2008 | Added methods to create xml/hmtl/dat files to provide visibility to the data sent and displayed at %GRATIA_APEL_UI% and %OSG_WLCG_REPORTING% |
| November 2008 | Added an additional filter on the selection criterea. Only selecting <nop>ResourceType='Batch'.  Changes to the condor probes (v1.00.3) will result in distinguishing between the actual  grid jobs (Batch) and the grid monitoring job (<nop>GridMonitor) when jobs are submitted using condor_submit. Any 'local' job used to submit a job on the CE node will be filtered, but should they at some point be passed to Gratia, these will be identified as Local. |
| March 2009 | Started saving the configuration file for reportable sites and normalization factors for each month.  This provided the capability to re-send prior months data in the event a site had problems and still retain that period's configuration. |
| May 2009 | Added the User's Distinguished Name (DN) as part of the summary criterea and data sent. |
| June 2009 | Started checking for Gratia sites that had stopped reporting data to Gratia.  This provided a pro-active means of identifying problems rather than waiting for the monthly MOU reports to be issued. |
| July 2009 | Added an extract of OIM downtimes to use  when determining if a Gratia site failed to report |
| December 2009 | Added use of a new class (!InactiveResources) to query MyOsg for Resource that have been marked inactive.  This is used in conjunction with the Downtimes class when checking why a site/resourcehas not reported |
| January 2010 | APEL/EGI started reporting MOU reports using <nop>HEPSpec2006 normalization factors in place of the <nop>SpecInt2000 values we are reporting.  We still use <nop>SpecInt2000.  They apply a factor of 4x as means of adjusting until all sites report using <nop>HEPSpec2006.  When we have <nop>HEPSpec2006 available we divide by 4 to maintain consistency. |
| December 2010 | The ALICE VO was added to the list of reportable VOs and sites. |
| August 2011 | This represents a major change to the interface.  All OSG reporting to WLCG has been in reference to !MyOsg resource group.  However, the <nop>MyOsg <nop>InteropAccounting flag for WLCG Information is at the resource, not resource group, level.  The changes made in this revision will now:%BR%1. treat the lcg-reportableSites config file entries as resource groups. This also means the Normalization Factors should be calculated at the resource group level.%BR%2. determine which resources within that resource group should have their gratia data reported to APEL/EGI.%BR%3. summarize (using sql) the accounting data for the month for all interfaced resources for the resource group. A new class, <nop>InteropAccounting(.py), provides the access to <nop>MyOsg. |
| June 2012 | Changed the APEL interface from a direct update of the APEL database to the use of a messaging system (SSM) |

More detail information related to code, reportable sites and normalization factors can be found in the [[GratiaInterfacesApelLcgHistory][Gratia Interfaces - APEL/WLCG - History twiki]]

---++ More information
---+++ Sending Data to EGI Based on VO Only
   * [[GratiaInterfacesApelEgiByVo][Sending Data to EGI Based on VO Only]]
---+++ APEL SSM/ActiveMQ Interface
   * [[Interoperability/AccountingInteropQuestionsAndIssues][APEL SSM/ActiveMQ Interface]]

---+++ Developers Corner
   * [[ApelWlcgDevelopersCorner][APEL/WLCG Developers Corner twiki]].

---+++ EGI 
   *  %EGI_PORTAL_OSG_VIEW%
   *  %EGI_PORTAL_TIER1_VIEW%
   *  %EGI_PORTAL_TIER2_VIEW%
   *  %EGI_PORTAL_USER_VIEW%
   *  %EGI_PORTAL_VOMEMBER_VIEW%   
   *  %WLCG_REBUS_TOPOLOGY%

%STOPINCLUDE%




<!-- MAJOR UPDATES
For significant updates to the topic, consider adding your 'signature' (beneath this editing box) !-->
---++!! Major updates
<!--Future editors should add their signatures beneath yours!-->
-- Main.JohnWeigand - 19 Nov 2009: Updated for implementation of User Distinguished Name on 11/1/2009%BR%
-- Main.JohnWeigand - 08 Feb 2010: Split the developers corner (doc) out as a separate twiki (!ApelWlcgDevelopersCorner) %BR%

%META:FILEATTACHMENT{name="Normalization-factors.xls" attr="" autoattached="1" comment="Normalization factor calculations" date="1206131451" path="Normalization-factors.xls" size="38912" user="Main.JohnWeigand" version="2"}%
%META:FILEATTACHMENT{name="lcg-reportableSites" attr="" autoattached="1" comment="APEL/WLCG site table" date="1206131342" path="lcg-reportableSites" size="6951" user="Main.JohnWeigand" version="13"}%
%META:FILEATTACHMENT{name="OIM-registered-resource-3-5-2009.xls" attachment="OIM-registered-resource-3-5-2009.xls" attr="" comment="OIM Registered Resources 3/5/2009 (.xls format)" date="1237479078" path="OIM-registered-resource-3-5-2009.xls" size="49359" stream="OIM-registered-resource-3-5-2009.xls" tmpFilename="/usr/tmp/CGItemp6367" user="JohnWeigand" version="1"}%
