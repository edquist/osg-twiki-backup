%META:TOPICINFO{author="DerekWeitzel" date="1276647306" format="1.1" reprev="1.14" version="1.14"}%
%META:TOPICPARENT{name="UsingTheGrid"}%
%LINKCSS%

<!-- This is the default OSG documentation template. Please modify it in -->
<!-- the sections indicated to create your topic.                        --> 

<!-- By default the title is the WikiWord used to create this topic. If  -->
<!-- you want to modify it to something more meaningful, just replace    -->
<!-- %TOPIC% below with i.e "My Topic".                                  -->

---+!! Condor-G to Glidein Workflow Management System porting guide
%DOC_STATUS_TABLE%
%TOC%

---++ About This Document
This document is meant for VO's transitioning from Condor-G to !GlideinWMS.  It assumes some knowledge of Condor, a working install of !GlideinWMS, as well as access to Condor-G submission files.

---++Submission File
The differences between the submission file for Condor-G and !GlideinWMS are minimal.


   * Since Condor is no longer submitting directly to the grid, the universe for the job will need to change from grid, to vanilla.
   <pre class="file">
   universe=grid</pre>
   to
    <pre class="file">
   universe=vanilla</pre>

   * It is no longer necessary to set a timeout or periodic_hold expression.  This is due to the nature of pilot submission, when a slot is free, you can instantly run on it.

   * It is useful to have an error detection/correction statement in the submission file such as:
   <pre class="file">
   OnExitHold = (ExitStatus =!= 0)
   OnExitRemove = (ExitStatus == 0)
   PeriodicRelease = ((CurrentTime - EnteredCurrentStatus) > 60) && (HoldReasonCode =!= 1) && (NumJobStarts <= N) </pre>
   This statement will hold the job if it exits with a non-zero status.  It will remove the job only if it exited successfully (exit status 0).  And it will release the job if it wasn't held with 'condor_hold' after 60 seconds and the job hasn't started more than N times.
%NOTE% It is not necessary to use error detection when using dagman.  Dagman has it's own retry [[http://www.cs.wisc.edu/condor/manual/v7.4/2_10DAGMan_Applications.html#SECTION003106100000000000000][mechanism]].


---+++ File Transfer
   * Need to specify should_transfer_files:
     <pre class="file">
     should_transfer_files = YES</pre>

   * It is still necessary to specify transfer_input_files, but do not need to specify transfer_output_files.  !GlideinWMS will transfer every file that is created back to the submission host.  This often leads to many temporary files being transferred back when a job completes.  It is important to delete temporary files as a part of your job.


---+++ User Proxy
Some sites on the OSG require a user proxy to accompany a !GlideinWMS job.  Therefore, it must be explicitly specified on in the submit file:

<pre class="file">
X509UserProxy = /tmp/x509up_u... </pre>


---+++ Demotion after failed jobs
In OSGMM, a typical submission file included the lines:
<pre class="file">
match_list_length = 4
Rank              = (TARGET.Rank) - &#92;
                    ((TARGET.Name =?= LastMatchName0) * 1000) - &#92;
                    ((TARGET.Name =?= LastMatchName1) * 1000) - &#92;
                    ((TARGET.Name =?= LastMatchName2) * 1000) - &#92;
                    ((TARGET.Name =?= LastMatchName3) * 1000)
</pre>

Although this statement will still work with !GlideinWMS, it will not have the same effect that it did in OSGMM.  In !GlideinWMS, =TARGET.Name= referrers to the specific worker node rather than a entire site as it did in OSGMM.  There is no equivalent statement in !GlideinWMS to demote the rank of a site.

---+++ Example !GlideinWMS Condor submission
%TWISTY{
mode="div"
showlink="Show !GlideinWMS Submission file"
hidelink="Hide"
showimgleft="%ICONURLPATH{toggleopen-small}%"
hideimgleft="%ICONURLPATH{toggleclose-small}%"
}%
<pre class="file">
inputTab = PrimaseCTDnohis.tab
storeNumber = 01.24.10-11.34.59

should_transfer_files = YES
when_to_transfer_output = ON_EXIT

transfer_input_files = $(inputTab)
remote_output_files = srm://red-srm1.unl.edu:8443/srm/v2/server?SFN=/mnt/hadoop/user/powers/Rosetta/$(storeNumber)/Step1/rosetta.step1.tar.gz

executable = init.sh
Args = $(inputTab) $(remote_output_files)

output=condor_out/output.$(Cluster).$(Process)
error=condor_out/error.$(Cluster).$(Process)
log=results.log

X509UserProxy = /tmp/x509up_u501

queue 1
</pre>

   * The =inputTab= and =storeNumber= are the inputs into the file.  =storeNumber= is a unique identifier used for storing on the srm server.
   * Notice the =should_transfer_files= and =when_to_tranfser_output= are both specified.  These are specified because there is no shared file system in !GlideinWMS
   * =transfer_input_files= is here to designate what files to transfer with the job.  
   * =remote_output_files= is where to store the output file after the job completes.  The job (init.sh) has the transfer written into it.
   * =output=, =error=, and =log= are standard in any Condor job description.


%ENDTWISTY%


---++DAGMan Pitfalls

When A Condor-G job completes, the exit status of the job is always 0 regardless of the actual exit status at the remote site.  Since Condor interprets a 0 exit status as success, DAGMan will always interpret the job as succeeding in Condor-G.  A common approach to solve this is to have each job have a post script to check for successful completion.

In !GlideinWMS, the correct exit status will be transferred back with the job.  In this case, it is easier to use DAGMan's automatic exit status checking for error detection.  If you only want error detection, then you do not need to add anything to the DAG.  If you want DAGMan to retry the job if it fails, add:
<pre class="file">
RETRY node_name 5</pre>
This will retry the job after a failure 5 times.

%TWISTY{
mode="div"
showlink="Show example !DAGMan Submission file"
hidelink="Hide"
showimgleft="%ICONURLPATH{toggleopen-small}%"
hideimgleft="%ICONURLPATH{toggleclose-small}%"
}%
<pre class="file">
JOB step1 condor.step1.submit
JOB step3 condor.step3.submit
SCRIPT PRE step1 pre.sh step1
JOB step2-0 condor.step2.submit
PARENT step1 CHILD step2-0
PARENT step2-0 CHILD step3
RETRY step2-0 1000
JOB step2-1 condor.step2.submit
PARENT step1 CHILD step2-1
PARENT step2-1 CHILD step3
RETRY step2-1 1000
....
JOB step2-999 condor.step2.submit
PARENT step1 CHILD step2-999
PARENT step2-999 CHILD step3
RETRY step2-999 1000

Retry step1 5
Retry step3 5
</pre>

In this example, the DAG has a single setup node (step1), a 1000 node wide middle (step2), and a single finishing node (step3).  

%ENDTWISTY%


---++Monitoring Jobs

It is more difficult in !GlideinWMS to monitor exactly where your jobs are going.  !GlideinWMS's VOFrontend provides some monitoring regarding the total jobs running at a site.  A useful command is:
<pre class="screen">
condor_status -format '%s\n' 'GLIDEIN_Site' -const 'IS_MONITOR_VM =!= TRUE' | sort | uniq -c</pre>
This command will output the number of glideins at each site.
%TWISTY{
mode="div"
showlink="Show example output"
hidelink="Hide"
showimgleft="%ICONURLPATH{toggleopen-small}%"
hideimgleft="%ICONURLPATH{toggleclose-small}%"
}%

<pre class="screen">
[dweitzel@glidein ~]$ condor_status -format '%s\n' 'GLIDEIN_Site' -const 'IS_MONITOR_VM =!= TRUE' | sort | uniq -c
      3 BNL
    210 Nebraska
    764 Omaha
     57 UConn
      1 UCSD
     16 UNESP
      5 Wisconsin
</pre>

%ENDTWISTY%

We've also found adding the following to your local condor_config is helpful.  The first line defines the JOBGLIDEIN_Site attribute to be equal to the glidein-site of the batch slot.  The second line instructs condor to insert the JOBGLIDEIN_Site attribute into every job when it is submitted.
<pre class="file">
JOBGLIDEIN_Site="$$([TARGET.GLIDEIN_Site])"
SUBMIT_EXPRS = $(SUBMIT_EXPRS) JOBGLIDEIN_Site
</pre>
This means that every running job will have an entry in their !ClassAd noting where it is running.

For example, you can query your job locations using the following:
%TWISTY{
mode="div"
showlink="Show example output"
hidelink="Hide"
showimgleft="%ICONURLPATH{toggleopen-small}%"
hideimgleft="%ICONURLPATH{toggleclose-small}%"
}%
<pre class="screen">
[bbockelm@glidein ~]$ condor_q -run -format '%s\n' MATCH_EXP_JOBGLIDEIN_Site | sort | uniq -c
    403 Omaha
      5 UConn
</pre>
%ENDTWISTY%


---++ Node Verification in !GlideinWMS
Verification of a worker node can be done before the glidein starts jobs.  A verification script can be specified inside the !VOFrontend's configuration file, =frontend.xml=.

<pre class="file">
...
&lt;files&gt;
   &lt;file absfname="/home/frontend/glidein_scripts/startd.sh" after_entry="True" const="True" executable="True" untar="False" wrapper="False"&gt;
      &lt;untar_options cond_attr="TRUE"/&gt;
   &lt;/file&gt;
&lt;/files&gt;
...
</pre>
More documentation on custom scripts can be found on the  [[http://www.uscms.org/SoftwareComputing/Grid/WMS/glideinWMS/doc.v2/manual/factory/custom_scripts.html][GlideinWMS pages]].
---++ *Comments*
%COMMENT{type="tableappend"}%

<!-- CONTENT MANAGEMENT PROJECT
############################################################################################################
 DEAR DOCUMENT OWNER
 ===================

 Thank you for claiming ownership for this document! Please fill in your FirstLast name here:
   * Local OWNER = DerekWeitzel

 Please define the document area, choose one of the defined areas from the next line
 DOC_AREA = (ComputeElement|Storage|VO|Security|User|Monitoring|General|Integration|Operations|Tier3)
   * Local DOC_AREA       = User

 define the primary role the document serves, choose one of the defined roles from the next line
 DOC_ROLE = (EndUser|Student|Developer|SysAdmin|VOManager)
   * Local DOC_ROLE       = Developer

 Please define the document type, choose one of the defined types from the next line
 DOC_TYPE = (Troubleshooting|Training|Installation|HowTo|Planning|Navigation|Knowledge)
   * Local DOC_TYPE       = HowTo
  Please define if this document in general needs to be reviewed before release ( %YES% | %NO% )
   * Local INCLUDE_REVIEW = %YES%

 Please define if this document in general needs to be tested before release ( %YES% | %NO% )
   * Local INCLUDE_TEST   = %NO%

 change to %YES% once the document is ready to be reviewed and back to %NO% if that is not the case
   * Local REVIEW_READY   = %YES%

 change to %YES% once the document is ready to be tested and back to %NO% if that is not the case
   * Local TEST_READY     = %NO%

 change to %YES% only if the document has passed the review and the test (if applicable) and is ready for release
   * Local RELEASE_READY  = %NO%


 DEAR DOCUMENT REVIEWER
 ======================

 Thank for reviewing this document! Please fill in your FirstLast name here:
   * Local REVIEWER       = GabrieleGarzoglio
 Please define the review status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local REVIEW_PASSED  = %IN_PROGRESS%


 DEAR DOCUMENT TESTER
 ====================

 Thank for testing this document! Please fill in your FirstLast name here:
   * Local TESTER         = 
 Please define the test status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local TEST_PASSED    = %IN_PROGRESS%
############################################################################################################
-->



-- Main.DerekWeitzel - 24 May 2010

%META:TOPICMOVED{by="DerekWeitzel" date="1274881384" from="Documentation.OSGMMToGlidein" to="Documentation.CondorGToGlidein"}%
