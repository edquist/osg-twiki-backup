%META:TOPICINFO{author="DouglasStrain" date="1331074071" format="1.1" reprev="1.19" version="1.19"}%
%META:TOPICPARENT{name="InstallBestPractices"}%
%LINKCSS%
---+!! %SPACEOUT{ "Install !XRootD" }%
%DOC_STATUS_TABLE%
%TOC{depth="3"}%

---+ About this Document

Here we describe how to install the !XRootD redirector as part of a storage element for the Open Science Grid.
This document is intended for system administrators who wish to install !XRootD as part of a storage element or as part of a global namespace.


---+ Requirements

---++ Host and OS

   * A host to install the !XRootD redirector
      * Most likely, other hosts are needed for !XRootD data nodes.
   * OS is %SUPPORTED_OS%. 
   * Root access

---++ Users

This installation will create one user:

%STARTSECTION{"Users"}%
| *User* | *Comment* |
| =xrootd= | User that will run xrootd services. |
%ENDSECTION{"Users"}%

---++ Networking

%STARTSECTION{"Firewalls"}%
%INCLUDE{"Documentation/Release3.FirewallInformation" section="FirewallTable" lines="xrootd"}% \
%ENDSECTION{"Firewalls"}%


---+ Install Instructions

%INCLUDE{"YumRepositories" section="OSGRepoBrief" headingoffset="1"}%

---++ Installing !XRootD Server

Install xrootd-server and dependent rpms:

For i386:
<pre class="rootscreen">
yum install xrootd-server
</pre>

For x86_64:
<pre class="rootscreen">
yum install xrootd-server.x86_64
</pre>


---++ Initial Setup for !XRootD Server

   Run xrootd setup, which creates an appropriate directory for xrootd, creates user,group "xrootd" if needed and changes permissions appropriately.

<pre class="rootscreen">
$ service xrootd setup     
</pre>

All xrootd related configuration files and directories are now belong to the user defined in ==/etc/sysconfig/xrootd== (default: user "xrootd", group "xrootd"). All xrootd related daemons are owned by this user. These user and group are created if they don't exist. If you want to change the user and the group that xrootd runs as, modify XROOTD_USER and XROOTD_GROUP in the file ==/etc/sysconfig/xrootd==.  If you start daemons as one user and then decide to change a user, you have to modify ==/etc/sysconfig/xrootd== and rerun "service xrootd setup".  

---+ Starting and Stopping !XRootD Server

Start the xrootd server using the following commands.  You will want to start the services on the redirector node before any services on the data node(s).
<pre class="rootscreen">
$ service xrootd start
Starting xrootd (xrootd, default):                         %GREEN%[  OK  ]%ENDCOLOR%
</pre> 

To stop xrootd server:
<pre class="rootscreen">
$ service xrootd stop
</pre>

*Note:* If you have installed cluster management services (in the following sections) for an xrootd server,
you will also need to start and stop cmsd on each node.

---+++ Starting and Stopping !CmsD Server

Start the cmsd daemon using the following command.  Note that you will want to start both the xrootd and cmsd on the redirector before starting xrootd and cmsd on the data nodes.
<pre class="rootscreen">
$ service cmsd start
Starting xrootd (cmsd, default):                          %GREEN% [  OK  ]%ENDCOLOR%
</pre> 

To stop cmsd server:
<pre class="rootscreen">
$ service cmsd stop
</pre>


---+ Initial Verification for !XRootD Server

   In order to test that xrootd is working as a stand alone data server, start the server using the commands in the previous section.  You should be able now to copy files using xrdcp command in ==/tmp==. To test do:

<pre class="rootscreen">
$ xrdcp /bin/sh root://localhost:1094//tmp/first_test
[xrootd] Total 0.76 MB  |====================| 100.00 % [inf MB/s]
$ ls -l /tmp/first_test 
-rw-r--r-- 1 xrootd xrootd 801512 Apr 11 10:48 /tmp/first_test
</pre>

---+ Advanced Configuration
  
---++ Creating Xrootd Cluster

     <img src="%ATTACHURLPATH%/rdr.jpg" alt="rdr.jpg" width='736' height='318' />    

An !XRootD cluster can make a storage installation much more scalable.  Controlling file acceess queries to the cluster is the "redirector" node.  This node will serve as a frontend for user requests and redirect their file accesses to the appropriate data node(s) that have the data they are requesting.  To facilitate this, two daemons xrootd (controlling file access and storage) and cmsd (controlling "cluster management services" and communications between nodes) will be started on each node once installation and configuration is completed.  Note that, for large virtual organizations, a site-level redirector may actually also communicate upwards to a regional or global redirector that handles access to a multi-level hierarchy.  This section will only cover handling one level of !XRootD hierarchy.  

In the below instructions, RDRNODE will refer to the redirector instances and DATANODE will refer to the data node host.  Each instance of this below should be replaced with the FQDN, ie output of 'hostname'.

---+++ Modify =/etc/xrootd/xrootd-clustered.cfg=

You will need to modify the xrootd-clustered.cfg on both nodes.  The following example should serve as a base configuration for clustering.  
Further customizations are detailed below.

<pre class="file">
all.export /tmp stage
set xrdr = RDRNODE
all.manager $(xrdr):3121
if $(xrdr)
  all.role manager
else
  all.role server
  cms.space min 2g 5g
fi
</pre>
Note: if there are other lines in the file, you can comment them out or delete them unless you are an expert user.

You will need to customize the following lines:

|*Configuration Line*|*Changes Needed*|
|=all.export /tmp stage=| Change =/tmp= to the directory to allow !XRootD access to|
|=set xrdr&#61;RDRNODE= | Change to the hostname of the redirector |
|=cms.space min 2g 5g= | Reserve this amount of free space on the node.  For this example, if space falls below 2GB, xrootd will not store further files on this node until space climbs above 5GB. You can use k, m, g, or t to indicate kilobyte, megabytes, gigabytes, or terabytes, respectively.|


Further information can be found at [[http://xrootd.slac.stanford.edu/doc]]



---+++ Starting services

Both =xrootd= and =cmsd= need to be started on all nodes:

<pre class="rootscreen">
$ service xrood start
Starting xrootd (xrootd, default):                         %GREEN%[  OK  ]%ENDCOLOR%
$ service cmsd start
Starting xrootd (cmsd, default):                          %GREEN% [  OK  ]%ENDCOLOR%
</pre>

---+++ Verifying cluster

Verify that you can copy file to /tmp on the server data via redirector:

<pre class="rootscreen">
$ xrdcp /bin/sh  root://%RED%RDRNODE%ENDCOLOR%:1094///tmp/second_test
[xrootd] Total 0.76 MB  |====================| 100.00 % [inf MB/s]
</pre>

Check that the ==/tmp/second_test== is located on data server DATANODE.

---++ Adding Simple Server Inventory  to your cluster

The Simple Server Inventory (SSI) provide means to have an inventory for each data server (See details in [[http://xrootd.org/doc/prod/cms_config.htm][XRootD CMS config]]).
In order to configure it you will need to run a second instance of xrootd daemon as well !XrdCnsd process that should run on every data server. We will configure xrootd cluster that consists of two nodes.  Note, this cnsd process is short for "composite name space" and will handle the inventory.
Host A is a redirector node that is running the following daemons:
   1. xrootd redirector
   1. cmsd 
   1. xrootd - second instance that required for SSI

Host B is a data server that is running the following daemons:
   1. xrootd data server
   1. cmsd
   1. !XrdCnsd - started automatically by xrootd

We will need to create a directory on the redirector node for Inventory files. 
<pre class="rootscreen">
$ mkdir -p /data/inventory
$ chown xrootd.xrootd /data/inventory
</pre>

On the data server (host B) let's create the storage cache that will be different from ==/tmp==.
<pre class="rootscreen">
$ mkdir -p  /local/xrootd
$ chown xrootd.xrootd /local/xrootd
</pre>

Now, we have to change ==/etc/sysconfig/xrootd== on  redirector node %RED%hostA%ENDCOLOR% to run multiple instances of xrootd. Second instance of xrood will be name "cns" and will be used for SSI<pre class="file">
XROOTD_USER=xrootd
XROOTD_GROUP=xrootd
XROOTD_DEFAULT_OPTIONS="%RED%-k 7%ENDCOLOR% -l /var/log/xrootd/xrootd.log -c /etc/xrootd/xrootd-clustered.cfg"
%RED%XROOTD_CNS_OPTIONS="-k 7 -l /var/log/xrootd/xrootd.log -c /etc/xrootd/xrootd-clustered.cfg"%ENDCOLOR%
CMSD_DEFAULT_OPTIONS="%RED%-k 7%ENDCOLOR% -l /var/log/xrootd/cmsd.log -c /etc/xrootd/xrootd-clustered.cfg"
FRMD_DEFAULT_OPTIONS="%RED%-k 7%ENDCOLOR% -l /var/log/xrootd/frmd.log -c /etc/xrootd/xrootd-clustered.cfg"
%RED%XROOTD_INSTANCES="default cns"%ENDCOLOR%
CMSD_INSTANCES="default"
FRMD_INSTANCES="default"
</pre>

Now we have to modify ==/etc/xrootd/xrootd-clustered.cfg== on both nodes so it looks like this:<pre class="file">
all.export /data/xrootdfs
set xrdr=%RED%hostA%ENDCOLOR%
all.manager $(xrdr):3121
if $(xrdr) && named cns
      all.export /data/inventory
      xrd.port 1095
else if $(xrdr)
      all.role manager
      xrd.port 1094
else
      all.role server
      oss.localroot /local/xrootd
      ofs.notify closew create mkdir mv rm rmdir trunc | /usr/bin/XrdCnsd -d -D 2 -i 90 -b $(xrdr):1095:/data/inventory
      #add cms.space if you have less the 11GB
      # cms.space options http://xrootd.slac.stanford.edu/doc/dev/cms_config.htm
      cms.space min 2g 5g
fi
</pre>

Now, we can start xrootd cluster executing the following commands. On redirector you will see:<pre class="rootscreen">
$ service xrootd start
Starting xrootd (xrootd, default):                        %GREEN%[  OK  ]%ENDCOLOR%
Starting xrootd (xrootd, cns):                             %GREEN%[  OK  ]%ENDCOLOR%
$ service cmsd start
Starting xrootd (cmsd, default):                          %GREEN%[  OK  ]%ENDCOLOR%
</pre>

On redirector node you should see two instances of xrootd running:<pre class="rootscreen">
$ ps auxww|grep xrootd
xrootd   29036  0.0  0.0  44008  3172 ?        Sl   Apr11   0:00 /usr/bin/xrootd -k 7 -l /var/log/xrootd/xrootd.log -c /etc/xrootd/xrootd-clustered.cfg -b -s /var/run/xrootd/xrootd-default.pid -n default
xrootd   29108  0.0  0.0  43868  3016 ?        Sl   Apr11   0:00 /usr/bin/xrootd -k 7 -l /var/log/xrootd/xrootd.log -c /etc/xrootd/xrootd-clustered.cfg -b -s /var/run/xrootd/xrootd-cns.pid -n cns
xrootd   29196  0.0  0.0  51420  3692 ?        Sl   Apr11   0:00 /usr/bin/cmsd -k 7 -l /var/log/xrootd/cmsd.log -c /etc/xrootd/xrootd-clustered.cfg -b -s /var/run/xrootd/cmsd-default.pid -n default
</pre>%ICON{warning}% the log file for second named instance of xrootd with be placed in /var/log/xrootd/cns/xrootd.log 

On data server node you should that !XrdCnsd process has been started:<pre class="rootscreen">
$ ps auxww|grep xrootd
xrootd   19156  0.0  0.0  48096  3256 ?        Sl   07:37   0:00 /usr/bin/cmsd -l /var/log/xrootd/cmsd.log -c /etc/xrootd/xrootd-clustered.cfg -b -s /var/run/xrootd/cmsd-default.pid -n default
xrootd   19880  0.0  0.0  46124  2916 ?        Sl   08:33   0:00 /usr/bin/xrootd -l /var/log/xrootd/xrootd.log -c /etc/xrootd/xrootd-clustered.cfg -b -s /var/run/xrootd/xrootd-default.pid -n default
xrootd   19894  0.0  0.1  71164  6960 ?        Sl   08:33   0:00 /usr/bin/XrdCnsd -d -D 2 -i 90 -b fermicloud053.fnal.gov:1095:/data/inventory
</pre>
---+++ Testing Xrootd Cluster with SSI
   1. Copy file to redirector node specifying storage path (/data/xrootdfs instead of /tmp): <pre class="rootscreen">
$ xrdcp /bin/sh root://localhost:1094//data/xrootdfs/test1
[xrootd] Total 0.00 MB  |====================| 100.00 % [inf MB/s]
</pre>
   1. To verify that SSI is working execute cns_ssi command on the redirector node: <pre class="rootscreen">
$ cns_ssi list /data/inventory
fermicloud054.fnal.gov incomplete inventory as of Mon Apr 11 17:28:11 2011
$ cns_ssi updt /data/inventory
cns_ssi: fermicloud054.fnal.gov inventory with 1 directory and 1 file updated with 0 errors.
$ cns_ssi list /data/inventory
fermicloud054.fnal.gov complete inventory as of Tue Apr 12 07:38:29 2011
/data/xrootdfs/test1
</pre>  _Note_: In this example fernilcould53.fnal.gov is a redirector node and fermicloud054.fnal.gov is a data server

---++ Adding Simple (Unix) Security 
In order to add simple security to your cluster you will need to add "auth_file" on the your data server node. Create ==/etc/xrootd/auth_file== :<pre class="file">
# This means that all the users have read access to the datasets
u * %RED%/data/xrootdfs%ENDCOLOR% lr

# This means that all the users have full access to their private dirs
u = %RED%/data/xrootdfs/%ENDCOLOR%@=/ a

# This means that this privileged user can do everything
# You need at least one user like that, in order to create the
# private dir for each user willing to store his data in the facility
u xrootd %RED%/data/xrootdfs%ENDCOLOR% a
</pre> Here we assume that your storage path is "/data/xrootdfs" (same as in the previous example).

Change file ownership (if you have created file as root):<pre class="rootscreen">
 $ chown xrootd.xrootd /etc/xrootd/auth_file
</pre>

The next step is to modify  ==/etc/xrootd/xrootd-clustered.cfg== on both nodes:<pre class="file">
all.export /data/xrootdfs
set xrdr=%RED%hostA%ENDCOLOR%
all.manager $(xrdr):3121
if $(xrdr) && named cns
      all.export /data/inventory
      xrd.port 1095
else if $(xrdr)
      all.role manager
      xrd.port 1094
else
      all.role server
      oss.localroot /local/xrootd
      ofs.notify closew create mkdir mv rm rmdir trunc | /usr/bin/XrdCnsd -d -D 2 -i 90 -b $(xrdr):1095:/data/inventory
      cms.space min 2g 5g
%RED% 
     # ENABLE_SECURITY_BEGIN
        xrootd.seclib /usr/lib64/libXrdSec.so
        # this specify that we use the 'unix' authentication module, additional one can be specified.
        sec.protocol /usr/lib64 unix
        # this is the authorization file
        acc.authdb /etc/xrootd/auth_file
        ofs.authorize
        # ENABLE_SECURITY_END
%ENDCOLOR%
fi
%ENDCOLOR%
</pre> _Note_: change %RED%*.fnal.gov%ENDCOLOR% with appropriate domain name.

After making all the changes, please, resart xrootd and cmsd daemons on all nodes.

---+++ Testing Xrootd Cluster with simple security enabled
   1. Login on redirector node as root
   1. Check that user "root" still can read files: <pre class="rootscreen">  
$ xrdcp  root://localhost:1094//data/xrootdfs/test1 /tmp/b
[xrootd] Total 0.00 MB  |====================| 100.00 % [inf MB/s]
</pre>
   1. Check that user "root" can not write files under /data/xrootdfs:<pre class="rootscreen"> 
$  xrdcp /tmp/b root://localhost:1094//data/xrootdfs/test2
Last server error 3010 ('Unable to create /data/xrootdfs/test2; Permission denied')
Error accessing path/file for root://localhost:1094//data/xrootdfs/test3
</pre> or you may get this error:<pre class="rootscreen"> 
$ xrdcp /tmp/b root://localhost:1094//data/xrootdfs/test2
Last server error 3011 ('No servers are available to write the file.')
Error accessing path/file for root://localhost:1094//data/xrootdfs/test2
</pre>
   1. Check that user can copy/retrieve files to/from /data/xrootdfs/~/...<pre class="rootscreen">
$ su - %RED%user%ENDCOLOR%
-bash-3.2$   xrdcp  /tmp/a  root://localhost:1094//data/xrootdfs/%RED%user%ENDCOLOR%/test1
[xrootd] Total 0.00 MB  |====================| 100.00 % [inf MB/s]
-bash-3.2$  xrdcp    root://localhost:1094//data/xrootdfs/%RED%user%ENDCOLOR%/test1 /tmp/c
[xrootd] Total 0.00 MB  |====================| 100.00 % [inf MB/s]
</pre>

---++ Adding File Residency Manager (FRM) to Xrootd Cluster
The FRM deals with two major mechanisms:
   * local disk
   * remote servers

The description of fully functional multiple xrootd clusters is beyond the scope of this document. In order to have this fully functional system you will need a global redirector and at least one remote xrootd cluster from where files could be moved to the local cluster. 

Below are the modifications you should make in order to enable FRM on your local cluster:
   1. Make sure that FRM is enabled in  ==/etc/sysconfig/xrootd== on your data sever:<pre class="file">
ROOTD_USER=xrootd
XROOTD_GROUP=xrootd
XROOTD_DEFAULT_OPTIONS="-l /var/log/xrootd/xrootd.log -c /etc/xrootd/xrootd-clustered.cfg"
CMSD_DEFAULT_OPTIONS="-l /var/log/xrootd/cmsd.log -c /etc/xrootd/xrootd-clustered.cfg"
FRMD_DEFAULT_OPTIONS="-l /var/log/xrootd/frmd.log -c /etc/xrootd/xrootd-clustered.cfg"
XROOTD_INSTANCES="default"
CMSD_INSTANCES="default"
FRMD_INSTANCES="default"
</pre>
   1. Modify ==/etc/xrootd/xrootd-clustered.cfg== on both nodes to specify options for frm_xfrd (File Transfer Daemon)  and frm_purged (File Purging Daemon).  For more information, you can visit the [[http://xrootd.org/doc/prod/frm_config.htm][FRM Documentation]] in the [[http://xrootd.org/doc/prod/frm_config.htm#_Toc298165607][frm_xfrd section]] and the [[http://xrootd.org/doc/prod/frm_config.htm#_Toc298165601][frm_purged section]]
   1. Start frm daemons on data server: <pre class="rootscreen">
$ service frm_xfrd start
$ service frm_purged start
</pre>
</pre>  %ICON{warning}% Both daemons will use  /var/log/xrootd/frmd.log for logging.

---++ Screendump of Install
%TWISTY{
mode="div"
showlink="Click here for a full installation example."
hidelink="Hide the example"
showimgleft="%ICONURLPATH{toggleopen-small}%"
hideimgleft="%ICONURLPATH{toggleclose-small}%"
}%
<pre class="screen">
[root@fermicloud091 ~]# wget http://download.fedoraproject.org/pub/epel/5/i386/e
pel-release-5-4.noarch.rpm
--2011-10-11 16:27:27--  http://download.fedoraproject.org/pub/epel/5/i386/epel-
release-5-4.noarch.rpm
Resolving download.fedoraproject.org... 140.211.169.197, 152.19.134.146, 209.132
.181.16, ...
Connecting to download.fedoraproject.org|140.211.169.197|:80... connected.
HTTP request sent, awaiting response... 302 FOUND
Location: http://mirror.hmc.edu/epel/5/i386/epel-release-5-4.noarch.rpm [followi
ng]
--2011-10-11 16:27:28--  http://mirror.hmc.edu/epel/5/i386/epel-release-5-4.noar
ch.rpm
Resolving mirror.hmc.edu... 134.173.34.196
Connecting to mirror.hmc.edu|134.173.34.196|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 12232 (12K) [application/octet-stream]
Saving to: `epel-release-5-4.noarch.rpm'

100%[======================================>] 12,232      --.-K/s   in 0.1s

2011-10-11 16:27:28 (92.9 KB/s) - `epel-release-5-4.noarch.rpm' saved [12232/122
32]

[root@fermicloud091 ~]# yum install yum-priorities
Loaded plugins: kernel-module
fermi-base                                               | 2.1 kB     00:00
fermi-security                                           | 1.9 kB     00:00
fermi-security/primary_db                                | 1.7 MB     00:00
sl-base                                                  | 2.1 kB     00:00
Setting up Install Process
Resolving Dependencies
--> Running transaction check
---> Package yum-priorities.noarch 0:1.1.16-14.el5 set to be updated
--> Finished Dependency Resolution
Beginning Kernel Module Plugin
Finished Kernel Module Plugin

Dependencies Resolved

================================================================================
 Package               Arch          Version               Repository      Size
================================================================================
Installing:
 yum-priorities        noarch        1.1.16-14.el5         sl-base         14 k

Transaction Summary
================================================================================
Install       1 Package(s)
Upgrade       0 Package(s)

Total download size: 14 k
Is this ok [y/N]: y
Downloading Packages:
yum-priorities-1.1.16-14.el5.noarch.rpm                  |  14 kB     00:00
Running rpm_check_debug
Running Transaction Test
Finished Transaction Test
Transaction Test Succeeded
Running Transaction
  Installing     : yum-priorities                                           1/1

Installed:
  yum-priorities.noarch 0:1.1.16-14.el5

Complete!
[root@fermicloud091 ~]# rpm -Uvh http://repo.grid.iu.edu/osg-release-latest.rpm
Retrieving http://repo.grid.iu.edu/osg-release-latest.rpm
warning: /var/tmp/rpm-xfer.rGxEw7: Header V3 DSA signature: NOKEY, key ID 824b86
03
Preparing...                ########################################### [100%]
   1:osg-release            ########################################### [100%]
[root@fermicloud091 ~]# yum install --enablerepo=osg-testing xrootd-server
Loaded plugins: kernel-module, priorities
osg                                                      | 1.9 kB     00:00
osg/primary_db                                           |  65 kB     00:00
osg-testing                                              | 1.9 kB     00:00
osg-testing/primary_db                                   | 320 kB     00:00
752 packages excluded due to repository priority protections
Setting up Install Process
Resolving Dependencies
--> Running transaction check
---> Package xrootd-server.i386 1:3.0.5-1.osg.xu set to be updated
--> Processing Dependency: xrootd-libs = 1:3.0.5-1.osg.xu for package: xrootd-se
rver
--> Processing Dependency: xrootd-client = 1:3.0.5-1.osg.xu for package: xrootd-
server
--> Processing Dependency: libXrdNet.so.0 for package: xrootd-server
--> Processing Dependency: libXrdSecsss.so.0 for package: xrootd-server
--> Processing Dependency: libXrdPosix.so.0 for package: xrootd-server
--> Processing Dependency: libXrdClient.so.0 for package: xrootd-server
--> Processing Dependency: libXrdFfs.so.0 for package: xrootd-server
--> Processing Dependency: libXrdNetUtil.so.0 for package: xrootd-server
--> Processing Dependency: libXrdSec.so.0 for package: xrootd-server
--> Processing Dependency: libXrdSys.so.0 for package: xrootd-server
--> Processing Dependency: libXrdOuc.so.0 for package: xrootd-server
---> Package xrootd-server.x86_64 1:3.0.5-1.osg.xu set to be updated
--> Running transaction check
---> Package xrootd-client.i386 1:3.0.5-1.osg.xu set to be updated
---> Package xrootd-client.x86_64 1:3.0.5-1.osg.xu set to be updated
---> Package xrootd-libs.i386 1:3.0.5-1.osg.xu set to be updated
--> Processing Dependency: libxml2.so.2 for package: xrootd-libs
---> Package xrootd-libs.x86_64 1:3.0.5-1.osg.xu set to be updated
--> Running transaction check
---> Package libxml2.i386 0:2.6.26-2.1.2.8 set to be updated
--> Finished Dependency Resolution
Beginning Kernel Module Plugin
Finished Kernel Module Plugin

Dependencies Resolved

================================================================================
 Package            Arch        Version                  Repository        Size
================================================================================
Installing:
 xrootd-server      i386        1:3.0.5-1.osg.xu         osg-testing      2.1 M
 xrootd-server      x86_64      1:3.0.5-1.osg.xu         osg-testing      2.1 M
Installing for dependencies:
 libxml2            i386        2.6.26-2.1.2.8           sl-base          795 k
 xrootd-client      i386        1:3.0.5-1.osg.xu         osg-testing      490 k
 xrootd-client      x86_64      1:3.0.5-1.osg.xu         osg-testing      496 k
 xrootd-libs        i386        1:3.0.5-1.osg.xu         osg-testing      503 k
 xrootd-libs        x86_64      1:3.0.5-1.osg.xu         osg-testing      523 k

Transaction Summary
================================================================================
Install       7 Package(s)
Upgrade       0 Package(s)

Total download size: 7.0 M
Is this ok [y/N]: y
Downloading Packages:
(1/7): xrootd-client-3.0.5-1.osg.xu.i386.rpm             | 490 kB     00:00
(2/7): xrootd-client-3.0.5-1.osg.xu.x86_64.rpm           | 496 kB     00:00
(3/7): xrootd-libs-3.0.5-1.osg.xu.i386.rpm               | 503 kB     00:00
(4/7): xrootd-libs-3.0.5-1.osg.xu.x86_64.rpm             | 523 kB     00:00
(5/7): libxml2-2.6.26-2.1.2.8.i386.rpm                   | 795 kB     00:00
(6/7): xrootd-server-3.0.5-1.osg.xu.i386.rpm             | 2.1 MB     00:00
(7/7): xrootd-server-3.0.5-1.osg.xu.x86_64.rpm           | 2.1 MB     00:00
--------------------------------------------------------------------------------
Total                                           1.7 MB/s | 7.0 MB     00:04
warning: rpmts_HdrFromFdno: Header V3 DSA signature: NOKEY, key ID 824b8603
osg-testing/gpgkey                                       | 1.7 kB     00:00
Importing GPG key 0x824B8603 "OSG Software Team (RPM Signing Key for Koji Packag
es) <vdt-support@opensciencegrid.org>" from /etc/pki/rpm-gpg/RPM-GPG-KEY-OSG
Is this ok [y/N]: y
Running rpm_check_debug
Running Transaction Test
Finished Transaction Test
Transaction Test Succeeded
Running Transaction
  Installing     : xrootd-libs                                              1/7
  Installing     : xrootd-client                                            2/7
  Installing     : libxml2                                                  3/7
  Installing     : xrootd-server                                            4/7
  Installing     : xrootd-libs                                              5/7
  Installing     : xrootd-client                                            6/7
  Installing     : xrootd-server                                            7/7

Installed:
  xrootd-server.i386 1:3.0.5-1.osg.xu   xrootd-server.x86_64 1:3.0.5-1.osg.xu

Dependency Installed:
  libxml2.i386 0:2.6.26-2.1.2.8           xrootd-client.i386 1:3.0.5-1.osg.xu
  xrootd-client.x86_64 1:3.0.5-1.osg.xu   xrootd-libs.i386 1:3.0.5-1.osg.xu
  xrootd-libs.x86_64 1:3.0.5-1.osg.xu

Complete!
[root@fermicloud091 ~]# service xrootd setup
[root@fermicloud091 ~]# service xrootd start
Starting xrootd (xrootd, default):                         [  OK  ]
[root@fermicloud091 ~]# xrdcp /bin/sh root://localhost:1094//tmp/first_test
[xrootd] Total 0.76 MB  |====================| 100.00 % [inf MB/s]
[root@fermicloud091 ~]# ls /tmp/first_test
/tmp/first_test

</pre>
%ENDTWISTY% 

---+ File Locations


%STARTSECTION{"Locations"}%

| *Service/Process* | *Configuration File* | *Description* |
| !XRootD | /etc/xrootd/xrootd-clustered.cfg | Main xrootd configuration and settings|
| | /etc/xrootd/auth_file | Authorized users file |

| *Service/Process* | *Log File* | *Description* |
| !XRootD | /var/log/xrootd/xrootd.log | !Xrootd server daemon log |
| cmsd | /var/log/xrootd/cmsd.log | Cluster management log |
| cns | /var/log/xrootd/cns/xrootd.log | Server inventory (composite name space) log |


%ENDSECTION{"Locations"}%


---+ How to get Help?
If you cannot resolve the problem, the best way to get help is by contacting osg-software@opensciencegrid.org. %BR%
For a full set of help options, see [[HelpProcedure][Help Procedure]].

---+ References

---+ Comments
%COMMENT{type="tableappend"}%



<!-- CONTENT MANAGEMENT PROJECT
############################################################################################################
 DEAR DOCUMENT OWNER
 ===================

 Thank you for claiming ownership for this document! Please fill in your FirstLast name here:
   * Local OWNER = DouglasStrain

 Please define the document area, choose one of the defined areas from the next line
 DOC_AREA = (ComputeElement|Storage|VO|Security|User|Monitoring|General|Integration|Operations|Tier3)
   * Local DOC_AREA       = Storage

 define the primary role the document serves, choose one of the defined roles from the next line
 DOC_ROLE = (EndUser|Student|Developer|SysAdmin|VOManager)
   * Local DOC_ROLE       = SysAdmin

 Please define the document type, choose one of the defined types from the next line
 DOC_TYPE = (Troubleshooting|Training|Installation|HowTo|Planning|Navigation|Knowledge)
   * Local DOC_TYPE       = Installation
  Please define if this document in general needs to be reviewed before release ( %YES% | %NO% )
   * Local INCLUDE_REVIEW = %YES%

 Please define if this document in general needs to be tested before release ( %YES% | %NO% )
   * Local INCLUDE_TEST   = %YES%

 change to %YES% once the document is ready to be reviewed and back to %NO% if that is not the case
   * Local REVIEW_READY   = %YES%

 change to %YES% once the document is ready to be tested and back to %NO% if that is not the case
   * Local TEST_READY     = %YES%

 change to %YES% only if the document has passed the review and the test (if applicable) and is ready for release
   * Local RELEASE_READY  = %YES%


 DEAR DOCUMENT REVIEWER
 ======================

 Thank for reviewing this document! Please fill in your FirstLast name here:
   * Local REVIEWER       = NehaSharma
 Please define the review status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local REVIEW_PASSED  = %YES%


 DEAR DOCUMENT TESTER
 ====================

 Thank for testing this document! Please fill in your FirstLast name here:
   * Local TESTER         = NehaSharma
 Please define the test status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local TEST_PASSED    = %YES%
############################################################################################################
-->




-- Main.DouglasStrain - 01 Sep 2011

%META:FILEATTACHMENT{name="rdr.jpg" attachment="rdr.jpg" attr="h" comment="Xrootd Cluster example" date="1330101681" path="rdr.jpg" size="28782" stream="rdr.jpg" tmpFilename="/usr/tmp/CGItemp5321" user="DouglasStrain" version="1"}%
%META:TOPICMOVED{by="JamesWeichel" date="1317239787" from="Documentation.InstallXrootd" to="Documentation/Release3.InstallXrootd"}%
