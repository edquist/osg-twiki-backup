%META:TOPICINFO{author="BrianLin" date="1422644116" format="1.1" version="1.15"}%
<!--
   * Set TODO = <span style="color: white; background-color: #F0F; font-weight: bold; padding: 2px;">TODO:</span>
-->

---+ HTCondor CE Overview

%TOC{depth="2"}%

---++ About this Document

This document serves as an introduction to HTCondor CE, how it works, and its differences with a GRAM CE. 

---++ Document Requirements

Before continuing with this document, make sure that you are familiar with the following concepts:

   * %RED%FIXME plan your site doc goes here%ENDCOLOR% 
      * What is a batch system and which one your site will be utilizing ([[Documentation/GlossaryOfTerms#DefsCondor][HTCondor]], PBS, LSF, or SGE)
      * PKI infrastructure of the OSG (i.e. [[Documentation/GlossaryOfTerms#DefsCA][Certificate authorities]], user and host [[Documentation/GlossaryOfTerms#DefsCertificate][certificates]], proxies)
   * Pilot jobs, frontends, and factories (i.e. [[Documentation/GlossaryOfTerms#DefsGlideinWMS][GlideinWMS]], !AutoPy)

---++ What is a Compute Element?

The OSG Compute Element (CE) is the entry point for the OSG to your local resources. At the heart of the CE is the _job gateway_ software, which is responsible for handling incoming jobs, authorizing them, and delegating them to your batch system(s) for execution. Historically, the OSG only had one option for a job gateway solution, Globus Toolkit’s GRAM-based gatekeeper, but now offers the HTCondor CE as an alternative.

---++ What is HTCondor CE?

HTCondor CE is a special configuration of the HTCondor software designed to be the preferred job gateway solution for the OSG. 

---+++ Differences with a GRAM CE

   * Scalability
   * Consolidate tech providers
   * Debugging tools
   * Upgrades won't overwrite site customizations

---++ How Jobs Run

In the OSG, most incoming jobs (we refer to these as the _grid job_) will be in the form of pilots submitted from the factories. If these pilot jobs are authorized to run at the site they're submitted to, the job is placed into the job gateway’s scheduler and is transformed (referred to as the _routed job_) before it is submitted to the site’s batch system (referred to as the _batch system job_). The job gateway monitors the status of the batch system job and passes that information back to the routed job, then to the grid job, and eventually to the user until the job completes, whereupon files are transferred back along the chain and the process ends.

---+++ How jobs run on HTCondor batch systems

For a site with a HTCondor batch system, the !JobRouter will transform and mirror the grid job into the routed job in the site's batch system.  The process is illustrated below:

<img src="%ATTACHURLPATH%/ce_condorbatchsystem.png" alt="condor-ce-condor-schematics.png" width='320' height='306' /> 

Notice the !JobRouter copies the job directly into the site's batch system and does not make use of =condor_submit=. This means that if the HTCondor batch system is setup to add attributes to incoming jobs when they are submitted (i.e. =SUBMIT_EXPRS=), these attributes will not be added to the routed jobs.

---+++ How jobs run on other batch systems

Submission into a non-HTCondor batch system is done slightly differently than with an HTCondor batch system. For example, with a PBS batch system, the routed job stays in the HTCondor CE schedd (as the !JobRouter does not know how to submit directly into the PBS queue), and the routed job is submitted into PBS using the BLAHP, resulting in the batch job. See the illustration below:

<img src="%ATTACHURLPATH%/ce_otherbatchsystem.png" alt="condor-ce-condor-schematics.png" width='320' height='306' /> 

Notice that the BLAHP, not the !JobRouter, submits the job to PBS in this case.

---++ How Files are Transferred

HTCondor CE uses HTCondor's internal CEDAR protocol to move a job's files from the submit node to the CE's spool directory. If the job matches a job route, the CE submits the job to the local batch system. If the local batch system is HTCondor, the files are transferred to the batch system's spool directory. For all other batch systems, HTCondor CE's spool directory needs to be mounted on a shared file system such that both the CE and worker nodes can access the job's files.

---++ How the CE is Customized

HTCondor CE uses HTCondor's configuration language for its own customization since it is a special configuration of HTCondor. The default configuration should suffice for small sites but if you need to set site-specific attributes or resource limits, you can do this with job routes. For examples of how to edit your job routes, consult [[Documentation/Release3.JobRouterRecipes][this page]].

If you are running HTCondor as your batch system, you will have two HTCondor configurations side-by-side (one residing in =/etc/condor/= and the other in =/etc/condor-ce=) and will need to make sure to differentiate the two when editing any configuration.

---++ How Security Works

In the OSG, security depends on a PKI infrastructure involving Certificate Authorities (CAs) where CAs sign and issue certifcates to users and hosts. When these users and hosts wish to communicate with each other, the identities of each party is confirmed by cross-checking their certificates with the signing CA and establishing trust. 

Due to the OSG's distributed nature, a user's job may end up at any number of sites, potentially needing to re-authenticate at multiple points. Instead of sending the user's certificate with the job for this re-authentication, trust can be delegated to a proxy that is generated from the user certificate, which is then attached to the job and expires after some set time for added security.

In its default configuration, HTCondor CE uses GSI-based authentication and authorization (the same as Globus GRAM) to verify the certificate chain, which will work with existing GUMS servers or grid mapfiles. Additionally, it can be reconfigured to provide alternate authentication mechanisms such as Kerberos, SSL, shared secret, or even IP-based authentication. More information about authorization methods can be found here [[http://research.cs.wisc.edu/htcondor/manual/v8.2/3_6Security.html#SECTION00463000000000000000][here]].

---++ Next steps

If you're transitioning from a GRAM CE to HTCondor CE, the process is the same as if you were setting up a completely new CE, whether you're installing it on a new machine or alongside your GRAM CE.

   * [[InstallHTCondorCE][Installing and configuring]] HTCondor CE
   * Setting up [[JobRouterRecipes][job routes]]
   * [[TroubleshootingHTCondorCE][Troubleshooting]] HTCondor CE
   * Register the CE with OIM
   * Register with the OSG !GlideinWMS factories and the ATLAS !AutoPyFactory

%META:FILEATTACHMENT{name="ce_condorbatchsystem.png" attachment="ce_condorbatchsystem.png" attr="h" comment="A diagram of the HTCondor CE/HTCondor batch system job submission" date="1412871085" path="ce_condorbatchsystem.png" size="22860" stream="ce_condorbatchsystem.png" tmpFilename="/usr/tmp/CGItemp14227" user="BrianLin" version="1"}%
%META:FILEATTACHMENT{name="ce_otherbatchsystem.png" attachment="ce_otherbatchsystem.png" attr="h" comment="A diagram of the HTCondor CE/non-HTCondor batch system job submission" date="1412871141" path="ce_otherbatchsystem.png" size="23591" stream="ce_otherbatchsystem.png" tmpFilename="/usr/tmp/CGItemp18203" user="BrianLin" version="1"}%
