%META:TOPICINFO{author="BrianLin" date="1425590622" format="1.1" version="1.18"}%
<!--
   * Set TODO = <span style="color: white; background-color: #F0F; font-weight: bold; padding: 2px;">TODO:</span>
-->

---+ HTCondor CE Overview

%TOC{depth="3"}%

---++ About this Document

This document serves as an introduction to HTCondor CE, how it works, and its differences with a GRAM CE. 

---++ Document Requirements

Before continuing with this document, make sure that you are familiar with the following concepts:

   * %RED%FIXME plan your site doc goes here%ENDCOLOR% 
      * What is a batch system and which one your site will be utilizing ([[Documentation/GlossaryOfTerms#DefsCondor][HTCondor]], PBS, LSF, or SGE)
      * Security in the OSG via [[Documentation/GlossaryOfTerms#DefsGridSecurityInfrastructure][GSI]] (i.e. [[Documentation/GlossaryOfTerms#DefsCA][Certificate authorities]], user and host [[Documentation/GlossaryOfTerms#DefsCertificate][certificates]], proxies)
   * Pilot jobs, frontends, and factories (i.e. [[Documentation/GlossaryOfTerms#DefsGlideinWMS][GlideinWMS]], !AutoPy)

---++ What is a Compute Element?

The OSG Compute Element (CE) is the entry point for the OSG to your local resources: a layer of software that you install on a machine that has the ability to submit jobs into your local batch system (LBS). At the heart of the CE is the _job gateway_ software, which is responsible for handling incoming jobs, authorizing them, and delegating them to your LBS for execution. Historically, the OSG only had one option for a job gateway solution, Globus Toolkit’s GRAM-based gatekeeper, but now offers the HTCondor CE as an alternative.

---++ What is HTCondor CE?

HTCondor CE is a special configuration of the HTCondor software designed to be the preferred job gateway solution for the OSG. Out of the box, HTCondor supports the remote job submission and GSI-based authorization methods. To handle job delegation, HTCondor CE uses the [[http://research.cs.wisc.edu/htcondor/manual/v8.2/5_4HTCondor_Job.html][JobRouter daemon]], which has the ability to transform jobs and submit them to the LBS&rsquo;s supported by the OSG (HTCondor, PBS, SLURM, LSF and SGE).

---+++ Differences with a GRAM CE

The biggest difference you will see between an HTCondor CE and a GRAM CE is the way that jobs are submitted to your LBS; HTCondor CE&rsquo;s use the built-in !JobRouter daemon whereas GRAM CE&rsquo;s use jobmanager scripts written in Perl. Customizing your site&rsquo;s CE now requires editing configuration files instead of editing jobmanager scripts.

Listed below are some other benefits to switching to HTCondor CE:

   * *Scalability:* HTCondor CE has reached approximately 16k parallel running jobs in [[Sandbox.HTCondorCEScaleTests][testing]]
   * *Debugging Tools:* HTCondor CE offers many job introspection tools to help [[TroubleshootingHTCondorCE][troubleshoot]] issues with jobs
   * *Consistency Between Upgrades:* HTCondor&rsquo;s configuration system allows for site customizations to be retained through system upgrades

---++ How Jobs Run...

In the OSG, most incoming jobs (referred to as _grid jobs_) will be in the form of pilots submitted from the factories. Once a grid job is authorized, it is placed into HTCondor CE&rsquo;s scheduler, where the !JobRouter transforms it (referred to as the _routed job_) and submits it to the LBS (referred to as the _batch system job_). HTCondor CE monitors the status of the batch system job and passes that information back to the routed job, then to the grid job, and eventually to the user until the job completes, whereupon files are transferred back along the chain and the process ends.

---+++ On HTCondor LBS&rsquo;s

For a site with an HTCondor LBS, the !JobRouter transforms the grid job directly into the batch system&rsquo;s schedd i.e., the routed and batch system jobs are one and the same. This means that the are three job IDs (illustrated below): the job ID on the submit host, the grid job&rsquo;s ID on the CE, and the routed/batch system job ID.

<img src="%ATTACHURLPATH%/ce_condorbatchsystem.png" alt="condor-ce-condor-schematics.png" width='320' height='306' /> 

In an HTCondor CE/HTCondor setup, files are transferred from HTCondor CE&rsquo;s spool directory (specified by the =SPOOL= configuration variable) directly to the LBS&rsquo;s spool directory using internal HTCondor protocols.

%NOTE% The !JobRouter copies the job directly into the LBS and does not make use of =condor_submit=. This means that if the HTCondor batch system is configured to add attributes to incoming jobs when they are submitted (i.e. =SUBMIT_EXPRS=), these attributes will not be added to the routed jobs.

---+++ On other LBS&rsquo;s

For non-HTCondor LBS&rsquo;s, the !JobRouter transforms the grid job into the routed job on the CE and the routed job submits a job into the batch system via a process called the BLAHP. This means that there are four job IDs (illustrated below): the job ID on the submit host, the grid job&rsquo;s ID on the CE, the routed job&rsquo;s ID on the CE, and the batch system job ID. Although the following example specifies the PBS case, it applies to all non-HTCondor LBS&rsquo;s:

<img src="%ATTACHURLPATH%/ce_otherbatchsystem.png" alt="condor-ce-condor-schematics.png" width='320' height='306' /> 

With non-HTCondor LBS&rsquo;s, HTCondor CE cannot use internal HTCondor protocols to transfer files so its spool directory must be exported to a shared file system that is mounted on the worker nodes.

---++ How the CE is Customized

Aside from the [[Documentation.Release3/InstallHTCondorCE#Configuring_HTCondor_CE][basic configuration]] required in the CE installation, there are two main ways that you will be customizing your CE (if you decide any customization is required at all): deciding which VOs are allowed to run at your site and how to filter and transform the grid jobs to be run on your LBS. 

The method of limiting the VOs that are allowed to run on your site has not changed between GRAM and HTCondor CE&rsquo;s: you will need to edit =/etc/edg-mkgridmap.conf= or your GUMS configuration (via the web interface or directly editing =/etc/gums/gums.config=), depending on which authorization system you are using. 

To filter and transform grid jobs (i.e., setting site-specific attributes or resource limits), you will want to do this by editing the =JOB_ROUTER_ENTRIES= variable in your configuration. For examples of common job routes, consult the [[Documentation/Release3.JobRouterRecipes][JobRouter recipes]] page.

%NOTE% If you are running HTCondor as your LBS, you will have two HTCondor configurations side-by-side (one residing in =/etc/condor/= and the other in =/etc/condor-ce=) and will need to make sure to differentiate the two when editing any configuration.

---++ How Security Works

%RED%TODO: Drop this section?%ENDCOLOR%

In the OSG, security depends on a PKI infrastructure involving Certificate Authorities (CAs) where CAs sign and issue certifcates to users and hosts. When these users and hosts wish to communicate with each other, the identities of each party is confirmed by cross-checking their certificates with the signing CA and establishing trust. 

Due to the OSG's distributed nature, a user's job may end up at any number of sites, potentially needing to re-authenticate at multiple points. Instead of sending the user's certificate with the job for this re-authentication, trust can be delegated to a proxy that is generated from the user certificate, which is then attached to the job and expires after some set time for added security.

In its default configuration, HTCondor CE uses GSI-based authentication and authorization (the same as Globus GRAM) to verify the certificate chain, which will work with existing GUMS servers or grid mapfiles. Additionally, it can be reconfigured to provide alternate authentication mechanisms such as Kerberos, SSL, shared secret, or even IP-based authentication. More information about authorization methods can be found here [[http://research.cs.wisc.edu/htcondor/manual/v8.2/3_6Security.html#SECTION00463000000000000000][here]].

---++ Next steps

If you're transitioning from a GRAM CE to HTCondor CE, the process is the same as if you were setting up a completely new CE, whether you're installing it on a new machine or alongside your GRAM CE.

   * [[InstallHTCondorCE][Installing and configuring]] HTCondor CE
   * Setting up [[JobRouterRecipes][job routes]]
   * [[SubmittingHTCondorCE][Submitting]] jobs to HTCondor CE
   * [[TroubleshootingHTCondorCE][Troubleshooting]] HTCondor CE
   * Register the CE with OIM
   * Register with the OSG !GlideinWMS factories and the ATLAS !AutoPyFactory

%META:FILEATTACHMENT{name="ce_condorbatchsystem.png" attachment="ce_condorbatchsystem.png" attr="h" comment="A diagram of the HTCondor CE/HTCondor batch system job submission" date="1412871085" path="ce_condorbatchsystem.png" size="22860" stream="ce_condorbatchsystem.png" tmpFilename="/usr/tmp/CGItemp14227" user="BrianLin" version="1"}%
%META:FILEATTACHMENT{name="ce_otherbatchsystem.png" attachment="ce_otherbatchsystem.png" attr="h" comment="A diagram of the HTCondor CE/non-HTCondor batch system job submission" date="1412871141" path="ce_otherbatchsystem.png" size="23591" stream="ce_otherbatchsystem.png" tmpFilename="/usr/tmp/CGItemp18203" user="BrianLin" version="1"}%
