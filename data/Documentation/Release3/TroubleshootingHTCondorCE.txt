%META:TOPICINFO{author="BrianLin" date="1413499432" format="1.1" version="1.12"}%
%TOC{depth="3"}%

---+ Troubleshooting HTCondor CE

In this document, you will find a collection of files, commands, and suggested actions to help troubleshoot HTCondor CE.

Other HTCondor CE pages:
   * HTCondor CE overview and architecture (coming soon)
   * [[InstallHTCondorCE][Installing HTCondor CE]]
   * [[HTCondorCERoutes][Configuring HTCondor CE job routes]]

---++ HTCondor CE Troubleshooting Data

The following files are located on the CE host.

#MasterLog
---+++ Master log

The HTCondor CE master log tracks status of all of the other HTCondor daemons and thus contains valuable information if they fail to start. 

To increase the debug level in this log, set the following value in =/etc/condor-ce/config.d/99-local.conf= on the CE host:

<pre class="file">MASTER_DEBUG = D_FULLDEBUG</pre>

*Location:*
<pre>/var/log/condor-ce/MasterLog</pre>

*Key Contents*
Start-up, shut-down and communication with other HTCondor daemons

*What to look for:*

Successful daemon start-up. The following line shows that the Collector daemon started successfully:\
   <pre class="file">10/07/14 14:20:27 <span style="background-color: #FFCCFF;">Started DaemonCore process "/usr/sbin/condor_collector -f -port 9619"</span>, pid and pgroup = 7318</pre>

#SchedLog
---+++ Schedd log

The HTCondor CE schedd log contains information on all jobs that are submitted to the CE. It contains valuable information when trying to troubleshoot authentication issues. 

To increase the debug level in this log, set the following value in =/etc/condor-ce/config.d/99-local.conf= on the CE host:

<pre class="file">SCHEDD_DEBUG = D_FULLDEBUG</pre>

*Location:*
<pre>/var/log/condor-ce/SchedLog</pre>

*Key Contents*
   * Every job submitted to the CE
   * User authorization events

*What to look for:*

   * Job owner is authorized and mapped:\
   <pre class="file">10/07/14 16:52:17 <span style="background-color: #FFCCFF;">Command=QMGMT_WRITE_CMD</span>, peer=<131.225.154.68:42262>
10/07/14 16:52:17 <span style="background-color: #FFCCFF;">AuthMethod=GSI, AuthId=/DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Brian Lin 1047,/GLOW/Role=NULL/Capability=NULL, CondorId=glow@users.opensciencegrid.org</span></pre>\
   In this example, the job is authorized with the job's proxy subject using GSI and is mapped to the =glow= user.
   * Job is submitted to the CE queue: \
   <pre class="file">10/07/14 16:52:17 <span style="background-color: #FFCCFF;">Submitting new job 234.0</span></pre>\
   In this example, the ID of the submitted job is =234.0=.

#JobRouterLog
---+++ Job router log

The HTCondor CE job router log produced by the job router itself and thus contains valuable information when trying to troubleshoot issues with job routing.

To increase the debug level in this log, set the following value in =/etc/condor-ce/config.d/99-local.conf= on the CE host:

<pre class="file">JOB_ROUTER_DEBUG = D_FULLDEBUG</pre>

*Location:*
<pre>/var/log/condor-ce/JobRouterLog</pre>

*Key contents:*
   * Every attempt to route a job
   * Routing success messages
   * Job attribute changes, based on chosen route

*What to look for:*

   * Job is considered for routing:\
      <pre class="file">09/17/14 15:00:56 JobRouter (src=86.0,route=Local_LSF): <span style="background-color: #FFCCFF;">found candidate job</span></pre>\
      <p>In parentheses are the original HTCondor CE job ID (e.g., =86.0=) and the route (e.g., =Local_LSF=).</p>
   * Job is successfully routed:\
      <pre class="file">09/17/14 15:00:57 JobRouter (src=86.0,route=Local_LSF): <span style="background-color: #FFCCFF;">claimed job</span></pre>
   * If your job is not routed, there will not be any evidence of it within the log itself. To investigate why your jobs aren't being routed, use the [[#CondorJobRouterTool][condor_ce_job_router_tool]]

#GridmanagerLog
---+++ Gridmanager log

The HTCondor CE grid manager log  tracks the submission and status of jobs on the batch system. It contains valuable information when trying to troubleshoot jobs that have been routed but failed to complete. Details on how to read the Gridmanager log can be found on the [[https://htcondor-wiki.cs.wisc.edu/index.cgi/wiki?p=GridmanagerLog][HTCondor Wiki]]. 

To increase the debug level in this log, set the following value in =/etc/condor-ce/config.d/99-local.conf= on the CE host:

<pre class="file">GRIDMANAGER_DEBUG = D_FULLDEBUG</pre>

*Location:*
<pre>/var/log/condor-ce/GridmanagerLog.&lt;job owner&gt;</pre>

*Key Contents*
   * Every attempt to submit a job to a batch system or other grid resource
   * Status updates of submitted jobs 

*What to look for:*

   * Job is submitted to the batch system:\
   <pre class="file">09/17/14 09:51:34 [12997] <span style="background-color: #FFCCFF;">(85.0)</span> gm state change: GM_SUBMIT_SAVE -> <span style="background-color: #FFCCFF;">GM_SUBMITTED</span></pre>\
   <p>Every state change the Gridmanager tracks should have the job ID in parentheses (i.e.=(85.0)).</p>
   * Job status being updated:\
   <pre class="file">09/17/14 15:07:24 [25543] (87.0) gm state change: GM_SUBMITTED -> <span style="background-color: #FFCCFF;">GM_POLL_ACTIVE</span>
09/17/14 15:07:24 [25543] GAHP[25563] <- 'BLAH_JOB_STATUS 3 lsf/20140917/482046'
09/17/14 15:07:24 [25543] GAHP[25563] -> 'S'
09/17/14 15:07:25 [25543] GAHP[25563] <- 'RESULTS'
09/17/14 15:07:25 [25543] GAHP[25563] -> 'R'
09/17/14 15:07:25 [25543] GAHP[25563] -> 'S' '1'
09/17/14 15:07:25 [25543] GAHP[25563] -> '3' '0' 'No Error' '4' '<span style="background-color: #FFCCFF;">[ BatchjobId = "482046"; JobStatus = 4; ExitCode = 0; WorkerNode = "atl-prod08" ]</span>'</pre>\
   <p>The first line tells us that the Gridmanager is initiating a status update and the following lines are the results. The most interesting line is the second highlighted section that notes the job ID on the batch system and its status. If there are errors querying the job on the batch system, they will appear here.</p>
   * Job completion on the batch system:\
   <pre class="file">09/17/14 15:07:25 [25543] (87.0) gm state change: GM_TRANSFER_OUTPUT -> <span style="background-color: #FFCCFF;">GM_DONE_SAVE</span></pre>

---+++ Messages log

The messages file can include output from lcmaps, which handles mapping of X.509 proxies to Unix usernames. If there are issues with the [[InstallHTCondorCE#5_2_Setup_Authorization][authentication setup]], the errors may appear here.

*Location:*
<pre>/var/log/messages</pre>

*Key Contents*
   * User authentication

*What to look for:*
      
   * A user is mapped:\
   <pre class="file">Oct  6 10:35:32 osgserv06 <span style="background-color: #FFCCFF;">htondor-ce-llgt[12147]: Callout to "LCMAPS" returned local user (service condor): "osgglow01"</span></pre>
   * Specific error messages and methods to troubleshoot them can be found in [[TroubleshootingGlexecLcmaps][this document]]

---++ HTCondor CE Troubleshooting Tools

---+++ condor_ce_run

---++++ Usage

Similar to =globus-job-run=, =condor_ce_run= is a tool that submits a simple job to your CE, so it is useful for verifying that job submission works from end-to-end. To submit a job to the CE and run the =env= command on the remote batch system:

<pre class="screen">
%UCL_PROMPT% condor_ce_run -r <span style="background-color: #D1CAF2;">condorce.example.com</span>:9619 env
</pre>

Replace the <span style="background-color: #D1CAF2;">highlighted</span> text with the hostname of the CE. 

---++++ Troubleshooting

   1. *If you do not see any results:* =condor_ce_run= does not display results until the job completes on the CE, which may take several minutes or longer if the CE is busy. In the meantime,  can use [[#CondorQ][condor_ce_q]] in a separate terminal to track the job on the CE. If you never see any results, use [[#CondorTrace][condor_ce_trace]] to pinpoint errors.
   1. *If you see an error message that begins with "Failed to&hellip;":* Check connectivity to the CE with [[#CondorTrace][condor_ce_trace]] or [[#CondorPing][condor_ce_ping]]

#CondorTrace
---+++ condor_ce_trace

If =condor_ce_run= fails, the =condor_ce_trace= tool may help in verifying the install:

<pre class="screen">
condor_ce_trace --debug <span style="background-color: #D1CAF2;">condorce.example.com</span>
</pre>

%TWISTY{%TWISTY_OPTS_OUTPUT% showlink="Show an example condor_ce_trace run"}%
<pre class="screen">
%UCL_PROMPT% condor_ce_trace fermicloud133.fnal.gov
Testing HTCondor-CE collector connectivity.
***** condor_ping output *****
10/07/14 12:54:40 recognized 60011 as command number.
Remote Version:              $CondorVersion: 8.0.7 Sep 24 2014 $
Local  Version:              $CondorVersion: 8.0.7 Sep 24 2014 $
Session ID:                  fermicloud133:22494:1412704480:2403
Instruction:                 60011
Command:                     60011
Encryption:                  none
Integrity:                   MD5
Authenticated using:         GSI
All authentication methods:  GSI
Remote Mapping:              glow@users.opensciencegrid.org
Authorized:                  TRUE

********************
- Successful ping of collector on <131.225.154.68:9619>.

Testing HTCondor-CE schedd connectivity.
***** condor_ping output *****
10/07/14 12:54:40 recognized 60011 as command number.
Remote Version:              $CondorVersion: 8.0.7 Sep 24 2014 $
Local  Version:              $CondorVersion: 8.0.7 Sep 24 2014 $
Session ID:                  fermicloud133:22495:1412704480:336
Instruction:                 60011
Command:                     60011
Encryption:                  none
Integrity:                   MD5
Authenticated using:         GSI
All authentication methods:  GSI
Remote Mapping:              glow@users.opensciencegrid.org
Authorized:                  TRUE

********************
- Successful ping of schedd on <131.225.154.68:9620?sock=22489_8590_4>.

Job ad, pre-submit: 
    [
        Log = "/cloud/login/blin/.log_5237_YCPBqo"; 
        x509UserProxyVOName = "GLOW"; 
        x509userproxysubject = "/DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Brian Lin 1047/CN=proxy"; 
        Out = "/cloud/login/blin/.stdout_5237_s9KGwd"; 
        LeaveJobInQueue = ( StageOutFinish > 0 ) isnt true; 
        x509UserProxyFirstFQAN = "/GLOW/Role=NULL/Capability=NULL"; 
        x509userproxy = "/tmp/x509up_u47646"; 
        x509UserProxyFQAN = "/GLOW/Role=NULL/Capability=NULL"; 
        Args = ""; 
        Err = "/cloud/login/blin/.stderr_5237_j_FluG"; 
        Cmd = "/bin/env"; 
        x509UserProxyExpiration = 1412736896
    ]
Submitting job to schedd <131.225.154.68:9620?sock=22489_8590_4>
- Successful submission; cluster ID 229
Resulting job ad: 
    [
        BufferSize = 524288; 
        NiceUser = false; 
        CoreSize = -1; 
        CumulativeSlotTime = 0; 
        OnExitHold = false; 
        RequestCpus = 1; 
        Err = "_condor_stderr"; 
        BufferBlockSize = 32768; 
        x509userproxy = "/tmp/x509up_u47646"; 
        TransferOutputRemaps = "_condor_stdout=/cloud/login/blin/.stdout_5237_s9KGwd;_condor_stderr=/cloud/login/blin/.stderr_5237_j_FluG"; 
        ImageSize = 100; 
        CurrentTime = time(); 
        WantCheckpoint = false; 
        CommittedTime = 0; 
        TargetType = "Machine"; 
        WhenToTransferOutput = "ON_EXIT"; 
        Cmd = "/bin/env"; 
        JobUniverse = 5; 
        ExitBySignal = false; 
        HoldReasonCode = 16; 
        Iwd = "/cloud/login/blin"; 
        NumRestarts = 0; 
        CommittedSuspensionTime = 0; 
        Owner = undefined; 
        NumSystemHolds = 0; 
        CumulativeSuspensionTime = 0; 
        RequestDisk = DiskUsage; 
        Requirements = true && TARGET.OPSYS == "LINUX" && TARGET.ARCH == "X86_64" && TARGET.HasFileTransfer && TARGET.Disk >= RequestDisk && TARGET.Memory >= RequestMemory; 
        MinHosts = 1; 
        JobNotification = 0; 
        NumCkpts = 0; 
        LastSuspensionTime = 0; 
        NumJobStarts = 0; 
        WantRemoteSyscalls = false; 
        JobPrio = 0; 
        RootDir = "/"; 
        CurrentHosts = 0; 
        x509UserProxyExpiration = 1412736896; 
        StreamOut = false; 
        WantRemoteIO = true; 
        OnExitRemove = true; 
        DiskUsage = 1; 
        In = "/dev/null"; 
        PeriodicRemove = false; 
        RemoteUserCpu = 0.0; 
        LocalUserCpu = 0.0; 
        LocalSysCpu = 0.0; 
        RemoteSysCpu = 0.0; 
        ClusterId = 229; 
        Log = "/cloud/login/blin/.log_5237_YCPBqo"; 
        CompletionDate = 0; 
        RemoteWallClockTime = 0.0; 
        x509UserProxyFQAN = "/GLOW/Role=NULL/Capability=NULL"; 
        LeaveJobInQueue = JobStatus == 4 && ( CompletionDate is UNDDEFINED || CompletionDate == 0 || ( ( time() - CompletionDate ) < 864000 ) ); 
        CondorVersion = "$CondorVersion: 8.0.7 Sep 24 2014 $"; 
        MyType = "Job"; 
        StreamErr = false; 
        HoldReason = "Spooling input data files"; 
        PeriodicHold = false; 
        ProcId = 0; 
        x509UserProxyFirstFQAN = "/GLOW/Role=NULL/Capability=NULL"; 
        Out = "_condor_stdout"; 
        JobStatus = 5; 
        PeriodicRelease = false; 
        RequestMemory = ifthenelse(MemoryUsage isnt undefined,MemoryUsage,( ImageSize + 1023 ) / 1024); 
        Args = ""; 
        MaxHosts = 1; 
        TotalSuspensions = 0; 
        CommittedSlotTime = 0; 
        x509userproxysubject = "/DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Brian Lin 1047/CN=proxy"; 
        x509UserProxyVOName = "GLOW"; 
        CondorPlatform = "$CondorPlatform: X86_64-CentOS_6.5 $"; 
        ShouldTransferFiles = "YES"; 
        ExitStatus = 0; 
        QDate = 1412704480; 
        EnteredCurrentStatus = 1412704480
    ]
Spooling cluster 229 files to schedd <131.225.154.68:9620?sock=22489_8590_4>
- Successful spooling
Querying job status (1/600)
Job status: Held
Querying job status (2/600)
Job status: Idle
Querying job status (3/600)
Job status: Idle
Querying job status (4/600)
Job status: Idle
Querying job status (5/600)
Job status: Idle
Querying job status (6/600)
Job status: Idle
Querying job status (7/600)
Job status: Idle
Querying job status (8/600)
Job status: Idle
Querying job status (9/600)
Job status: Idle
Querying job status (10/600)
Job status: Idle
Querying job status (11/600)
Job status: Idle
Querying job status (12/600)
Job status: Idle
Querying job status (13/600)
Job status: Idle
Querying job status (14/600)
Job status: Idle
Querying job status (15/600)
Job status: Idle
Querying job status (16/600)
Job status: Idle
Querying job status (17/600)
Job status: Idle
Querying job status (18/600)
Job status: Idle
Querying job status (19/600)
Job status: Idle
Querying job status (20/600)
Job status: Idle
Querying job status (21/600)
Job status: Idle
Querying job status (22/600)
Job status: Idle
Querying job status (23/600)
Job status: Idle
Querying job status (24/600)
Job status: Idle
Querying job status (25/600)
Job status: Idle
Querying job status (26/600)
Job status: Idle
Querying job status (27/600)
Job status: Idle
Querying job status (28/600)
Job status: Idle
Querying job status (29/600)
Job status: Idle
Querying job status (30/600)
Job status: Idle
Querying job status (31/600)
Job status: Idle
Querying job status (32/600)
Job status: Idle
Querying job status (33/600)
Job status: Idle
Querying job status (34/600)
Job status: Idle
Querying job status (35/600)
Job status: Idle
Querying job status (36/600)
Job status: Idle
Querying job status (37/600)
Job status: Idle
Querying job status (38/600)
Job status: Idle
Querying job status (39/600)
Job status: Idle
Querying job status (40/600)
Job status: Idle
Querying job status (41/600)
Job status: Idle
Querying job status (42/600)
Job status: Idle
Querying job status (43/600)
Job status: Idle
Querying job status (44/600)
Job status: Idle
Querying job status (45/600)
Job status: Idle
Querying job status (46/600)
Job status: Idle
Querying job status (47/600)
Job status: Idle
Querying job status (48/600)
Job status: Completed
***** Job output *****
_CONDOR_ANCESTOR_22435=22441:1412360582:256213668
_CONDOR_ANCESTOR_22441=5347:1412704518:1792957092
_CONDOR_ANCESTOR_5347=5356:1412704519:2135643703
PATH=/bin:/usr/bin:/sbin:/usr/sbin
OSG_JOB_CONTACT=host.name/jobmanager-condor
_CONDOR_SLOT=
OSG_DEFAULT_SE=None
OSG_GRID=/etc/osg/wn-client/
TMPDIR=/var/lib/condor/execute/dir_5347
GLOBUS_LOCATION=/usr
_CONDOR_SCRATCH_DIR=/var/lib/condor/execute/dir_5347
_CONDOR_JOB_IWD=/var/lib/condor/execute/dir_5347
TEMP=/var/lib/condor/execute/dir_5347
OSG_HOSTNAME=fermicloud136.fnal.gov
OSG_STORAGE_ELEMENT=False
OSG_SITE_NAME=local
_CONDOR_JOB_PIDS=
OSG_APP=/share/osg/app
OSG_WN_TMP=None
X509_USER_PROXY=/var/lib/condor/execute/dir_5347/x509up_u47646
TMP=/var/lib/condor/execute/dir_5347
_CONDOR_JOB_AD=/var/lib/condor/execute/dir_5347/.job.ad
OSG_SITE_WRITE=None
OSG_GLEXEC_LOCATION=None
OSG_DATA=UNAVAILABLE
HOME=/home/glow
_CONDOR_MACHINE_AD=/var/lib/condor/execute/dir_5347/.machine.ad
OSG_SITE_READ=None
********************
</pre>
%ENDTWISTY%

The tool contacts both the CE's Schedd and Collector daemons to see if you have permission to submit to the CE, displays the submit script that it submits to the CE,  and tracks the resultant job.

---++++ Troubleshooting

   1. <p>*If the command fails with "Failed ping&hellip;":* Make sure that the HTCondor CE daemons are running on the CE</p>
   1. <p>*If you see "gsi@unmapped" in the "Remote Mapping" line:* Either your credentials are not mapped on the CE or authentication is not set up at all. To set up authentication, refer to our [[InstallHTCondorCE#5_2_Setup_Authorization][installation document]].</p>
   1. <p>*If the job submits but does not complete:* Look at the status of the job and perform the relevant [[#TroubleshootingItems][troubleshooting steps]].</p>

#CondorPing
---+++ condor_ce_ping

---++++ Usage

Use the =condor_ce_ping= command to test connectivity to the CE or to test the user that your proxy is mapped to:

<pre class="screen">
%UCL_PROMPT% env _condor_SEC_CLIENT_AUTHENTICATION_METHODS=GSI condor_ce_ping -verbose -name <span style="background-color: #D1CAF2;">condorce.example.com</span> -pool <span style="background-color: #D1CAF2;">condorce.example.com</span>:9619 WRITE
</pre>

%TWISTY{%TWISTY_OPTS_OUTPUT% showlink="Show sample output&hellip;"}%
Remote Version:              $CondorVersion: 8.0.7 Sep 24 2014 $
Local  Version:              $CondorVersion: 8.0.7 Sep 24 2014 $
Session ID:                  fermicloud133:27407:1412286981:3
Instruction:                 WRITE
Command:                     60021
Encryption:                  none
Integrity:                   MD5
Authenticated using:         GSI
All authentication methods:  GSI
Remote Mapping:              glow@users.opensciencegrid.org
Authorized:                  TRUE
%ENDTWISTY%

If you run the =condor_ce_ping= command on the CE that you are testing, omit the =-name= and =-pool= options. =condor_ce_ping= takes the same arguments as =condor_ping= and is documented in the [[http://research.cs.wisc.edu/htcondor/manual/v8.0/condor_ping.html][HTCondor manual]].

---++++ Troubleshooting

   1. *If you see "ERROR: couldn't locate (null)!"*, that means the  HTCondor CE schedd (the daemon that schedules jobs) cannot be reached. To track down the issue, increase the debugging levels on the CE with:
   <pre class="file">
MASTER_DEBUG = D_FULLDEBUG
SCHEDD_DEBUG = D_FULLDEBUG</pre>\
   <p>Then look in the [[#MasterLog][Master log]] and [[#SchedLog][Schedd log]] for any errors.</p>
   1. *If you see "gsi@unmapped" in the "Remote Mapping" line*, this means that either your credentials are not mapped on the CE or that authentication is not set up at all. To set up authentication, refer to our [[InstallHTCondorCE#5_2_Setup_Authorization][installation document]].

#CondorQ
---+++ condor_ce_q

---++++ Usage

=condor_ce_q= can tell you the status of jobs in the CE's queue or specific attributes of a job. 

To list all of jobs on a CE, use the following:

<pre class="screen">
%UCL_PROMPT% condor_ce_q -name <span style="background-color: #D1CAF2;">condorce.example.com</span> -pool <span style="background-color: #D1CAF2;">condorce.example.com</span>:9619
</pre>

To inspect a specific job, specify the =-l= flag and the job ID to see its full !JobAd:

<pre class="screen">
%UCL_PROMPT% condor_ce_q -name <span style="background-color: #D1CAF2;">condorce.example.com</span> -pool <span style="background-color: #D1CAF2;">condorce.example.com</span>:9619 -l &lt;Job ID&gt;
</pre>

If you run the =condor_ce_q= command on the CE that you are testing, omit the =-name= and =-pool= options. =condor_ce_q= takes the same arguments as =condor_q= and is documented in the [[http://research.cs.wisc.edu/htcondor/manual/v8.0/condor_q.html][HTCondor manual]]. 

---++++ Troubleshooting

If the jobs that you are submiting to a CE aren't completing, =condor_ce_q= can tell you the status of your jobs.

   1. *If the schedd is not running:* You will see a lengthy message about being unable to contact the schedd. To track down the issue, increase the debugging levels on the CE with: <pre class="file">
MASTER_DEBUG = D_FULLDEBUG
SCHEDD_DEBUG = D_FULLDEBUG
</pre> <p>Then look in the [[#MasterLog][Master log]] and [[#SchedLog][Schedd log]] on the CE for any errors.</p>
   1. *If a job is held:* There should be an accompanying =HoldReason= that will tell you why it is being held. The =HoldReason= is in the !JobAd, so you can use the long form of =condor_ce_q= to extract its value: <pre class="screen">
%UCL_PROMPT% condor_ce_q -name fermicloud133.fnal.gov -pool fermicloud133.fnal.gov:9619 -l <Job ID> | grep HoldReason</pre>
   1. *If a job is idle:* The most common cause is that it is not matching any routes in the CE's job router. To find out whether this is the case, use the [[#CondorJobRouterTool][condor_ce_job_router_tool]].

#CondorJobRouterTool
---+++ condor_ce_job_router_tool

---++++ Usage

Use the =condor_ce_job_router_tool= command to help troubleshoot your routes and how jobs will match to them. 

To see all of your routes (the output is long because it combines your routes with =JOB_ROUTER_DEFAULTS=):

<pre class="screen">
%UCL_PROMPT_ROOT% condor_ce_job_router_tool -config
</pre>

%TWISTY{%TWISTY_OPTS_OUTPUT% showlink="Show sample output&hellip;"}%
<pre class="screen">
Route 1
Name         : "Local_PBS"
Universe     : 9
MaxJobs      : 10000
MaxIdleJobs  : 2000
GridResource : batch pbs
Requirements : target.osgTestPBS is true
ClassAd      : 
    [
        set_osg_environment = "OSG_GRID='/etc/osg/wn-client/' OSG_SITE_READ='None' OSG_APP='/share/osg/app' OSG_HOSTNAME='fermicloud136.fnal.gov' OSG_DATA='UNAVAILABLE' OSG_GLEXEC_LOCATION='None' GLOBUS_LOCATION='/usr' OSG_STORAGE_ELEMENT='False' OSG_SITE_NAME='local' OSG_WN_TMP='None' PATH='/bin:/usr/bin:/sbin:/usr/sbin' OSG_SITE_WRITE='None' OSG_DEFAULT_SE='None' OSG_JOB_CONTACT='host.name/jobmanager-condor'"; 
        set_requirements = true; 
        MaxJobs = 10000; 
        copy_environment = "orig_environment"; 
        eval_set_remote_SMPGranularity = ifThenElse(InputRSL.xcount isnt null,InputRSL.xcount,ifThenElse(xcount isnt null,xcount,ifThenElse(default_xcount isnt null,default_xcount,1))); 
        delete_PeriodicRemove = true; 
        GridResource = "batch pbs"; 
        set_RoutedJob = true; 
        name = "Local_PBS"; 
        MaxIdleJobs = 2000; 
        eval_set_environment = debug(strcat("HOME=",userHome(Owner,"/")," ",ifThenElse(orig_environment is undefined,osg_environment,strcat(osg_environment," ",orig_environment)))); 
        eval_set_RequestMemory = ifThenElse(InputRSL.maxMemory isnt null,InputRSL.maxMemory,ifThenElse(maxMemory isnt null,maxMemory,ifThenElse(default_maxMemory isnt null,default_maxMemory,2000))); 
        eval_set_remote_NodeNumber = ifThenElse(InputRSL.xcount isnt null,InputRSL.xcount,ifThenElse(xcount isnt null,xcount,ifThenElse(default_xcount isnt null,default_xcount,1))); 
        eval_set_remote_queue = ifThenElse(InputRSL.queue isnt null,InputRSL.queue,ifThenElse(queue isnt null,queue,ifThenElse(default_queue isnt null,default_queue,""))); 
        eval_set_remote_cerequirements = ifThenElse(InputRSL.maxWallTime isnt null,strcat("Walltime == ",string(60 * InputRSL.maxWallTime)," && CondorCE == 1"),"CondorCE == 1"); 
        delete_osgTestPBS = true; 
        Requirements = target.osgTestPBS is true; 
        eval_set_RequestCpus = ifThenElse(InputRSL.xcount isnt null,InputRSL.xcount,ifThenElse(xcount isnt null,xcount,ifThenElse(default_xcount isnt null,default_xcount,1))); 
        delete_CondorCE = true; 
        TargetUniverse = 9
    ]

Route 2
Name         : "Condor Test"
Universe     : 5
MaxJobs      : 10000
MaxIdleJobs  : 2000
GridResource : 
Requirements : true
ClassAd      : 
    [
        set_osg_environment = "OSG_GRID='/etc/osg/wn-client/' OSG_SITE_READ='None' OSG_APP='/share/osg/app' OSG_HOSTNAME='fermicloud136.fnal.gov' OSG_DATA='UNAVAILABLE' OSG_GLEXEC_LOCATION='None' GLOBUS_LOCATION='/usr' OSG_STORAGE_ELEMENT='False' OSG_SITE_NAME='local' OSG_WN_TMP='None' PATH='/bin:/usr/bin:/sbin:/usr/sbin' OSG_SITE_WRITE='None' OSG_DEFAULT_SE='None' OSG_JOB_CONTACT='host.name/jobmanager-condor'"; 
        eval_set_accounting_group = "accounting_group"; 
        set_requirements = true; 
        MaxJobs = 10000; 
        copy_environment = "orig_environment"; 
        eval_set_remote_SMPGranularity = ifThenElse(InputRSL.xcount isnt null,InputRSL.xcount,ifThenElse(xcount isnt null,xcount,ifThenElse(default_xcount isnt null,default_xcount,1))); 
        delete_PeriodicRemove = true; 
        set_RoutedJob = true; 
        name = "Condor Test"; 
        MaxIdleJobs = 2000; 
        eval_set_environment = debug(strcat("HOME=",userHome(Owner,"/")," ",ifThenElse(orig_environment is undefined,osg_environment,strcat(osg_environment," ",orig_environment)))); 
        eval_set_accounting_group_user = "blin_user"; 
        eval_set_RequestMemory = ifThenElse(InputRSL.maxMemory isnt null,InputRSL.maxMemory,ifThenElse(maxMemory isnt null,maxMemory,ifThenElse(default_maxMemory isnt null,default_maxMemory,2000))); 
        eval_set_remote_NodeNumber = ifThenElse(InputRSL.xcount isnt null,InputRSL.xcount,ifThenElse(xcount isnt null,xcount,ifThenElse(default_xcount isnt null,default_xcount,1))); 
        eval_set_remote_queue = ifThenElse(InputRSL.queue isnt null,InputRSL.queue,ifThenElse(queue isnt null,queue,ifThenElse(default_queue isnt null,default_queue,""))); 
        eval_set_remote_cerequirements = ifThenElse(InputRSL.maxWallTime isnt null,strcat("Walltime == ",string(60 * InputRSL.maxWallTime)," && CondorCE == 1"),"CondorCE == 1"); 
        Requirements = true; 
        eval_set_RequestCpus = ifThenElse(InputRSL.xcount isnt null,InputRSL.xcount,ifThenElse(xcount isnt null,xcount,ifThenElse(default_xcount isnt null,default_xcount,1))); 
        delete_CondorCE = true; 
        TargetUniverse = 5
    ]
</pre>
%ENDTWISTY%

To see how the !JobRouter is handling a job that is currently in the CE's queue, analyze the output of =condor_ce_q= (replace the <span style="background-color: #D1CAF2;">highlighted</span> text with the job ID that you are interested in):

<pre class="screen">
%UCL_PROMPT_ROOT% condor_ce_q -l <span style="background-color: #D1CAF2;">&lt;Job ID&gt;</span> | condor_ce_job_router_tool -match-jobs -ignore-prior-routing -jobads -
</pre>

%TWISTY{%TWISTY_OPTS_OUTPUT% showlink="Show sample output&hellip;"}%
<pre class="screen">
Matching jobs against routes to find candidate jobs.

Checking for candidate jobs. routing table is:
Route Name             Submitted/Max        Idle/Max     Throttle
Local_PBS                      0/  10000       0/   2000     none
Condor Test                    0/  10000       0/   2000     none

Umbrella constraint: ((target.x509userproxysubject =!= UNDEFINED) && (target.x509UserProxyExpiration =!= UNDEFINED) && (time() < target.x509UserProxyExpiration) && (target.JobUniverse =?= 5 || target.JobUniverse =?= 1)) && ( (target.osgTestPBS is true) || (true) ) && (target.ProcId >= 0 && target.JobStatus == 1 && (target.StageInStart is undefined || target.StageInFinish isnt undefined) && target.Managed isnt "ScheddDone" && target.Managed isnt "External" && target.Owner isnt Undefined && target.RoutedBy isnt "htcondor-ce")
Checking Job src=162,0 against all routes
	Route Matches: Condor Test
Found candidate job src=162,0,route=Condor Test
1 candidate jobs found
</pre>
%ENDTWISTY%

Ton inspect a job that has already left the queue, use =condor_ce_history= instead of =condor_ce_q=:

<pre class="screen">
%UCL_PROMPT_ROOT% condor_ce_history -l <span style="background-color: #D1CAF2;">&lt;Job ID&gt;</span> | condor_ce_job_router_tool -match-jobs -ignore-prior-routing -jobads -
</pre>

%NOTE% If the proxy for the job has expired, the job will not match any routes. To work around this constraint:

<pre class="screen">
%UCL_PROMPT_ROOT% condor_ce_history -l <span style="background-color: #D1CAF2;">&lt;Job ID&gt;</span> | sed "s/^\(x509UserProxyExpiration\) = .*/\1 = `date +%s --date '+1 sec'`/" | condor_ce_job_router_tool -match-jobs -ignore-prior-routing -jobads -
</pre>

Alternatively, you can provide a file containing the !JobAd as the input and edit attributes within that file:

<pre class="screen">
%UCL_PROMPT_ROOT% condor_ce_job_router_tool -match-jobs -ignore-prior-routing -jobads <span style="background-color: #D1CAF2;">&lt;JobAd file&gt;</span>
</pre>

---++++ Troubleshooting

   1. <p><b>If your job is not matching any route:</b> You can identify this case when you see =0 candidate jobs found= in the =condor_job_router_tool= output. This messages means that, when compared to your !JobAd, the Umbrella constraint does not evaluate to =true=. When troubleshooting, look at all of the expressions prior to the =target.ProcId >&#61; 0= expression since it and everything following it is logic that the !JobRouter added so that routed jobs do not get routed again. \
%TWISTY{%TWISTY_OPTS_OUTPUT% showlink="Show sample output&hellip;"}%<pre class="screen">
Umbrella constraint: ((target.x509userproxysubject =!= UNDEFINED) && (target.x509UserProxyExpiration =!= UNDEFINED) && (time() < target.x509UserProxyExpiration) && (target.JobUniverse =?= 5 || target.JobUniverse =?= 1)) && ( (target.osgTestPBS is true) || (true) ) && (target.ProcId >= 0 && target.JobStatus == 1 && (target.StageInStart is undefined || target.StageInFinish isnt undefined) && target.Managed isnt "ScheddDone" && target.Managed isnt "External" && target.Owner isnt Undefined && target.RoutedBy isnt "htcondor-ce")
<span style="background-color: #D1CAF2;">0 candidate jobs found</span>
</pre> %ENDTWISTY% </p>
   1. *If your job matches more than one route:* the tool will tell you by showing all matching routes after the job ID: 
   <pre class="screen">Checking Job src=162,0 against all routes
<span style="background-color: #D1CAF2;">Route Matches: Local_PBS</span>
<span style="background-color: #D1CAF2;">Route Matches: Condor Test</span></pre>\
      To troubleshoot why this is occuring, look at the combined Requirements expressions for all routes and compare it to the !JobAd provided. The combined Requirements expression is <span style="background-color: #D1CAF2;">highlighted</span> below:\
<pre class="screen">Umbrella constraint: ((target.x509userproxysubject =!= UNDEFINED) && 
(target.x509UserProxyExpiration =!= UNDEFINED) && 
(time() < target.x509UserProxyExpiration) && 
(target.JobUniverse =?= 5 || target.JobUniverse =?= 1)) && 
<span style="background-color: #D1CAF2;">( (target.osgTestPBS is true) || (true) )</span> && 
(target.ProcId >= 0 && target.JobStatus == 1 && 
(target.StageInStart is undefined || target.StageInFinish isnt undefined) && 
target.Managed isnt "ScheddDone" && 
target.Managed isnt "Extenal" && 
target.Owner isnt Undefined && 
target.RoutedBy isnt "htcondor-ce")
</pre>\
Both routes evaluate to =true= for the !JobAd because it had =osgTestPBS = true=. Make sure your routes are mutually exclusive, otherwise you may have jobs routed incorrectly! See the [[JobRouterRecipes][job route configuration page]] for more details.

---+++ condor_ce_status

---++++ Usage

To see the daemons running on a CE, you can run the following:

<pre class="screen">
%UCL_PROMPT% condor_ce_status -any -name <span style="background-color: #D1CAF2;">condorce.example.com</span> -pool <span style="background-color: #D1CAF2;">condorce.example.com</span>:9619
</pre>

Replace the <span style="background-color: #D1CAF2;">highlighted</span> text with the hostname of the CE. If you run the =condor_ce_status= command on the CE that you are testing, omit the =-name= and =-pool= options. =condor_ce_status= takes the same arguments as =condor_status= and is documented in the [[http://research.cs.wisc.edu/htcondor/manual/v8.0/condor_status.html][HTCondor manual]].

---++++ Troubleshooting

To list the daemons that are configured to run:

<pre class="screen">
%UCL_PROMPT% condor_ce_config_val -v DAEMON_LIST
DAEMON_LIST: MASTER COLLECTOR SCHEDD JOB_ROUTER, SHARED_PORT, SHARED_PORT
  Defined in '/etc/condor-ce/config.d/03-ce-shared-port.conf', line 9.
</pre>

If you do not see these daemons in the output of =condor_ce_status=, check the [[#MasterLog][Master log]] for errors.

#ConfigVal
---+++ condor_ce_config_val

---++++ Usage

To see the value of configuration variables and where they are set, use =condor_ce_config_val=. Primarily, This tool is used with the other troubleshooting tools to make sure your configuration is set properly. To see the value of a single variable and where it is set:

<pre class="screen">
%UCL_PROMPT% condor_ce_config_val -v <span style="background-color: #D1CAF2;">&lt;configuration variable&gt;</span>
</pre>

To see a list of all configuration variables and their values:

<pre class="screen">
%UCL_PROMPT% condor_ce_config_val -dump
</pre>

=condor_ce_config_val= takes the same arguments as =condor_config_val= and is documented in the [[http://research.cs.wisc.edu/htcondor/manual/v8.0/condor_config_val.html][HTCondor manual]].

---++ General Troubleshooting Steps

---+++ Making sure packages are up-to-date

It is important to make sure that the HTCondor CE and related RPMs are up-to-date.

<pre class="screen">yum update <em>"htcondor-ce*" blahp condor</em></pre>\

If you just want to see the packages to update, but do not want to perform the update now, answer <code>N</code> at the prompt.

#TroubleshootingItems
---++ HTCondor CE Troubleshooting Items

This section contains common issues you may encounter using HTCondor CE and next actions to take when you do.

---+++ Jobs stay idle on the CE

Check the following subsections in order, but note that jobs may take several minutes or longer to run if the CE is busy.

---++++ Idle jobs on CE: Is the job router handling the incoming job?

Jobs on the CE will be put on hold if they do not match any job routes after 30 minutes, but you can check a few things if you suspect that the jobs are not being matched. Check if the !JobRouter sees a job before that by looking at the [[#JobRouterLog][job router log]] and looking for the text =src=&lt;job id&gt;&hellip;claimed job=. 

*Next actions*

Use [[#CondorJobRouterTool][condor_ce_job_router_tool]] to see why your idle job does not match any routes

---++++ Idle jobs on CE: Verify correct operation within the BLAHP/GAHP

The BLAHP/GAHP are responsible for submitting and tracking jobs on your batch system and their output is logged in the [[#GridmanagerLog][Gridmanager logs]]. Look for =gm state change&hellip;= lines to figure out where the issures are occuring. 

*Next actions*

   1. <p><b>If you see failures in the Gridmanager log during job submission:</b> Try [[#ManualSubmission][manual submission]] to the batch system. If that succeeds, make sure that the BLAHP knows where your binaries are located by setting the =&lt;batch system&gt;_binpath= in =/etc/blah.config=.</p>
   1. <p><b>If you see failures in the Gridmanager log  during queries for job status:</b> Query the resultant job with your batch system tools from the CE. If you can, the BLAHP uses scripts to query for status in =/usr/libexec/blahp/&lt;batch system&gt;_status.sh= (e.g., =/usr/libexec/blahp/lsf_status.sh=) that take the argument =batch system/YYYMMDD/job ID= (e.g., =lsf/20141008/65053=). Run the appropriate "status" script for your batch system and upon success, you should see the following output:</p>\
   <pre class="screen">[ BatchjobId = "894862"; JobStatus = 4; ExitCode = 0; WorkerNode = "atl-prod08" ]</pre>\
   If the script fails, [[#OsgSupport][request help]] from the OSG.
   
#ManualSubmission
---++++ Idle jobs on CE: Make sure the underlying batch system can run jobs

HTCondor CE communicates directly with an HTCondor batch system schedd, so if jobs are not running, examine the [[#SchedLog][schedd log]] and diagnose the problem from there. For other batch systems, the BLAHP is used to submit jobs using your batch system's job submission binaries, whose location is specified in =/etc/blah.config=.

*Procedure*
   1. Manually create and submit a simple job (e.g., =sleep=)
   1. Check for errors in the submission itself
   1. Watch the job in the batch system queue (e.g., using =condor_q=)
   1. If the job does not run, check for errors on the batch system

*Next actions*

If the underlying batch system does not run a simple manual job, it will probably not run a job coming from HTCondor CE. Once you can run simple manual jobs on your batch system, try submitting to the HTCondor CE again.

---++++ Idle jobs on CE: Verify ability to change permissions on key files

HTCondor CE needs the ability to write and chown files in its =spool= directory. If it cannot, jobs will not run at all.

*Sample failure*

<pre class="file">09/17/14 14:45:42 Error: Unable to chown '/var/lib/condor-ce/spool/1/0/cluster1.proc0.subproc0/env' from 12345 to 54321</pre>

*Next actions*

   1. <p>As root, try to change ownership of the file or directory in question. If the file does not exist, a parent directory may have improper permissions.</p>
   1. <p>If using a shared file system, verify that root squash is turned off. For NFS, this is turned off by setting the following in =/etc/exports=:</p>\
       <pre class="screen">no_root_squash</pre>

---+++ Jobs stay idle on a remote host submitting to the CE

If you're submitting your job from a separate submit host to the CE and it stays idle in the queue forever, this means that your job cannot contact the CE for submission or it's not authorized to run there. Note that jobs may take several minutes or longer if the CE is busy.

---++++ Remote idle jobs: Can you contact the CE?

To check basic connectivity to a CE, use [[#CondorPing][condor_ce_ping]]:

*Sample failure*

<pre class="screen">
%UCL_PROMPT% env _condor_SEC_CLIENT_AUTHENTICATION_METHODS=GSI condor_ping -verbose -name fermicloud133.fnal.gov -pool fermicloud133.fnal.gov:9619 WRITE 
<span style="background-color: #D1CAF2;">ERROR: couldn't locate fermicloud133.fnal.gov!</span>
</pre>

*Next actions*

   1. Make sure that the HTCondor CE daemons are running:\
   <pre class="screen">service condor-ce status</pre>
   1. Verify the <span style="background-color: #D1CAF2;">CE</span> is reachable from your submit host:\
   <pre class="screen">ping <span style="background-color: #D1CAF2;">CE</span></pre>

---++++ Remote idle jobs: Are you authorized to run jobs on the CE?

The CE will only accept jobs from users that authenticate via GUMS or a grid mapfile. You can use [[#CondorPing][condor_ce_ping]] to check if you are authorized and what user your proxy is being mapped to.

*Sample failure*

<pre class="screen">
%UCL_PROMPT% env _condor_SEC_CLIENT_AUTHENTICATION_METHODS=GSI condor_ping -verbose -name fermicloud133.fnal.gov -pool fermicloud133.fnal.gov:9619 WRITE 
Remote Version:              $CondorVersion: 8.0.7 Sep 24 2014 $
Local  Version:              $CondorVersion: 8.0.7 Sep 24 2014 $
Session ID:                  fermicloud133:3343:1412790611:0
Instruction:                 WRITE
Command:                     60021
Encryption:                  none
Integrity:                   MD5
Authenticated using:         GSI
All authentication methods:  GSI
<span style="background-color: #D1CAF2;">Remote Mapping:              gsi@unmapped</span>
<span style="background-color: #D1CAF2;">Authorized:                  FALSE</span>
</pre>

*Next actions*

   1. Verify that an [[InstallHTCondorCE#5_2_Setup_Authorization][authentication method]] is set up on the CE
   1. Verify that your proxy is mapped to an existing system user

---+++ Jobs go on hold

Jobs will be put on held with a =HoldReason= attribute that can be inspected with [[#CondorQ][condor_ce_q]]:

<pre class="screen">%UCL_PROMPT% condor_ce_q -l <span style="background-color: #D1CAF2;">&lt;job ID&gt;</span> -attr HoldReason
HoldReason = "CE job in status 5 put on hold by SYSTEM_PERIODIC_HOLD due to non-existent route or entry in JOB_ROUTER_ENTRIES."
</pre>

---++++ Held jobs: Missing/expired user proxy

HTCondor CE requires a valid user proxy for each job that is submitted. You can check the status of your proxy with the following

<pre class="screen">%UCL_PROMPT% voms-proxy-info -all</pre>

*Next actions*

Ensure that the owner of the job generates their proxy with =voms-proxy-init=.

---++++ Held jobs: Invalid job universe

The HTCondor CE only accepts jobs that have =universe= in their submit files set to =vanilla=, =standard=, =local=, or =scheduler=. These universes also have corresponding integer values that can be found in the [[http://research.cs.wisc.edu/htcondor/manual/v8.0/12_Appendix_A.html#88647][HTCondor manual]]. 

*Next actions*

   1. Ensure jobs submitted locally, from the CE host, are submitted with =universe = vanilla=
   1. Ensure jobs submitted from a remote submit point are submitted with:\
   <pre class="file">universe = grid
grid_resource = condor <span style="background-color: #D1CAF2;">condorce.example.com condorce.example.com</span>:9619</pre>\
   With the <span style="background-color: #D1CAF2;">condorce.example.com</span>'s replaced by the hostname of the CE.

---++++ Held jobs: Non-existent route or entry in JOB_ROUTER_ENTRIES

Jobs on the CE will be put on hold if they do not match any job routes within 30 minutes. 

*Next actions*

Use [[#CondorJobRouterTool][condor_ce_job_router_tool]] to see why your idle job does not match any routes.

#OsgSupport
---++ Further Help with HTCondor CE

---+++ Requesting help from OSG

If you are still experiencing issues after using this document, please let us know!

   1. <p>Gather basic HTCondor CE and related information (versions, relevant configuration, problem description, etc.)</p>
   1. <p>Gather system information:</p>\
       <pre class="screen">osg-system-profiler &gt; ~/osg-system-profiler-<span style="background-color: #D1CAF2;">YYYYMMDD</span>.txt</pre>
   1. <p>Send email to goc@opensciencegrid.org</p>
      * Describe issue and expected or desired behavior
      * Include basic HTCondor CE and related information
      * Attach the osg-system-profiler output
