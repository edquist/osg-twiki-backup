%META:TOPICINFO{author="BrianLin" date="1370548307" format="1.1" version="1.22"}%
%META:TOPICPARENT{name="Blueprint.WebHome"}%
---+!! Installing the HTCondor-CE

%TOC{depth="2"}%

---# About this Document

This document is for System Administrators. It covers the installation of the HTCondor-CE software, which aims to provide an end-to-end gatekeeper technology built entirely out of core HTCondor components.  As a goal, we aim for the HTCondor-CE to be a particular "configuration" of HTCondor, and not include any non-HTCondor daemons.

The HTCondor-CE approach is under active investigation; this page provides *developer documentation* for installing and configuration the CE.

%INCLUDE{"Documentation/DocumentationTeam/DocConventions" section="Header"}%
%INCLUDE{"Documentation/DocumentationTeam/DocConventions" section="CommandLine"}%

---# How to get Help?
To get assistance please use the [[HelpProcedure][this page]].

---# Requirements

---## Host and OS
   * A host to install the Compute Element
   * OS is %SUPPORTED_OS%
   * Root access

---## Users

%STARTSECTION{"Users"}%

The following users are needed by HTCondor-CE at all sites
| *User* | *Comment* |
| =condor= | The HTCondor-CE will be run as root, but perform most of its operations as the =condor= user. |
| =gratia= | Runs the Gratia probes to collect accounting data |

The above user will be added to the system automatically when the HTCondor RPM installs.  If your fabric management automatically overwrites users and groups, you will want to create this user beforehand.

%ENDSECTION{"Users"}%

---## Certificates
| *Certificate* | *User that owns certificate* | *Path to certificate* |
| Host certificate | =root= | =/etc/grid-security/hostcert.pem= <br> =/etc/grid-security/hostkey.pem= |

Find instructions to request a host certificate [[Documentation/Release3.GetHostServiceCertificates][here]].

---## Networking

%STARTSECTION{"Firewalls"}%
%INCLUDE{"Documentation/Release3/FirewallInformation" section="FirewallTable" lines="htcondorce,htcondorce_shared"}% 

Allow inbound and outbound network connection to all internal site servers, such as GUMS and the batch system head-node <br/>

Only ephemeral outgoing ports are necessary.

%ENDSECTION{"Firewalls"}%

---## Additional Requirements
To be part of the OSG Production Grid, your CE must be registered in OIM. To register your resource:
   * Use your user certificate.  Find instructions to request a user certificate [[CertificateUserGet][here]].
   * Register in OIM as described in Operations.OIMRegistrationInstructions

---### HTCondor Versions
One goal of the HTCondor-CE is to use the site's condor_* binaries, but run a completely different set of daemons (similar to OSG's condor-cron for RSV).

%WARNING% During the development phase of the CE, you'll need the latest-greatest version of HTCondor due to a few prerequisite patches.  Install HTCondor 7.9.5 or later.  You may have to remove the existing RPMs manually if the repository you use doesn't ship this yet.

%WARNING% The HTCondor 7.9.6 RPM from UW-Madison does not work with HTCondor-CE. If you would like to still use the HTCondor-CE, consider grabbing the =condor= package from =osg-upcoming= until the 8.0 series is released.

---### Home Directories

If your site uses the HTCondor batch system, no home directories are necessary.  All data movement is handled via HTCondor file transfer. For all other batch systems, home directories for all grid users must exist and be exported to the worker nodes.

%INCLUDE{"Documentation/Release3/YumRepositories" section="OSGRepoBrief" TOC_SHIFT="+"}%
%INCLUDE{"Documentation/Release3/InstallCertAuth" section="OSGBriefCaCerts" TOC_SHIFT="+"}%

---# Installation Procedure

First, install CRLs and authorization:
<pre class="rootscreen">
%UCL_PROMPT_ROOT% yum install fetch-crl lcmaps lcas-lcmaps-gt4-interface
</pre>

Do one of the following, depending on your batch system:

<pre class="rootscreen">
%RED%# For an HTCondor batch system%ENDCOLOR%
%UCL_PROMPT_ROOT% yum install --enablerepo=osg-development htcondor-ce-condor gratia-probe-condor
%RED%# For a PBS batch system%ENDCOLOR%
%UCL_PROMPT_ROOT% yum install --enablerepo=osg-development htcondor-ce-pbs gratia-probe-pbs-lsf
</pre>

%NOTE% In the future, we will use meta-RPMs to put this all into one step
%NOTE% We currently distribute the HTCondor-CE only in the osg-development repository.

---# Configuration Instructions

---## Setup authorization
If you are using GUMS, you need to configure =/etc/lcmaps.db=, as you would a [[Documentation.Release3.InstallComputeElement#8_1_Using_GUMS_for_Authorization][GRAM-based OSG-CE]].  Remember to uncomment the line in =/etc/grid-security/gsi-authz.conf=.

%NOTE% Once gsi-authz.conf is in place, your site's HTCondor will attempt to utilize the LCMAPS callouts if enabled in the condor_mapfile.  If this is not the desired behavior, set GSI_AUTHZ_CONF=/dev/null in the HTCondor configuration.

If you are not using GUMS, you will need to add the appropriate lines to =/etc/condor-ce/condor_mapfile=. 

---## Setup Job Routes

%NOTE% This section covers just the basic customizations; a site needing more elaborate configurations should refer to [[HTCondorCERoutes][this page]].

The HTCondor-CE depends on the [[http://research.cs.wisc.edu/htcondor/manual/v7.8/5_5HTCondor_Job.html][HTCondor JobRouter]] to transform an incoming grid job into a batch system job.  This is controlled by a job _route_; default routes are installed in =/etc/condor-ce/config.d/02-ce-*.conf=.  Each route corresponds to a separate job transformation.

The built-in routes contain only the minimal base functionality needed for starting jobs at a small site.  A larger site may [[HTCondorCERoutes][want to refer to this document]] for hints on how to better customize their site.

Place customizations in =/etc/condor-ce/config.d/99-local.conf= (or a similarly named file which overrides 02-*; files in the directory are evaluated in alphabetical order), not the original =02-ce-*.conf=.

For HTCondor sites, =02-ce-condor.conf= assumes that the SPOOL location for the site schedd is in the "normal" location of /var/lib/condor/spool, and the schedd's name is =$(FULL_HOSTNAME)=.  You must customize these if you run a non-RPM version of HTCondor.

---## Other Customizations

   * The site HTCondor schedd must have the following value set: <pre>QUEUE_SUPER_USER_MAY_IMPERSONATE = %RED%.*%ENDCOLOR%</pre>  This allows the !JobRouter to submit jobs from any user.  You may tighten the regular expression to limit which users are allowed to use the CE.

   * The Unix environment variables for the HTCondor-CE daemons is controlled by =/etc/sysconfig/condor-ce=.

   * You can place site HTCondor-CE configuration customizations in =/etc/condor-ce/config.d=; *do not edit files* in this directory installed by the HTCondor-CE, as edits will be lost on upgrade.  Instead, add a new file that overrides HTCondor-CE's settings.  Any filename prefixed with "99-" will override the files from the CE.

%NOTE% The HTCondor-CE installs a *custom configuration of HTCondor*.  If you are running HTCondor as a batch system, this means you will have two sets of HTCondor daemons running.  This is similar to how RSV works. To configure the CE, you need to look at =/etc/condor-ce=, *NOT* =/etc/condor=. Similarly, to list the jobs in queue, you will need to perform =condor_ce_q=, not =condor_q=.
   

---# Services

The following services need to be enabled with =chkconfig= and started with =service=:
   * =condor-ce=: This is the set of Condor daemons which implement the Condor-CE.
   * Batch system: You need to have your batch system started for the Condor-CE to interact with it; batch system operation does not change, even for Condor sites.
   * =fetch-crl=: This maintains the validity of the CRL files in =/etc/grid-security/certificates=.
   * =gratia-probe-cron=: This service enables or disables a cron job, which uploads accounting information to the OSG.

---++ Starting and Enabling Services

   1. %INCLUDE{"Documentation/Release3/InstallCertAuth" section="OSGBriefFetchCrlStart"}%
   
   2. Start Gratia: <pre class="rootscreen">
%UCL_PROMPT_ROOT% /sbin/service gratia-probe-cron start
</pre>
   3. Start your batch system (choose the appropriate one): <pre class="rootscreen">
%UCL_PROMPT_ROOT% /sbin/service condor start
%UCL_PROMPT_ROOT% /sbin/service pbs_server start
</pre>
   4. Start HTCondor-CE: <pre class="rootscreen">
%UCL_PROMPT_ROOT% /sbin/service condor-ce start
</pre>

[Optional but recommended:] Enable services so that they start automatically when your system is powered on:

   * %INCLUDE{"Documentation/Release3/InstallCertAuth" section="OSGBriefFetchCrlEnable"}%
   * Enable HTCondor-CE: <pre class="rootscreen">
%UCL_PROMPT_ROOT% /sbin/chkconfig condor-ce on
</pre>
   * Enable batch system (choose one): <pre class="rootscreen">
%UCL_PROMPT_ROOT% /sbin/chkconfig condor on
%UCL_PROMPT_ROOT% /sbin/chkconfig pbs_server on
</pre>
   * Enable Gratia: <pre class="rootscreen">
%UCL_PROMPT_ROOT% /sbin/chkconfig gratia-probe-cron on
</pre>

---++ Stopping and Disabling Services

   1. Stop HTCondor-CE: <pre class="rootscreen">
%UCL_PROMPT_ROOT% /sbin/service condor-ce stop
</pre>
   2. Stop your batch system (choose the appropriate one): <pre class="rootscreen">
%UCL_PROMPT_ROOT% /sbin/service condor stop
%UCL_PROMPT_ROOT% /sbin/service pbs_server stop
</pre>
   3. Stop Gratia: <pre class="rootscreen">
%UCL_PROMPT_ROOT% /sbin/service gratia-probe-cron stop
</pre>
   4. (other grid service running on the machine may still use it)
   %INCLUDE{"Documentation/Release3/InstallCertAuth" section="OSGBriefFetchCrlStop"}%
Stop services from starting when the system is powered on:

   * Disable HTCondor-CE: <pre class="rootscreen">
%UCL_PROMPT_ROOT% /sbin/chkconfig condor-ce off
</pre>
   * Disable batch system (choose one): <pre class="rootscreen">
%UCL_PROMPT_ROOT% /sbin/chkconfig condor off
%UCL_PROMPT_ROOT% /sbin/chkconfig pbs_server off
</pre>
   * Disable Gratia: <pre class="rootscreen">
%UCL_PROMPT_ROOT% /sbin/chkconfig gratia-probe-cron off
</pre>
   * (other grid service running on the machine may still use it) %INCLUDE{"Documentation/Release3/InstallCertAuth" section="OSGBriefFetchCrlDisable"}%
   
---# Troubleshooting

---## Useful Configuration and Log Files 

   * =/var/log/condor/*=: HTCondor daemon files.
   * =/var/log/condor/user/*=, =/var/log/condor/Gridmanager.*=: Per-user log files recording individual submissions and interactions with the batch system.
   * =/var/log/messages=: LCMAPS sends authentication and authorization information into syslog; check this if you are having authz difficulties.

---## Included test utilities

You can use the =condor_ce_run= utility to send test jobs to a remote HTCondor-CE.  For example, to run the =env= binary in the remote batch system, you can do:

<pre class="screen">
condor_ce_run -r %RED%condorce.example.com:9619%ENDCOLOR% env
</pre>

Replacing the %RED%red%ENDCOLOR% text with the hostname of the CE. HTCondor will submit directly to the remote schedd with the =-r= flag;  Without the flag, it will submit to the local schedd using the grid universe.

If =condor_ce_run= fails, then the =condor_ce_trace= tool will assist in verifying the install:

<pre class="screen">
condor_ce_trace %RED%condorce.example.com%ENDCOLOR%
</pre>

%TWISTY{%TWISTY_OPTS_OUTPUT% showlink="Show an example condor_ce_trace run"}%
<pre class="screen">
%UCL_PROMPT% condor_ce_trace red.unl.edu
Testing HTCondor-CE collector connectivity.
- Successful ping of collector on <129.93.239.129:9619>.

Testing HTCondor-CE schedd connectivity.
- Successful ping of schedd on <129.93.239.129:9620?sock=8556_0571_4>.

Submitting job to schedd <129.93.239.129:9620?sock=8556_0571_4>
- Successful submission; cluster ID 112170
Resulting job ad: 
    [
        BufferSize = 524288; 
        NiceUser = false; 
        CoreSize = -1; 
        CumulativeSlotTime = 0; 
        OnExitHold = false; 
        RequestCpus = 1; 
        Err = "_condor_stderr"; 
        BufferBlockSize = 32768; 
        x509userproxy = "/tmp/x509up_u1221"; 
        TransferOutputRemaps = "_condor_stdout=/home/cse496/bbockelm/projects/condor-ce/.stdout_23011_RD17wL;_condor_stderr=/home/cse496/bbockelm/projects/condor-ce/.stderr_23011_XeO5dg"; 
        ImageSize = 100; 
        CurrentTime = time(); 
        WantCheckpoint = false; 
        CommittedTime = 0; 
        TargetType = "Machine"; 
        WhenToTransferOutput = "ON_EXIT"; 
        Cmd = "/bin/env"; 
        JobUniverse = 5; 
        ExitBySignal = false; 
        HoldReasonCode = 16; 
        Iwd = "/home/cse496/bbockelm/projects/condor-ce"; 
        NumRestarts = 0; 
        CommittedSuspensionTime = 0; 
        Owner = undefined; 
        NumSystemHolds = 0; 
        CumulativeSuspensionTime = 0; 
        RequestDisk = DiskUsage; 
        Requirements = true && TARGET.OPSYS == "LINUX" && TARGET.ARCH == "X86_64" && TARGET.HasFileTransfer && TARGET.Disk >= RequestDisk && TARGET.Memory >= RequestMemory; 
        MinHosts = 1; 
        JobNotification = 0; 
        NumCkpts = 0; 
        LastSuspensionTime = 0; 
        NumJobStarts = 0; 
        WantRemoteSyscalls = false; 
        JobPrio = 0; 
        RootDir = "/"; 
        CurrentHosts = 0; 
        x509UserProxyExpiration = 1367717162; 
        StreamOut = false; 
        WantRemoteIO = true; 
        OnExitRemove = true; 
        DiskUsage = 1; 
        In = "/dev/null"; 
        PeriodicRemove = false; 
        RemoteUserCpu = 0.0; 
        LocalUserCpu = 0.0; 
        LocalSysCpu = 0.0; 
        RemoteSysCpu = 0.0; 
        ClusterId = 112170; 
        Log = "/home/cse496/bbockelm/projects/condor-ce/.log_23011_QRcWCU"; 
        CompletionDate = 0; 
        RemoteWallClockTime = 0.0; 
        LeaveJobInQueue = JobStatus == 4 && ( CompletionDate is UNDDEFINED || CompletionDate == 0 || ( ( time() - CompletionDate ) < 864000 ) ); 
        CondorVersion = "$CondorVersion: 7.9.6 Apr 22 2013 BuildID: RH-7.9.6-0.2.de1f9cc.git.lark.osg.el6 PRE-RELEASE-UWCS $"; 
        MyType = "Job"; 
        StreamErr = false; 
        HoldReason = "Spooling input data files"; 
        PeriodicHold = false; 
        ProcId = 0; 
        Out = "_condor_stdout"; 
        JobStatus = 5; 
        PeriodicRelease = false; 
        RequestMemory = ifthenelse(MemoryUsage isnt undefined,MemoryUsage,( ImageSize + 1023 ) / 1024); 
        Args = ""; 
        MaxHosts = 1; 
        TotalSuspensions = 0; 
        CommittedSlotTime = 0; 
        x509userproxysubject = "/DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Brian Bockelman/CN=4221328"; 
        CondorPlatform = "$CondorPlatform: X86_64-ScientificLinux_6.3 $"; 
        ShouldTransferFiles = "YES"; 
        ExitStatus = 0; 
        QDate = 1367674672; 
        EnteredCurrentStatus = 1367674672
    ]
Spooling cluster 112170 files to schedd <129.93.239.129:9620?sock=8556_0571_4>
- Successful spooling
Job status: Held
Job transitioned from Held to Idle
Job transitioned from Idle to Running
Job transitioned from Running to Completed
- Job was successful
</pre>
%ENDTWISTY%


---## Testing by hand

From a test submit host, use this file to submit to the CE:
<pre class="file">
universe = grid
grid_resource = condor %RED%condorce.example.com condorce.example.com:9619%ENDCOLOR%

executable = test.sh
output = test_g.out
error = test_g.err
log = test_g.log

ShouldTransferFiles = YES
WhenToTransferOutput = ON_EXIT

use_x509userproxy = true

queue
</pre>

Replace =condorce.example.com= with the hostname of the HTCondor-CE, submit this file using =condor_submit= from an external host and make sure to create an executable =test.sh=. 

---# Known Issues

   * (PBS Sites; blahp < 1.18.3.bosco) The blahp requires you to use old-style proxies; the newest =voms-proxy-init= will generate new-style proxies by default.  In HTCondor-CE 0.4 and prior, you need to hand-install /usr/bin/grid-proxy-info via yum.
      * You have hit this issue if the job goes on hold with the error "Attempts to submit failed" and you have the line =blah_job_submit() failed: Unable to limit the proxy= in =/var/log/condor-ce/GridmanagerLog.%RED%$USER%ENDCOLOR%= on the Condor-CE host.
   * (Client authorization; condor < 7.9.2) You need to add <pre>GSI_DAEMON_NAME=/DC=org/DC=doegrids/OU=Services/CN=%RED%condor-ce.example.com%ENDCOLOR%
CERTIFICATE_MAPFILE = /etc/condor/condor_mapfile
</pre> to the Condor configuration on the submit host (update the condor-ce.example.com line appropriately).  You also need to have a line like <pre>GSI "\/DC\=org\/DC\=doegrids\/OU\=Services\/CN\=%RED%condor-ce.example.com%ENDCOLOR%" %RED%condor-ce%ENDCOLOR%@ce.opensciencegrid.org</pre> in =/etc/condor/condor_mapfile=.
   * (!DigiCert CA hostcert, htcondor-ce < 0.5.4) or (non-OSG CA for hostcert or service certificate).  The hostcert for the HTCondor-CE service needs to be recognized by HTCondor's mapfile system.  If your host certificate is actually a service certificate, or from a non-OSG CA, you will need to add this to the =/etc/condor-ce/condor_mapfile=.  For versions prior to 0.5.4, you need the following for a !DigiCert-issued hostcert: <pre>GSI "^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$" \2@daemon.opensciencegrid.org</pre>

%META:TOPICMOVED{by="BrianBockelman" date="1355365789" from="Blueprint.CondorCE" to="Documentation.InstallHTCondorCE"}%
