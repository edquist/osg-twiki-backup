%META:TOPICINFO{author="JohnWeigand" date="1378300480" format="1.1" reprev="1.40" version="1.40"}%
%META:TOPICPARENT{name="NavUserApplications"}%
<!-- Local variables
   * Set CONDORREL = 7.8.6
   * Set AS_OF_DATE = Mar 19, 2013
   * Set TWISTY_OPTS_DETAILED = mode="div" showlink="Show Detailed Output" hidelink="Hide" showimgleft="/twiki/pub/TWiki/TWikiDocGraphics/toggleopen-small.gif" hideimgleft="/twiki/pub/TWiki/TWikiDocGraphics/toggleclose-small.gif" remember="on" start="hide" 
-->

---+!! !GlideinWMS VO Frontend Installation
%DOC_STATUS_TABLE%
%TOC{depth="3"}%

---+ About This Document

This document describes how to install the Glidein Workflow Managment System (!GlideinWMS) VO Frontend for use with the OSG glidein factory.  This software is the minimum requirement for a VO to use glideinWMS.

This document assumes expertise with Condor and familiarity with the glideinWMS software.  It *does not* cover anything but the simplest possible install.   Please consult the [[http://www.uscms.org/SoftwareComputing/Grid/WMS/glideinWMS/doc.prd/install.html][Glidein WMS reference documentation]] for advanced topics, including non-=root=, non-RPM-based installation.

This document covers three components of the !GlideinWMS a !VO needs to install:
   * *User Pool Collectors*: A set of =condor_collector= processes.  Pilots submitted by the factory will join to one of these collectors to form a Condor pool.
   * *User Pool Schedd*: A =condor_schedd=.  Users may submit Condor vanilla universe jobs to this schedd; it will run jobs in the Condor pool formed by the *User Pool Collectors*.
   * *Glidein Frontend*: The frontend will periodically query the *User Pool Schedd* to determine the desired number of running job slots.   If necessary, it will request the factory to launch additional pilots.

This guide covers installation of all three components on the same host: it is designed for small to medium VOs (see the Hardware Requirements below).  Given a significant, large host, we have been able to scale the single-host install to 10,000 running jobs.

%ATTACHURL%/simple_diagram.png

%INCLUDE{"Documentation/DocumentationTeam/DocConventions" section="Header"}%
%INCLUDE{"Documentation/DocumentationTeam/DocConventions" section="CommandLine"}%

---+ Release
This document reflects glideinWMS v2.7.2.rc2.

---+ How to get Help?

To get assistance about the OSG software please use [[HelpProcedure][this page]]. 

For specific questions about the Frontend configuration (and how to add it in your HTCondor infrastructure) you can email the !glideinWMS support glideinwms-support@fnal.gov

To request access the OSG Glidein Factory (e.g. the UCSD factory) you have to send an email to osg-gfactory-support@physics.ucsd.edu (see below).


---+ Requirements
 
---++ Hardware requirements

The Glidein WMS VO Frontend has the following requirements:
   * *CPU*: Four cores, preferably no more than 2 years old.
   * *RAM*: 3GB plus 2MB per running job.  For example, to sustain 2000 running jobs, a host with 5GB is needed.
   * *Disk*:  30GB will be plenty sufficient for all the binaries, config and log files related to glideinWMS.  As this will be an interactive submit host, plan enough disk space for your users' jobs.  Depending on your workflow, this might require 2MB to 2GB per job in a workflow.
   * *Network*:  The VO frontend must have reliable network connectivity, be on the public internet (no NAT), and preferably with no firewalls.  Each running pilot requires 5 outgoing TCP ports.  Incoming TCP ports 9618 to 9660 must be open.
      * For example, 2000 running jobs require about 10,100 TCP connections.  This will overwhelm many firewalls; if you are unfamiliar with your network topology, you may want to warn your network administrator.

---++ Operating system

This has been tested on SL6.3, SL5.5 and !CentOS 5.5, x86_64 architecture.  Any RHEL-5.x, RHEL-6.x clone should work .  Other platforms are not supported.

---++ Required software

All software requirements are defined in the RPM, and will be pulled in at install time.

---++ Users

%STARTSECTION{"Users"}%
| *User* | *Comment* |
| =frontend= | This user runs the !glideinWMS VO frontend.  It also owns the certificate forwarded to the factory to use for the glideins.|
| =condor= | Condor user (installed via dependencies). |
%ENDSECTION{"Users"}%

---++ CA Certificates
The OSG Client will install the CA certificates and CRLs as part of the installation.  These are used for authentication purposes for the various !glideinWMS services.  Refer to the [[InstallCertAuth][Installing Certificate Authorities Certificates and related RPMs]] document for more information on these.




---++ VO Frontend Certificate/Proxy Requirements
The VO Frontend will use two certificates in its interactions with the the other !glideinWMS services.  At this time, these will be proxy files.
   1 the %GREEN%VO Frontend proxy%ENDCOLOR% (used to authenticate with the other !glideinWMS services).
   1 one or more glideinWMS %BLUE%pilot proxies%ENDCOLOR% (used/delegated to the factory services and submitted on the !glideinWMS pilot jobs).

The %GREEN%VO Frontend proxy%ENDCOLOR% and the %BLUE%pilot proxy%ENDCOLOR% can be the same.
By default, the VO Frontend will run as user =frontend= (UID is machine dependent) so these proxies must be owned by the user =frontend=. 

---+++ VO Frontend proxy
The use of a service or host certificate is recommended.  Then you create a proxy from the certificate as explained in the [[#Proxy_Configuration][proxy configuration section]]. This can be a plain grid proxy (from =grid-proxy-init=), no VO extensions are required.

*You must notify the Factory operation of the DN of this proxy when you initially setup the frontend and each time the DN changes*.


---+++ Pilot proxies
This proxy is used by the factory to submit the glideinWMS pilot jobs. Therefore, they  must be authorized to access to the CEs (factory entry points) where jobs are submitted.  There is no need to notify the Factory operation about the DN of this proxy (neither at the initial registration nor for subsequent changes). This second proxy has no special requirement or controls added by the factory but will probably require VO attributes because of the CEs: if you are able to use this proxy to submit jobs to the CEs where the Factory runs glideinWMS pilots for you, then the proxy is OK.





---++ OSG Factory access
Before installing the Glidein WMS VO Frontend you need the information about a [[http://www.uscms.org/SoftwareComputing/Grid/WMS/glideinWMS/doc.prd/factory/index.html][Glidein Factory]] that you can access:
   1 (recommended) OSG is managing a factory at UCSD and one at GOC and you can request access to them
   1 You have another Glidein Factory that you can access
   1 You [[InstallGlideinWMSFactory][install your own Glidein Factory]]

To request access to the OSG Glidein Factory at UCSD you have to send an email to osg-gfactory-support@physics.ucsd.edu providing:
   1 Your Name
   1 The VO that is utilizing the VO Frontend
   1 The DN of the proxy you will use to communicate with the Factory (VO Frontend DN)
   1 You can propose a security name that will have to be confirmed/changed by the Factory managers (see below)
   1 A list of sites where you want to run:
      * Your VO must be supported on those sites
      * You can provide a list or piggy back on existing lists, e.g. all the sites supported for the VO. Check with the Factory managers
      * You can start with one single site 
In the reply from the OSG Factory managers you will receive some information needed for the configuration of your VO Frontend
   1 The exact spelling and capitalization of your VO name. Sometime is different from what is commonly used, e.g. OSG VO is "OSGVO".
   1 The host of the Factory Collector: =gfactory-1.t2.ucsd.edu=
   1 The DN os the factory, e.g. =/DC=org/DC=doegrids/OU=Services/CN=gfactory-1.t2.ucsd.edu=
   1 The factory identity, e.g.: =gfactory@gfactory-1.t2.ucsd.edu=
   1 The identity on the factory you will be mapped to. Something like: =username@gfactory-1.t2.ucsd.edu=
   1 Your security name. A unique name, usually containing your VO name: =My_SecName=
   1 A string to add in the main factory query_expr in the frontend configuration, e.g. =stringListMember("%RED%VO%ENDCOLOR%",GLIDEIN_Supported_VOs)=. From there you get the correct name of the VO (above in this list).


---+ Installation Procedure

%INCLUDE{"YumRepositories" section="OSGRepoBrief" TOC_SHIFT="+"}%

%INCLUDE{"InstallCertAuth" section="OSGBriefCaCerts" TOC_SHIFT="+"}%

%STARTSECTION{"InstallGWMSFrontend"}%
---++ Download and install the VO Frontend RPM

The RPM is available in the OSG repository:

Install the RPM and dependencies (be prepared for a lot of dependencies).

   <pre class="rootscreen">%UCL_PROMPT_ROOT% yum install glideinwms-vofrontend</pre>

This will install the current production release verified and tested by OSG with default condor configuration.
This command will install the glideinwms vofrontend, condor, the OSG client, and all the required dependencies all on one node.

If you wish to install a different version of !GlideinWMS, add the "--enablerepo" argument to the command as follows:

   * =yum install --enablerepo=osg-testing glideinwms-vofrontend=: The most recent production release, still in testing phase.  This will usually match the current tarball version on the !GlideinWMS home page.  (The osg-release production version may lag behind the tarball release by a few weeks as it is verified and packaged by OSG).  Note that this will also take the osg-testing versions of all dependencies as well.
   * =yum install --enablerepo=osg-contrib glideinwms-vofrontend=:  The most recent development series release, ie version 3 release.  This has newer features such as cloud submission support, but is less tested.

Note that these commands will install default condor configurations with all services on one node.

%ENDSECTION{"InstallGWMSFrontend"}%

---+++ Advanced: Multi-node Installation 

For advanced users requiring heavy usage on their submit node, you may want to consider splitting the usercollector, user submit, and vo frontend services.

This can be doing using the following three commands (on different machines):

<pre class="rootscreen">
%UCL_PROMPT_ROOT% yum install glideinwms-vofrontend-standalone
%UCL_PROMPT_ROOT% yum install glideinwms-usercollector
%UCL_PROMPT_ROOT% yum install glideinwms-userschedd
</pre>

In addition, you will need to perform the following steps:

   * On the vofrontend and userschedd, modify CONDOR_HOST to point to your usercollector.  This is in =/etc/condor/config.d/00_gwms_general.config=.  You can also override this value by placing it in a new config file.  (For instance, =/etc/condor/config.d/99_local_custom.config= to avoid rpmsave/rpmnew conflicts on upgrades).
   * In =/etc/condor/certs/condor_mapfile=, you will need to all DNs for each machine (userschedd, usercollector, vofrontend).  Take great care to escape all special characters.  Alternatively, you can use the =glidecondor_addDN= to add these values.
   * In the =/etc/gwms-frontend/frontend.xml= file, change the schedd locations to match the correct server.  Also change the collectors tags at the bottom of the file.  More details on frontend xml are in the following sections.

---+++ Upgrade Procedure

If you have a working installation on glideinwms-frontend you just upgrade the frontend rpms and skip the most of the configuration procedure below.

<pre class="rootscreen">
%RED%# Update the glideinwms-vofrontend packages%ENDCOLOR%
%UCL_PROMPT_ROOT% yum update glideinwms-vofrontend
%RED%# Update the scripts in the working directory to the latest one%ENDCOLOR%
%UCL_PROMPT_ROOT% service gwms-frontend upgrade
</pre>




---+ Configuration Procedure 

After installing the RPM, you need to configure the components of the glideinWMS VO Frontend:
   1. Edit Frontend configuration options
   1. Edit Condor configuration options
   1. Create a Condor grid map file
   1. Reconfigure and Start frontend

---++ Configuring the Frontend

The VO Frontend configuration file is =/etc/gwms-frontend/frontend.xml=.  The next steps will describe each line that you will need to edit if you are using the OSG Factory at UCSD.  The portions to edit are highlighted in red font. If you are using a different Factory more changes are necessary, please check [[http://www.uscms.org/SoftwareComputing/Grid/WMS/glideinWMS/doc.prd/frontend/configuration.html][the VO Frontend configuration reference]].

   1. The VO you are affiliated with. This will identify those CEs that the glideinWMS pilot will be authorized to run on using the %BLUE%pilot proxy%ENDCOLOR% described previously in the [[InstallGlideinWMSFrontend#Pilot_proxies][this section]]. Sometime the whole =query_expr= is provided to you by the factory (see Factory access above):
   <pre class="file">
&lt;factory query_expr='((stringListMember("%RED%VO%ENDCOLOR%", GLIDEIN_Supported_VOs)))'></pre>
   1.  Factory collector information.%BR%
 The =username= that you are assigned by the factory (also called the identity you will be mapped to on the factory, see above) .  Note that if you are using a factory different than the production factory, you will have to change also =DN=, =factory_identity= and =node= attributes. (refer to the information provided to you by the factory operator):   <pre class="file">
&lt;collector DN="/DC=org/DC=doegrids/OU=Services/CN=gfactory-1.t2.ucsd.edu" 
                   comment="Define factory collector globally for simplicity" 
                   factory_identity="gfactory@gfactory-1.t2.ucsd.edu" 
                   my_identity="%RED%username%ENDCOLOR%@gfactory-1.t2.ucsd.edu" 
                   node="gfactory-1.t2.ucsd.edu"/>
</pre>
   1. Factory security information.%BR%- The =classad_proxy= in the _security_ entry is the location of the %GREEN%VO Frontend proxy%ENDCOLOR%  described previously [[#VO_Frontend_proxy][here]].%BR%- The =proxy_DN= is the DN of the =classad_proxy= above.%BR%- The =security_name= identifies this VO Frontend to the the Factory, It is provided by the factory operator.%BR%- The =absfname= in the _proxy_ entry is the location of the !glideinWMS %BLUE%pilot proxy%ENDCOLOR% described in the requirements section [[#Pilot_proxies][here]]. There can be multiple %BLUE%pilot proxies%ENDCOLOR%.%BR%Both the =classad_proxy= and =absfname= files should be owned by =frontend= user. 
   <pre class="file">
&lt;security classad_proxy="%RED%/tmp/vo_proxy%ENDCOLOR%" 
                   proxy_DN="%RED%DN of vo_proxy%ENDCOLOR%" 
                   proxy_selection_plugin="ProxyAll" 
                   security_name="%RED%The security name, this is used by factory%ENDCOLOR%" 
                   sym_key="aes_256_cbc"> 
    &lt;proxies>
        &lt;proxy absfname="%RED%/tmp/vo_proxy%ENDCOLOR%" security_class="frontend"/>
    &lt;/proxies> 
&lt;/security>
</pre>
   1. The schedd information.%BR%- The =DN= of the %GREEN%VO Frontend Proxy%ENDCOLOR% described previously [[#VO_Frontend_proxy][here]].%BR%- The =fullname= attribute is the fully qualified domain name of the host where you installed the VO Frontend (=hostname --fqdn=).%BR%A secondary schedd is optional.  You will need to delete the secondary schedd line if you are not using it. Multiple schedds allow the frontend to service requests from multiple submit hosts.
   <pre class="file">
&lt;schedds>
   &lt;schedd DN="%RED%Cert DN used by the schedd at fullname:%ENDCOLOR%" 
                    fullname="%RED%Hostname of the schedd%ENDCOLOR%"/>
   &lt;schedd DN="%RED%Cert DN used by the second Schedd at fullname:%ENDCOLOR%" 
                    fullname="%RED%schedd name%ENDCOLOR%@%RED%Hostname of second schedd%ENDCOLOR%"/>
&lt;/schedds></pre>
   1. The User Collector information.%BR%- The =DN= of the %GREEN%VO Frontend Proxy%ENDCOLOR% described previously [[#VO_Frontend_proxy][here]].%BR%- The =node= attribute is the full hostname of the collectors (=hostname --fqdn=) and port%BR%- The =secondary= attribute indicates whether the element is for the primary or secondary collectors (True/False).%BR%The default Condor configuration of the VO Frontend starts multiple Collector processes on the host (=/etc/condor/config.d/11_gwms_secondary_collectors.config=).. The =DN= and  =hostname=  on the second line are the same as the ones in the first one. The hostname (e.g. hostname.domain.tld) is filled automatically during the installation. The secondary collector ports can be defined as a range, e.g., 9620-9660).  
   <pre class="file">
&lt;collector DN="%RED%DN of main collector%ENDCOLOR%" 
                   node="hostname.domain.tld:9618" secondary="False"/>
&lt;collector DN="%RED%DN of secondary collectors (usually same as DN in line above)%ENDCOLOR%" 
                   node="hostname.domain.tld:9620-9660" secondary="True"/>
</pre>

---++ Configuring Condor
The condor configuration for the frontend is placed in =/etc/condor/config.d=.
   * 00_gwms_general.config
   * 00personal_condor.config  (this is added by Condor if not already installed)
   * 01_gwms_collectors.config
   * 02_gwms_schedds.config
   * 03_gwms_local.config
   * 11_gwms_secondary_collectors.config
   * 90_gwms_dns.config
 
The =00personal_condor.config= may or may not exist if you already have a Condor installed.  This config file should be removed.

<!--
In versions of Condor 7.4.4 and above, this configuration is read automatically.
 if there is also a =/etc/condor/condor_config.local= file from the condor installation, please move it to =/etc/condor/config.d/00_condor_config.local= to make sure that it is read before the frontend configuration.  

If you have a version lower than 7.4.4, the local condor configuration file which is located at =/etc/condor/condor_config.local= must be edited.  Adding the following line to the bottom of =condor_config.local= will pick up the !GlideinWMS condor configuration.
<pre class="file">
LOCAL_CONFIG_DIR = /etc/condor/config.d</pre>
-->

For most installations, the items you need to modify are in =03_gwms_local.config=.  
%TWISTY{%TWISTY_OPTS_OUTPUT% showlink="Show example 03_gwms_local.config."}%<pre class="file">
#
# Reminder: You may want to define these in later files
#

#-- Condor user: enter uid condor in form xxuid.xxgid e.g. 4716.4716
#CONDOR_IDS = 
#--  Contact (via email) when problems occur
#CONDOR_ADMIN = 

############################
# GSI Security config
############################
#-- Grid Certificate directory
GSI_DAEMON_TRUSTED_CA_DIR= /etc/grid-security/certificates

#-- Credentials
GSI_DAEMON_CERT =  /etc/grid-security/hostcert.pem
GSI_DAEMON_KEY  =  /etc/grid-security/hostkey.pem

#-- Condor mapfile
CERTIFICATE_MAPFILE= /etc/condor/certs/condor_mapfile

###################################
# Whitelist of condor daemon DNs
###################################
</pre>
%ENDTWISTY% %BR%

The lines you will have to edit are:
   1. Credentials of the machine.%BR%You can either run using a proxy, or a service certificate.  It is recommended to use a host certificate and specify it's location in the variables =GSI_DAEMON_CERT= and =GSI_DAEMON_KEY=.  The host certificate and key should be owned by =root= and have the correct permissions, 600.%BR%*NOTE* that this configuration is for HTCondor, not for the frontend that requires a proxy as specified in other parts of this document.
   2. Verify the =GSI_DAEMON_TRUSTED_CA_DIR= is correct and that your CRLs are up-to-date.
   3. Verify the =CERTIFICATE_MAPFILE= is correct.
   4. Uncomment and update the =CONDOR_IDS= and =CONDOR_ADMIN= attributes



---+++ Using other Condor RPMs, e.g. UW Madison HTCondor RPM

The above procedure will work if you are using the OSG HTCondor RPMS.
You can verify that you used the OSG HTCondor RPM by using =yum list condor=. The version name should include "osg", e.g. =7.8.6-3.osg.el5=.
%TWISTY{%TWISTY_OPTS_DETAILED% showlink="Click here to show an example" }% <pre class="screen">%UCL_PROMPT% yum list condor
Loaded plugins: kernel-module, priorities
Excluding Packages from SLF 5 base
Finished
Reducing SLF 5 base jdk to included packages only
Finished
Excluding Packages from SLF 5 security updates
Finished
Reducing SLF 5 security updates jdk only to included packages only
Finished
Excluding Packages from SL 5 base
Finished
Reducing SL 5 base jdk to included packages only
Finished
1106 packages excluded due to repository priority protections
Installed Packages
condor.x86_64                                                         7.8.6-3.osg.el5                                                          installed
</pre>
%ENDTWISTY%

If you are using the UW Madison Condor RPMS, be aware of the following changes:
   * This Condor RPM uses a file =/etc/condor/condor_config.local= to add your local machine slot to the user pool.
   * If you want to disable this behavior (recommended), you should blank out that file or comment out the line in =/etc/condor/condor_config= for LOCAL_CONFIG_FILE.  (Make sure that LOCAL_CONFIG_DIR is set to =/etc/condor/config.d=)
   * Note that the variable LOCAL_DIR is set differently in UW Madison and OSG RPMs.  This should not cause any more problems in the glideinwms RPMs, but please take note if you use this variable in your job submissions or other customizations.

In general if you are using a non OSG RPM or if you added custom configuration files for HTCondor please check the order of the configuration files: <pre class="screen">%UCL_PROMPT% condor_config_val -config
Configuration source:
	/etc/condor/condor_config
Local configuration sources:
        /etc/condor/config.d/00_00personal_condor.config
        /etc/condor/config.d/00_gwms_general.config
        /etc/condor/config.d/01_gwms_collectors.config
        /etc/condor/config.d/02_gwms_schedds.config
        /etc/condor/config.d/03_gwms_local.config
        /etc/condor/config.d/11_gwms_secondary_collectors.config
        /etc/condor/config.d/90_gwms_dns.config
	<b><font color="blue">/etc/condor/condor_config.local</font></b>
</pre>
If, like in the example above, the !GlideinWMS configuration files are not the last ones in the list please verify that important configuration options have not been overridden by the other configuration files.

---+++ Verify your Condor configuration
1. The !glideinWMS configuration files in =/etc/condor/config.d= should be the last ones in the list.  If not, please verify that important configuration options have not been overridden by the other configuration files.

2. Verify the alll the expected HTCondor daemons are running: <pre class="screen">
%UCL_PROMPT% condor_config_val -verbose DAEMON_LIST
DAEMON_LIST: MASTER,  COLLECTOR, NEGOTIATOR,  SCHEDD, SHARED_PORT, SCHEDDJOBS2 COLLECTOR0 COLLECTOR1 
COLLECTOR2 COLLECTOR3 COLLECTOR4 COLLECTOR5 COLLECTOR6 COLLECTOR7 COLLECTOR8 COLLECTOR9 
COLLECTOR10 , COLLECTOR11, COLLECTOR12, COLLECTOR13, COLLECTOR14, COLLECTOR15, COLLECTOR16, COLLECTOR17, 
COLLECTOR18, COLLECTOR19, COLLECTOR20, COLLECTOR21, COLLECTOR22, COLLECTOR23, COLLECTOR24, COLLECTOR25, 
COLLECTOR26, COLLECTOR27, COLLECTOR28, COLLECTOR29, COLLECTOR30, COLLECTOR31, COLLECTOR32, COLLECTOR33, 
COLLECTOR34, COLLECTOR35, COLLECTOR36, COLLECTOR37, COLLECTOR38, COLLECTOR39, COLLECTOR40
  Defined in '/etc/condor/config.d/11_gwms_secondary_collectors.config', line 193.
</pre>
If you don't see all the collectors. shared port and the two schedd, then the configuration must be corrected.  There should be  __no__  =startd= daemons listed.


---+++ Create a Condor grid mapfile.

The Condor grid mapfile (=/etc/condor/certs/condor_mapfile=) is used for authentication between the !glideinWMS pilot running on a remote worker node, and the local collector.  Condor uses the mapfile to map certificates to pseudo-users on the local machine.  It is important that you map the DN's of:
   * <font color="red">Each schedd proxy</font>: The =DN= of each schedd that the frontend talks to. Specified in the frontend.xml schedd element =DN= attribute:<pre class="file">
&lt;schedds>
    &lt;schedd DN="/DC=org/DC=doegrids/OU=Services/CN=YOUR_HOST" fullname="YOUR_HOST"/>
    &lt;schedd DN="/DC=org/DC=doegrids/OU=Services/CN=YOUR_HOST" fullname="schedd_jobs2@YOUR_HOST"/>
 &lt;/schedds>
</pre>
   * <font color="green">Frontend proxy</font>: The DN of the proxy that the frontend uses to communicate with the other !glideinWMS services. Specified in the frontend.xml security element =proxy_DN= attribute:<pre class="file">
&lt;security classad_proxy="/tmp/vo_proxy" proxy_DN="DN of vo_proxy" ....
</pre>
   * <font color="blue">Each pilot proxy</font> The DN of __each__ proxy that the frontend forwards to the factory to use with the !glideinWMS pilots.  This allows the !glideinWMs pilot jobs to communicate with the User Collector. Specified in the frontend.xml proxy =absfname= attribute (you need to specify the =DN= of each of those proxies:<pre class="file">
&lt;security ....
   &lt;proxies&gt;
         &lt; proxy absfname="/tmp/vo_proxy" ....
         :
   &lt;/proxies&gt;
</pre>


Below is an example mapfile, by default found in =/etc/condor/certs/condor_mapfile=. In this example there are lines for each of services mentioned above.  <b>Note:</b> The =example_of_format= entry as each DN should use this format for security purposes.
<pre class="file">
GSI "%RED%DN of schedd proxy%ENDCOLOR%" schedd
GSI "%GREEN%DN of frontend proxy%ENDCOLOR%" frontend
GSI "%BLUE%DN of pilot proxy%ENDCOLOR%$" pilot_proxy
GSI "^\/DC\=org\/DC\=doegrids\/OU\=Services\/CN\=personal\-submit\-host2\.mydomain\.edu$" <b>example_of_format</b>
GSI (.*) anonymous
FS (.*) \1 </pre>

---+++ Restart Condor
After configuring condor, be sure to restart condor:
<pre class="rootscreen">
service condor restart</pre>


---++ Proxy Configuration
There are 2 types of (or purposes for)  proxies required for the VO Frontend:
   1 the %GREEN%VO Frontend proxy%ENDCOLOR% (used to authenticate with the other !glideinWMS services)
   1 one or more glideinWMS %BLUE%pilot proxies%ENDCOLOR% (used/delegated to the factory services and submitted on the !glideinWMS pilot jobs)
The %GREEN%VO Frontend proxy%ENDCOLOR% and the %BLUE%pilot proxy%ENDCOLOR% can be the same.
By default, the VO Frontend will run as user =frontend= (UID is machine dependent) so these proxies must be owned by the user =frontend=. 

---+++ Manual proxy renewal
%GREEN%VO Frontend proxy%ENDCOLOR%%BR%
The VO Frontend Proxy is used for communicating with the other !glideinWMS services (Factory, User Collector and Schedd/Submit services).
Create the proxy using the !glidenWMS VO Frontend Host (or Service) cert and change ownership to the frontend user.
   <pre class="rootscreen">
%UCL_PROMPT_ROOT% voms-proxy-init -valid &lt;hours_valid> \
             -cert /etc/grid-security/hostcert.pem \
             -key /etc/grid-security/hostkey.pem 
             -out %GREEN%/tmp/vofe_proxy%ENDCOLOR%
%UCL_PROMPT_ROOT% chown frontend %GREEN%/tmp/vofe_proxy%ENDCOLOR% </pre>

%BLUE%Pilot proxy%ENDCOLOR%%BR%
The pilot proxy is used on the !glideinWMS pilot jobs submitted to the CEs. 
Create the proxy using the %BLUE%pilot certificate%ENDCOLOR% and change ownership to the frontend user.
   <pre class="screen">
%UCL_PROMPT% voms-proxy-init -valid &lt;hours_valid> \
             -voms &lt;vo>
             -cert &lt;pilot_cert> \
             -key &lt;pilot_key>  \
             -out %BLUE%/tmp/pilot_proxy%ENDCOLOR%
%UCL_PROMPT_ROOT% chown frontend %BLUE%/tmp/pilot_proxy%ENDCOLOR% </pre>

%WARNING% *Proxies do expire.* You can extend the validity by using a longer time interval, e.g. =-valid 3000:0=.   This sequence of commands will need to be renewed when the proxy expires or the machine reboots (if /tmp is used only).  

Make sure that this location is specified correctly in the =frontend.xml= described in the [[#Configuring_the_Frontend][Configuring the Frontend]] section.

You may want to automate the procedure above (or part of it) by writing a script and adding it to crontab.

---+++ Example of automatic proxy renewal
This example (user provided) uses the script [[%ATTACHURL%/make-proxy.sh][make-proxy.sh]] attached to this document.
You still need to do some prep-work but this can be done only once a year and the script will warn you with an email.

Preparation for the %GREEN%VO Frontend proxy%ENDCOLOR%. You'll have to redo this each time the Host (or Service) certificate and key are renewed:
   1. Copy the Host (or Service) certificate and key <pre class="rootscreen">
%UCL_PROMPT_ROOT% cp /etc/grid-security/hostcert.pem -key /etc/grid-security/hostkey.pem /var/lib/gwms-frontend/ </pre>
   1. Change ownership and permission of the certificate and key <pre class="rootscreen">
%UCL_PROMPT_ROOT% chown frontend: /var/lib/gwms-frontend/host*.pem
%UCL_PROMPT_ROOT% chmod 0600 /var/lib/gwms-frontend/host*.pem </pre>

Preparation for the %BLUE% pilot proxy.%ENDCOLOR%.  You'll have to redo this for each new or renewed pilot cert.
   1. Create the proxy using the pilot certificate/key (as the user/submitter) <pre class="screen">%UCL_PROMPT% grid-proxy-init -valid 8800:0 -out /tmp/tmp_proxy -old</pre>
   1. Copy the proxy to the correct name and change ownership and permissions (as root)   <pre class="rootscreen">
%UCL_PROMPT_ROOT% cp /tmp/tmp_proxy /var/lib/gwms-frontend/vofe_base_gi_delegated_proxy
%UCL_PROMPT_ROOT% chown frontend: /var/lib/gwms-frontend/vofe_base_gi_delegated_proxy
%UCL_PROMPT_ROOT% chmod 0600 /var/lib/gwms-frontend/vofe_base_gi_delegated_proxy
%UCL_PROMPT_ROOT% rm /tmp/tmp_proxy </pre>

Configure the script for the %GREEN%VO Frontend proxy%ENDCOLOR%:
   1. Download the [[%ATTACHURL%/make-proxy.sh][attached script]] and save it as =/var/lib/gwms-frontend/make-frontend-proxy.sh=, make sure that it is executable.
   1. Edit the VARIABLES section to look something like (replace your email, host name and the paths that are different in your setup - the comments in the script will help): <pre class="file">SETUP_FILE=""
CERT_FILE="/var/lib/gwms-frontend/hostcert.pem"
KEY_FILE="/var/lib/gwms-frontend/hostkey.pem"
IN_NAME="/var/lib/gwms-frontend/frontend_base_proxy"
OUT_NAME="/tmp/vofe_proxy"
OWNER_EMAIL="%RED%your@email_here%ENDCOLOR%"
PROXY_DESCRIPTION="VO Fronted on %RED%hostname%ENDCOLOR%"
VOMS_OPTION=""</pre>

Configure the script for the  %BLUE%pilot proxy%ENDCOLOR%:
   1. Download the [[%ATTACHURL%/make-proxy.sh][attached script]] and save it as =/var/lib/gwms-frontend/make-pilot-proxy.sh=, make sure that it is executable.
   1. Edit the VARIABLES section to look something like  (replace your email, host name and the paths that are different in your setup - the comments in the script will help): <pre class="file">SETUP_FILE=""
CERT_FILE=""
KEY_FILE=""
IN_NAME="/var/lib/gwms-frontend/vofe_base_gi_delegated_proxy"
OUT_NAME="/tmp/vofe_gi_delegated_proxy"
OWNER_EMAIL="%RED%your@email_here%ENDCOLOR%"
PROXY_DESCRIPTION="VO Fronted glidein delegated on %RED%hostname%ENDCOLOR%"
VOMS_OPTION="osg:/osg"</pre>

Before adding the scripts to the crontab I'd recommend to test them manually once to make sure that there are no errors. As user =frontend= run the scripts (you can also use ==sh -x== to debug them): <pre class="screen">
/var/lib/gwms-frontend/make-frontend-proxy.sh  --no-voms-proxy
/var/lib/gwms-frontend/make-pilot-proxy.sh
</pre>

Add the scripts to the crontab of the user =frontend= with =crontab -e=:  <pre class="file">
10 * * * * /var/lib/gwms-frontend/make-frontend-proxy.sh  --no-voms-proxy
10 * * * * /var/lib/gwms-frontend/make-pilot-proxy.sh
</pre>

An additional script like [[%ATTACHURL%/make-proxy-control.sh][make-proxy-control.sh]] can be used for an independent verification of the proxies. If you like, download it, fix the variables and add it to the crontab like the other two.

<!--
Depending on the previous choices it may be used to authenticate with the factory or not. 
If you are using a separate certificate to authenticate with the Factory (Glidein Frontend Condor cert) then create the proxy. This is a simple x509 proxy without VO extensions, so you are not limited in the lifetime and it is recommended to use long lived proxies (170:00 hours will give you a week, 750:00 a month) and to use a cron job if you used a service certificate (doesn't need a password to refresh the proxy).
   1. Create the proxy using the Glidein Frontend Condor cert
   <pre class="rootscreen">
%UCL_PROMPT_ROOT% grid-proxy-init -valid &lt;hours_valid> -cert /etc/grid-security/gwms/vofe-glidein-fe-condor-cert.pem -key /etc/grid-security/gwms/vofe-glidein-fe-condor-key.pem </pre>
   1. Copy the proxy to the correct name
   <pre class="rootscreen">
%UCL_PROMPT_ROOT% cp /tmp/x509up_u`id -u` /tmp/x509up_vofe </pre>
   1. Change ownership of the proxy
   <pre class="rootscreen">
%UCL_PROMPT_ROOT% chown frontend: /tmp/x509up_vofe </pre>
-->

---++ Reconfigure and verify installation
In order to use the frontend, first you must reconfigure it.
Each time you change the configuration you must reconfigure it.

<pre class="rootscreen">
%UCL_PROMPT_ROOT% service gwms-frontend reconfig </pre>

After reconfiguring, you can start the frontend:
<pre class="rootscreen">
%UCL_PROMPT_ROOT% service gwms-frontend start </pre>


---++ Adding Gratia Accounting and a Local Monitoring Page on a Production Server
You must report to Gratia if you are running on OSG more than a few test jobs.

Accounting.ProbeConfigGlideinWMS explains how to instal and configure the HTCondor Gratia probe. If you are on a Campus Grid without x509 certificates pay attention to the [[Accounting/ProbeConfigGlideinWMS#Users_without_Certificates][Users without Certificates part]] in the Unusual Use Cases section.

In gratia you can see your jobs but if you are running only few it may be easier to run have a display with more targeted queries like the [[http://osg-xsede.grid.iu.edu/gratia-summary/][one on OSG-XSEDE]].

Attached to this document you can find the script provided by Main.MatsRynge for the monitoring page:
   * Download the script [[%ATTACHURL%/download-gratia-graphs][download-gratia-graphs]]
   * Create the "data" directory
   * Make it available on your Web Server
   * Configure and run the script
   * Run the script regularly (e.g. via =crontab=) to update the content


---+ Service Activation and Deactivation


The scripts updating your CA and CRLs plus three frontend services need to be running:
   1. %INCLUDE{"InstallCertAuth" section="OSGBriefFetchCrlStart" TOC_SHIFT="+"}%
   1. Condor <pre class="rootscreen">
%UCL_PROMPT_ROOT% service condor start </pre>
   1. Httpd <pre class="rootscreen">
%UCL_PROMPT_ROOT% service httpd start</pre>
   1. VO Frontend <pre class="rootscreen">
%UCL_PROMPT_ROOT% service gwms-frontend start </pre>


To stop the frontend:<pre class="rootscreen">
%UCL_PROMPT_ROOT% service gwms-frontend stop </pre>
And you can stop also the other services if you are not using them independently form the frontend.


---+ Validation of Service Operation
The complete validation of the frontend is the submission of actual jobs.  However, there are a few things that can be checked prior to submitting user jobs to Condor.

   1 Verify all Condor daemons are started.  <pre class="screen"> %UCL_PROMPT% condor_config_val -verbose DAEMON_LIST 
DAEMON_LIST: MASTER,  COLLECTOR, NEGOTIATOR,  SCHEDD, SHARED_PORT, SCHEDDJOBS2 COLLECTOR0 COLLECTOR1 COLLECTOR2 
COLLECTOR3 COLLECTOR4 COLLECTOR5 COLLECTOR6 COLLECTOR7 COLLECTOR8 COLLECTOR9 COLLECTOR10 , COLLECTOR11, 
COLLECTOR12, COLLECTOR13, COLLECTOR14, COLLECTOR15, COLLECTOR16, COLLECTOR17, COLLECTOR18, COLLECTOR19, COLLECTOR20, 
COLLECTOR21, COLLECTOR22, COLLECTOR23, COLLECTOR24, COLLECTOR25, COLLECTOR26, COLLECTOR27, COLLECTOR28, COLLECTOR29, 
COLLECTOR30, COLLECTOR31, COLLECTOR32, COLLECTOR33, COLLECTOR34, COLLECTOR35, COLLECTOR36, COLLECTOR37, COLLECTOR38, 
COLLECTOR39, COLLECTOR40
  Defined in '/etc/condor/config.d/11_gwms_secondary_collectors.config', line 193.
</pre> If you don't see all the collectors and the two schedd, then the configuration must be corrected. There should be  __no__  =startd= daemons listed
   1 Verify all VO Frontend Condor services are communicating.<pre class="screen"> %UCL_PROMPT% condor_config_val -any
MyType               TargetType           Name                          
Scheduler            None                 fermicloud379.fnal.gov        
DaemonMaster         None                 fermicloud379.fnal.gov        
Negotiator           None                 fermicloud379.fnal.gov        
Collector            None                 frontend_service@fermicloud379
Scheduler            None                 schedd_jobs2@fermicloud379.fna</pre>


---++ Glidein WMS Job submission
Condor submit file =glidein-job.sub=. This is a simple job printing the hostname of the host where the job is running:
<pre class="file">
#file glidein-job.sub
universe = vanilla
executable = /bin/hostname
output = glidein/test.out
error = glidein/test.err
requirements = IS_GLIDEIN == True
log = glidein/test.log
ShouldTransferFiles = YES

when_to_transfer_output = ON_EXIT
queue
</pre>

To submit the job: <pre class="screen">
condor_submit glidein-job.sub
</pre>

Then you can control the job like a normal condor job, e.g. 
to check the status of the job use =condor_q=.

---+ Troubleshooting

---++ File Locations

|  *File Description*  |  *File Location*  |
|Configuration file | /etc/gwms-frontend/frontend.xml |
|Logs | /var/log/gwms-frontend/ |
|Startup script | /etc/init.d/gwms-frontend |
|Web Directory | /var/lib/gwms-frontend/web-area |
|Web Base| /var/lib/gwms-frontend/web-base |
|Working Directory | /var/lib/gwms-frontend/vofrontend/ |
|Lock files | /etc/init.d/gwms-frontend/vofrontend/lock/frontend.lock  <br> /etc/init.d/gwms-frontend/vofrontend/group_*/lock/frontend.lock  |
|Status files | /var/lib/gwms-frontend/vofrontend/monitor/group_*/frontend_status.xml |

%NOTE% =/var/lib/gwms-frontend= is also the home directory of the =frontend= user

---++ Frontend failing to start
If the startup script of the frontend is failing, check the log file for errors (probably =/var/log/gwms-frontend/frontend/frontend.%RED%TODAY%ENDCOLOR%.err.log=  and =.debug.log=). 

If you find errors like _"Exception occurred: ... 'ExpatError: no element found: line 1, column 0\n']"_ and _"IOError: [Errno 9] Bad file descriptor"_ you may have  an empty status file (=/var/lib/gwms-frontend/vofrontend/monitor/group_*/frontend_status.xml=) that causes Glidein WMS Frontend not to start. The !glideinFrontend crashes after a XML parsing exception visible in the log file ("Exception occurred: ... 'ExpatError: no element found: line 1, column 0\n']").

Remove the status file.
Then start the frontend. The fronten will be fixed in future versions to handle this automatically.

---++ Certificates not there
The scripts should send an email warning if there are problems and they fail to generate the proxies. Anyway something could go wrong and you want to check manually. If you are using the scripts to generate automatically the proxies but the proxies are not there (in =/tmp= or wherever you expect them):
   * make sure that the scripts are there and configured with the correct values
   * make sure that the scripts are executable 
   * make sure that the scripts are in =frontend='s crontab
   * make sure that the certificates (or master proxy) used to generate the proxies is not expired

---++ Failed authentication
If you get a failed authentication error (e.g. "Failed to talk to factory_pool gfactory-1.t2.ucsd.edu...) then:
   * check that you have the right x509 certificates mentioned in the security section of =/etc/gwms-frontend/frontend.xml=
      * the owner must be =frontend= (user running the frontend)
      * the permission must be 600
      * they must be valid for more than one hour (2/300 hours), at least the non VO part
   * check that the clock is synchronized (see HostTimeSetup)

---++ Frontend doesn't trust factory
If your frontend complains in the debug log:
<pre class="file">
code 256:['Error: communication error\n', 'AUTHENTICATE:1003:Failed to authenticate with any method\n', 'AUTHENTICATE:1004:Failed to authenticate using GSI\n', "GSI:5006:Failed to authenticate because the subject '/DC=org/DC=doegrids/OU=Services/CN=devg-3.t2.ucsd.edu' is not currently trusted by you.  If it should be, add it to GSI_DAEMON_NAME in the condor_config, or use the environment variable override (check the manual).\n", 'GSI:5004:Failed to gss_assist_gridmap /DC=org/DC=doegrids/OU=Services/CN=devg-3.t2.ucsd.edu to a local user.
</pre>

A possible solution is to comment/remove the LOCAL_CONFIG_DIR in the file =/usr/share/gwms-frontend/frontend.condor_config=.


---++ Jobs not running
If your jobs remain Idle
   * Check the frontend log files (see above)
   * Check the condor log files (=condor_config_val LOG= will give you the correct log directory):
      * Specifically look the CollectorXXXLog files

Common causes of problems could be:
   * x509 certificates
      * missing or expired or too short-lived proxy 
      * incorrect ownership or permission on the certificate/proxy file
      * missing certificates


<!--
---++!! &lt;How can I resolve this Problem?&gt;
%GRAY%
Use sub-sections for each problem you want to address in particular. Link to HelpProcedure at the end if the problem could not be resolved.
%ENDCOLOR%
-->

<!-- ---++!! Known problem

---+++!! Frontend failing to start
An empty status file (=/var/lib/gwms-frontend/vofrontend/monitor/group_main/frontend_status.xml=) causes Glidein WMS Frontend not to start.
It crashes after a XML parsing exception visible in the log file ("Exception occurred: ... 'ExpatError: no element found: line 1, column 0\n']").
Remove the file.
-->


---+ Advanced Configurations

   * [[GlideinWMSCampusGrid][GlideinWMS Frontend on a Campus Grid]]


---+ References
Definitions:
   * What is a [[http://www.opensciencegrid.org/About/Learn_About_Us/OSG_Organization/VOs][Virtual Organisation]]
   * [[http://twiki.grid.iu.edu/bin/view/Documentation/UsingTheGrid][Introduction to the Grid for users/scientists]]
   * [[http://twiki.grid.iu.edu/bin/view/Documentation/CondorGToGlidein][How to switch to Glideins if you are using already Condor-G]]
   * You can [[http://twiki.grid.iu.edu/bin/view/Engagement/EngageNewUserGuide][get started with the support of the Engage VO]]

Documents about the Glidein-WMS system and the VO frontend:
   * http://www.uscms.org/SoftwareComputing/Grid/WMS/glideinWMS/
   * http://www.uscms.org/SoftwareComputing/Grid/WMS/glideinWMS/doc.prd/manual/
   * [[GlideinWMSCampusGrid][How to setup a Submit host flocking to the VO Frontend]]
   * [[CampusGrids.InstallCondorFlockSubmit][Install a Submit host flocking to OSG run frontends]]

<!--
Other examples:
   * http://home.fnal.gov/~weigand/weigand/www/glideinWMS_rpm/index.shtml

!M2Crypto:
   * http://www.heikkitoivonen.net/blog/2008/10/14/ssl-in-python-26/
   * http://chandlerproject.org/bin/view/Projects/MeTooCrypto
   * http://freshmeat.net/projects/m2crypto
RRDTools:
   * http://packages.sw.be/rrdtool/
javascriptRRD:
   * http://sourceforge.net/projects/javascriptrrd/

Other documents
   * RRD tools: http://segfault.in/2010/03/python-rrdtool-tutorial/
   * RRD tools: http://sourceforge.net/projects/py-rrdtool/
   * http://oss.oetiker.ch/rrdtool/download.en.html
   * http://www.express.org/~wrl/rrdtool/
   * Downloads from Nebraska: http://t2.unl.edu/store/repos/nebraska/5/nebraska/x86_64/
-->

---+ Comments
| In the &#34;Advanced: Multi-node Installation&#34; section it says to install the following packages:&#60;br /&#62;&#60;br /&#62;glideinwms-vofrontend-standalone &#60;br /&#62;glideinwms-usercollector &#60;br /&#62;glideinwms-userschedd&#60;br /&#62;&#60;br /&#62;But they don&#39;t appear to exist. This is on CentOS 6.3 with the osg-release-3.0-22.osg.el6.noarch installed.&#60;br /&#62;&#60;br /&#62;&#34;yum search all glideinwms&#34; shows the following packages are available:&#60;br /&#62;&#60;br /&#62;glideinwms-factory.noarch : The Factory for glideinWMS&#60;br /&#62;glideinwms-vofrontend.noarch : The VOFrontend for glideinWMS submission host&#60;br /&#62;glideinwms-factory-condor.noarch : The VOFrontend condor config&#60;br /&#62;glideinwms-minimal-condor.noarch : The VOFrontend minimal condor config&#60;br /&#62;glideinwms-vofrontend-condor.noarch : The VOFrontend condor config&#60;br /&#62;gratia-probe-glideinwms.noarch : Configuration for Gratia GlideinWMS integration. | Main.MickTimony | 09 Apr 2013 - 18:54 |
| Document got ahead of the release. Standalone package is available from glideinwms v2.7 onwards.  | Main.ParagMhashilkar | 11 Apr 2013 - 20:20 |
%COMMENT{type="tableappend"}%

<!-- CONTENT MANAGEMENT PROJECT
############################################################################################################
 DEAR DOCUMENT OWNER
 ===================

 Thank you for claiming ownership for this document! Please fill in your FirstLast name here:
   * Local OWNER = MarcoMambelli

 Please define the document area, choose one of the defined areas from the next line
 DOC_AREA = (ComputeElement|General|Integration|Monitoring|Operations|Security|Storage|Tier3|User|VO)
   * Local DOC_AREA       = General

 define the primary role the document serves, choose one of the defined roles from the next line
 DOC_ROLE = (Developer|Documenter|Scientist|Student|SysAdmin|VOManager)
   * Local DOC_ROLE       = SysAdmin

 Please define the document type, choose one of the defined types from the next line
 DOC_TYPE = (HowTo|Installation|Knowledge|Navigation|Planning|Training|Troubleshooting)
   * Local DOC_TYPE       = Installation
  Please define if this document in general needs to be reviewed before release ( %YES% | %NO% )
   * Local INCLUDE_REVIEW = %YES%

 Please define if this document in general needs to be tested before release ( %YES% | %NO% )
   * Local INCLUDE_TEST   = %YES%

 change to %YES% once the document is ready to be reviewed and back to %NO% if that is not the case
   * Local REVIEW_READY   = %YES%

 change to %YES% once the document is ready to be tested and back to %NO% if that is not the case
   * Local TEST_READY     = %YES%

 change to %YES% only if the document has passed the review and the test (if applicable) and is ready for release
   * Local RELEASE_READY  = %YES%


 DEAR DOCUMENT REVIEWER
 ======================

 Thank for reviewing this document! Please fill in your FirstLast name here:
   * Local REVIEWER       = ParagMhashilkar
 Please define the review status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local REVIEW_PASSED  = %YES%


 DEAR DOCUMENT TESTER
 ====================

 Thank for testing this document! Please fill in your FirstLast name here:
   * Local TESTER         = ParagMhashilkar
 Please define the test status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local TEST_PASSED    = %YES%
############################################################################################################
-->


%META:FILEATTACHMENT{name="simple_diagram.png" attachment="simple_diagram.png" attr="" comment="" date="1319061747" path="simple_diagram.png" size="36007" stream="simple_diagram.png" tmpFilename="/usr/tmp/CGItemp20094" user="MarcoMambelli" version="1"}%
%META:FILEATTACHMENT{name="make-proxy.sh" attachment="make-proxy.sh" attr="" comment="Example of make-proxy script" date="1369768195" path="make-proxy.sh" size="5110" stream="make-proxy.sh" tmpFilename="/usr/tmp/CGItemp39278" user="MarcoMambelli" version="3"}%
%META:FILEATTACHMENT{name="make-proxy-control.sh" attachment="make-proxy-control.sh" attr="" comment="Controls voms proxies" date="1369768173" path="make-proxy-control.sh" size="1427" stream="make-proxy-control.sh" tmpFilename="/usr/tmp/CGItemp40260" user="MarcoMambelli" version="1"}%
%META:FILEATTACHMENT{name="download-gratia-graphs" attachment="download-gratia-graphs" attr="" comment="Gratia download script" date="1372451902" path="download-gratia-graphs" size="5315" stream="download-gratia-graphs" tmpFilename="/usr/tmp/CGItemp34766" user="MarcoMambelli" version="1"}%
