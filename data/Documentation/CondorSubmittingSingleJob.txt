%META:TOPICINFO{author="BrianBockelman" date="1266460733" format="1.1" reprev="1.10" version="1.10"}%
%META:TOPICPARENT{name="GridUsersGuide"}%
%LINKCSS%
---+ Submitting a Single Job Using Condor-G

%STARTINCLUDE%
%EDITTHIS%

<ol>
  <li>Write a simple script to execute!  We provide one below that will print out a few environment variables, setup the worker node client, and sleep for a bit:
<br/>
%TWISTY{
mode="div"
showlink="Show..."
hidelink="Hide"
showimgleft="%ICONURLPATH{toggleopen-small}%"
hideimgleft="%ICONURLPATH{toggleclose-small}%"
}%
<pre class="programlisting">
#!/bin/sh
echo "Hello from `hostname`"
echo "Going to source the file $OSG_GRID/setup.sh"
source $OSG_GRID/setup.sh
echo "Resulting environment:"
printenv
echo "Output of lcg-cp --help (lcg-cp is a commonly used SRM client):"
lcg-cp --help
echo 'Directories in \$OSG_APP'
ls $OSG_APP
date
sleep 120
date
</pre>
%ENDTWISTY%
<br/>
Name this script "mytest.sh" and set it executable with =chmod +x mytest.sh=.
  </li>
  <li>Create a file named =condorg_test.submit= that contains the following (we will cover this line-by-line below):
<br/>
%TWISTY{
mode="div"
showlink="Show condor submit file..."
hidelink="Hide condor submit file"
showimgleft="%ICONURLPATH{toggleopen-small}%"
hideimgleft="%ICONURLPATH{toggleclose-small}%"
}%
<pre class="programlisting">
Universe        = grid
grid_resource = gt2 red.unl.edu:/jobmanager-condor
Executable      = myhostname
Output          = job_test.output
Error           = job_test.error
Log             = job_test.log
</pre>
%ENDTWISTY%
Replace the endpoint =red.unl.edu:/jobmanager-condor= with the endpoint you selected from the [[FindAvailableResource][finding available resources guide]].
<!--
<pre class="programlisting">
universe=globus

# You will probably want to change the following line to point to
# some remote site that supports your VO
GlobusScheduler=osg-gw-2.t2.ucsd.edu:/jobmanager-condor

# You will certainly want to change the following line to point
# to the executable you want to run on the OSG.  /usr/bin/env is useful for
# testing the submission process, but that's about it.
executable=/usr/bin/env
# If your executable originates from your submission machine rather than
# being guaranteed to be available on the destination, you need to uncomment:
# transfer_input_files = True

# These attributes should be False in general for GRID operations
stream_output = False
stream_error  = False

# This makes the standard output of your program end up in the local file
# named test1.out.  Any additional output files your job creates will be detected
# and returned to the submitting directory.

# Standard output from your job.
output = test1.out

# Standard error from your job
error  = test1.err

# Condor messages related to the scheduling and execution of your job.
log    = test1.log

# Generic directives
#
# maxWallTime in minutes is advisable because some sites have short default times
# if this is not specified.
# 
# JobType is advisable because on many sites where the underlying batch manager is
# of the PBS flavor default to the "multiple" type. Note the escaping of the
# quotes on the string value for the quantity. For a full description of RSL, see
# http://www.globus.org/toolkit/docs/2.4/gram/rsl_spec1.html
globusrsl = (maxWallTime=14400)(JobType=\"single\")

# The following line must be last in the file.  The order of the other
# lines does not matter.
queue
</pre>
-->
   </li>
   <li>Source the environment for the OSG client.
<pre class="screen">
<userinput>source $VDT_LOCATION/setup.sh</userinput>
</pre>
   </li>
   <li>Obtain a proxy from your VOMS:
 <pre class="screen">
<userinput>voms-proxy-init --voms cms:/cms</userinput>
</pre>
Replace =cms:/cms= as appropriate for your VO.
   </li>
   <li>Submit the =condorg_test.submit= job:
<pre class="screen">
$ <userinput>condor_submit condorg_test.submit</userinput>
</pre>
   </li>
   <li>Give yourself some time. Grid middleware can add a latency of about a minute on top of the amount of time your job spends in the batch system queue (if any time).
   </li>
   <li>Use =condor_q= to display information about your jobs:
<pre class="screen">
$ <userinput>condor_q -globus</userinput>
</pre>
You should expect to see the jobs idle for a minute or two, go into the running state for a minute or two, and then end.  You can also follow along in the log file job_test.log which Condor should create in your working directory.

Here is sample output from =condor_q -globus=:
<br/>
%TWISTY{
mode="div"
showlink="Show condor output..."
hidelink="Hide condor output"
showimgleft="%ICONURLPATH{toggleopen-small}%"
hideimgleft="%ICONURLPATH{toggleclose-small}%"
}%
<pre>
-bash-3.2$ condor_q -globus


-- Submitter: hcc-grid.unl.edu : <129.93.229.131:50400> : hcc-grid.unl.edu
 ID      OWNER          STATUS  MANAGER  HOST                EXECUTABLE        
7709.62  dweitzel      ACTIVE fork     condor.crc.nd.edu  /opt/osg/osg-120/o
7709.802 dweitzel      ACTIVE fork     condor.crc.nd.edu  /opt/osg/osg-120/o
7709.816 dweitzel      ACTIVE fork     tuscany.med.harvar  /opt/osg/osg-120/o
7990.0   dweitzel         PENDING condor   condor.crc.nd.edu   /opt/osg/osg-120/o
8078.0   dweitzel         PENDING condor   gridgk02.racf.bnl.  /opt/osg/osg-120/o
8079.0   dweitzel         PENDING pbs      condor.crc.nd.edu  /opt/osg/osg-120/o
8064.0   dweitzel         PENDING condor   condor.oscer.ou.ed  /opt/osg/osg-120/o
8073.0   osgmm         PENDING sge      antaeus.hpcc.ttu.e  /opt/osg/osg-120/o
</pre>
%ENDTWISTY%
    </li>
</ol>

 
%NOTE% In most cases, a basic grid proxy certificate generated by =<span class="command">grid-proxy-init</span>= should be sufficient. =<span class="command">voms-proxy-init</span>= is only necessary if your VO supports user roles and if the site you submit to can map your jobs to different local accounts depending on these roles. 

%STOPINCLUDE%

For more information, see the [[http://www.cs.wisc.edu/condor/condorg/][Condor-G documentation]].

%BOTTOMMATTER%
-- Main.ForrestChristian - edited from GridUsersGuide %BR%
-- Main.ForrestChristian - 03 April 2007
