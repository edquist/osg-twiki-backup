%META:TOPICINFO{author="RuthPordes" date="1266432390" format="1.1" reprev="1.5" version="1.5"}%
%META:TOPICPARENT{name="NEESFileTransfer"}%
--- Documents for sharing among the team

<verbatim>

Franks comments on NEES requirements:

Dear Ruth,

here are my comments.

Let me start with introducing myself.
I'm a physicist who was co-lead of the CDF offline & computing organization
a few years ago. During this time, I gained some familiarity with processes, policies,
and technologies involved in archival storage for CDF at FNAL.
It is my recollections from that time that Ruth asked me to write down to give you an impression of how relationships are configured between a large customer of archival storage at FNAL and the technical teams there. To be very clear, the CDF customer and the FNAL Computing Division as service provider are very much separate sociological entities. Relationships
are quite formal, especially in the area of archival storage.

Reading your document I have two comments.

Comment 1) Data archiving and long term space maintenance
------------------
Your write up says:
"The ability to incrementally add to an archive and selectively retrieve files would also be useful."
"The need for multiple copies of data on tape is driven by the potential silent corruption of file data that could unintentially propagate to tape archive, ..."
"Long term space maintenance ..."

I think there may be a misconception of how the tape archives work.
The tape infrastructure as I know it at FNAL is arranged around the premise of guaranteeing
- minimal file losses or corruption. I encourage you to get historic data on this from FNAL.
   It is impressive!
- sufficient read/write access speed that far exceed your needs in NEES.

Deletions are not done as a regular procedure. And updates of files are not done either.
Meaning, the HEP user communities are sufficiently paranoid about unintentional data loss
or data corruption that deletions are done only as a deliberate procedure requiring 
something akin to operator involvement. Overwriting never happens.

So if you change one byte in a file, and then want to archive the change then you need to write the entire file as a second version to archive. From the archive's perspective, this second version is just another file with no linkage to the previous version.

The only deletion procedures I know of are essentially semi-manual in that you dump the tape to disk, delete the files you no longer want, and write a new tape. The old tape can then be
recycled as needed or desired. Generally, this was rarely done in CDF. 

Deletions are done primarily in the spirit of what you write about "long term space management". I.e. whole tapes are "recycled". This has been done to the tune of 100's of TB
in CMS.

When you estimate your total volume you need for archive you may want to make this estimate
assuming that deletions happen maybe once a year or less, and are then done preferably
in form of deleting all tapes with content older than some date. Tapes are relatively cheap.
There's not much of an economic incentive to do deletions often.

Comment 2):
------------------
Regarding "verification of all data stored".
The operating procedures of the archive at fnal as I remember them included a routine
and regular validation of all tapes. This means that the tape is read to disk, all files are
individually checksummed (adler32, as I recall), the chksum is compared with its nominal
value, and any and all errors lead to human interaction.

If a tape can not be read then this triggers a recovery procedure that involves vendors.
As manager of the computing organization of one of fnal's large customers, I would get
routine reports on the results of this validation.

I think you should consider leaving validation to the archive itself. I.e. negotiate an 
agreement that spells out clearly the expectations in this regard and then not worry about it yourself.

Sincerely, Frank

Frank Wuerthwein
Professor of Physics
UCSD


Requirements for Data Movement and Archiving from a user perspective
Thomas Hacker and Rudi Eigenmann, Purdue University, January 2010
This document describes a minimal set of requirements involving data for the NEES project from a user’s, rather than a strictly technical, perspective.  There are two major areas of work in regards to data: data archiving, and data upload.  The first area, data archiving, is the need to provide a backup and recovery capability (on stable media such as tape) that can be used for disaster recover in the event of a incident that wipes out critical NEES data.  The second area is focused on the problem of providing a easy-to-use, reliable, and fast (from a usability perspective) set of functionalities to allow users at NEES sites to easily upload a large number of small files or large individual files to a central NEES data repository.   Our approach will first focus on developing a proof-of-concept to move data from Purdue to Fermi and Wisconsin, with the goal of developing the software and procedures for data archiving and file upload to meet the needs of the NEES sites. 
1)	Data Archiving
NEES currently maintains approximately 6TB of files, mostly consisting of small files in various formats such as PDF, Word, and Excel.  A smaller set of files (in number) represent recorded videos, usually stored in MPEG format.  We expect that the total amount of storage used for these files will grow to approximately 30 TB in a couple of years.   We don’t have information on the percentage of files that change every month, but with improved data upload and the growing use of high definition videos at the NEES sites, we expect significant growth in the number and size of files over the next few years.  The ability to incrementally add to an archive and selectively retrieve files would be also be useful.

For long term data archiving and integrity of stored data, it would be desirable to host several copies of the data on tape media.  The need for multiple copies of data on tape is driven by the potential silent corruption of file data that could unintentionally propagated to the tape archive, thus wiping out the original uncorrupted file data.   A mechanism to detect and react to silent data corruption to prevent this problem is desirable.  

The need in this area is to have an offsite location (Fermi, for example) to which NEES can periodically dump a set of files (full dumps and incrementals) for disaster recovery.

The first implementation approach we are pursuing is focused to provide data archiving involves the use of a GridFTP interface to Fermi, in which NEES will create aggregate collections of smaller files into a larger collective (such as a tar file) and utilize a GridFTP interface to directly transfer these files to tape at Fermi.
  
High Level Design and Functionality

Our initial thoughts on how to implement this is based on the following components:

1)	cron script running on the data source side to gather all files that need to be backed up into a tar/zip file (perhaps using rsync).  The files must be put into blocks of X gigabytes in size, and a record of which files are present in a specific block must be maintained.  Result: this-file.   The list of files to be archived would consist of new files and files that have changed since the last backup.    
2)	Create a checksum of the individual files and the tar file that will be uploaded
a.	create-checksum(thisfile,checksum1)  // a local function; checksum1 is result
3)	Perform the backup operation to remote data storage
a.	call create-backup(this-file,checksum2,reply) 
    // a backup interface function, checkksum2 and reply are results

4)	Assess the results of the backup operation, and check that the resulting backed-up file has not been corrupted.
a.	Alert SysAdmin if checksum1 <> checksum2 or if reply indicates problem
5)	Log the backup attempt
a.	Enter in log file: backup was attempted, the reply, the checksum, current time
6)	An optional component is to verify all of the data stored on the backup system to ensure that it has not been corrupted on a periodic basis.
a.	If lastVerifyTime + verifyInterval < NOW then // NOW is current time
   // every verifyInterval, check that the backup is still valid
   call verify(reply)  // an backup interface function
   Alert SysAdmin if reply indicates problem
   Enter in log: Verify was performed, the reply, NOW
7)	Provide the capability to retrieve a file from backup
a.	Upon a fatal failure, the backup would be invoked via
retrieve-from-backup(NOW,file,foundtime,reply) 
8)	Long term space maintenance – old outdated versions of the backup data should be removed to save space
a.	House keeping: space for old backups will be freed up (e.g., older than 3 years)
purge-backup-files(NOW minus 3 years)

This functionality would require the following backup interface functions: 
(the syntax is unimportant)

create-backup(filename,checksum,reply)
  // transfers the file <filename> into remote backup storage; creates a
  // checksum; stores the checksum and NOW together with the file;
  // reply indicates success or possible error conditions
 // It would be good to get additional metadata on: the timestamp of the start of the transfer; the 
// timestamp of when the upload completed; the checksum; the size of the file; the location of the file; 
// the owner of the file and permission bits – something like a “data receipt” that indicates successful 
// storage.

verify(reply)
  // re-checks the checksum of all stored backups;
  // reply indicates possible errors found or error conditions during verify
  // operation.

retrieve-from-backup(time, file, foundtime, reply)
  // retrieves the most recent backup file stored before <time>
  // foundtime is the time stamp stored with the backup file
  // reply indicates possible error conditions

purge-backup-files(time)
  // deletes backup files that are older than <time>	
2)	File Upload

NEES sites utilize network links from their experimental facilities to upload experimental data and large encoded video files.  The current approach develop by NEESit for this functionality involved the use of a web based application, which required the user to fill out a web form describing file metadata, then use pop-up web upload tool to push files to the central server through HTTP.  While this approach was tolerable for a small number of small sized files, it failed to scale for a large number of files and for large file sizes.  The scaling failure was due to two causes: a cumbersome web interface provided to the users for providing file metadata; and poor end-to-end network performance and connection reliability conspiring with fault intolerant upload tools.  As a result of this scaling problem, many users and site managers simply gave up trying to upload data, and resorted to storing files on hard drives and shipping them to SDSC.    One approached developed by the community, SingleShot, is promising, but users were required to fill out a XML document describing that data that would be provided as input to SingleShot for file upload, which put a large burden on the user community.

To ease the process of file upload for the user community, there is a critical need for a “click and forget” data upload tool that take a specification of the files to uploaded with minimal metadata, perform “offline” uploading of the files, and to send a response to the user assuring them of the successful completion of the transfer.   Moreover, there is a need for the data upload system to check the integrity of the file once transfer is completed (e.g. through the use of a checksum) to ensure that the file data has not become corrupted. 

Our initial thoughts on how this might be accomplished is to create a “data order” that provides file metadata as well as user contact information (e.g. email address) that the data uploader can use to send a notification back the user that the bulk file transfer has successful completed.  

The key guiding principals for this system should be:

•	Transfer speed is important (e.g. it would be not good to take too long to satisfy a user transfer request), but basic usability and user experience should not be significantly compromised for speed.
•	Keep it simple
•	Provide some indication back to the user that the bulk file upload completed successfully
•	Upload and store a large file or a large number of files without requiring the user to sit and wait for the completion.  High definition video files are one known source of large files. 
Implementation Strategy
	In our initial discussions, we decided that our approach to implementing this would focus first on the transfer of a single file from Purdue to Wisconsin.   Once we have this working, we will focus on the transfer of a number of files.
High Level Design
	The interfaces that would be needed for this functionality are in the areas of the user interface, and administrator interface.  The user interface would include: a file format to specify the metadata regarding the file to be uploaded and the user contact information (the “data order”), a command to submit a data upload request, a command to request the status of a file upload that has been submitted, and a command to cancel a pending upload.  The administrator interface should include: a command to check the status of the data transfer service (up/down/debug), a command to list the status of the file upload requests (pending/in progress) , a command to retrieve a list of files that have been successfully uploaded with the final status of the upload (including checksum verification), a command to cancel a pending file upload, and a command to list the contents of the remote file upload area  (like a remote ‘ls’ command).


</verbatim>
---+++ Topic access settings

    * Set ALLOWTOPICVIEW = Main.AlainRoy, Main.RuthPordes, Main.TanyaLevshina


-- Main.RuthPordes - 17 Feb 2010

%META:PREFERENCE{name="ALLOWTOPICVIEW" title="ALLOWTOPICVIEW" type="Set" value="AlainRoy, RuthPordes, TanyaLevshina"}%
