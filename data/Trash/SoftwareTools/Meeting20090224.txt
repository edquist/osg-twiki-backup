%META:TOPICINFO{author="KyleGross" date="1476285789" format="1.1" version="1.4"}%
%META:TOPICPARENT{name="Trash/SoftwareToolsMeetings"}%
---+ OSG Software Tools Group Meeting

---+++ Meeting Coordinates

| <b>Date</b> | Tuesday, February 24, 2009 |
| <b>Time</b> | 9:00am Central |
| <b>Telephone Number</b> | 510-665-5437 |
| <b>Teleconference ID<b> | 4321 |

---++ Agenda
   * Review action items
   * Discuss Suchandra's VTB/ITB testing project (30 minutes)
   * Discuss WLCG Installed Capacity (30 minutes)

---++ Attendees

   * Bockelman, Brian
   * Levshina, Tanya
   * Quick, Rob
   * Roy, Alain
   * Thapa, Suchandra

---++ Apologies

   * Altunay, Mine (On the road)

---++ Review of action items
At the [[Meeting20090203][last meeting]] we had the following action items:

| *Person* | *State* | *Action* | *Comments* |
| Brian | Done | Answer question: What numbers go to management vs. VOs? | |
| Brian | Done | Answer question: Do funding agencies want to know resources used?  | |
| Brian | Done | Answer question: Can we have separate data paths? One set of data (from OIM) to funding agency vs. another (sites/GIP) going to VOs. | |
| Brian | Done | Answer question: Can we take data from the OSG BDII? | |
| Rob | Done | Talk to James Casey about how we can deliver the data to WLCG. | | 

---++ Suchandra's software development: ITB automated testing framework

[[%ATTACHURL%/2009-2-17.ValidationToolsSTG.pdf][Presentation]]

The purpose of his development is for automated ITB testing. The goal is to assist a VO in testing. The basic idea is that a VO would install some software that would let them easily test a set of sites with a variety of probes that reflect common tasks done by the VO. Then the results would be reported to a central collector run at the University of Chicago. For a picture of the architecture, [[%ATTACHURL%/2009-2-17.ValidationToolsSTG.pdf][see Suchandra's  presentation]]

Three people are working on it:

Suchandra: 20%<br>
Robert Veitch: 20%<br>
Rob Gardner: Not much time.<br>

Work so far: basic scripts and server stuff.  Not much time invested yet, maybe 3 FTE weeks? 

Everyone on the call recommended to Suchandra that this new framework not be developed. The architecture diagram looks identical to the RSV architecture, including the Gratia reporting to a central collector. If RSV doesn't meet the ITB automated testing needs, then we should put our time towards improving RSV. We strongly suspect that not much would need to be done to improve RSV/Gratia. Suchandra had a couple of missing features, but upon analysis, we believe those features are not missing, though perhaps they are not obvious or well-documented. 

Suchandra agreed to talk to Robert and Rob about our suggestion and move forward with RSV.

---++ WLCG Installed Capacities.
Brian answered questions for us:

   1. What numbers go to management vs. VOs? Management: static, VOs: dynamic.
   1. Do funding agencies want to know resources used (dynamic information)? No.
   1. Can we have separate data paths? One set of data (from OIM) to funding agency vs. another (sites/GIP) going to VOs. Yes
   1. Answer question: Can we take data from the OSG BDII? Yes.

Rob did talk to James Casey and Ruth on Monday. Came to agreement... Does it have to be top-level BDII and nothing else? James Casey will talk to Flavia and others. Discussion is ongoing. RSV could be alternate mechanism. Or maybe just text file with management type information. 

Brian looked at dividing things into static and dynamic information, and having separate data paths. This allows us to publish correct numbers even when sites report wrong numbers. One idea is to put it into OIM. Brian is getting good idea of what data should be static or dynamic. Dynamic data is still expected to go through BDII.  May be filtered based on static data on the way to the interop BDII.

How do we archive dynamic data? Trying to delay on this until we have a better idea of the whole picture--how much data is needed, how much Gratia development might be needed, etc. Therefore no estimate of full impact yet on Gratia. Imagine queried rate (back of the napkin): moderate input rate, small data rate. (Brian had rough numbers, I didn't write them down, sorry.)

What numbers do VOs want? ATLAS does want dynamic data. CMS had a fuzzy message. Unclear

How to aggregate daily samples? Miron had commented that one per day was insufficient. Brian proposes we record one value per day which is average of samples across day. Brian thinks that one sample an hour is sufficient. 

Do funding agencies want to know resources used? Answer no: just static numbers. 

Big things: will try to split up dynamic and static information. Static is important for funding information, dynamic is interesting but lower need for high quality. 

Static information will be input by Tier-2 coordinators to OIM. Tier 1s will be handled manually. 

Where do we go from here? 

*Critical path*

   1. GIP Deployment. Code complete, on its way. 
   1. OIM information. Rob thinks it's easy as long as it is well-defined. Needs clear request. 
   1. Filtering of dynamic data in the BDII. Need decision on where that comes from. Effort from Karthik? Elsewhere? Brian doesn't have time, but can help coordinate, and describe problem and make sure implementation is correct.

*Not critical path*

   1. Gratia graph changes. 

%META:FILEATTACHMENT{name="2009-2-17.ValidationToolsSTG.pdf" attachment="2009-2-17.ValidationToolsSTG.pdf" attr="" comment="" date="1235487886" path="2009-2-17.ValidationToolsSTG.pdf" size="504755" stream="2009-2-17.ValidationToolsSTG.pdf" tmpFilename="/usr/tmp/CGItemp11506" user="AlainRoy" version="2"}%
