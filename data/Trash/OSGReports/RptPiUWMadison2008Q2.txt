%META:TOPICINFO{author="KyleGross" date="1225985954" format="1.1" version="1.4"}%
%META:TOPICPARENT{name="CreateNewReport"}%
<!-- Complete the template. You can either use TWiki style, copy in plain text, or put in HTML. --> <!-- IF COPYING IN HTML: Please only include the sections between your BODY tags. -->

---+!! 2008Q2 PI Quarterly Report

%STARTINCLUDE%

---++ University of Wisconsin - Madison
%EDITTHIS% <!-- EDIT BELOW THIS LINE ONLY! -->

---+++ Management Activities

Participation in OSG related presentations, workshops, steering meetings, incl:
   1 SBGrid workshop in Boston in May. 
   1 Meeting with WLCG and EGEE in Madison in May. 
   1 OSG Users meeting in BNL. 
   1 HPDC VirtualOrganizations/VOInfo workshop in Boston in June. 
   1 HPC workshop in Italy in late June and visit DOE and NSF offices in late June. Still looking to hire another VDT developer and a Deputy Facility Coordinator. 

---+++ Software Activities

---++++ VDT

VDT Releases since April 1:
   * VDT 1.9.1: For VTB testing 
   * VDT 1.10.0: For ITB testing before OSG 1.0 
   * VDT 1.10.1: Basis for OSG 1.0 
   * OSG 1.0: Major release. Done on June 13, 2008 

The OSG software stack has greatly improved the quality of information available to users and management in three ways. First, in OSG 0.8 we introduced Resource and Service Validation software, which allows sites to test various aspects of their functionality and know where problems are. The quality of this testing was improved in OSG 1.0, and the results are shared with the WLCG&rsquo;s GridView for reporting site availability. Second, we have updated the Gratia accounting software, which reports on the usage of sites (both jobs and storage). This information is used both within OSG and to report to WLCG, and new versions of Gratia have significantly improved the quality of the accounting information. Third, the Generic Information Provider was significantly improved in OSG 1.0, and provides real-time information about sites to enable decisions about where jobs might be run, both by the OSG Resource Selection Service and the WLCG Workload Management System. <br /> <br />The OSG Software stack has improved supports for WLCG users by providing new needed software. This includes data access tools on compute nodes (such as lcg-utils , which was added in OSG 1.0 and improved versions of SRM client tools), and improved versions of dCache for storage management. <br /> <br />Staffing: AT UW-Madison, have 3 out of 4 people. Hiring has been slow, still working on it. <br /> <br />The OSG software has two major ongoing initiatives. First, we are improving the support for WLCG client data management software, which is considered critical for WLCG users. We are also considering revising the mechanism by which we package software, to allow us to more easily distribute and update software to our users.
---++++ Middleware Contributions for OSG

Work this quarter on the condor_procd daemon for use in pilot job accounting and auditing has continued, with most of the effort toward fixing bugs found in the version currently available in the VDT. In addition, Igor Sfiligoi (FNAL), Greg Quinn (UW), Greg Thain (UW), and Chris Green (FNAL) prepared a paper regarding this work, which will be presented at IEEE Grid 2008 this Fall.

Upon discovery that WS GRAM 4.0 can't handle many job removal requests at the same time, we added a throttle in Condor-G to avoid flooding the server with job removal requests.

We started work on supporting GRAM 4.2 in Condor. I found a couple bugs in the beta GRAM code, which we reported back to the Globus Project.

Fixed NorduGrid support in Condor-G to handle newer NorduGrid servers and avoid crashing on unexpected replies from servers. 

---+++ Troubleshooting Activities

Steve Timm reported many failed jobs with pre-WS GRAM and Condor-G. Most of the failures were traced to a bad firewall configuration. Some failures remained. We built a gahp for Condor-G with extra debugging to pinpoint the source of the faiures. <br /> <br />BNL had problems with Condor-G and pre-WS GRAM. Their setup resulted in the gridmanager frequently contacting the wrong jobmanager and reacting badly when the jobmanager said "I don't have that job." We fixed Condor to handle this case gracefully.

Some CERN collaborators reported problems with Condor-G submitting to NorduGrid. I tracked the problem down to the NorduGrid server ignoring some connections when too many simultaneous connections are made. We have a workaround to minimize the errors, but not a solution.

Jens Voeckler was having trouble with Condor-G reporting jobs done before they really were. Turned out to be a buggy GRAM PBS poll script.

Investigated a user report (OSG ISSUE 4867) of trouble with Condor-G and GRAM. Problem turned out to be overly-restrictive port range in a firewall. <br />
%STOPINCLUDE%