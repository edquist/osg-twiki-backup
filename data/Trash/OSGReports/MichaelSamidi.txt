%META:TOPICINFO{author="MichaelSamidi" date="1170270091" format="1.1" reprev="1.3" version="1.3"}%
---++ Monthly Reports from Michael Samidi

%TOC%

The current OSG WBS is located [[http://projects.fnal.gov/osg/WBS/changeControl/WBSFromProjectPlan.htm][here]]. 

My work falls into this category from the current OSG WBS:
   * 1.3.2.5.2 - Sustained operations of LIGO workflow at UCSD at the level of 25 jobs for one week (2/1/07).
   * 1.3.2.5.3 - Sustained operations of LIGO workflow across OSG using 100 slots for one week (6/1/07).
   * 1.3.2.5.4 - Sustained operations of LIGO workflow across OSG at the level of 1000 jobs peak (10/1/07).

---++ Period: January 2007
   * Completed the first OSG milestone, running LIGO workflow at UCSD with local cache and job clustering using 25 or more CPU slots continuously in one week (Jan 11, 2007 - Jan 17, 2007). 

%ATTACHURL%/first-milestone-small.gif

   * Wrote Tcl script to push LIGO GWFs from CIT repository to UCSD SRM server. The script is still in the testing mode. Roughly 80% to 90% of LIGO GWFs have been pushed to the UCSD SRM server.   

   * Communicated with Pegasus team member (Karan Vahi) to resolve the following Pegasus/SRM issues:
      1. missing a single quote surrounding SRM URL in the Pegasus submit script
      2. problem when sourcing OSG source file via Condor-G
 
   * Still testing several OSG site candidates (PSU, UMilwaukee, Fermilab, Purdue, ATLAS) for running LIGO workflow to meet the second OSG milestone. 

---++ Period: December 2006
   * I have completed job clustering study running at PSU with 24 and 18 partitions. This study will identify the most efficient way for clustering LIGO workflow running at OSG production cluster. I'm almost done with 12 partitions (completed 50, 75, 100, 500 and 1000 clustering factor) and I need to complete 25 and 0 clustering factor). 

   * Running small LIGO workflow with local cache at several production clusters for checking the site is ready for running full HIPE with local cache.
      1. UCSD (completed)
      2. UWMilwaukee (stage-out data failed)
      3. Purdue_ITaP (stage-out data failed)
      4. OSG_LIGO_PSU (stage-out data failed)

     Based on previous item, I have started running full HIPE at UCSD with local cache. As of Dec 20, 2006, 9877 jobs are completed out of 77915 and 1945 jobs failed. The failure is caused by expired host certificates on the submit host. But, I'm using LIGO workflow planner which will auto-restart from the last rescue DAG which will eventually complete all failed jobs. This is to meet the first milestone indicated in the WBS (see above). 
     
---++ Period: November 2006

Moved LIGO data into local cache at UCSD. This local cache is used by Pegasus planner for getting LIGO GWFs, the input data. Normally, the data will be transferred from LIGO repository at Caltech to the remote site.  

Added two addiitonal sites for runnig LIGO workflow:
   1. Fermilab, FNAL_GPFARM (voms-proxy-init) 
   2. STAR_BNL

Configured Pegasus planner to use job clustering in order to reduce the scheduler overhead running small jobs at remote site. I had to upgrade the VDS binary executable at remote site because of the compatibility issue and put the binary under $OSG_APP directory. We're still experimenting with this feature at osg-gw-2_t2_ucsd_edu (UCSD) and OSG_LIGO_PSU production clusters using 25, 50, 75, 100, 500 and 1000 clustered jobs per DAG node.

---++ Period: October 2006

Completed running LIGO workflow containing ~80,000 DAG nodes with a minimum of 700 GB disk space at UCSD production cluster (osg-gw-2_t2_ucsd_edu).

Completed the same workflow at the following sites (limited disk space, < 150 GB):
   1. Purdue_ITaP
   2. UWMilwaukee

Added the following features into LIGO workflow planner for running a workflow of ~80,000 DAG nodes at several OSG production clusters with limited disk space (<150 GB):
  
   1. N arbitrary workflow partitioning
   2. removal of input GWFs when there is no data dependency
 
-- Main.MichaelSamidi - 29 Nov 2006

%META:FILEATTACHMENT{name="first-milestone-small.gif" attr="" autoattached="1" comment="" date="1170269976" path="first-milestone-small.gif" size="24121" user="Main.MichaelSamidi" version="1"}%
%META:FILEATTACHMENT{name="first_milestone.gif" attr="" autoattached="1" comment="" date="1170269495" path="first_milestone.gif" size="27412" user="Main.MichaelSamidi" version="1"}%
