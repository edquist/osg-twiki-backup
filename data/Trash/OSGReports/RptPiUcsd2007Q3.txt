%META:TOPICINFO{author="KyleGross" date="1225985954" format="1.1" version="1.3"}%
%META:TOPICPARENT{name="CreateNewReport"}%
<!-- Complete the template. You can either use TWiki style, copy in plain text, or put in HTML. -->
<!-- IF COPYING IN HTML: Please only include the sections between your BODY tags. -->

---+!! 2007Q3 PI Quarterly Report 

%STARTINCLUDE%

---++  <nop>UCSD
%EDITTHIS%
<!-- EDIT BELOW THIS LINE ONLY! -->

As instructed by Chander, I am adding here a high-level summary of year 1 accomplishements, thus going beyond the usual
quarterly report.

---+++ Key Accomplishments
UCSD agreed to contribute in three broad areas, storage, user community suport, and hardening of the Compute Element. Goals were met
or exceeded in the first two. Progress was made in the third area, but not all goals were met due to a hiring delay.

---++++ Storage
   * Contributed to testing of the first VDT release of dCache. This was very successful, leading to successful deployment of 1.7 at all
      CMS Tier-2 centers, and ultimately some itb sites as part of OSG 0.7 itb activities.
      * The testing was restricted to functionality and packaging testing only. We found this to be insufficient, as it led to a rapid fire of around 
         20 point releases for dCache v1.7 within 2 months or so after deployment started. This led to a change in procedure for v1.8. We now are
         doing detailed performance testing with the goal to verify that operational stability of the new release is as good or better as the previously
         deployed release. See below for more details on v1.8 status.
   * Worked with Cornell and Oklahoma on data transfer accounting. UCSD's responsibility here are in specifications and testing. 
      * A GRATIA probe that works off the dCache billing DB was completed by Cornell, and multiple versions were deployed and 
        tested on the UCSD production system.
      * Oklahoma is contributing effort on viewing the GRATIA accounting system. UCSD's involvement here was to specify the work, and guide it
         in collaboration with the GRATIA team.
      * At this point, the ball for deployment is in the court of the GRATIA team. They need to follow up on both items, and push them to production.
   * Deployed an at scale dCache testbed for the purpose of large scale performance testing of v1.8.
      * We learned from v1.7 deployment that we need much more thorough testing at scale. As v1.8 is a major upgrade with many changes to many
         aspects, including the addition of space reservation, we are taking this very serious. The goal is to use v1.8 as a proof of principle that we
         are capable of delivering a substantially modified code base to deployment in a shape that it is no step back in terms of operational stability
         once deployed.
      * The testbed deployed is at scale in the sense that the admin hardware infrastructure is identical to a typical deployment at a tier-2. 
        The testbed is located physically next to the production system at UCSD, allowing us to move pools between the two systems as needed
        in order to add additional space to the testbed as needed. The default configuration include about 10TB of disk space in the testbed.
      * To exercise the testbed, we are pointing the PhEDEx (CMS data transfer system) debug instance at the testbed for loadtest transfers from 
         Tier-2 centers in CMS. To-date, only srm v1 in v1.8 has been exercised at scale in this fashion. However, the testbed is included in the
         functionality testing for srm v2.2 organized centrally for EGEE and OSG from CERN, as well as the OSG organized srm testing by LBNL.
      * The following shows the daily volume transfered to the teststand for writes and reads. 5TB per day corresponds to 60MB/sec sustained IO 
         throughout the day:
<img src="%ATTACHURLPATH%/teststand-writes.png" alt="teststand-writes.png" width='800' height='500' />
<img src="%ATTACHURLPATH%/teststand-read.png" alt="teststand-read.png" width='800' height='500' />
      * This work is ongoing in year 2.

---++++ User Community Support
   * We hosted the OSG all-hands meeting at UCSD. This meeting was combined with the first a tier-3 workshop for the LHC community,
      an OSG council meeting, ATLAS and CMS tier-2 meetings, and a meeting by the joint middleware security group. All of these meetings
      were "serialized" over the timeframe of one week.
   * We contributed to the user group in terms of holding weekly meetings, as well as the first annual user workshop at FNAL.
   * Participation and presentations at the first OSG site admin workshop.
   * We worked with Caltech on LIGO milestones with regard to jobs running, and have recently started working with them as well as Engage on data storage using SRM.
   * We coordinated the release validation for OSG 0.6 and 0.8.
   * Conducted the 1st annual VirtualOrganizations/VOInfo/user satisfaction survey, followed by reporting feedback to operations, EB, and Council.

---++++ Compute Element hardening
   * We worked with the VDT on inclusion of NFS-lite into VDT.
   * We worked with Condor on scalability issues of the compute element. Some problems were identified, and some improvements made.
      However, the work planned on systematically testing the CE for weaknesses has been started but not completed due to delays in hiring.
   * We developed and deployed at UCSD a complete monitoring of all FQAN's arriving at our site. We offered this for inclusion into OSG in the future.
      At this point, it is not clear if this is going tobe adopted, as it overlaps with developments requested from CDIGS and work underway in CEDPS.
   * We contributed to the itb for 0.6 and 0.8. Suggestions for packaging and deployment were fed back to VDT, and adopted. This includes in particular
      issues pertaining to RSV, as well as packaging such that preinstalled condor versions can be used rather than unnecessarily installing additional
      versions on top of it.




%STOPINCLUDE%

%META:FILEATTACHMENT{name="teststand-writes.png" attr="" autoattached="1" comment="" date="1191425688" path="teststand-writes.png" size="57971" user="Main.FkW" version="1"}%
%META:FILEATTACHMENT{name="teststand-read.png" attr="" autoattached="1" comment="" date="1191425742" path="teststand-read.png" size="55587" user="Main.FkW" version="1"}%
%META:TOPICMOVED{by="ForrestChristian" date="1173993132" from="Sandbox.WebTopicTemplateTesting" to="OSGReports.TemplateForReports"}%
