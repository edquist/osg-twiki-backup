%META:TOPICINFO{author="TimCartwright" date="1418837111" format="1.1" reprev="1.9" version="1.9"}%
%META:TOPICPARENT{name="WebHome"}%
---+!! Installing the HTCondor CE

%TOC{depth="2"}%

---# About this Document

This document is for System Administrators. It covers the installation of the HTCondor&nbsp;CE software, which aims to provide an end-to-end gatekeeper technology built entirely out of core HTCondor components.  As a goal, we aim for the HTCondor&nbsp;CE to be a particular "configuration" of HTCondor, and not include any non-HTCondor daemons.

This document follows the general OSG documentation conventions: %TWISTY{%TWISTY_OPTS_OUTPUT% showlink="Click to expand document conventions..."}%
%INCLUDE{"Documentation/DocumentationTeam/DocConventions" section="Header"}%
%INCLUDE{"Documentation/DocumentationTeam/DocConventions" section="CommandLine"}%
%ENDTWISTY%

---# How to get Help?
To get assistance please use the [[Documentation.HelpProcedure][this page]].

---# Requirements

---## Host and OS
   * A host to install the Compute Element
   * OS is %SUPPORTED_OS%
   * Root access

---## Users

%STARTSECTION{"Users"}%

The following users are needed by HTCondor CE at all sites
| *User* | *Comment* |
| =condor= | The HTCondor CE will be run as root, but perform most of its operations as the =condor= user. |
| =gratia= | Runs the Gratia probes to collect accounting data |

The above user will be added to the system automatically when the HTCondor RPM installs.  If your fabric management automatically overwrites users and groups, you will want to create this user beforehand.

%ENDSECTION{"Users"}%

---## Certificates
| *Certificate* | *User that owns certificate* | *Path to certificate* |
| Host certificate | =root= | =/etc/grid-security/hostcert.pem= <br> =/etc/grid-security/hostkey.pem= |

Find instructions to request a host certificate [[Documentation/Release3.GetHostServiceCertificates][here]].

---## Networking

%STARTSECTION{"Firewalls"}%
%INCLUDE{"Documentation/Release3/FirewallInformation" section="FirewallTable" lines="htcondorce,htcondorce_shared"}% 

Allow inbound and outbound network connection to all internal site servers, such as GUMS and the batch system head-node only ephemeral outgoing ports are necessary.</br>

%ENDSECTION{"Firewalls"}%

---# Installation

This section describes how to install the OSG software that is needed for your HTCondor CE.

%NOTE% HTCondor&nbsp;CE is available in OSG 3.2 and later; be sure to use an appropriate Yum repository, as described below.

%INCLUDE{"Documentation/Release3.YumRepositories" section="OSGRepoBrief" TOC_SHIFT="+"}%
%INCLUDE{"Documentation/Release3.InstallCertAuth" section="OSGBriefCaCerts" TOC_SHIFT="+"}%

---## Installing HTCondor CE and Related Software

A complete CE installation consists of the job gateway (i.e., the HTCondor&nbsp;CE job router) and other support software (e.g., !GridFTP, a Gratia probe, authorization software). To simplify installation, OSG provides convenience RPMs that help you install all required software with a single command.

<ol>
<li>
<p>If you are updating an existing CE, it is recommended that you update existing software first:</p>
<pre class="rootscreen">%UCL_PROMPT_ROOT% yum update</pre>
</li>
<li>
<p>Select the appropriate convenience RPM(s):</p>
%TABLE{sort="off"}%
| *If your batch system is…* | *Then use the following package(s)…* |
| HTCondor | =osg-ce-condor= |
| LSF | =osg-ce-lsf= |
| PBS | =osg-ce-pbs= |
| SGE | =osg-ce-sge= |
| SLURM | =osg-ce-pbs gratia-probe-slurm= |
</li>
<li>
<p>Install the CE software:</p>
<pre class="rootscreen">%UCL_PROMPT_ROOT% yum install <em>PACKAGE(S)</em></pre>
</li>
</ol>

%NOTE% To ease the transition from GRAM to HTCondor CEs, the convenience RPMs install both types of job gateway software. By default, the HTCondor gateway is enabled and the GRAM gateway is disabled, which is the correct configuration for most HTCondor CE-based sites (but see the gateway configuration section below for more options).

%NOTE% HTCondor&nbsp;CE version 1.6 or later is required to send site resource information to OSG for matching jobs to resources.


---# Configuration

   * The Unix environment variables for the HTCondor CE daemons are controlled by =/etc/sysconfig/condor-ce=.
   * You can place site HTCondor CE configuration customizations in =/etc/condor-ce/config.d=. Any filename prefixed with "99-" will override the default files from the CE.
   * If you have an HTCondor local batch system, make sure to differentiate between the configuration that goes in =/etc/condor-ce= and the configuration that goes in =/etc/condor=.

---## Setup osg-configure
[[Documentation.Release3.IniConfigurationOptions][osg-configure]] is an automatic configuration tool that is used to set up a CE. This section only covers the HTCondor&nbsp;CE specific options of =osg-configure=: you will have to make other configuration changes before applying your configuration with =osg-configure=. 

   1. For sites updating from a GRAM CE, enable the HTCondor gateway and disable the GRAM gateway in =/etc/osg/config.d/10-gateway.ini=. This is the default in new installations: \
<pre class="file">
gram_gateway_enabled = False
htcondor_gateway_enabled = True
</pre> \
%NOTE% If you need to run _both_ HTCondor&nbsp;CE and GRAM (e.g. you need to run SAM tests), you need to enable both gateways:\
<pre class="file">
gram_gateway_enabled = True
htcondor_gateway_enabled = True
</pre>\
<p>More information about the GRAM CE can be found at Documentation.Release3.InstallComputeElement.</p>
   1. Enable your batch system by editing the =enabled= field in =/etc/osg/config.d/20-<span style="background-color: #FFCCFF;">&lt;your batch system&gt;</span>.ini=: \
<pre class="file">
enabled = True
</pre>
   1. Verify your configuration: \
<pre class="rootscreen">
%UCL_PROMPT_ROOT% osg-configure -v
</pre>
   1. Apply your configuration: \
<pre class="rootscreen">
%UCL_PROMPT_ROOT% osg-configure -c
</pre>

---## Setup authorization with edg-mkgridmap

<i>Alternatively, setup authorization with [[#GumsAuth][GUMS]].</i>

   1. Edit your list of accepted VO&rsquo;s in =/etc-edg-mkgridmap.conf= as specified in the [[Documentation/Release3.Edg-mkgridmap][edg-mkgridmap]] document.
   1. Under the =authorize_only= policy of =/etc/lcmaps.db=, comment out the =gumsclient= line and uncomment the =gridmapfile= line.  The resulting policy should read: \
<pre class="file">
authorize_only:
# gumsclient -> good | bad
gridmapfile -> good | bad
</pre>
   1. Specify the location of your grid mapfile in =/etc/condor-ce/config.d/01-common-auth.conf=: \
<pre class="file">
GRIDMAP = /etc/grid-security/grid-mapfile
</pre>

---## Non-HTCondor batch system configuration

The following subsections are only required if you  are *not* using HTCondor as your local batch system. 

---### Sharing the spool directory

Like GRAM, HTCondor&nbsp;CE requires a shared file system between worker nodes and the CE to transfer files. Unlike GRAM, it does not write job files into the user&rsquo;s =$HOME= directory.  By default, job files are written into =/var/lib/condor-ce= and hence that directory must appear at that location on all worker nodes. We recommend setting up an NFS server on the CE dedicated to sharing the spool directory with the site&rsquo;s worker nodes instead of using a pre-existing NFS share.    

%NOTE% You can control the exported directory by setting the =SPOOL= configuration variable in =/etc/condor-ce/config.d=.  
%NOTE% Root squash must be turned off and the directory must be readable/writeable by the condor user for HTCondor&nbsp;CE to function correctly.

---### Disable blahp worker node proxy renewal

Turn off worker node proxy renewal in =/etc/blah.conf= by specifying the following two lines:

<pre class="file">
blah_disable_wn_proxy_renewal=yes
blah_delegate_renewed_proxies=no
</pre>

There should be no whitespace around the =&#61;=. Neither functionality is used with HTCondor&nbsp;CE; enabling worker node proxy renewal will actually cause jobs to fail to refresh the proxy in some setups.

---## Optional Configuration

The following configuration steps are optional and will likely not be required for setting up a small site.

#JobRoutes
---### Setup Job Routes
     <i>Main document: [[Documentation/Release3.JobRouterRecipes][Job Router Recipes]]</i>

#GumsAuth
---### Setup authorization with GUMS

   1. Install and set up GUMS as specified in the [[Documentation/Release3.InstallGums][installation document]].
   1. Set the =authorization_method= and =gums_host= in =/etc/osg/config.d/10-misc.ini=:\
<pre class="file">
authorization_method = xacml
gums_host = <span style="background-color: #FFCCFF;">gumshost.example.com</span>
</pre>\
<p>Replacing <span style="background-color: #FFCCFF;">gumshost.example.com</span> with the hostname of your GUMS server</p>
   1. Verify your configuration: \
<pre class="rootscreen">
%UCL_PROMPT_ROOT% osg-configure -v
</pre>
   1. Apply your configuration: \
<pre class="rootscreen">
%UCL_PROMPT_ROOT% osg-configure -c
</pre>

%NOTE% Once gsi-authz.conf is in place, your local HTCondor will attempt to utilize the LCMAPS callouts if enabled in the condor_mapfile.  If this is not the desired behavior, set GSI_AUTHZ_CONF=/dev/null in the local HTCondor configuration.

---### Configuring for multiple network interfaces
If you have multiple network interfaces with different hostnames, the HTCondor&nbsp;CE daemons need to know which hostname to use when communicating to each other. Generally, you will want to set =NETWORK_HOSTNAME= to the hostname of your public interface in your =/etc/condor-ce/config.d/= directory with the line:

<pre class="file">
NETWORK_HOSTNAME=<span style="background-color: #FFCCFF;">condorce.example.com</span>
</pre>

Replacing <span style="background-color: #FFCCFF;">condorce.example.com</span> text with your public interface&rsquo;s hostname.

---### Configure jobs running on the CE

Local and scheduler universes are HTCondor&nbsp;CE&rsquo;s analogue to GRAM&rsquo;s managed fork: they allow jobs to be run on the CE itself. The two universes are effectively the same (scheduler universe launches a starter process for each job), so we will be configuring them in unison.

   * *To change the default limit* on the number of locally run jobs (the current default is 20), add the following to  =/etc/condor-ce/config.d/99-local.conf=: <pre class='file'>START_LOCAL_UNIVERSE = <span style="background-color: #FFCCFF;">TotalLocalJobsRunning + TotalSchedulerJobsRunning < &lt;job limit&gt;</span>
START_SCHEDULER_UNIVERSE = $(START_LOCAL_UNIVERSE)</pre>
   * *To only allow a specific user* to start locally run jobs, add the following to  =/etc/condor-ce/config.d/99-local.conf=: <pre class='file'>START_LOCAL_UNIVERSE = <span style="background-color: #FFCCFF;">target.Owner =?= "&lt;username&gt;</span>"
START_SCHEDULER_UNIVERSE = $(START_LOCAL_UNIVERSE)</pre>
   * *To disable* locally run jobs, add the following to  =/etc/condor-ce/config.d/99-local.conf=: <pre class='file'>START_LOCAL_UNIVERSE = <span style="background-color: #FFCCFF;">False</span>
START_SCHEDULER_UNIVERSE = $(START_LOCAL_UNIVERSE)</pre>

---### HTCondor accounting groups

%NOTE% For HTCondor batch systems only 

%INCLUDE{"Documentation/Release3/InstallComputeElement" section="AccountingGroups"}%

---#### /etc/osg/uid_table.txt
%INCLUDE{"Documentation/Release3/InstallComputeElement" section="uid_table"}%

---#### /etc/osg/extattr_table.txt
%INCLUDE{"Documentation/Release3/InstallComputeElement" section="extattr_table"}%

---### Batch system client tools in non-standard locations

%NOTE% For non-HTCondor batch systems only 

If your batch system binaries aren&rsquo;t in the standard location or not in your PATH, you will need to configure =/etc/blah.config= to point to the directory where you keep said binaries. If your SGE binaries live in =/opt/sge/bin=, then you would want to change the =sge_binpath= configuration variable to read:

<pre class="file">
sge_binpath=<span style="background-color: #FFCCFF;">/opt/sge/bin</span>
</pre>

---### Adding attributes to each job

%NOTE% This method adds attributes to *all* jobs that are submitted to your batch system. It is recommended to instead use [[Documentation/Release3.JobRouterRecipes][job routes]] wherever possible: you can use job routes to specify [[Documentation/Release3.JobRouterRecipes#2_6_Setting_a_Default][defaults]] for requested memory, requested number of cores, batch system queue, and walltime.

Additional attributes can be inserted into the job submit script by editing =/usr/libexec/blahp/<span style="background-color: #FFCCFF;">&lt;batch system&gt;</span>_local_submit_attributes.sh=.  This file is sourced during submit time and anything printed to stdout is appended to the job submit script.  For example, the following will set a default walltime for PBS: \

<pre class="file">#!/bin/sh

# Set walltime according to request; the batch system
# may reject this, of course!
if [ -n "$Walltime" ]; then
  echo "#PBS -l walltime=$Walltime"
else
  echo "#PBS -l walltime=24:00:00"
fi
</pre>

The environment variable =$Walltime= is set if the the attribute =remote_cerequirements= is set in the HTCondor-G job.  That attribute should follow the form:

<pre class="file">remote_cerequirements = foo == X && bar == Y && ...</pre>

to set =foo= to value X and =bar= to Y in the environment of =<span style="background-color: #FFCCFF;">&lt;batch system&gt;</span>_local_submit_attributes.sh=.  So, to set the Walltime to 1 hour with the above =<span style="background-color: #FFCCFF;">&lt;batch system&gt;</span>_local_submit_attributes.sh=, the job would need:

<pre class="file">remote_cerequirements = Walltime == 3600</pre>

---# Testing and Verification
<i>Main document: [[Documentation/Release3.InstallRSV][Install RSV]]</i>

In addition to RSV, you may find the need to manually test and verify your HTCondor&nbsp;CE. To do this, use the [[Documentation/Release3.TroubleshootingHTCondorCE#condor_ce_run][condor_ce_run]], [[Documentation/Release3.TroubleshootingHTCondorCE#condor_ce_trace][condor_ce_trace]], and [[Documentation/Release3.TroubleshootingHTCondorCE#condor_submit][condor_submit]] commands against your CE from a remote host. 

---# Troubleshooting
     <i>Main document: [[Documentation/Release3.TroubleshootingHTCondorCE][Troubleshooting HTCondorCE]]</i>
     
---# Services

Start and enable the following services:

   * =fetch-crl-boot= (or =fetch-crl3-boot= for EL5)
   * =fetch-crl-cron= (or =fetch-crl3-cron= for EL5)
   * =gratia-probes-cron=
   * Your batch system (=condor=, =pbs_server=, etc.)
   * =condor-ce=


---# Registering the CE

To be part of the OSG Production Grid, your CE must be registered in the [[https://oim.grid.iu.edu/ OSG Information Management System]] (OIM).

To register your resource:

   1. [[Documentation.CertificateUserGet][Obtain, install, and verify your user certificate]] (which you may have done already)
   1. [[Operations.OIMRegistrationInstructions][Register your site and CE in OIM]]


---# Reference

   * HTCondor CE overview and architecture (coming soon)
   * [[Documentation/Release3.JobRouterRecipes][Configuring HTCondor CE job routes]]
   * [[Documentation/Release3.TroubleshootingHTCondorCE][Troubleshooting HTCondor CE]]
