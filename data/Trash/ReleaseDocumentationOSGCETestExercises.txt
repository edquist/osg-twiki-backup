%META:TOPICINFO{author="MarcoMambelli" date="1267221895" format="1.1" reprev="1.1" version="1.1"}%
%META:TOPICPARENT{name="GridColombiaWorkshop2009"}%
---+!! *<nop>%SPACEOUT{ "%TOPIC%" }%*
%TOC%

---++ Introduction
This page presents some test that you can run against the OSG CE using the OSG client.
Requirement are:
   * A OSG CE, installed as described in InstallCETutorial and called for reference =gc1-ce.yourdomain.org=
   * A Client, installed as described in GridClientTutorial and made available by sourcing the =setup.(c)sh= script
   * Valid certificates, as explained in the "Grid Clients and Certificates" section of GridColombiaWorkshop2009
 
---++ Tests

---+++ Obtain a Grid Proxy: *grid-proxy-init* and *voms-proxy-init*

In the following examples it is assumed that your =usercert.pem= and =userkey.pem= files are in =$HOME/.globus/=. If not, you will need to specify them explicitly via "-cert" and "-key" arguments to the xxxx-proxy-init commands.

   * Obtain a grid-proxy via =grid-proxy-init= <pre>
$ grid-proxy-init
<b>
Your identity: /DC=org/DC=doegrids/OU=People/CN=XXX XXXXX #####
Enter GRID pass phrase for this identity:
Creating proxy ....................................... Done
Your proxy is valid until: Wed Aug 22 04:57:38 2007
</b>
</pre>

   * Obtain a voms-proxy via =voms-proxy-init=:<pre>
$ voms-proxy-init -voms osg
<b>
Cannot find file or dir: /home/condor/execute/dir_14135/userdir/glite/etc/vomses
Enter GRID pass phrase:
Your identity: /DC=org/DC=doegrids/OU=People/CN=XXX XXXXX #####
Cannot find file or dir: /home/condor/execute/dir_14135/userdir/glite/etc/vomses
Creating temporary proxy ................................ Done
Contacting  voms.opensciencegrid.org:15027 [/DC=org/DC=doegrids/OU=Services/CN=host/voms.opensciencegrid.org] "osg" Done
Creating proxy .................................... Done
Your proxy is valid until Tue Oct 30 23:32:54 2007
</b>
</pre>

<b>Note</b>: the apparent error message ==Cannot find file or dir: /home/condor/.....== is not an error but an artifact of the software build used in the VDT.  You should ignore that message.

<!--

---+++ Querying Resources  

The client tools include utilities to query GRID resources. Examples here used to test the client are directed the OSG-ITB repositories.

   * Query ReSS <pre>condor_status -pool osg-ress-4.fnal.gov -format '%s\n' GlueSiteName | uniq
<b>CIT_ITB_1
ITB_INSTALL_TEST_2
ITB_INSTALL_TEST_3
CMS-BURT-ITB
...</b>
</pre>
   * Query BDII (see ValidateBDII documentation) <pre>ldapsearch -x -LLL -p 2170 -h is-itb.grid.iu.edu -b mds-vo-name=LBNL_VTB,mds-vo-name=local,o=grid
<b>dn: mds-vo-name=LBNL_VTB,mds-vo-name=local,o=grid
objectClass: GlueTop
 
dn: GlueSEUniqueID=osp1.lbl.gov,mds-vo-name=LBNL_VTB,mds-vo-name=local,o=grid
...</b>
</pre>
   * Query by LCG tools (<b>NOTE</b> =lcg-info= and =lcg-infosites= are not in ones path by default):<pre class=screen> $VDT_LOCATION/lcg/bin/lcg-info - - list-ce - - bdii is-itb.grid.iu.edu:2170 - - vo osg
<b> - CE: cithep201.ultralight.org:2119/jobmanager-condor-osg
- CE: cms-xen1.fnal.gov:2119/jobmanager-condor-osg
....</b>

$VDT_LOCATION/lcg/bin/lcg-info - -list-se - -bdii is-itb.grid.iu.edu:2170 - -vo osg
<b>- SE: cit-se.ultralight.org
- SE: cms-xen1.fnal.gov
</b>

$VDT_LOCATION/lcg/bin/lcg-infosites - -vo osg -f ce  - -is is-itb.grid.iu.edu 
<b>valor del bdii: is-itb.grid.iu.edu:2170
#CPU    Free    Total Jobs      Running Waiting ComputingElement
----------------------------------------------------------
  40      40       0              0        0    osp1.lbl.gov:2119/jobmanager-pbs-batch
   2       0       0              0        0    tb10.grid.iu.edu:2119/jobmanager-condor-osg
1042       2       0              0        0    itb.rcac.purdue.edu:2119/jobmanager-condor-osg
....</b> 
<!--
$VDT_LOCATION/lcg/bin/lcg-infosites - -vo osg -f se  - -is is-itb.grid.iu.edu 
<b>Avail Space(Kb) Used Space(Kb)  Type    SEs
----------------------------------------------------------
125             2               n.a     osp1.lbl.gov
28824440        10638628        n.a     tb10.grid.iu.edu
37              242             n.a     itb.rcac.purdue.edu
....</b>
</pre>  -->

---+++ Simple Client Jobs
For the following exercises it is assumed that you have sourced the =$VDT_LOCATION/setup.(c)sh= script , have a valid grid-proxy, and are aware of resources available to you. 
Specifically we will submit tests to the CE installed in InstallCETutorial. For reference we will call it =gc1-ce.yourdomain.org=

----++++ Submit a remote job: =globus-job-run=
To the default (fork) queue:<pre>
$globus-job-run gc1-ce.yourdomain.org/jobmanager /bin/hostname
<b>gc1-ce.yourdomain.org</b>
</pre>

To the local batch system queue: (specific syntax depends on what batch system is deployed [Condor|PBS|LSF|SGE], you will have Condor)<pre>
$globus-job-run gc1-ce.yourdomain.org/jobmanager-condor /bin/hostname
<b>gc1-ce.yourdomain.org</b>
</pre>

----++++ File tranfer: =globus-url-copy,srmcp,uberftp=
Copy a file using globus-url-copy from a local system to a remote gsiftp server.<pre>
$ls -l /tmp/testdata_10.dat
<b>-rw-r--r--  1 qwerty qwerty 2121000 Feb 15 11:25 /tmp/testdata_10.dat</b>

$globus-url-copy file:///tmp/testdata_10.dat gsiftp://gc1-ce.yourdomain.org:2811/tmp/testdata_destination.dat
</pre>

Now copy it back and compare:<pre>
$globus-url-copy gsiftp://gc1-ce.yourdomain.org:2811/tmp/testdata_destination.dat  file:///tmp/testdata_return.dat
$ls -l /tmp/testdata_return.dat
<b>-rw-r--r--  1 qwerty qwerty 2121000 Feb 15 11:27 /tmp/testdata_return.dat</b>

$diff /tmp/testdata_10.dat /tmp/testdata_return.dat
</pre>

You can repeat the above tests between two remote gsiftp servers (server1 and server2) using the syntax:<pre>
$globus-url-copy  gsiftp://server1:2811/filesystem/filename gsiftp://server2:2811/filesystem2/filename2
</pre>

<!--
You can repeat the above tests using =srmcp= instead of =globus-url-copy=. In addition you can access a remote SRM service explicitly. For example:<pre>
$srmcp gsiftp://gc1-ce.yourdomain.org:2811/tmp/testdata.dat srm://osg-itb.ligo.caltech.edu:8643/pnfs/ligo.caltech.edu/data/star/testdata_dest.dat
</pre>

You may also use the "-debug" flag which will generate diagnostic messages.  Also, <b>srm-v2-client</b> package is included in the OSG-client installation but the software is not added to ones path by default. 

To test =uberftp=, simply point to a known resource:<pre>$ uberftp osg-itb.ligo.caltech.edu
<b>220 osg-itb.ligo.caltech.edu GridFTP Server 2.5 (gcc32dbg, 1182369948-63) ready.
230 User qwerty logged in.
</b>
</pre>
-->

<!--
----++++ Submit a remote job to WS GRAM: =globusrun-ws=

Basic submission using WS GRAM is done with =globusrun-ws= analgous to =globus-job-run= with GRAM.   A wide range of tests are shown in the  ValidateGramWebServices documentation.  Here is a basic test to verify that the client tools are in order.
<pre>
$globusrun-ws -submit -F osp1.lbl.gov:9443 -Ft Fork -s -c /bin/hostname
<b>
Delegating user credentials...Done.
Submitting job...Done.
Job ID: uuid:7bfd4324-93b7-11dc-8f33-00304889ddce
Termination time: 11/16/2007 20:15 GMT
Current job state: Active
Current job state: CleanUp-Hold
osp1.lbl.gov
Current job state: CleanUp
Current job state: Done
Destroying job...Done.
Cleaning up any delegated credentials...Done.
</b>
</pre>
-->

---+++ *Condor-G submission*

OSG Client includes a condor package for use as a Condor-G submit host. To test this service 

   * verify service is running:<pre> $condor_q
 
-- Submitter: qwerty@osp3.lbl.gov : <128.3.30.238:59969> : osp3.lbl.gov
 ID      OWNER            SUBMITTED     RUN_TIME ST PRI SIZE CMD               
 
0 jobs; 0 idle, 0 running, 0 held
</pre>

   * prepare submit file for either GRAM or WS-GRAM <pre> $cat test.submit
<b>#specify resource destination
Universe            = grid
grid_resource       = gt4 https://hostname:9443 [Condor|PBS|SGE]

# specify executable
Executable          = /bin/hostname
Transfer_Executable = false
 
# copy stdout stderr to local files, referenced by job (Process) and submission id (Cluster)
output  =  mytest.out.$(Cluster).$(Process)
error   =    mytest.err.$(Cluster).$(Process)
#a single local log file for tracking Condor-g submission
log    = mytest.log
 
# do not send email notification
notification=Never

# submit 2 identical jobs: Process=0 and Process=1
Queue 2</b>
</pre>
   * Submit job <pre>$condor_submit test.submit 
<b>Submitting job(s)..
Logging submit event(s)..
2 job(s) submitted to cluster 51.</b>
</pre>
   * monitor jobs <pre>$condor_q
  
<b>-- Submitter: qwerty@osp3.lbl.gov : <128.3.30.238:59969> : osp3.lbl.gov
 ID      OWNER            SUBMITTED     RUN_TIME ST PRI SIZE CMD               
  51.0   qwerty         11/15 12:29   0+00:00:00 I  0   9.8  hostname          
  51.1   qwerty         11/15 12:29   0+00:00:00 I  0   9.8  hostname          
  52.0   qwerty         11/15 12:29   0+00:00:15 R 0   0.0  gridftp_wrapper.sh
 
3 jobs; 2 idle, 1 running, 0 held</b>
</pre>
   * verify jobs completed <pre class=scree>$cat mytest.out.51.0
<b>osp3.lbl.gov</b>
</pre>



---++ More information
   * InstallConfigureAndManageGUMS

%BR%
%COMPLETE1% %BR%
%RESPONSIBLE% Main.MarcoMambelli - 26 Feb 2010 %BR%
%REVIEW%

---++ Comments
%COMMENT{type="tableappend"}%

<!--
NOTE: this page is not compliant with new CM standards since part of the GridColombia workshop
-->

<!--
   * Set USERSTYLEURL = https://twiki.grid.iu.edu/twiki/pub/ReleaseDocumentation/GridColombiaWorkshop2009/centerpageborder.css
-->
