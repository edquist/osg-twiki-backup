%META:TOPICINFO{author="TanyaLevshina" date="1271274408" format="1.1" reprev="1.42" version="1.42"}%
%META:TOPICPARENT{name="WebHome"}%
%DOC_STATUS_TABLE%
https://twiki.grid.iu.edu/twiki/pub/Storage/WebHome/images.jpg
%TOC{depth="2"}%
%STARTINCLUDE%
%BR%

---++ Introduction
This document describes the installation of a Storage Element that consists of !BeStMan-Gateway that provides an SRM interface coupled with a !GridFTP server on top of Xrootd.
!BeStMan, developed by the Scientific Data Management Group of Lawrence Berkeley National Laboratory, is a generic SRM v2.2 load balancing frontend for transfer servers.
Xrootd is a high performance network storage system widely used in high energy physics experiments such as ATLAS and ALICE. The underlying Xroot data transfer protocol provides highly efficient access to ROOT based data files. Please see [[#References][these]] references for more information.

For general information on storage software architecture, implementations and use, please read [[https://twiki.grid.iu.edu/bin/view/ReleaseDocumentation/StorageInfrastructureSoftware][StorageInfrastractureSoftware]]. For information on planning, installing and validating storage software, please follow this link to [[https://twiki.grid.iu.edu/bin/view/ReleaseDocumentation/StorageSiteAdministrator][StorageSiteAdministrator]].

The configuration of this distributed storage is pretty complicated, so we will not be able to provide automatic configuration scripts for all options available for each components for the time being. The goal of this document is to give enough information for system administrators to do initial simple configuration of the storage as well as provide references to the documents that may help to accomplish more sophisticated configuration. 

---+++!! Applicable Versions
The applicable software versions for this document are 
%RED%
%OSG_VERSION% 
%ENDCOLOR%
(or higher) and 
%RED%
*vdt-version  2.0*
%ENDCOLOR%
(or higher).

---+++!!Engineering Considerations
!BeStMan-Gateway/Xrootd Storage Element requires at least three nodes. The following components have to be installed on the first node:
   * !BeStMan-Gateway is an implementation of SRM v2.2 for essential interfaces to disk based storage systems - [[http://datagrid.lbl.gov/bestman][BeStMan Home Page]] 
   * !GridFTP-Xrootd  package that contains  !GridFTP server and Data Storage Interface (DSI) module for Xrootd/Posix. !GridFTP provides a high-performance, secure, reliable data transfer [[http://www.globus.org/toolkit/docs/3.2/gridftp][GridFTP documentation]]. The Xrootd preload library allows standard POSIX I/O calls to xrootd servered files instead of calls to the local file system.
   * If you want that !BeStMan to use GUMS for authorization, you should be able to access GUMS server that is installed on your site or installed it yourself on a different node, following [[https://twiki.grid.iu.edu/bin/view/ReleaseDocumentation/InstallConfigureAndManageGUMS][GUMS Server Installation Guide ]] 
   * !XrootdFS is a Posix filesystem  that allows !GridFTP, !BeStMan and other grid applications to work with Xrootd storage system. !XrootdFS works on top of !FUSE.
   * optional package
      * Gratia gridftp transfer probe - cron job that reports all the file transfers to [[https://twiki.grid.iu.edu/bin/view/ReleaseDocumentation/GratiaSiteCollector Gratia collector]]
!Xrootd should be installed on two or more other nodes. One node should be configured as a head node (redirector node) all the other nodes will serve as data servers. 
 
<img src="%ATTACHURLPATH%/betsman_gateway_xrootd.jpeg" alt="betsman_gateway_xrootd.jpeg" width='384' height='288' />

 
The following questions should be answered before you can proceed with installation and configuration of !BeStMan-Gateway/Xrootd Storage solution: 

   $ Q. _What authorization mechanism do you prefer?_ : You need to decide if you want to use grid-mapfile or !GUMS server for users’ authentication and authorization. More details about !GUMS could be found at [[https://twiki.grid.iu.edu/bin/view/ReleaseDocumentation/InstallConfigureAndManageGUMS GUMS Installation Guide]]. %BR% %BR% We currently recommend using GUMS as it provides superior flexibility and allows a site to manage all of its mappings in one central location; most large sites use GUMS.

   $ Q. _Do you need to support space tokens?_ : !BeStMan-Gateway supports predefined, static space tokens that should be included in configuration. It doesn't keep trace or enforce static space tokens.  If you want partition your storage space and have a “designated” space for some VOs or users you can choose to use space tokens. You will have to decide the names and descriptions of the tokens as well as the size of the area. This information will be used in !BeStMan configuration, and Xrootd server configuration on data server and redirector nodes.  

   $ Q. _How to partition storage areas on Xrootd redirector and data server nodes_?: !Xrootd is using two storage areas. One storage area (referred as _storage_path_) could be accessed by clients using Xroot protocol. This area contains symbolic links to the data files that are located in the cache storage area (referred as  _storage_cache_).
The Xrootd developers recommended to use a separate partition for each storage area, but  in principal for _storage_path_ a directory can be used as well. In Xrootd 
production instillation at SLAC an ext3 partition is used for  _storage_path_. This storage area requires a significant amount of inodes. However, too many inodes 
means small block size. For real file, that means a limit of file size (though not clear about sym linked files, which are big in size but are filled with empty holes). At 
SLAC, the block size is set to 1k (thus put a limit of real file size at ~256GB). 
 

   $ Q. _Do you want to enable Gratia gridftp-transfer probes_?: If you want to report all the transfers in and out of your storage you would need to install or enable Gratia gridftp-transfer probes. More details should be found at [[https://twiki.grid.iu.edu/bin/view/Accounting/WebHome  Gratia Home Page]]. The reported information will include the source and destination of transfer, certificate subject of transfer initiator, size and status of the transferred file.   
 
---+++!!Help!
If a problem occurs during installation or verification of the service, see [[#DebugInfo][Debugging Information]].
%BR%
If you cannot resolve the problem, the best way to get help is by following this InstallHelpProcedure.

---++Checklist
   1. [[ReleaseDocumentation/PacmanInstall][pacman]] version >= %PACMAN_VERSION% is required
   1. !FUSE should be installed on the "!BeStMan-Gateway" node
   1. The server must have a fully qualified domain name and a valid [[ReleaseDocumentation/GetGridCertificates][grid host certificate]] installed in =/etc/grid-security/=
   1. !BeStMan server needs to have a valid host certificate installed in =/etc/grid-security/bestmancert=. The certificate should be own by a user that is running !BeStMan server. The right permission (600) should be set on those files. %ICON{warning}%  !BeStMan should be configured with host certificate in order to be able to handle requests from !LCG-Utils tools. This is mandatory for at least all !BeStMan servers that support ATLAS experiment. Normally the OSG !BeStMan implementation uses a service certificate, not a host certificate. This causes lcg-cp to fail because the certificate name (which looks like http/hostname instead of just hostname) doesn't match the hostname. 
   1. The firewall must allow incoming connections to the !BeStMan-Gateway ports (default:1080,10443)
   1. The firewall must allow incoming connections to the !GridFTP port (default 2811). Outgoing connections must be allowed from high ports ( typically in range 32769-65535 ). We recommend to consult the [[ReleaseDocumentation/ComputeElementFirewalls][Firewall Guide]] if you install the !GridFTP server for the first time.
   1.  The firewall must allow multiple ports to be opened for Xrootd daemons on redirector and data server nodes. See detailed information [[][here]].
   1. A working GUMS server or a gridmap-file are needed for authorization using grid certificates.

---++ !FUSE 

!FUSE is a kernel module that intercepts and services user requests to the !XrootdFS.  It has to be installed on the node where !BeStMan and !XrootdFS will be installed.

!FUSE can be installed via “yum install” or rpms. You will need three packages: 
   * fuse
   * fuse-libs
   * kernel-module-fuse

or you can download it  from   
http://sourceforge.net/project/showfiles.php?group_id=121684&package_id=132802 and build according to instructions  provided at http://fuse.sourceforge.net.   
 
You will need to have root access to install it. 
It is essential that FUSE version ( &gt; 2.7.3) and flavor match your kernel. Contact your sys admin if you have any questions.

---++ !BeStMan/Xrootd-GridFTP/XrootdFS Installation Procedure 
!BeStMan, !XrootdFS  and !FUSE have be installed on the same node. !BeStMan and !XrootdFS should be installed under the same directory. 
Login as root and check if pacman version >=%PACMAN_VERSION% is installed:
<pre class="screen">
su root
cd &lt;PACMAN3.28_LOCATION&gt;
. setup.sh
pacman -version
</pre>

Next,  create an installation directory and change to this directory. This directory will later be used to get the !BeStMan package  from the %CACHE% cache.

<pre class="screen">
mkdir -p /opt/osg_%OSG_VERSION%-bestman/
cd /opt/osg_%OSG_VERSION%-bestman/
</pre>

Install !XrootdFS from %CACHE%. Pacman will ask whether you want to trust the cache (=yall=).
Next, you will need to install !BeStMan in the same directory. If you are using GUMS authorization method you will need to setup _VDT_GUMS_HOST_ environment variable, if you are using  gridmap-file ,please, proceed to the next step.
<pre class="screen"> 
cd /opt/osg_%OSG_VERSION%-bestman/
export VDT_GUMS_HOST=&lt;GUMS hostname&gt;  
</pre>


Next, execute pacman to get the !BeStMan package from the %CACHE% cache. Pacman will ask whether you want to trust the cache (=yall=).
<pre class="screen">
pacman -get %CACHE%:Bestman
</pre>
The install procedure will print out a warning:
<verbatim>
========== IMPORTANT ==========
Most of the software installed by the VDT *will not work* until you install
certificates.  To complete your CA certificate installation, see the notes
in the post-install/README file.
</verbatim>

The information provided in the README is out of date. Please setup the CA certificates in the following way instead:
<pre class="screen">
source setup.sh
$VDT_LOCATION/vdt/bin/vdt-ca-manage setupca --location local -url osg
</pre>
This command will download certificates distributed by the OSG to =$VDT_LOCATION/globus/share/certificates= and create a symlink from =$VDT_LOCATION/globus/TRUSTED_CA= to that location. [[VDTCAManage][Other options]] are also available.

To reflect the changes update the environment and run the post installation script:
<pre class="screen">
vdt-post-install
</pre>

Generic !GridFTP server comes with  !BeStMan installation but you will need to install additional package in order for !GridFTP to work with !Xrootd. This package should be installed in the same directory where !BeStMan is installed.  You can choose to have multiple !GridFTP servers for load balancing. Please follow [[][these]] isntuction to install standalone !GridFTP server.

<pre class="screen">
pacman -get %CACHE%:Xrootd-GridFTP 
. setup.sh
</pre>


You can verify that the version installed is the version you expected by executing =vdt-version=. To see all services available use =vdt-control -list=
<pre class="screen">
vdt-version
vdt-control --list
</pre>


This completes the installation of the !BeStMan/Xrootd-GridFTP/XrootdFS packages. Move to the next section to configure the !BeStMan,!Xrootd-GridFTP and !XrootdFS. You may also chose to configure Gratia transfer probe at this time.
If you want to install additional !GridFTP servers on the different nodes, please, follow [[GsiFtpStandAlone][this document]]

---++ !BeStMan/Xrootd-GridFTP/XrootdFS Configuratation 
In order to configure !XrootdFS you will need to do the following: 
<pre class="screen">
<verbatim> 
cd  /opt/osg_%OSG_VERSION%-bestman/
. setup.sh
$VDT_LOCATION/vdt/setup/configure_xrootdfs \
 --user &lt;user&gt; \
 --cache &lt;storage_path&gt; \
 --xrdr-host &lt;hostname&gt;  \
 --xrdr-storage-path &lt;storage_path&gt;
</verbatim>
</pre>
 
Where _$VDT_LOCATION_  is a directory where the package is installed,<br/> 
_user name_ of the non-privileged user that runs xrootdfs daemon and  is an owner of <br/>
_hostname_ is a FQDN of Xrootd redirector host <br/> 
_storage_path_ is  a !XrootdFS mount point that will be created for you. The name of the mount point should correspond to the name of  storage area on !Xrootd nodes  <br/> 

%ICON{"warning"}%The _storage_path_ is used throughout this document and it refers to the path that has to be provided while accessing !BeStMan-Gateway, !GridFTP, !XrootdFS and Xrootd. For !XrootdFS the _storage_path_ is a !XrootdFS mount point that is mapped to  _&lt;xrdr_host&gt;:&lt;xrdr_port&gt;:storage_path_. On the node where !XrootdFS is installed you can access data files directly. For !GridFTP the _storage_path_ is virtual mount point that allows to redirect user requests to  _&lt;xrdr_host&gt;:&lt;xrdr_port&gt;:storage_path_.  The  _storage_path_ should be the same for !GridFTP and !XrootdFS in order for !BeStMan to operate correctly.
For Xrootd the _storage_path_ is a directory that client (user , !XrootdFS, !GridFTP) can access using xroot protocol directly. This directory contains the symbolic links to the actual data files that is stored in _storage_cache_ area (Xrootd cache partition that should exist on every Xrootd node).   

Next, you will need to configure !BeStMan-Gateway first in order to enable it as a service. You will need to specify "use-xrootd" option so BeStMan could be configured in gateway-mode and be able to use xrootd as DFS. In gateway-mode !BeStMan is not managing your disk but rather relies on !Xrootd to do so. You have to choose what authorization mechanism to use. Also, you have to decide if you would like to use static space token reservation, and in this case to come up with a list of token 
names, description and size of space allocated for each token. 
 
The example below shows how to configure !BeStMan in gateway-mode, enable !GUMS and space token usage: 
<pre class="screen">
<verbatim>
$VDT_LOCATION/vdt/setup/configure_bestman --server y \
 --user <user> \
 --cert  <service_cert> \
 --key   <service_key> \
 --http-port  <public_port> \
 --https-port  <secured_port> \
 --gums-host  <GUMS hostname> \
 --gums-port  <GUMS port number> \
 --use-xrootd  \
 --with-tokens-list  "<TOKEN_1_NAME>[desc:<TOKEN_1_DESC>][<TOKEN_1_SIZE_GB>];<TOKEN_2_NAME>[desc:<TOKEN_2_DESC>][<TOKEN_2_SIZE>]"   \
 --with-transfer-servers <GridFTP server list>;
</verbatim>
</pre> 



Where  _user_ name of the non-privileged user that runs !BeStMan </br>  
_service_cert_  path to service certificate (the certificate file should belong to the _user_)<br/>
_service_key_  path to service certificate private key (the certificate key file should belong to the _user_).
%ICON{"warning"}% *the certificate file and key  should belong to the user* - Please, see [[#Checklist][Checklist]]. 
%ICON{warning}%  !BeStMan should be configured with host certificate in order to be able to handle requests from LCG-Utils tools. This is mandatory for at least all !BeStMan servers that support ATLAS experiment. Normally the OSG !BeStMan implementation uses a service certificate, not a host certificate. This causes lcg-cp to fail because the certificate name (which looks like http/hostname instead of just hostname) doesn't match the hostname. 
<br/>
 
_public_port_http_ public port (default : 10080;commonly used port is 8080 unless there is a conflict) <br/> 
_secured_port_http_ private port (default: 10443;commonly used port is 8443 unless there is a conflict) <br/> 
_GridFTP server list_  is FQDN of your !GridFTP servers,  <br/>  
_GUMS hostname_ the name of  !GUMS server, <br/>  
_GUMS port number_ the port of !GUMS  server,   <br/>  

token list example: <br/>
"ATLASDATADISK[desc:ATLASDATADISK][40000];ATLASPRODDISK[desc:ATLASPRODDISK][30000];ATLASGROUPDISK[desc:ATLASGROUPDISK][30000]"

_GridFTP server list_  is a list !FQDN of your !GridFTP servers, separated by ; . e.g. 
“gsiftp://host1.domain.tld;gsiftp://host2.domain.tld” <br/> 
 
If you want to use grid-map-file for user authentication and authorization do not specify 
the following options: </br>  
--gums-host   </br>  
--gums-port </br>  
   
 
If you do not want to use statically reserved space tokens do not specify the following 
options: </br>  
--with-tokens-list 
 
Please, make the appropriate modification to _/etc/sudoers_ described in !BeStMan 
documentation, namely add the following lines to this file: 
<pre class="file">
<verbatim>
Cmnd_Alias SRM_CMD = /bin/rm, /bin/mkdir, /bin/rmdir, /bin/mv, /bin/ls 
Runas_Alias SRM_USR = ALL, !root 
<user_name> ALL=(SRM_USR) NOPASSWD: SRM_CMD 
</verbatim>
</pre>
Please keep in mind that this is just an example, you can choose more  be more restrictive policy for your site.
Now, you have to configure  !GridFTP to work with !Xrootd

<pre class="screen">
<verbatim>
$VDT_LOCATION/vdt/setup/configure_gridftp --use-xrootd \
 --xrootd-host <hostname>\
 --xrootd-mount-point <storage_path> \
 --xrootd-storage-path <storage_path> 
</verbatim>
</pre>
Where _$VDT_LOCATION_ is a directory for !GridFTP installation,  <br/>
_hostname_ is a FQDN of the Xrootd redirector host,  <br/>
_storage_path_ is a !GridFTP virtual mount point and storage area on redirector node 

If you are using GUMS for authorization perform the following commands:
<pre class="screen">
cp $VDT_LOCATION/post-install/prima-authz.conf /etc/grid-security 
cp $VDT_LOCATION/post-install/gsi-authz.conf /etc/grid-security 
</pre> 

If you are dealing with firewall the gridftp port range should be properly set. In order to do so you will have to modify _vdt-local-setup.sh_.
<pre class="screen">
#edit $VDT_LOCATION/vdt/etc/vdt-local-setup.sh 
GLOBUS_TCP_SOURCE_RANGE=&lt;low_port,high_port&gt;
GLOBUS_TCP_PORT_RANGE=&lt;low_port,high_port&gt;
export GLOBUS_TCP_SOURCE_RANGE
export GLOBUS_TCP_PORT_RANGE
</pre>

Where _low_port,high_port_ - controls all outbound globus connections for gridftp (e.g GLOBUS_TCP_SOURCE_RANGE=40000,49150)
 
---+++ Gratia !GridFTP Transfer Probe
If you are using !GridFTP server that is installed during the !BeStMan installation you will need to enable, configure Gratia !GridFTP transfer probe and perform the actions described in
 [[GratiaTransferProbe][Preparing, Installing and Validating Gratia transfer probe]]

---++Xrootd Installation 

You will have to install Xrootd on redirector node and each data server node. The installation described here is done as root even though the services do not  run as root. You need a non privileged Xrootd user account on the redirector and all data servers, and that user must have a login shell. If you manage your accounts by hand (rather than using a service such as LDAP) you would, on your management node:

/usr/sbin/groupadd xrootd 
/usr/sbin/useradd --gid xrootd xrootd

and copy /etc/passwd, /etc/shadow, /etc/group, and /etc/gshadow to each of the xrootd nodes. 


Next create and change to an installation directory. <pre class="screen">
mkdir -p /opt/xrootd/
cd /opt/xrootd/
</pre>

Install the !Xrootd package from the %CACHE% cache.  Pacman will ask whether you want to trust the cache (answer =yall=).
<pre class="screen">
pacman -get %CACHE%:Xrootd
</pre>

Update the environment and run the post installation script:
<pre class="screen">
source setup.sh
vdt-post-install
</pre>

You can verify that the version installed is the version you expected by invoking =vdt-version= : <pre class="screen">
vdt-version
</pre>

---++ Xrootd  Configuration on data server node 
To configure Xrootd on each data server node you have to login to the node as root and perform the following actions:

<pre class="screen">
<verbatim>
cd /opt/xrootd
. setup.sh
$VDT_LOCATION/vdt/setup/configure_xrootd \
 --server y \
 --user <user& \
 --xrdr-host  <hostname> \
 --xrdr-storage-path <storage_path> \
 --xrdr-storage-cache <storage_cache> \
 --with-tokens-list "<TOKEN_1_NAME>[desc:<TOKEN_1_DESC>][<TOKEN_1_SIZE_GB>];<TOKEN_2_NAME>[desc:<TOKEN_2_DESC>][<TOKEN_2_SIZE>]"   \
 --public-cache-size <PUBLIC_SPACE_SIZE>;
</verbatim>
</pre>
Where _$VDT_LOCATION_ is a directory of  Xrootd installation, <br/>
_user_ name of the non-privileged user that runs Xrootd (this user SHOULD have a login shell) <br/>
_hostname_ that FQDN of redirector  host <br/>
_storage_cache_ is the name of a directory that hosts actual data. Files under_cache_ is not visible to users.<br/>
_storage_path_ is the name of a directory that contains symbolic links to actual files in _cache_. Xrootd clients have access to _storage_path_.<br/>
_TOKEN_NAME_,_TOKEN_SIZE_ should matched tokens described in the !BeStMan configuration . If you  are not using static space tokens you should skip this option. <br/>
_PUBLIC_SPACE_SIZE_ is the size of storage area (in GB) allocated for public use (are not reserved with a particular space token)   
 

---++ Xrootd redirector node Configuration

<pre class="screen">
cd &lt;VDT_LOCATION&gt;
. setup.sh 
$VDT_LOCATION/vdt/setup/configure_xrootd \
 --server y \
 --user &lt;user&gt; \
 --this-is-xrdr \
 --xrdr-storage-path &lt;storage_path&gt; \
 --xrdr-storage-cache &lt;storage_cache&gt; \
 --with-tokens-list "&lt;TOKEN_1_NAME&gt;[desc:&lt;TOKEN_1_DESC&gt;][&lt;TOKEN_1_SIZE_GB&gt;];&lt;TOKEN_2_NAME&gt;[desc:&lt;TOKEN_2_DESC&gt;][&lt;TOKEN_2_SIZE&gt;]"   \
 --public-cache-size &lt;PUBLIC_SPACE_SIZE&gt;
</pre>
 
Where _$VDT_LOCATION_ is a directory of  Xrootd installation, <br/>
_user_ name of the non-privileged user that runs Xrootd (this user SHOULD have a login shell) <br/>
_storage_cache_ is the name of a directory that hosts actual data. Files under_cache_ is not visible to users.<br/>
_storage_path_ is the name of a directory that hosts  symbolic links to actual files in _cache_.  Xrootd clients have access to  _storage_path_.<br/>
_TOKEN_NAME_,_TOKEN_SIZE_ should matched tokens described in the !BeStMan configuration.If you  are not using static space tokens you should skip this option.   <br/>
_PUBLIC_SPACE_SIZE_ is the size of storage area (in GB) allocated for public use (are not reserved with a particular space token)   
 
---++ Start  the system 
You have to be root to start each service. You have to start all the components in the 
following order (this is order is optional but seems logical): 
   1. Start Xrootd redirector. Login on redirector node,  then: <pre class="screen">cd  &lt;VDT_LOCATION&gt; 
. setup.sh 
vdt-control –on
</pre> 
   1. Start Xrootd on all the data server nodes. Login on each Xrootd data server node, then:<pre class="screen">cd  &lt;VDT_LOCATION&gt; 
. setup.sh 
vdt-control –on
</pre> 
   1, Start !XrootdFS,!GridFTP and  !BeStMan. Login on !BeStMan node, then: <pre class="screen">cd  &lt;VDT_LOCATION&gt; 
. setup.sh 
vdt-control –on
</pre> 
   1. Start standalone !GridFTP servers. Login on each !GridFTP server node, then:  <pre class="screen">cd  &lt;VDT_LOCATION&gt; 
. setup.sh 
vdt-control –on
</pre> 

---++ Stop the system 
You have to be root to stop each service. You have to stop all the components in the 
following order (this is order is optional but seems logical): 
 
   1. Stop !XrootdFS,!GridFTP and !BeStMan. Login on !BeStMan node, then: <pre class="screen">cd  &lt;VDT_LOCATION&gt; 
. setup.sh 
vdt-control –off
</pre> 
   1. Stop standalone !GridFTP servers. Login on each !GridFTP server node, then: <pre class="screen">cd  &lt;VDT_LOCATION&gt; 
. setup.sh 
vdt-control –off
</pre>  
   1. Stop Xrootd redirector. Login on redirector node,  then: <pre class="screen">cd  &lt;VDT_LOCATION&gt; 
. setup.sh 
vdt-control –off
</pre> 
   1.. Stop Xrootd on all the data server nodes. Login on each Xrootd data server node, then: <pre class="screen">cd  &lt;VDT_LOCATION&gt; 
. setup.sh 
vdt-control –off
</pre> 

---++ System sanity check 
In order to verify that the system is functional you will need to download client package. Create a directory, e.g.  /opt/osg-client. Make sure there are no non-standard versions of perl, python, tcsh, or bash in your $PATH variable. 
We will refer to this directory as _&lt;VDT_LOCATION&gt;_.  

<pre class="screen"> 
cd &lt;VDT_LOCATION&gt;
pacman -get %CACHE%:client
. setup.sh 
</pre>
You will need to get your _voms-proxy_ certificate:
<pre class="screen"> 
voms-proxy-init –voms &lt;voname&gt;:/&lt;voname&gt;
</pre>
 
Execute srm-ping: 
<pre class="screen">
 srm-ping srm://&lt;BeStMan_host&gt;:&lt;secured_port_http&gt;/srm/v2/server 
 </pre>
Expected results:
<pre class="screen"> 
########################################### 
SRM_HOME is /usr/local/osg-client/srm-client-lbnl 
JAVA_HOME is /usr/local/osg-client/jdk1.5 X509_CERT_DIR = 
/usr/local/osg-client/globus/TRUSTED_CA 
GSI_DAEMON_TRUSTED_CA_DIR = /usr/local/osg-client/globus/TRUSTED_CA 
########################################### 
 
SRM-CLIENT: got remote srm object 
 
SRM-PING: Thu Sep 18 11:55:50 CDT 2008 Calling SrmPing Request... 
Ping versionInfo=v2.2 
 
Extra information 
        Key=backend_type 
        Value=BeStMan 
        Key=backend_version 
        Value=2.2.1.1 
        Key=GatewayMode 
        Value=Enabled 
        Key=gsiftpTxfServers 
        Value=gsiftp://osg-ress-2.fnal.gov 
        Key=clientDN 
        Value=/DC=org/DC=doegrids/OU=People/CN=Tanya Levshina 508821 
        Key=localIDMapped 
        Value=fnalgrid 
        Key=staticToken(0) 
        Value=DISK1 desc=DATA1 size=1073741824 
        Key=staticToken(1) 
        Value=DISK2 desc=DATA2 size=2147483648 
</pre> 
If you have reasonable result you may try to srm copy. In order to do so create a file _test1_ in _/tmp_ directory and execute: 
<pre class="screen"> 
srm-copy   file:////tmp/test1 srm://&lt;BeStMan_host&gt;:&lt;secured_port_http&gt;/srm/v2/server\?SFN=&lt;storage_path&gt;/test1 -spacetoken &lt;TOKEN_1_NAME&gt; 
</pre> 
You should get back something like that: 
<pre class="screen"> 
########################################### 
SRM_HOME is /usr/local/osg-client/srm-client-lbnl 
JAVA_HOME is /usr/local/osg-client/jdk1.5 X509_CERT_DIR = 
/usr/local/osg-client/globus/TRUSTED_CA 
GSI_DAEMON_TRUSTED_CA_DIR = /usr/local/osg-client/globus/TRUSTED_CA 
########################################### 
SRM-CLIENT: Thu Sep 18 11:57:09 CDT 2008 Connecting to 
httpg://cmswn086.fnal.gov:8443/srm/v2/server 
 SRM-CLIENT: Thu Sep 18 11:57:10 CDT 2008 Calling SrmPrepareToPutRequest 
now ... 
request.token=put:0 
status=SRM_SUCCESS 
explanation=null 
 
SRM-CLIENT: RequestFileStatus for SURL=file:////tmp/test1 is Ready. 
SRM-CLIENT: received TURL=gsiftp://osg-ress- 
2.fnal.gov//storage/local/data1/testxrootfs/test36 
 
SRM-CLIENT: Thu Sep 18 11:57:14 CDT 2008 start file transfer. 
SRM-CLIENT:Source=file:////tmp/test1 
SRM-CLIENT:Target=gsiftp://osg-ress- 
2.fnal.gov//storage/local/data1/testxrootfs/test36 
 
SRM-CLIENT: Thu Sep 18 11:57:22 CDT 2008 end file transfer. 
 
SRM-CLIENT: Thu Sep 18 11:57:22 CDT 2008 Calling putDone for 
srm://cmswn086.fnal.gov:8443/srm/v2/server?SFN=/storage/local/data1/tes 
txrootfs/test36 
 
SRM-CLIENT: Thu Sep 18 11:57:27 CDT 2008 end file transfer. 
 
SRM-CLIENT: Request completed with success 
 
SRM-CLIENT: Printing text report now ... 
 
SRM-CLIENT*REQUESTTYPE=put 
SRM-CLIENT*TOTALFILES=1 
SRM-CLIENT*TOTAL_SUCCESS=1 
SRM-CLIENT*TOTAL_FAILED=0 
SRM-CLIENT*REQUEST_TOKEN=put:0 
SRM-CLIENT*REQUEST_STATUS=SRM_SUCCESS 
SRM-CLIENT*SOURCEURL[0]=file:////tmp/test1 
SRM- 
CLIENT*TARGETURL[0]=srm://cmswn086.fnal.gov:8443/srm/v2/server?SFN=/sto 
rage/local/data1/testxrootfs/test36 
SRM-CLIENT*TRANSFERURL[0]=gsiftp://osg-ress- 
2.fnal.gov//storage/local/data1/testxrootfs/test36 
SRM-CLIENT*ACTUALSIZE[0]=15 
SRM-CLIENT*FILE_STATUS[0]=SRM_SUCCESS 
SRM-CLIENT*EXPLANATION[0]=SRM-CLIENT: PutDone is called successfully 
 
SRM-CLIENT: Thu Sep 18 11:57:27 CDT 2008 end file transfer. 
ExitCode=0 
</pre> 


If you turn on Gratia !GridFTP transfer probes you should be able to see the accounting information by accessing your Gratia collector. See details in  [[GratiaTransferProbe][Preparing, Installing and Validating Gratia transfer probe]].


 
---++ Troubleshooting – What could go wrong with such trivial tasks? 
 
If   sanity checks failed you would probably need to check the each component in order 
to verify what went wrong with your installation. In order to do so you should ,probably, 
check all them in the following order: 
   * Xrootd 
   * !XroodFS 
   * !GUMS (if in use) 
   * !GridFTP 
   * !BeStMan 

---+++ Verifying Xrootd 
Login on the node where you have installed !BeStMan, then 
<pre class="screen">
cd $VDT_LOCATION
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$VDT_LOCATION/xrootd/lib 
export LD_PRELOAD=$VDT_LOCATION/xrootd/lib/libXrdPosixPreload.so 
echo “This is a test” >/tmp/test 
cp /tmp/test xroot://&lt;XRDR_host&gt;:1094//&lt;XRDR_storage_path&gt;/test 
cp xroot://&lt;XRDR_host&gt;:1094//&lt;XRDR_storage_path&gt;/test /tmp/test1 
diff /tmp/test1 /tmp/test 
</pre>

---+++ Verifying !XrootdFS 
Login on the node where you have installed !XrootdFS, then 
<pre class="screen">
cd &lt;storage_path&gt;
echo “This is a test” >test1 
ls –l test1 
cat test1 
</pre>

---+++ Verifying !GUMS 
Make sure that the service certificate you are specified for !BeStMan  configuration with  
--cert &lt;service_cert&gt; , --key  &lt;service_key&gt;  options and !GridFTP service certificate are 
accepted by !GUMS  (see [[http://vdt.cs.wisc.edu/releases/1.10.1/notes/GUMS.html GUMS Installation Documentation]])   
 
Get mapping _uid_ for your certificate and verify that this _uid_ exists on !BeStMan and !GridFTP node. 
 
---+++ Verifying !GridFTP 
Login on the node where you have installed have your certificate installed and  access to %CACHE%:client.

You will need to get your voms-proxy certificate: 
<pre class="screen">
voms-proxy-init –voms &lt;voname&gt;:/&lt;voname&gt; 
</pre>

Then test !GridFtp: 

<pre class="screen">
cd $VDT_LOCATION 
. setup.sh 
echo “This is a test” >/tmp/test 
globus-url-copy -dbg file:///tmp/test gsiftp://&lt;GridFtp_host&gt;/tmp/test 
</pre>

---+++ Verifying !BeStMan
Make sure that !BeStMan is running and there is no error in the log file (_$VDT_LOCATION/vdt-app-data/bestman/logs/event.srm.log_). Login on the node where you have installed !BeStMan then

<pre class="screen">
[root@cmswn085 itb_bestman]# ps auxww|grep $VDT_LOCATION/bestman|grep -v grep
daemon   27648  0.0  0.0  4944 1168 pts/2    S    07:46   0:00 /bin/sh /usr/local/itb_bestman/bestman/sbin/bestman.server
daemon   27676  3.3  7.4 715240 155208 pts/2 Sl   07:46   1:59 /usr/local/itb_bestman/jdk1.6/bin/java -server -Xmx512m -Dorg.globus.tcp.port.range=20000,25000 -DX509_CERT_DIR=/usr/local/itb_bestman/globus/TRUSTED_CA -Daxis.ServerConfigFile=/usr/local/itb_bestman/bestman/conf/server-config.wsdd gov.lbl.srm.server.Server /usr/local/itb_bestman/bestman/conf/bestman.rc
</pre>

---++ List of utilized ports
|*Module Name*|*Port Number*| *Protocol*|
|!BeStMan| 8080 (default 10080)| tcp|
||8443 (default 10443)|tcp|
|!GridFTP|2811|tcp|
||lowPort,maxPort if needed to control outbound globus connections|tcp|
|!Xrootd redirector|1094|tcp|
||2094|tcp|
||1213|tcp|
|!Xrootd data server| opens random port selected by OS;|tcp|
|^|replace "xrd.port any" with a particular port in $VDT_LOCATION/xrootd/etc/xrootd.cfg| |

---++ Log file and configuration locations 
 
If any of the tests described above have failed or you are just curious to see what’s going 
on you could find log and configuration files for each of the module in the following 
location on a relevant node: 
|*Module Name*|*Configuration files*| *Log files*| 
|!BeStMan| $VDT_LOCATION/bestman/conf/bestman.rc |$VDT_LOCATION/vdt-app-data/bestman/logs/event.srm.log| 
|!GridFTP|$VDT_LOCATION/vdt/services/vdt-run-gsiftp.sh.env | $VDT_LOCATION/globus/var/log/gridftp.log <br/>$VDT_LOCATION/globus/var/log/gridftp-auth.log | 
|!XrootdFS |$VDT_LOCATION/xrootdfs/start.sh <br/>$VDT_LOCATION/xrootdfs/stop.sh |NA| 
|Xrootd – redirector |$VDT_LOCATION/xrootd/etc/xrootd.cfg  <br/>$VDT_LOCATION/xrootd/etc/xrootd_2.cfg  <br/>$VDT_LOCATION/xrootd/etc/StartXRD.cf  <br/>|$VDT_LOCATION/xrootd/var/logs/xrdlog  <br/>$VDT_LOCATION/xrootd/var/logs/cmslog  <br/>$VDT_LOCATION/xrootd/var/logs/ xrootd_cnd/xrdlog |
|Xrootd – data server| $VDT_LOCATION/xrootd/etc/xrootd.cfg  <br/>$VDT_LOCATION/xrootd/etc/StartXRD.cf |$VDT_LOCATION/xrootd/var/logs/xrdlog  <br/>$VDT_LOCATION/xrootd/var/logs/cmslog |
 
---++ Looking for help? 
The detailed information about each component can found on the following web sites: 
   * [[http://fuse.sourceforge.net  FUSE]]
   * [[http://wt2.slac.stanford.edu/xrootdfs/xrootdfs.html  XrootdFS]]
   * [[http://datagrid.lbl.gov/bestman BeStMan]]  
   * [[http://www.globus.org/toolkit/docs/3.2/gridftp  GridFTP]]
   * [[http://xrootd.slac.stanford.edu/papers/Scalla-Intro.htm  Xrootd]]
   * [[http://vdt.cs.wisc.edu/index.html current VDT cache]]


 
Numerous documents about storage solutions supported by OSG as well as other useful 
links could be found at [[https://twiki.grid.iu.edu/twiki/bin/view/Documentation/WebHome OSG Documnetation]]
 
See if your question is already answered under the [[https://twiki.grid.iu.edu/bin/view/Documentation/SETools%2cTips%2cFAQs FAQ section]] If not, please send all your questions to osg-storage@opensciencegrid.org  

---++ Known issues
   * None


---+++!!References
There are lots of references in this twiki to Bestman and Xrootd.
   * [[http://indico.fnal.gov/getFile.py/access?contribId=15&sessionId=26&resId=0&materialId=slides&confId=2538][Xrootd presentation on OSG Storage Forum]]
   * [[http://xrootd.slac.stanford.edu/doc/dev/xrd_config.htm][Xrootd XRD Config Reference]]
   * [[http://xrootd.slac.stanford.edu/doc/dev/cms_config.htm][Xrootd CMS Config Reference]] 
   * See BestmanGatewayXrootdUseCases for some site installation examples



%BR%
%COMPLETE2% %BR%
%RESPONSIBLE% Main.TanyaLevshina - 18 Feb 2009 %BR%
%REVIEW% Main.SuchandraThapa - 21 Jul 2009 %BR%
%REVFLAG% %X% %BR%

---++ *Comments*
| In the Stand-alone gridftp instructions, the user needs to run vdt-post-install to generate the prima conf files. | Main.SarahWilliams | 18 Nov 2009 - 21:02 |
| Same section, the user needs to edit prima-authz.conf to specify the correct location of their gums server. | Main.SarahWilliams | 18 Nov 2009 - 21:48 |
%COMMENT{type="tableappend"}%

<!-- CONTENT MANAGEMENT PROJECT
############################################################################################################
 DEAR DOCUMENT OWNER
 ===================

 Thank you for claiming ownership for this document! Please fill in your FirstLast name here:
   * Local OWNER = TanyaLevshina

 Please define the document area, choose one of the defined areas from the next line
 DOC_AREA = (ComputeElement|Storage|VO|Security|User|Monitoring|General|Integration|Operations|Tier3)
   * Local DOC_AREA       = Storage

 define the primary role the document serves, choose one of the defined roles from the next line
 DOC_ROLE = (EndUser|Student|Developer|SysAdmin|VOManager)
   * Local DOC_ROLE       = SysAdmin

 Please define the document type, choose one of the defined types from the next line
 DOC_TYPE = (Troubleshooting|Training|Installation|HowTo|Planning|Navigation|Knowledge)
   * Local DOC_TYPE       = Installation
  Please define if this document in general needs to be reviewed before release ( %YES% | %NO% )
   * Local INCLUDE_REVIEW = %YES%

 Please define if this document in general needs to be tested before release ( %YES% | %NO% )
   * Local INCLUDE_TEST   = %YES%

 change to %YES% once the document is ready to be reviewed and back to %NO% if that is not the case
   * Local REVIEW_READY   = %NO%

 change to %YES% once the document is ready to be tested and back to %NO% if that is not the case
   * Local TEST_READY     = %NO%

 change to %YES% only if the document has passed the review and the test (if applicable) and is ready for release
   * Local RELEASE_READY  = %NO%


 DEAR DOCUMENT REVIEWER
 ======================

 Thank for reviewing this document! Please fill in your FirstLast name here:
   * Local REVIEWER       = AlexSim
 Please define the review status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local REVIEW_PASSED  = %NO%


 DEAR DOCUMENT TESTER
 ====================

 Thank for testing this document! Please fill in your FirstLast name here:
   * Local TESTER         = FirstLast
 Please define the test status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local TEST_PASSED    = %NO%
############################################################################################################
-->

%META:FILEATTACHMENT{name="betsman_gateway_xrootd.jpeg" attachment="betsman_gateway_xrootd.jpeg" attr="" comment="BeStMan-gateway/Xrootd architecture" date="1235141572" path="betsman_gateway_xrootd.jpeg" size="35418" stream="betsman_gateway_xrootd.jpeg" tmpFilename="/usr/tmp/CGItemp11241" user="TanyaLevshina" version="1"}%
%META:FILEATTACHMENT{name="bestman-gateway-xrootd-howitworks.jpg" attachment="bestman-gateway-xrootd-howitworks.jpg" attr="" comment="!BeStMan Gateway with Xrootd - How it works" date="1237495053" path="bestman-gateway-xrootd-howitworks.jpg" size="52148" stream="bestman-gateway-xrootd-howitworks.jpg" tmpFilename="/usr/tmp/CGItemp8893" user="AlexSim" version="1"}%
