%META:TOPICINFO{author="RobGardner" date="1256358844" format="1.1" reprev="1.3" version="1.3"}%
%META:TOPICPARENT{name="GridColombiaWorkshop2009"}%
---+!! *<nop>%SPACEOUT{ "%TOPIC%" }%*
%TOC%

---++ Introduction
   * The purpose of this exercise is to setup a small test cluster that can be  used to illustrate creating a site capable of receiving Grid jobs and data.
   * It will have a minimal number of "head nodes" that will host various services such as a Condor job manager, an OSG gatekeeper and storage element.
   * It will have a two or more "compute nodes" that will receive and execute jobs.


---++ Site planning
   * Take a look at SitePlanning
   * Probably the first option will be to just use a gridmap file rather than a GUMS service
   * Identify which software (service) will be installed on which host.
   

---++ Identify the hosts and and assign their roles
Lets say your test grid cluster is going to have in its name,  "tg1",  and you have 7 machines.

   * =tg1-ce.yourdomain.org= a Compute Element (and cluster head-node) 
   * =tg1-se.yourdomain.org= a Storage Element 
   * =tg1-gums.yourdomain.org= a GUMS server
   * =tg1-nfs.yourdomain.org= an NFS server 
   * =tg1-ui.yourdomain.org=  your user interface machine
   * =tg1-c001.yourdomain.org= compute node 1
   * =tg1-c002.yourdomain.org= compute node 2
   * =tg1-c003.yourdomain.org= compute node 3
   
We may double up on services on some of the head nodes, and may add/subtract compute nodes (but you need at least one).  But this would be the basic host-role assignment.   You might call this your *node matrix*.

---++ The configuration
We will assume that all the machines are on the same network (public or private).  If the machines are all located on a private network, then the client machines attempting to submit jobs to the compute element (gatekeeper) would obviously need to be on that network as well.

---++ The machines
All machines are assumed to have a Linux OS installed. Linux releases differ for configuration and placement of files. These documents refer to Scientic Linux 5.3.  However, any Red Hat based Linux distribution (Fedora, !CentOS, etc.) should work fine.  You may have to adapt these instructions if you have something different (SUSE, Debian, or Gentoo for example).  A basic server installation is assumed. To simplify the cluster this configuration was used:
   * !SeLinux is disabled
   * =iptables= (firewall) is disabled 
   * =autofs= is disabled


%BR%
%COMPLETE3% %BR%
%RESPONSIBLE% Main.RobGardner - 23 Oct 2009 %BR%
%REVIEW%


---++ *Comments*
%COMMENT{type="tableappend"}%


<!--
   * Set USERSTYLEURL = https://twiki.grid.iu.edu/twiki/pub/ReleaseDocumentation/GridColombiaWorkshop2009/centerpageborder.css
-->
