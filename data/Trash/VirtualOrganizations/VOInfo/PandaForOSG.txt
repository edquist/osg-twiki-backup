%META:TOPICINFO{author="KyleGross" date="1225985921" format="1.1" version="1.4"}%
-- Main.UmeshkumarKeswani - 23 Apr 2007


%STARTINCLUDE%
---++ !!*PanDA and its implementation as !AutoPilot*
%TOC%


---++++ *What is !PanDA?*


!ATLAS processing and analysis places challenging requirements on throughput, scalability, robustness, minimal operations manpower, and efficient integrated data/processing management. To meet these computing challenges, US !ATLAS developed a Production ANd Distributed Analysis system aptly named PANDA.


Panda development began in August 2005 and and by December 2005 it took over production responsibilities for US !ATLAS. Within the !ATLAS production system Panda functions as a regional (!OSG) 'executor', interacting with an !ATLAS production system 'supervisor', to receive and report production work. It also operates as an end to end system in its own right, for both production and analysis workloads. Some of it key features being,

   * Designed from the beginning to support both managed production and individual users (analysis) via flexible job specification/injection
   * Designed to provide a coherent, homogeneous processing system over diverse and heterogeneous processing resources
   * Extensive [[http://gridui02.usatlas.bnl.gov:25880/server/pandamon/query][monitoring and browsing]]
      * Production and analysis operations, user analysis interfaces, data access, site status, logging system, Panda component monitoring 
   * Security via standard grid mechanisms -- see [[https://twiki.cern.ch/twiki/bin/view/Atlas/PandaSecurity][PandaSecurity]] 


For details on Panda implementation and its components, click [[https://twiki.cern.ch/twiki/bin/view/Atlas/PanDA][here]].

---++++ *What is !AutoPilot?*

In September 2006, a [[http://www.usatlas.bnl.gov/twiki/bin/view/AtlasSoftware/PandaExtensions][new effort]] began in collaboration with !OSG (and [[http://www.cs.wisc.edu/condor/][Condor]] ) to generalize Panda into a generic high level workload manager usable by anyone in the !OSG or wider grid community. An important part of this new effort is *AutoPilot*.


!AutoPilot is a simple and generic implementation of Panda pilot and pilot-scheduler for use in more varied environments than the production pilots and schedulers currently in use with Panda.

Panda pilot is a lightweight execution environment used to prepare the computing resources, request the actual payload (a production or user analysis job) from Panda server, execute it, and clean up when the payload has finished. Pilots are broadcasted from the Pilot Scheduler to the batch systems and the grid sites. 

!AutoPilot provides an pilot implementation that contains no US !ATLAS or !ATLAS specific content, such that it can be used in a wide range of contexts: within !ATLAS but outside !OSG, within !OSG but outside US !ATLAS, from an 'off-grid' laptop or workstation or batch queue, etc.


For details on !AutoPilot implementation, [[http://www.usatlas.bnl.gov/twiki/bin/view/AtlasSoftware/TestPilot][click here]].

------------

---++++ *Getting Started*
#GettingStarted

Before you begin submitting jobs to the !PanDA server or scheduling pilots to remote computing resources, there are a few of very important things that you are required to do. 
Things like obtaining a grid certificate, joining a VO, etc. For a detailed step by step guide on how to get started, please click [[https://www.racf.bnl.gov/docs/howto/grid][here]].

------------

---++++ *How to submit a job using !AutoPilot?*

To be able to submit a job to the PanDA server, you need a have a user account on a Linux/Unix machine with globus set-up and a grid certificate. To know how to obtain a grid certificate, click [[#GettingStarted][here]].

Once you have a Linux/Unix user account and a grid certificate, you log-in to your account and generate a new proxy certificate using the follwing command,
<pre>
grid-proxy-init
</pre>
On hitting enter/return, you would be asked to enter the GRID pass phrase that you had used while importing your grid certificate.
The 'grid-proxy-init' command will generate a new proxy certificate for you. A proxy certificate is a short-lived certificate which is used for delegation of rights to other entities.


To know more the usage of this and other Globus toolkit authorization commands, click [[http://www.globus.org/toolkit/docs/4.0/security/prewsaa/][here]].


Now that you have generated a proxy, you are all set to start submitting jobs to PanDA server. Follow the commands below,


*Note:* The file names _Setup.sh_, _Job.sh_ etc are just template file names. Generally these filenames are customized using the experiment name. For example, for a experiment named !CHARMM these file names are charmmSetup.sh, charmmJob.sh etc.
<pre>
Step 1) wget https://svn.usatlas.bnl.gov/svn/panda/autopilot/trunk/Setup.sh
</pre>
            Download set-up file from the code repository.

<pre>
Step 2) chmod +x Setup.sh
</pre>
            Change the mode. Now Setup.sh can be executed.

<pre>
Step 3) ./Setup.sh
</pre>
           Execute Setup.sh, which downloads Job.sh, Job.py along with some other code necessary for job submission.

<pre>
Step 4) ./Job.sh 
</pre>
           Finally, execute Job.sh. This sets up environment and input parameters for the job and submits the job to Panda.



These commands would setup the submission environment and submit a single Job. 
Hereafter, everytime you have to submit a new job, just repeat step 4.

-----------

---++++ *How to submit pilots using !AutoPilot?*

A pilot scheduler is already setup at UW, Madison on a server named condor-g-1.wisc.edu. You will have to first get an user account at condor-g-1.cs.wisc.edu. To get an account at condor-g-1.cs.wisc.edu, contact Torre at wenaus@bnl.gov .

Once you have that user account, you log into it and follow the commands below, 

<pre>
Step 1) cp ~wenaus/panda_setup.sh .  
</pre>
          Copy panda_setup.sh  to your home directory.

<pre>
Step 2) source panda_setup.sh .bashrc
</pre>
          Source panda_setup.sh to .bashrc.

<pre>
Step 3) Create a file mycron containing 0 3,9,15,21 * * * /hom e/wenaus/panda-osg/TestPilot/pilotCron.sh --tag=TagName --pandasite=SiteName
</pre>

<pre>
Step 4) crontab mycron
</pre>
            Register your cron.

<pre>
Step 5) /home/wenaus/panda-osg/TestPilot/pilotCron.sh --tag=TagName --pandasite=SiteName &
</pre>
             Do an initial launch of the pilot scheduler, the cron takes care of it thereafter.


_TagName_ is the label/tag given to a set of queues.
When you mention it in the command-line while launching the pilot scheduler, the scheduler submits pilots to only those queues that are tagged as _TagName_. A queue can be part of more than one tags.

_SiteName_ is the one of the important criterion while matching a pilot to a Job.
If the '--pandasite=' value of the pilot is not the same as the 'site=' value of the job (mentioned in _Job.py_), the job is not matched to that particular pilot. 

_TagName_ and _SiteName_ are generally the name of the experiment itself.

To set-up a new _SiteName_ or _TagName_,  contact Torre at wenaus@bnl.gov .

------------

---++++ *AutoPilot customized*

We will talk about the where and why of the experiment specific customizations to !AutoPilot while learning about the life-cycle of an !AutoPilot job.
Life of an !AutoPilot job can be divided into two phases. 'User Job submission' phase, where user submits the job to Panda server for execution and 'Remote Job execution' phase, where a remote computing resource actually executes the submitted job.

*User Job submission*

When a user submits the job, he/she executes _Job.sh_. Job.sh sets up the submission environment and also makes sure that all the input parameters required by the job are available.
_Experiment Customization_: Different experiments require different environments for their jobs. Also, input parameters to the job greatly vary from experiment to experiment. Input parameters like the executable file names, their location etc. Job.sh will need to be modified to incorporate all these changes.

Job.sh calls _Job.py_, which collects all the input parameters, bundles them together with the job and submits the package to Panda server.
_Experiment Customization_: As per the current Auto-Pilot implementation, Job.py needs to know the location of trans.sh file (explained below). This location may very from experiment to experiment. Job.py will need to be modified a change in trans.sh location


Once the job is submitted to Panda server, the sever reads all the computing requirements of the job. After reading, it matches this job with a remote resource that satisfies the jobs computing needs. Pilot scheduler schedules keeps on scheduling pilots on all the computing resources that are available to the Panda server. The scheduled pilot executes on the remote resources and  communicates with the Panda server, asking for a job. If the server has matched a job with a remote resources, it dispatches the job to the resource.


*Remote Job execution*

Once a job reaches the remote computing resources, _trans.sh_ is executed. It reads all the input parameters supplied along with the job and swings into action. Downloading the executables, input scripts and other files that may be required for execution. It basically supervises the whole execution process.
_Experiment Customization_: This is a very important file and generally undergoes many changes during customization. Thats because, this files supervises the remote execution process. This is the place where you implement your execution policy. Like, a job may have not one but multiple consecutive executables that are dependent on each other. In that case, this is the place where you write the code to get the output from one executable and give the same as input to another one ans so on. Also, you might want to submit another job as part of the current job execution. You can incorporate the code to submit a job here.
So, trans.sh will need to be modified to implement the experiment specific execution policies.


In the current implementation, trans.sh calls _run.sh_. run.sh is very tightly coupled with the executable. Checks whether all the input and restart (required to restart the job on some other machine, if need be) files exist or not. Creates the output and log files required by the executable. Executes the job executable and removes the temp files when finished.
_Experiment Customization_: Since it is so closely coupled with the executable, each executable needs a customized run.sh. Each executable reads different input files, writes to different number and type of output and log files, creates different temp files requirinf different clean up strategies, etc. run.sh will need to be modified to incorporate creating different files with different names and stored at different locations.

------------

---++++ *CHARMM Experience*

!AutoPilot is already in use by !CHARMM, a protein structure application that uses !OSG VO.
To know more about !AutoPilot implementation for !CHARMM, click [[https://twiki.grid.iu.edu/twiki/bin/view/VirtualOrganizations/VOInfo.PandaForCharmm][here]].
