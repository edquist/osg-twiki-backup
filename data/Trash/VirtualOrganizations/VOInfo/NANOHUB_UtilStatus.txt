%META:TOPICINFO{author="IlyaNarsky" date="1158956077" format="1.1" reprev="1.11" version="1.11"}%
%META:TOPICPARENT{name="WebHome"}%
</verbatim>

---++ Update on September 20 2006

!NANOHUB now submits jobs on a regular basis to two more sites: !UWMadisonCMS and UC_ATLAS_MWT2. Monalisa is now properly reporting on GRASE-CCR-U2. UNM_HPC is also being used for !NANOHUB jobs.

---++ Status of Atlas T2 sites utilization as of September 8

<verbatim>
Brookhaven (gridgk02.racf.bnl.gov) - condor   No support nanoHUB VO 2536 slots
U Indiana (bandicoot.uits.indiana.edu) - pbs  Authenticates 3/4 time 8 slots
U Chicago (tier2-osg.uchicago.edu) - condor   Authenticates 3/4 time 100 slots
UT Arlington (atlas.dpcc.uta.edu) - pbs       No support nanoHUB VO 140 slots
Boston U (atlas.bu.edu) - pbs                 Not authentication    168 slots
Oklahoma U (ouhep0.nhn.ou.edu) - ?            No support nanoHUB VO
</verbatim>

Submitted a GOC ticket about authentication failures at Brookhaven, UT Arlington, and Boston U.

---++ Status as of September 6

Nanohub is successfully running jobs on GRASE-CCR-U2, OSG_LIGO_PSU, and VAMPIRE-Vanderbilt. GRASE-CCR-U2 is not reporting to Monalisa (or GIP for that matter). I (Ilya) will let GOC know. Nanohub does not run on UNM_HPC anymore because that site is slow. Purdue_ITAP is not used actively either because it is generally busy and seems less reliable than others.

Steve Clark is going to look into running on the Atlas T2 sites in the near future, especially those that use PBS. 

So far, nanohub has been running only on PBS sites. As far as submissions to Condor, they need rto un jobs in the standard universe because vanilla universe does not provide checkpointing. Without switching from vanilla to standard, there are two ways to solve this problem:
   * To some extent, Nanohub jobs are capable of performing suspend-and-resume at the application level. If they can develop this functionality, they may not need checkpointing provided by Condor.
   * Nanohub could negotiate with site admins on batch pre-emption policy. Now they can split one run into ~100 jobs, with each job running for ~2 hours at a typical !OSG site. I suggested that a local site admin might want to give the Nanohub jobs low priority but implement the pre-emption policy in such a way that once a Nanohub job is started, it is not preempted or not preempted for a certain period of time. Condor allows to implement such a policy.

---++ Status as of August 25 2006

The eviction problem has apparently been resolved. The problem was caused by a condition with the local enhanced version of the gahp_server. Frequent failures with GAHP combined with a globus_resubmit condition caused periodic restart of jobs. A change in the globus_resubmit condition has reduced the number of evictions.

The current limitation now appears to be disk quota. Failed jobs do not cleanup properly leaving behind approximately 100MB of data. Since we are running under the nanoHUB home directory quota limits apply are being reached at Buffalo. PSU-LIGO is setup differently with the net effect that we can operate with a higher quota although this could change at any time.

The proper solution is to run the jobs under $OSG_DATA. We are looking for way to easily do this through CondorG. In the multi-site environment it would be preferred to use the symbolic name OSG_DATA rather than a real and potentially different name at each OSG site.

---++ Status as of August 22 2006

As you all are probably aware of by now I have started another set of nanoHUB
bioMOCA jobs at your respective sites (GRASE-CCR-U2, OSG_LIGO_PSU, VAMPIRE-Vanderbilt).
We have made progress in building a
process that should complete a single simulation from a parameter sweep of
90  simulations in about 9-10 days. This was accomplished by having the code
write  restart files at frequent intervals and using condor dag to organize the
simulation and data exchange process.

The good news is the individual simulation pieces do run and left to their own
devices run well and complete. Unfortunately the jobs at all three sites are
being prematurely evicted. When this happens any simulation time is wasted
and no results are returned.

It seems to me to be beyond coincidence that this same behavior is
happening  at all three sites. Does anybody have any thoughts on
what could cause such behavior?

To put a number on it 1235 jobs have been evicted, 414 jobs terminated
normally. This is definitely a high burn rate.

---++ Status as of August 21 2006

New blocks of simulations were sent to PSU-LIGO, Vanderbilt, and GRASE-CCR.
Jobs at PSU-LIGO are being prematurely evicted. Jobs at GRASE generate Globus error 22: the job manager failed to create an internal script argument file. I have temporarily lost contact with the jobs at Vanderbilt due to a Condor issue at nanoHUB.

---++ Status as of August 14 2006

Nanohub is currently not running any production due to a problem with Condor or Globus.
The problem appeared when Steve Clark was on vacation. The problem only affects
a fraction of jobs, large enough to stall the full-fledged production. May have something to do with
updated Condor binaries. May have something to do with Condor transferring big files
for Nanohub applications. Alain Roy and Jaime Frey are looking into this.

No attempts to include new sites have been made since July.

---++ Status as of July 12 2006

Currently nanoHUB is helping researchers at !UIUC conduct a simulation study of
ion transfer in artificial membranes. The simulation study is being used to
investigate a wide parameter space involving several variables. Each
simulation is expected to require from one to six weeks to complete on a
single processor. In total the plan is to run more than one thousand of these
individual simulations to study the impact of the various parameters.

!OSG provides a unique resource to be able to accomplish the objective. Several
members of !OSG have accepted jobs and nanohub is working to recruit more willing
members.

More information about the simulation tool can be found 
  [[https://www.nanohub.org/simulation_tools/biomoca_tool_information][here]].

A nanohub application requires 6-10 days to run on a typical !OSG site.

Nanohub jobs run successfully at Purdue and !UNM. The run time cutoff there
is 45 days.

Nanohub jobs are set up in principle to run at Penn State (!OSG_LIGO_PSU) and
Vanderbilt (vampire.accre.vanderbilt.edu) but these sites do not allow jobs longer than 2 days.  Nanohub
applications need a suspend-and-resume functionality at the application level. 
Nanohub is working on it now.

Running nanohub jobs at Fermilab has been difficult in general. There is
no run time limit but nanohub jobs are run at a low priority and so they
are preempted by other jobs. Effectively there is a short run time limit,
20 mins to half an hour, due to this preemption.

Caltech (CIT_CMS_T2) and Buffalo sites offered to run nanohub
applications. Nanohub also had some discussion with Florida_PG and there
is no objection on Florida's part to running nanohub. These sites do not
enforce a run limit policy.

Nanohub is looking to expand the list of sites they can run on, with help from applications coordinators and the !OSG executive team.
%META:FILEATTACHMENT{name="W_005_grid3.aset.psu.edu_20061214.pdf" attr="" autoattached="1" comment="Job state history" date="1166144129" path="W_005_grid3.aset.psu.edu_20061214.pdf" size="1952572" user="Main.StevenClark" version="1"}%
%META:FILEATTACHMENT{name="W_007_cmsgrid01.hep.wisc.edu_20070119.pdf" attr="" autoattached="1" comment="Create a link" date="1169255205" path="W_007_cmsgrid01.hep.wisc.edu_20070119.pdf" size="2268620" user="Main.StevenClark" version="1"}%
%META:FILEATTACHMENT{name="N_008_vampire.accre.vanderbilt.edu_20070112.pdf" attr="" autoattached="1" comment="Job state history" date="1168647593" path="N_008_vampire.accre.vanderbilt.edu_20070112.pdf" size="2277896" user="Main.StevenClark" version="1"}%
%META:FILEATTACHMENT{name="N_006_tier2-osg.uchicago.edu_20061130.pdf" attr="" autoattached="1" comment="Job state history" date="1164923336" path="N_006_tier2-osg.uchicago.edu_20061130.pdf" size="2616158" user="Main.StevenClark" version="1"}%
%META:FILEATTACHMENT{name="N_003_grid3.aset.psu.edu_20070112.pdf" attr="" autoattached="1" comment="Job state history" date="1168647425" path="N_003_grid3.aset.psu.edu_20070112.pdf" size="1723252" user="Main.StevenClark" version="1"}%
%META:FILEATTACHMENT{name="N_009_eckert.acis.ufl.edu_20061116.pdf" attr="" autoattached="1" comment="Job state history" date="1163719226" path="N_009_eckert.acis.ufl.edu_20061116.pdf" size="262714" user="Main.StevenClark" version="1"}%
%META:FILEATTACHMENT{name="N_006_tier2-osg.uchicago.edu_20070119.pdf" attr="" autoattached="1" comment="Job state history" date="1169254757" path="N_006_tier2-osg.uchicago.edu_20070119.pdf" size="3344835" user="Main.StevenClark" version="1"}%
