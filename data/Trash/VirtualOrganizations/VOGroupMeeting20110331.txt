%META:TOPICINFO{author="GabrieleGarzoglio" date="1301599816" format="1.1" version="1.2"}%
%META:TOPICPARENT{name="Meetings"}%
---++ *VO Group Weekly Forum | March 31, 2011*

   * Thursdays 1:30 PM Central Time. 
   * Phone: 866-740-1260, ID: 2460335 

---++ Attending
Rick St.Denis, Chander Sehgal, Mine Altunay, Steve Timm, John McGee, Marco Mambelli, Rob Quick, Richard Jones, Horst Severini, Gabriele Garzoglio


---++ Previous Minutes 

[[VOGroupMeeting20110324][Weekly Forum: March 24]] 

---++ Announcements

Chander: we are working to bring in tutorials to the VO forum. Tutorials so far have been manly on technologies and tools. If you are interested in a specific subject, please let us know and we'll try to organize it.

Rob Quick (Operations)
We have relesaed a new VO Package on Tue. 
We are now working on the IU campus VO and on a campus factory at IU.


---++  VOs In Focus 

---+++ Engage/NEES
Not available.

---+++ !SBGrid
Not available.

---+++ SURAGrid (Rob Quick)

We are working with SURAGrid to make available DOE Grids certificates.
We are now organizing a Registration Authority within the CA. 
Identified 1st-level sponsor. SURAGrid is now working on identifying site-level sponsors.


---+++ CDF (Rick St.Denis)
Running production at KISTI. We have copied several dataset for reprocessing.

KISTI has schedule a downtime on Apr 12. KISTI is buying disk to increase local space at worker nodes. Reorganizing local disk areas (/home area for LCG and /tmp for OSG). Upgrading the network with a new 2 GB link. Upgrading site storage with 100 TB for SAM Cache.

Keith has just come back from a visit at KISTI. CDF is interested in feedback from him.

Rick has recommended KISTI admin for the summer school. Also Gabriele did.

Staging ntuple to run analysis jobs in the summer at FermiGrid, KISTI and CNAF. Not enough space at Fermilab alone.
Moving up 100 dataset from 1 TB to up to 14 TB. Major portion of our analysis. For example, moving 160 TB to CNAF, Bologna, Italy.
Users can submit at Fermilab or offsite. We are ensuring that offiste have CDF software installed.

To use new sites, CDF needs SAM there. Looking for at least 100 TB of SAM cache at sites. Difficult to obtain it opportunistically.
500 -1000 nodes is considered a significant contribution. Need to take care of not saturating data handling system.
How much local disk do your jobs need per core? 20 GB/ slot.
We can manage with 10 GB / slot for some applications.

---+++ GLUE-X (Richard Jones)
Our opportunistic resources are currently used as follows: 3/4 SBGrid and 1/4 DZero.
Working on software issues for montecarlo.

How do people manage dCache when there are multiple applications with different requirements?
We are embedding the right token in the directory to do appropriate space reservation, but I see a violation of that. Discussing possible interaction with resiliency management.
Feel free to contact storage experts at osg-storage@opensciencegrid.org.

We have 1 student going to the summer school.



---+++ Enagage (John McGee)
We have a problem with throughput for our VO. We cannot run more than 1000 - 1500 jobs. This seems related to our submission engine i.e. OSG MM. It is NOT an issue with the hardware.
Currently 1300 jobs running at FermiGrid. For example, no jobs at UConn: why are they not matching?
We are currently working on a Glidein WMS deployment. Exploring if it can address this problem.
Chander: please feel free to reach out for help.

Steve Timm: One of the main issues is that there is no good way to advertise the memory per slot via the Glue Schema.

Looking into requesting temporary storage beyond a few 100s GB. We prefer to use POSIX.
It should be possible to find O(500 GB) of space to loan for a short time. It can be typically exposed as OSG_DATA.
Every job reads this 500 GB.
Marco: you may want to itegrate data retrieval via http and use Squid caches to do this.


---+++ Fermilab-VO (Steve Timm)
No news from last week.

-- Main.GabrieleGarzoglio - 31 Mar 2011