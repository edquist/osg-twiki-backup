%META:TOPICINFO{author="AbhishekSinghRana" date="1229597805" format="1.1" version="1.14"}%
%META:TOPICPARENT{name="WebHome"}%
---+!! *Joint ALICE-OSG Taskforce* <br>to enable ALICE on Open Science Grid<br>
%TOC%
---++ Key Expertise

*Iwona Sakrejda*, *Shreyas Cholia* - NERSC. Technical expertise on (ALICE)-OSG operations.<br>
*Pablo Saiz* - EU ALICE. Technical expertise on ALICE-(OSG) operations.<br>
*Latchezar Betev*, *Federico Carminati* - EU ALICE.<br>
*Ron Soltz*, *Jason Newby* - US ALICE. And, LLNL.<br>
*Alain Roy* - OSG Software, *Burt Holzman* - OSG Interoperability, *Mine Altunay* - OSG Security.<br>
*David Skinner*, *Jeff Porter* - NERSC. <br>
*Ruth Pordes*, *Miron Livny* - OSG. <br>

---++ Strategy and Goals

   * Understand more clearly the actual operational interaction of VO-Box/AliEn model with OSG model.
   * %RED%Understand the high-end hardware requirements for a VO-Box to get a view of usage limits and of scalability, considering average to full-scale heavy-duty 'job volume' by ALICE users.%ENDCOLOR%
   * Deploy VO-Box stack on top of OSG 1.0 stack, at NERSC, running ALICE jobs, then evaluate software stack commonalities and any issues from real operational experience.
   * Discuss expansion plan to more OSG sites, and corroborate on resolving any known severe technological barriers.
   * Expand to LLNL as the second ALICE OSG site.
   * Look at more sites if all has gone well. 

---++ VO-Box Security Policy Specification

Please see [[%ATTACHURL%/VO-Box-security-policy_v05.doc][VO-Box-security-policy_v05.doc]].

---++ !JobAgents, Site Proxy, Central Task Queue

ALICE uses generic pilots (!JobAgents), which fetch the payload 
from the ALICE central task queue. The Site Proxy (SP) service running 
on the VO-box, forwards the !JobAgent request to the central Task 
Queue (TQ).

In sum, the !JobAgent communicates with the SP, and the SP is the one that communicates with the central TQ. 

---++ Phase-1 Operational Summary (Pablo, Iwona)

To sum up the exercise, we managed to run ALICE jobs using the OSG software. We did it in two ways: first submitting from NERSC to the worker nodes using ==condor_submit== and requesting to submit to *pdsfgrid.nersc.gov/jobmanager-sge*. 

When that worked, we tried also sending to other sites, such as *osp1.lbl.gov/jobmanager-pbs* and *osg-edu.cs.wisc.edu/jobmanager-condor*. After landing on the worker nodes, a script installed !AliEn (if it had not been installed before) and start a !JobAgent that requested ALICE jobs. This second scenario also worked.

This is the updated list of issues in order of importance:

Case 1: If we want to run only at NERSC:

   * %RED%If we want to run this on production mode, we will need either some kind of proxy renewal or a service certificate without passphrase that can be used to create proxies on the fly.%ENDCOLOR%

   * There were some problems because the jobagents landed in worker nodes with the wrong platform. We fixed it by creating a ==$HOME/.sge_request== file, specifying the SGE queue and requirements. %RED%There was some discussion about passing the arguments from condor to SGE.  It is not clear if there was any conclusion, though. %ENDCOLOR%

   * X509_CER_DIR. %RED%The VO-Box needs to authenticate both to the ALICE servers and to the OSG servers%ENDCOLOR%. Therefore, this environment variable has to point to a directory that contains all of the CAs. At the moment, ==/chos/common/lx_local/pkg/OSG-1.0.0/globus/TRUSTED_CA== doesn't contain the !AliEn CA, so we setup the variable to point to the CAs distributed with !AliEn (ALICE distributes some of the CA of OSG, but not all). %RED%For the time being it works, but if OSG can decide to include a new CA%ENDCOLOR% - for e.g., in ==/chos/common/lx_local/pkg/OSG-1.0.0/globus/TRUSTED_CA==, %RED%ALICE will have to put it also in the CA distributed by !AliEn%ENDCOLOR%.

Case 2: If we want to run also on other sites:

   * The high ports on *pdsfvo.nersc.gov* are not visible from other sites. ALICE will need to have these open. %RED%We need to open at least ports 1094,8082,8084,8085 and 9991%ENDCOLOR%.

   * When Pablo submits to *osg-edu.cs.wisc.edu*, mapping is received to a generic user (osgedu.users). [<u>Question from Pablo</u>: There is a lot of software installed by other users mapped to the same generic user. Pablo hasn't tried, but it looks like he have the right to delete other software. Does it mean that any of these users can also delete Pablo's installs? <u>Answer from Alain</u>: Yes indeed. If you have a real need to run at the site (I thought it was just for testing), we can map you to a unique user. We have almost no resources at the site though--it's really only good for testing purposes.]

All the other known issues have been solved. 

---++ Items Open for Discussion

   * Site Authorization: %RED%ALICE VOMS server needs to be known to OSG sites?%ENDCOLOR%
   * VO Accounting: %RED%ALICE FQANs and other details?%ENDCOLOR%
   * Job Accounting: %RED%How best to do accounting of ALICE "jobs"?%ENDCOLOR%
   * Security Risk: %RED%ALICE VOMS server and related user banning policies in event of a security breach at CERN?%ENDCOLOR%
   * VO Registration: %RED%Usual OSG GOC procedure?%ENDCOLOR%

---++

---++ ALICE-OSG Meeting on Dec. 17 2008 

*Agenda*

%BLUE%
1. Proof of concept at LBNL, discussion of "operational" work accomplished, remaining "concerns". <br>
2. "Security" and Policy related topics. <br>
3. "Changes needed" in !AliEn software stack, if any. <br>
4. "Changes needed" in OSG software stack, if any. <br>
5. "Expansion" plan to add LLNL, and 1-2 more ALICE sites. <br>
6. "Planning" discussion to draw out a plan for future production-level ALICE operations on OSG. <br>
%ENDCOLOR%
 
*Coordinates*

%BLUE%
Wednesday, Dec. 17 <br>

7:30-8:30am Pacific / 9:30-10:30am Central / 4:30-5:30pm CERN time.  <br>

US Phone: 866-914-3976, Access ID: 923489# <br>
International Phone: +1-925-423-8104,  Access ID: 923489# <br>
%ENDCOLOR%

*Minutes*

Meeting: Joint ALICE-OSG Teleconference, Dec 17 2008
Participants: Ron, Iwona, Jeff, Pablo, Federico, Alain, Jason, Ruth, Mine, Abhishek

We discussed a subset of items highlighted in red at -- http://twiki.grid.iu.edu/bin/view/VirtualOrganizations/ALICE_OSG

General conclusion was that convergence is now near in sight, but this Phase-I can stay open till we implement a solution for proxy renewal, and until we demonstrate a larger-scale volume of jobs. Phase-II will be geared more toward expansion.

Sincere gratitude to everyone who made an extra effort to join despite rough weather and other logistical problems. Thanks to Ron Soltz for organizing the teleconference and for helping with the following minutes.

=== Item 1. Hardware Specifications ===

Miron had asked Abhishek to find views on: what are the high-end hardware requirements for VO-Box nodes to run full-scale production? Federico mentioned that a modern 8-core system with 16GB memory should be sufficient. For more specifics, Federico has sent link to a monitoring page that shows specifications of various sites -- http://pcalimonitor.cern.ch/stats?page=vobox_status . Iwona noted that sometimes Condor is slow at NERSC; Alain clarified that this is likely to be not related to hardware. [Jeff to look in more detail at NERSC.]

=== Item 2. Proxy Renewal ===

By design, VO-Box cannot operate beyond 24 hours with a regular short-lived proxy. Hence, there is a requirement for a proxy renewal mechanism, or otherwise for using unencrypted service certificates. This is currently the most high-priority item. NERSC has access to a local MyProxy server, and other certificate related services. Iwona and Jeff suggested there is possibility to use the same, and will look into it. Mine has started the process of identifying various options for ALICE, weighing advantages and risks, from an OSG security perspective. [Pablo to provide more insight to converge on the most suitable option.] [Iwona and Jeff to look into NERSC solution.]

=== Item 3. Batch Queue specification ===

If ALICE has a need to specify batch queue while making a job submission. Pablo says it is not clear if this is well understood. Iwona thinks if a configuration parameter change is needed, it can be done soon. [Iwona, Jeff, Alain, Pablo to continue to discuss more details.]

=== Item 4. Open Ports ===

In the hybrid model being investigated, a VO-Box on OSG is used to submit to local as well as to other sites on OSG. On these other sites, after landing at a WN, auto-install of AliEn is done and a JobAgent started to request ALICE jobs. The machine with VO-Box needs to have certain ports opened to the world. Mine indicated that OSG security does not regulate this, and if a site is in agreement with opening more ports, it is under site's own discretion. Because plan is to have only a handful of VO-Boxes, this may not be difficult to accomplish.

=== Item 5. CA Certificate Availability ===

VO-Box needs to authenticate to various servers, and this requires presence of AliEn CA. This is required on the site with the VO-Box, and may also be needed on the other sites where jobs execute. The latter was not clear and needs to be further discussed. Both CA distributions may need to be considered: OSG CA as well as AliEn CA. Alain told Pablo that OSG CA distribution can be provided as tarball to ALICE if needed. [More discussion expected in near-term.]

=== Item 6. Moving Forward: AliEn/OSG Needs ===

Based on the experience so far, there is no known change needed in the software stacks of OSG and AliEn. As soon as a solution is put in place for proxy renewal, the current model can be considered fit for moving forward. Federico, Ruth, Ron, Abhishek agreed that we need to demonstrate a larger-scale volume of job submission/execution. All agreed that full-scale testing that follows with a large number of jobs will be important. Hence, this is expected to be covered as part of the ongoing Phase-I.

=== Item 7. Moving Forward: Expansion to more Sites with VO-Boxes ===

Ron agreed that if current model succeeds in full-scale testing at NERSC, a forward path will be to proceed to adopt at other sites in the US: LLNL, Houston, Ohio. Ron thinks that LLNL can prepare by installing OSG client stack and Condor Batch Queue on the VO-Box node. Alain said that OSG supports a wide range of batch systems, and is open to sites with different batch systems. Foreseeable plan is to install a VO-Box each on 4 sites: NERSC, LLNL, Houston, Ohio -- Ron can provide liaison and facilitate. Ruth mentioned there are 2 sites in Brazil which can also be considered -- Federico can provide liaison and facilitate. Benefiting from key expertise at NERSC -- Iwona, Jeff, Shreyas -- will be useful. Abhishek thinks this can be structured as Phase-II of the Taskforce.

---++


-- Main.AbhishekSinghRana - 12 Nov 2008

%META:FILEATTACHMENT{name="VO-Box-security-policy_v05.doc" attachment="VO-Box-security-policy_v05.doc" attr="h" comment="" date="1229509319" path="VO-Box-security-policy_v05.doc" size="240640" stream="VO-Box-security-policy_v05.doc" tmpFilename="/usr/tmp/CGItemp8273" user="AbhishekSinghRana" version="1"}%
