%META:TOPICINFO{author="AbhishekSinghRana" date="1197186394" format="1.1" reprev="1.2" version="1.2"}%
%META:TOPICPARENT{name="WebHome"}%
---+!! OSG 1.0 Planning: Requirements set forth by VOs

---++!! Overview

The next major middleware release, OSG 1.0, is scheduled for a February 2008 rollout. This is a list of requirements being set forth by the VO community, in view of needs and expectations of running applications on OSG 1.0. If needed for reference, please see [[https://twiki.grid.iu.edu/twiki/bin/view/ReleaseDocumentation/SiteValidationTable#VO_validation][archived ITB 0.7 validation table]] with results of activity immediately prior to OSG 0.8 release. 

%TOC%

---++ *ATLAS*

*Modular packages/components*

   * Site admin can choose to install/uninstall a stand-alone component (such as GIP) without installing the whole OSG CE.                                                                                           
                                                                                                                                                 
*GUMS*                                                                                                                                                               

   * Map voms proxies from a particular user but different VOs to different pool accounts, even if all pool accounts are in one persistence factory.                                                                                             

*Globus Gatekeeper*                                                                                                                                                    
                                                                                                                                                                      
   * In general, improved gatekeeper scalability and fault tolerance.                                                                                                                                                                                                                                                                         
   * Load balancing w/ LVS (?)                                                                                                                                       
   * High availability                                                                                                                                               
                                                                                                                                                                                                                                                                                                                                      
   * Some kind of CE throttling to prevent CE from being impacted by !DoS.                                                                                               
   * Quota based on # jobs in batch system     
   * Quota by user and/or VO                                                                                                                                         
   * Throttling by CE load (?)                                                                                                                                       
                                                                                                                                                                       
*Globus JobManager*
                                                                                                                                                                      
   * Some mechanism to add processing to condor.pm (plugin), e.g., to add custom site-specific flags based on user, group, etc.                                                                                                                
                  
*RSV/Service availability monitoring*

   * A complete set of baseline service availability probes to monitor LHC Tier 1/Tier 2 services (CE, SE/SRM, FTS, MyProxy, BDII).  The test results can be easily integrated into site admin monitoring server (such as Nagios).                                                                                                                                                             

   * OSG availability monitoring needs to inter-operate with WLCG.  
   * a single web interface (gridview) shows WLCG/OSG/EGEE availability metrics.
   * scheduled downtime should be recognized by OSG availability monitoring, and availability metric should properly reflect the service downtime.                                                                                                                                                            

*GRATIA / Accounting*                                                                                                                                                 

   * Add ability to define subclusters, and specify submission method such                                                                                             
 that an accounting record is a triple (subcluster, submit host, user-vo). Or                                                                                         
 at least have an implicit mechanism for multiple Gratia instances run on                                                                                             
 different submit hosts to report records as part of a single site.                                                                                                   

*GIP*       

   * Support SRM 1 and SRM 2 (dCache Cell information provider,  xrootd), and allow SRM admin to easily publish static/dynamic information to OSG.

*BDII and/or WLCG BDII*

   * Make plugin that allows the site admin to fine-tune reported info, e.g., reporting each Condor VM as job slot instead of dividing by 2 or 4.

*Network performance test*
                                                                                                                                                                      
   * iperf:  Authorized users can remotely start an iperf server by running globus-job-run to test the network performance.                                                                                                                      

---++ *CDF*
---++ *CMS*
---++ *<notwiki>CompBioGrid</notwiki>*
---++ *DOSAR*
---++ *Dzero*
---++ *Engagement*
---++ *Fermilab VO*
---++ *LIGO*
---++ *nanoHUB*
---++ *SDSS/DES*
---++ *STAR*



-- Main.AbhishekSinghRana - 09 Dec 2007

