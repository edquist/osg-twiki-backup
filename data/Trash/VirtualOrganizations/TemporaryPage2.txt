%META:TOPICINFO{author="AbhishekSinghRana" date="1265623929" format="1.1" reprev="1.6" version="1.6"}%
%META:TOPICPARENT{name="WebHome"}%
---+!! *<nop>%SPACEOUT{ "%TOPIC%" }%*
%TOC%

%STARTINCLUDE%

*Purpose*: The purpose of this document is to provide Hadoop based SE administrators the information on how to prepare, install and validate the SE.

---++ Preparation
---+++ Introduction

Hadoop Distributed File System (HDFS) is a scalable reliable distributed file system developed in the Apache project. It is based on map-reduce framework and design of the Google file system. The VDT distribution of Hadoop includes all components needed to operate a multi-terabyte storage site. Included are:
   * An SRM interface for grid access; 
   * !GridFTP-HDFS as transport layer; and  
   * A FUSE interface for localized POSIX access.

The VDT packaging and distribution of Hadoop is based on YUM. All components are packaged as RPMs. Two YUM repositories are available: 
   * Stable repository for wider deployments and production usage.
   * Testing repository for limited deployments and pre-release evaluation.

Please note that this distribution is independent of the Pacman packaging of the VDT: it is separately versioned, and separately packaged. We expect future releases to eventually be common with the rest of the VDT, as the "rest" of the VDT begins to be packaged as RPMs. For now, the VDT distribution of Hadoop is distinct from the rest of the VDT.

The *stable YUM repository* is enabled by default through the *osg-hadoop RPM*, and contains the *golden release* supported by OSG for LHC operations. The VDT download webpage is http://vdt.cs.wisc.edu/components/hadoop.html

---+++ Architecture

---++ Installation

Please read the [[Storage.HadoopUnderstanding][planning document]] to understand different components of the system. 

Main server components can be divided in 3 categories: 
   * HDFS core: Namenode, Datanode.
   * Grid extensions: !BeStMan SRM, Globus !GridFTP, Gratia probe, and Xrootd server plugin, etc.
   * HDFS auxiliary: Secondary Namenode, Hadoop Balancer.

Main client components are FUSE and Hadoop command line client.

---+++ Java

The Hadoop RPMs require Sun Java JDK 1.6.0 or later. You can download it from http://java.sun.com. 

---+++ FUSE Kernel module

<!--
%RED% *NOTE:* %ENDCOLOR% This section is fully relevant only after you have installed =hadoop=, =fuse=, =fuse-libs= using the OSG YUM repository. Please read and revisit after the following sections.
-->

FUSE (Filesystem in USErspace) is a simple interface for userspace programs to export a virtual filesystem to the linux kernel. 

The FUSE interface to HDFS requires installation of an external FUSE kernel-module. The stock RHEL kernels do not include the FUSE kernel module yet. Refer to http://vdt.cs.wisc.edu/components/hadoop.html to find link to external FUSE kernel-module. It has module RPMs for the recent kernel and FUSE versions. 

Upgrade your kernel and FUSE versions, as needed, to match the kernel-module. 

<pre class="screen">
$ wget ftp://ftp.pbone.net/mirror/atrpms.net/OS-ARCH/atrpms/stable/fuse-kmdl-KERNEL-VER-FUSE-VER.rpm
$ rpm -Uvh fuse-kmdl-KERNEL-VER-FUSE-VER.rpm

$ wget ftp://ftp.pbone.net/mirror/atrpms.net/OS-ARCH/atrpms/stable/fuse-FUSE-VER.rpm
$ rpm -Uvh fuse-FUSE-VER.rpm

$ yum update kernel

$ shutdown -r now
</pre>

Example:

<pre class="screen">
$ uname -r
2.6.18-164.2.1.el5

$ rpm -qa | grep fuse
fuse-2.7.4-8_12.el5
fuse-kmdl-2.6.18-164.2.1.el5-2.7.4-8_12.el5
fuse-libs-2.7.4-8_10.el5
hadoop-fuse-0.19.1-15.el5

$ modprobe -l fuse
/lib/modules/2.6.18-164.2.1.el5/updates/fs/fuse/fuse.ko
</pre>

If needed, modify the GRUB bootloader to load the correct kernel image.

<pre class="screen">
$ vi /boot/grub/grub.conf -- Check value of 'default' and section of relevant kernel version.
</pre>

If you are running a custom kernel, then be sure to enable the FUSE module with =CONFIG_FUSE_FS=m=. Building a FUSE kernel-module for  custom kernels is beyond the scope of this document.

---+++ Initializer RPM

Download and install the =osg-hadoop= RPM . This will initialize the OSG YUM repository for Hadoop.

<pre class="screen">
$ wget http://vdt.cs.wisc.edu/hadoop/osg-hadoop-1-2.el5.noarch.rpm
$ rpm -Uvh osg-hadoop-1-2.el5.noarch.rpm
</pre>

This initializes YUM repository in =/etc/yum.repos.d/osg-hadoop.repo=. 

%RED% *NOTE for ITB Sites:* %ENDCOLOR% By default, *Stable Repository* is enabled (=enabled=1=) in the YUM configuration. ITB sites doing testing can enable the *Testing Repository* to fetch pre-release packages. Simply set =enabled=0= in =[hadoop]= section and =enabled=1= in =[hadoop-testing]= section of =/etc/yum.repos.d/osg-hadoop.repo=.

---+++ YUM install/upgrade of components 

Decide the components to be installed on each node. After java, FUSE kernel-module, and the initializer RPM =osg-hadoop= have been installed,  components of the SRM-Hadoop system can be installed and upgraded using =yum= commands. 

<pre class="screen">
$ yum install|upgrade <component-name>
</pre>

Examples:

<pre class="screen">
$ yum install|upgrade hadoop
$ yum install|upgrade gridftp-hdfs
$ yum install|upgrade bestman
$ yum install|upgrade gratia-probe-gridftp-transfer gums-client
$ yum install|upgrade gratia-probe-hadoop-storage
</pre>

Services can be started with:

<pre class="screen">
$ service hadoop-firstboot start
$ chkconfig <component-name> on
$ service <component-name> start|stop
</pre>

FUSE can be mounted at boot time. Instructions are [[Storage.HadoopInstallation#Mounting_fuse_at_boot_time][here]].

---++++ !NameNode

<pre class="screen">
$ yum install|upgrade hadoop
$ yum install|upgrade hadoop-fuse fuse
</pre>

Main configuration file is =/etc/sysconfig/hadoop=. See [[Storage.HadoopInstallation#Edit_etc_sysconfig_hadoop][configuration template]]. Parameter =HADOOP_NAMENODE= is set to the same value on all nodes. 

For more details, read [[Storage.HadoopInstallation][OSG Storage's Hadoop install document]].

---++++ !DataNode

<pre class="screen">
$ yum install|upgrade hadoop
$ yum install|upgrade hadoop-fuse fuse
</pre>

Main configuration file is =/etc/sysconfig/hadoop=. See [[Storage.HadoopInstallation#Edit_etc_sysconfig_hadoop][configuration template]]. Parameter =HADOOP_DATADIR= is important and sets the partition/directory where data is stored.

For more details, read [[Storage.Hadoop.HadoopInstallation][OSG Storage's Hadoop install document]].

---++++ !GridFTP

---++++ SRM

---++++ Transfer Probe

---++++ Storage Probe


---++ Validation

<pre class="screen">
srm-ping
</pre>

<pre class="screen">
lcg-cp
</pre>

<pre class="screen">
lcg-ls
</pre>

---++ References

<br />%STOPINCLUDE% 
%BR% 
%COMPLETE3% %BR% 
%RESPONSIBLE% Main.AbhishekSinghRana- 12 Sept 2008 %BR% 
%REVIEW% Main.TanyaLevshina - 21 Jul 2009 %BR%
%REVFLAG% %X% %BR%

%COMMENT{type="tableappend"}%

-- Main.AbhishekSinghRana - 05 Feb 2010
