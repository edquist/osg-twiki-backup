%META:TOPICINFO{author="MarcoMambelli" date="1275071621" format="1.1" reprev="1.1" version="1.1"}%
%META:TOPICPARENT{name="ModulesIntro"}%
---+!! *<nop>%SPACEOUT{ "%TOPIC%" }%*
%DOC_STATUS_TABLE%
%TOC%


---++Introduction
This is a tutorial to demonstrate how to install and setup a basic CE installation.  It will guide users through a basic CE installation step by step.  At the completion of this guide, you should have a simple CE available.

These instructions assume that the Compute Element software is being installed on system following the guidelines for OSG Tier 3s. 
These include a RHEL based OS and a Condor resource manager, installed as described in ModulesIntro. Other recommandations are at the beginning of [[ModulesIntro][that]] document. As usual different configuration will likely work but you may have to change/adapt the instructions.

---+++ Requirements
You'll need a server with the following:
   * RHEL 4 or 5 based Linux distribution (reference OS is Scientific Linux 5.4)
   * root access
   * ~5 GB of free space
   * Condor installed using the [[CondorRPMInstall][RPM distribution]] or the [[CondorSharedInstall][shared tar installation]]
   * internet access (at least outbound connectivity)
   * Host, http, and rsv certificates (you can copy the host certificate and use it for the http and rsv services)

To perform the tests you'll also need the following:
   * Personal grid certificate

---++ Getting started
---+++ Installing pacman
Pacman is a package management program used to install OSG software.   ReleaseDocumentation.PacmanInstall describes how to install Pacman which can be installed by either the cluster administrator or a non-privileged account.  For example the cluster administrator might install this in =/osg/app/pacman= or =/opt/pacman= such as in the following
%TWISTY{
mode="div"
showlink="Pacman installation example."
hidelink="Hide"
showimgleft="%ICONURLPATH{toggleopen-small}%"
hideimgleft="%ICONURLPATH{toggleclose-small}%"
}%
<pre class="screen">
cd /opt
wget http://atlas.bu.edu/~youssef/pacman/sample_cache/tarballs/pacman-3.29.tar.gz
tar --no-same-owner -xzvf pacman-3.29.tar.gz
cd pacman-3.29
source setup.sh
cd ..
ln -s pacman-3.29 pacman
</pre>
%ENDTWISTY% Once installed setup its environment with for example =source /opt/pacman/setup.sh=.  

---+++ Creating directories
Create the installation directory and =/etc/grid security=<pre class="screen">
mkdir /opt/osgce
mkdir /etc/grid-security
mkdir /etc/grid-security/http
</pre>

Next, the host and service certificates will need to be placed in the proper places in =/etc/grid-security=.  These instructions assume that the following files are in the current directory. ReleaseDocumentation.GetGridCertificates provides instruction on how to obtain host and service certificates/keys. If you have the host certificate/key but no service certificates/keys and are unable to obtain them, a copy of the host certificate will work as temporary solution.
   * =hostcert.pem= - host certificate file
   * =hostkey.pem= - host key file
   * =httpcert.pem= - http service certificate file
   * =httpkey.pem= - http service key file
   * =rsvcert.pem= - RSV service certificate file
   * =rsvkey.pem= - RSV service key file

Copy http certificate and key to =/etc/grid-security/http= and the host and RSV certificates and keys to =/etc/grid-security=:<pre class="screen">
cp httpcert.pem httpkey.pem /etc/grid-security/http   
cp hostcert.pem hostkey.pem /etc/grid-security/
cp rsvcert.pem rsvkey.pem /etc/grid-security/
</pre>
Make sure that the owner is root:<pre class="screen">
chown root:root /etc/grid-security/host*
chown root:root /etc/grid-security/rsv*
chown root:root /etc/grid-security/http/http*
</pre>
Set the correct permissions for the certificate and key files:<pre class="screen">
chmod 400 /etc/grid-security/hostkey.pem
chmod 444 /etc/grid-security/hostcert.pem
chmod 400 /etc/grid-security/rsvkey.pem
chmod 444 /etc/grid-security/rsvcert.pem
chmod 400 /etc/grid-security/http/httpkey.pem
chmod 444 /etc/grid-security/http/httpcert.pem=
</pre>
   
Now create and set  for the OSG service directories with the correct permissions: OSG_APP, OSG_DATA, OSG_GRID. More information on all the possible service directories and on recommended configurations is in  ReleaseDocumentation.LocalStorageConfiguration. We assume a shared file system is used and <pre class="screen">
ln -s /nfs/osg /osg
mkdir -p /osg/app
mkdir -p /osg/app/etc
chmod 1777 /osg/app
chmod 1777 /osg/app/etc
mkdir -p /osg/data
chmod 1777 /osg/data
mkdir -p /osg/wn
</pre>
   * Create grid security directory
<pre class="screen">
[root@uct3-edge5 opt]# mkdir /etc/grid-security
[root@uct3-edge5 opt]# mkdir /etc/grid-security/http
</pre>

---+++ Installing worker node software
   * Install WN stack
<pre class="screen">
[root@uct3-edge5 opt]# cd wn-1.2/
[root@uct3-edge5 wn-1.2]# pacman -allow trust-all-caches -get http://software.grid.iu.edu/osg-1.2:wn-client
</pre>

---+++ Installing CE software
   * Install CE stack
<pre class="screen">
[root@uct3-edge5 opt]# cd osg-1.2/
[root@uct3-edge5 osg-1.2]# pacman -allow trust-all-caches -get http://software.grid.iu.edu/osg-1.2:ce
Beginning VDT prerequisite checking script vdt-common/vdt-prereq-check...       

All prerequisite checks are satisfied.
                                                          


========== IMPORTANT ==========
Most of the software installed by the VDT *will not work* until you install
certificates.  To complete your CA certificate installation, see the notes
in the post-install/README file.



                                                                              
Pacman Installation of OSG-1.2.0 Complete
</pre>
   * Install managed fork
<pre class="screen">
[root@uct3-edge5 osg-1.2]# pacman -allow trust-all-caches -get http://software.grid.iu.edu/osg-1.2:ManagedFork
</pre>
   * Install jobmanager setup package
<pre class="screen">
[root@uct3-edge5 osg-1.2]# pacman -allow trust-all-caches -get http://software.grid.iu.edu/osg-1.2:Globus-Condor-Setup
</pre>

---+++ Configure CE
   * Run post-install script
<pre class="screen">
[root@uct3-edge5 osg-1.2]# source setup.sh 
[root@uct3-edge5 osg-1.2]# vdt-post-install 
Starting...
Configuring PRIMA... Done.
Configuring EDG-Make-Gridmap... Done.
Configuring PRIMA-GT4... Done.
Completed all configuration.
</pre>
   * Setup CA certificates
<pre class="screen">
[root@uct3-edge5 osg-1.2]# vdt-ca-manage setupca --location local --url osg
Setting CA Certificates for VDT installation at '/opt/osg-1.2'

Setup completed successfully.
</pre>
---++++ Modify config.ini
   * Edit =osg/etc/config.ini=
   * In =[Default]= section
      * Set =localhost= to the correct dns name for your CE (e.g. localhost = your.domain)
      * Set =admin_email= to your email address
   * In the =[Site Information]= section
      * Set =group= to OSG
      * Set =site_name= to your site's name
      * =sponsor= For this workshop, use 'osg'
      * =site_policy= A url to your site's usage policy. Example: http://www.mwt2.org/policy.html
      * =contact=, set this to your email address
      * =city=
      * =country=
      * =latitude= You can set this to 0 if you do not know your lattitude
      * =longitude= Like latitude
   * In the =[Condor]= section
      * =enabled= , change the =%(unavailable)s= to =%(enable)s=
      * =home=, set this to =/opt/osg-1.2/condor=
      * =wsgram= , change the =%(unavailable)s= to =%(enable)s=
   * In the =[ManagedFork]= section
      * =enabled= , change the =%(unavailable)s= to =%(enable)s=
      * =condor_location= , change the =%(unavailable)s= to =/opt/osg-1.2/condor=
   * In the =[Misc Services]= section
      * =use_cert_updater= , change the =%(unavailable)s= to =%(enable)s=
      * =authorization_method=, change the =%(unavailable)s= to gridmap
   * In the =[Storage]= section
      * =grid_dir= , change the =%(unavailable)s= to =/opt/wn-client=
      * =app_dir= , change the =%(unavailable)s= to =/opt/app=
      * =data_dir= , change the =%(unavailable)s= to =/opt/data=
      * =worker_node_temp= , change the =%(unavailable)s= to =/tmp=
      * =site_read= , change the =%(unavailable)s= to =/opt/data=
      * =site_write= , change the =%(unavailable)s= to =/opt/data=
   * In the  =[GIP]= section
      * Remove the =%(unavailable)s= and replace it with the correct values for the variables listed below
      * =batch= , change the =%(unavailable)s= to =condor=
   * In the  =[Subcluster CHANGEME]= section
      * Change name to =[Subcluster Main]=
      * =name=, change to =Main=
      * =node_count= , change the =NUMBER_OF_NODE= to the number of worker nodes your cluster has. For this tutorial, enter =1=
      * =ram_mb= , change the =MB_OF_RAM= to the ram that your cluster has in MB (hint: =cat /proc/meminfo=)
      * =cpu_module= , change the =CPU_MODEL_FROM_/proc/cpuinfo= to the model of your  cluster's cpus (hint: =cat /proc/cpuinfo=)
      * =cpu_vendor= , change the =VENDOR_AMD_OR_INTEL= to the vendor of your  cluster's cpus (e.g. =Intel=, =AMD=)
      * =cpu_speed_mhz= , change the =CLOCK_SPEED_MHZ= to the clock speed of your  cluster's cpus in MHz. For example, a 2.83GHz cpue runs at 2830 MHz.
      * =cpus_per_node=, change =#_PHYSICAL_CHIPS_PER_NODE= to number of chips per node (e.g. =1=)
      * =cores_per_node=, change =#_CORES_PER_NODE= to number of cores total in the node (e.g. =8= for a dual socket, quad core node)
   * In the =[RSV]= section
      * =enabled= , change the =%(unavailable)s= to =%(enable)s=
      * =rsv_user= , change the =%(unavailable)s= to name of the account that has been created for rsv ( rsv_user)
      * =enable_ce_probes= , change the =%(unavailable)s= to =%(enable)s=
      * =ce_hosts= , change the =%(unavailable)s= to =%(localhost)s=
      * =enable_gridftp_probes= , change the =%(unavailable)s= to =%(enable)s=
      * =gridftp_hosts= , change the =%(unavailable)s= to =%(localhost)s=
      * =use_service_cert= , change the =%(unavailable)s= to =%(enable)s=
      * =rsv_cert_file= , change the =%(unavailable)s= to =/etc/grid-security/rsv/rsvcert.pem=
      * =rsv_key_file= , change the =%(unavailable)s= to =/etc/grid-security/rsv/rsvkey.pem=
      * =setup_for_apache= , change the =%(disable)s= to =%(enable)s=

---++++ Run configure-osg
   * Verify configuration
<pre class="screen">
[root@uct3-edge5 osg-1.2]# configure-osg -v
Using /opt/osg-1.2/osg/etc/config.ini for configuration information
Configuration verified successfully
</pre>
   * Configure system
<pre class="screen">
[root@uct3-edge5 osg-1.2]# configure-osg -c
Using /opt/osg-1.2/osg/etc/config.ini for configuration information
running 'vdt-register-service --name fetch-crl --enable'... ok
Running /opt/osg-1.2/fetch-crl/share/doc/fetch-crl-2.6.6/fetch-crl.cron, this process make take some time to fetch all the crl updates
running 'vdt-register-service --name vdt-update-certs --enable'... ok
running 'vdt-register-service --name edg-mkgridmap --enable'... ok
running 'vdt-register-service --name gums-host-cron --disable'... ok
PRIMA for GT4 web services has been disabled
You will now be using a grid-mapfile for authorization.
Modifications to the /etc/sudoers file are still required.
You will need to restart the /etc/init.d/globus-ws container
to effect the changes.
Running /opt/osg-1.2/edg/sbin/edg-mkgridmap, this process make take some time to query vo and gums servers
The following consumer subscription has been installed:
	HOST:    https://osg-ress-4.fnal.gov:8443/ig/services/CEInfoCollector
	TOPIC:   OSG_CE
	DIALECT: OLD_CLASSAD

running 'vdt-register-service --name tomcat-55 --enable'... ok
The following consumer subscription has been installed:
	HOST:    http://is-itb.grid.iu.edu:14001
	TOPIC:   OSG_CE
	DIALECT: RAW

running 'vdt-register-service --name tomcat-55 --enable'... ok
running 'vdt-register-service --name mysql5 --enable'... ok
running 'vdt-register-service --name gsiftp --enable'... ok
Not defined: PER_JOB_HISTORY_DIR
running 'vdt-register-service --name gratia-condor --enable'... ok
INFO: Attempting to install latest RSV package from release repository. 
INFO: Attempting to install RSV consumers. 
INFO: Attempting to install RSV probes on appropriate URI(s). 
INFO: Creating .sub files for RSV probes of type OSG-Local-Monitor
	 for URI: uct3-edge5.uchicago.edu (host: uct3-edge5.uchicago.edu)
INFO: Creating .sub files for RSV probes of type OSG-CE
	 for URI: uct3-edge5.uchicago.edu (host: uct3-edge5.uchicago.edu)
INFO: Re-using metrics config file for uct3-edge5.uchicago.edu
 /opt/osg-1.2/osg-rsv/config/uct3-edge5.uchicago.edu_metrics.conf
 Existing settings like on/off and metric intervals will be re-used.
 Any new metrics found in probe set will be added with their default settings.

INFO: Creating .sub files for RSV probes of type OSG-GridFTP
	 for URI: uct3-edge5.uchicago.edu (host: uct3-edge5.uchicago.edu)
INFO: Re-using metrics config file for uct3-edge5.uchicago.edu
 /opt/osg-1.2/osg-rsv/config/uct3-edge5.uchicago.edu_metrics.conf
 Existing settings like on/off and metric intervals will be re-used.
 Any new metrics found in probe set will be added with their default settings.

running 'vdt-register-service --name condor-cron --enable'... ok
running 'vdt-register-service --name condor --enable'... ok
running 'vdt-register-service --name vdt-rotate-logs --enable'... ok
running 'vdt-register-service --name apache --enable'... ok
running 'vdt-register-service --name globus-gatekeeper --enable'... ok
running 'vdt-register-service --name globus-ws --enable'... ok
Configure-osg completed successfully

</pre>
   * Add your grid certificate DN to =/etc/grid-security/gridmap= if it's not there. E.g.
<pre class="screen">
[root@uct3-edge5 var]# echo "/DC=org/DC=doegrids/OU=People/CN=Suchandra Thapa 757586" sthapa > /etc/grid-security/gridmap
</pre>

----+++ Turn on software
   * Run vdt-control
<pre class="screen">
[root@uct3-edge5 osg-1.2]# vdt-control --on
enabling cron service fetch-crl... ok
enabling cron service vdt-rotate-logs... ok
enabling cron service vdt-update-certs... ok
skipping init service 'gris' -- marked as disabled
enabling inetd service globus-gatekeeper... ok
enabling inetd service gsiftp... ok
enabling init service mysql5... ok
enabling init service globus-ws... ok
skipping cron service 'gums-host-cron' -- marked as disabled
skipping init service 'MLD' -- marked as disabled
enabling init service condor-cron... ok
enabling init service apache... ok
enabling init service tomcat-55... ok
enabling init service condor... ok
enabling cron service gratia-condor... ok
enabling cron service edg-mkgridmap... ok
enabling init service osg-rsv... ok
</pre>

----+++ Verification
   * Run site_verify
<pre class="screen">
[sthapa@uct3-edge5 ~]$ cd /opt/osg-1.2/verify
[sthapa@uct3-edge5 verify]$ ./site_verify.pl
===============================================================================
Info: Site verification initiated at Wed Aug  5 20:21:00 2009 GMT.
===============================================================================
-------------------------------------------------------------------------------
-------- Begin uct3-edge5.uchicago.edu at Wed Aug  5 20:21:00 2009 GMT --------
-------------------------------------------------------------------------------
Checking prerequisites needed for testing: PASS
Checking for a valid proxy for sthapa@uct3-edge5.uchicago.edu: PASS
Checking if remote host is reachable: PASS
Checking for a running gatekeeper: YES; port 2119
Checking authentication: PASS
Checking 'Hello, World' application: PASS
Checking remote host uptime: PASS
   15:21:03 up 15 days,  2:50,  2 users,  load average: 0.53, 0.36, 0.18
Checking remote Internet network services list: PASS
Checking remote Internet servers database configuration: PASS
Checking for GLOBUS_LOCATION: /opt/osg-1.2/globus
Checking expiration date of remote host certificate: Jul  9 20:45:23 2010 GMT
Checking for gatekeeper configuration file: YES
  /opt/osg-1.2/globus/etc/globus-gatekeeper.conf
Checking users in grid-mapfile, if none must be using Prima: alice,cdf,cigi,compbiogrid,des,dosar,engage,fermilab,geant4,glow,gpn,grase,grow,i2u2,icecube,ilc,ligo,mis,nanohub,nebiogrid,nwicg,nysgrid,ops,osg,osgedu,samgrid,sbgrid,star,sthapa,usatlas1,uscms01
Checking for remote globus-sh-tools-vars.sh: YES
Checking configured grid services: PASS
  jobmanager,jobmanager-condor,jobmanager-fork,jobmanager-managedfork
Checking for OSG osg-attributes.conf: YES
Checking scheduler types associated with remote jobmanagers: PASS
  jobmanager is of type managedfork
  jobmanager-condor is of type condor
  jobmanager-fork is of type managedfork
  jobmanager-managedfork is of type managedfork
Checking for paths to binaries of remote schedulers: PASS
  Path to condor binaries is /opt/osg-1.2/condor/bin
  Path to managedfork binaries is .
Checking remote scheduler status: PASS
  condor : 1 jobs running, 0 jobs idle/pending
Checking if Globus is deployed from the VDT: YES; version 2.0.0p7
Checking for OSG version: NO
Checking for OSG grid3-user-vo-map.txt: YES
  ops users: ops
  cms users: uscms01
  i2u2 users: i2u2
  geant4 users: geant4
  atlas users: usatlas1,usatlas3,usatlas4
  grow users: grow
  osgedu users: osgedu
  nanohub users: nanohub
  alice users: alice
  icecube users: icecube
  gpn users: gpn
  nebiogrid users: nebiogrid
  cdf users: cdf
  nwicg users: nwicg
  osg users: osg
  engage users: engage
  star users: star
  cigi users: cigi
  dosar users: dosar
  grase users: grase
  sbgrid users: sbgrid
  jdem users: jdem
  ligo users: ligo
  glow users: glow
  nysgrid users: nysgrid
  fermilab users: fermilab
  ilc users: ilc
  dzero users: samgrid
  compbiogrid users: compbiogrid
  mis users: mis
  des users: des
Checking for OSG site name: UC_ITB_2
Checking for OSG $GRID3 definition: /opt/osg-1.2
Checking for OSG $OSG_GRID definition: /opt/wn-1.2
Checking for OSG $APP definition: /opt/share/app
Checking for OSG $DATA definition: /opt/share/data
Checking for OSG $TMP definition: /opt/share/data
Checking for OSG $WNTMP definition: /tmp
Checking for OSG $OSG_GRID existence: FAIL
Checking for OSG $APP existence: PASS
Checking for OSG $DATA existence: PASS
Checking for OSG $TMP existence: PASS
Checking for OSG $APP writability: PASS
Checking for OSG $DATA writability: PASS
Checking for OSG $TMP writability: PASS
Checking for OSG $APP available space: 8.833 GB
Checking for OSG $DATA available space: 8.833 GB
Checking for OSG $TMP available space: 8.833 GB
Checking for OSG additional site-specific variable definitions: YES
  MountPoints
    SAMPLE_LOCATION default /SAMPLE-path
    SAMPLE_SCRATCH devel /SAMPLE-path
Checking for OSG execution jobmanager(s): uct3-edge5.uchicago.edu/jobmanager-condor
Checking for OSG utility jobmanager(s): uct3-edge5.uchicago.edu/jobmanager
Checking for OSG sponsoring VO: osg:100
Checking for OSG policy expression: NONE
Checking for OSG setup.sh: YES
Checking for OSG $Monalisa_HOME definition: FAIL
Checking for MonALISA configuration: UNTESTED
Checking for a running MonALISA: UNTESTED
Checking for a running GANGLIA gmond daemon: PASS (pid 3212 ...)
  /usr/sbin/gmond
  name = "part_max_used"
  owner = "unspecified"
  url = "unspecified"
Checking for a running GANGLIA gmetad daemon: NO
  gmetad does not appear to be running
Checking for a running gsiftp server: YES; port 2811
Checking gsiftp (local client, local host -> remote host): PASS
Checking gsiftp (local client, remote host -> local host): PASS
Checking that no differences exist between gsiftp'd files: PASS
-------------------------------------------------------------------------------
--------- End uct3-edge5.uchicago.edu at Wed Aug  5 20:23:11 2009 GMT ---------
-------------------------------------------------------------------------------
===============================================================================
Info: Site verification completed at Wed Aug  5 20:23:11 2009 GMT.
</pre>
   * Check rsv status
      * Go to http://your.host:8443/rsv/

---++Presentation


---++References

   1 [[WebHome][Release Documentation]]

%BR%


%STOPINCLUDE%
%BR%

---++ *Comments*
%COMMENT{type="tableappend"}%

<!-- CONTENT MANAGEMENT PROJECT
############################################################################################################ 
   DEAR DOCUMENT OWNER
   ===================

   Thank you for claiming ownership for this document! Please fill in your FirstLast name here:
   * Local OWNER          = MarcoMambelli

   Please define the document area, choose one of the defined areas from the next line
   DOC_AREA = (ComputeElement|Storage|VO|Security|User|Monitoring|General|Integration|Operations|Tier3)
   * Local DOC_AREA       =  Tier3

   define the primary role the document serves, choose one of the defined roles from the next line
   DOC_ROLE = (EndUser|Student|Developer|SysAdmin|VOManager|Documenter)
   * Local DOC_ROLE       = SysAdmin

   Please define the document type, choose one of the defined types from the next line
   DOC_TYPE = (Troubleshooting|Training|Installation|HowTo|Planning|Navigation|Knowledge)
   * Local DOC_TYPE       = Installation
   
   Please define if this document in general needs to be reviewed before release ( %YES% | %NO% )
   * Local INCLUDE_REVIEW = %NO%

   Please define if this document in general needs to be tested before release ( %YES% | %NO% )
   * Local INCLUDE_TEST   = %NO%

   change to %YES% once the document is ready to be reviewed and back to %NO% if that is not the case
   * Local REVIEW_READY   = %YES%

   change to %YES% once the document is ready to be tested and back to %NO% if that is not the case
   * Local TEST_READY     = %NO%

   change to %YES% only if the document has passed the review and the test (if applicable) and is ready for release
   reviewed during DOC workshop
   * Local RELEASE_READY  = %NO%


   DEAR DOCUMENT REVIEWER
   ======================

   Thank for reviewing this document! Please fill in your FirstLast name here:
   * Local REVIEWER       = 
  
   Please define the review status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local REVIEW_PASSED  = %IN_PROGRESS%


   DEAR DOCUMENT TESTER
   ====================

   Thank for testing this document! Please fill in your FirstLast name here:
   * Local TESTER         = 
  
   Please define the test status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local TEST_PASSED    = %IN_PROGRESS%
############################################################################################################ 
-->

-- Main.MarcoMambelli - 28 May 2010
