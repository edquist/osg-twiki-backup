%META:TOPICINFO{author="KyleGross" date="1225985963" format="1.1" version="1.5"}%
%META:TOPICPARENT{name="SystemDeployment"}%
---+!! Service Readiness for the OSG Integration Test Bed

%TOC%

---++ Description of the Service
The Resource Selection Service provides a framework to

   1. reference resource attributes from the description of a job
   1. select a resource according to user provided requirements and ranking expressions.

The service is logically built by two components (see the [[ReSSArchitecture][architectural diagram]]):

   1. a central resource selection service
   1. an information publishing mechanism, deployed at all the resources

The central service is composed of an Information Gatherer, which interfaces to the distributed information publishing services, and the match making service of [[http://www.cs.wisc.edu/condor/condorg/][Condor-G]]. Thus, the resource selector naturally interfaces to the condor scheduling deamons (condor_schedd) for job description and scheduling capabilities.

The distributed services are implemented by the [[http://grid.pd.infn.it/cemon/field.php][CEMon]]
service. CEMon is an information publication system that interfaces to the site Generic Information Providers. All CEMon instances subscribe to the central Information Gatherer (IG) and send site resource characteristics in old classad format. The address of the IG is defined in the CEMon configuration.

This document focuses on the deployment of the CEMon service to the ITB resources. The central services will be deployed and maintained for the ITB by Resource Selection activity team.


---++ Dependencies and Other Services

The dependencies of CEMon are
   1. a servlet container: CEMon has been tested using Tomcat v5
   2. Generic Information Providers: CEMon formats and publishes information available from the GIP
   3. the OSG security infrastructure: allows mutual authentication of service queries/requests. In particular, CA certificates, revocation lists, and a grid-mapfile are required. The grid-mapfile can be blank, allowing only central ReSS services to have access to CEMon.

The resource selection service depends on a set of central services. These services are deployed and maintained for the ITB by the resource selection activity team. 

The resource selection service is currently interfaced only with the condor scheduling daemon (condor_schedd). This daemon is available in the OSG client software and can be configured to use the resource selection services by adding this line to its condor configuration file:
<verbatim>
COLLECTOR_HOST  = <fqdn of the central ReSS node (TBD)>
</verbatim>

---++ Required Resources

The resource selection service is currently utilized for the selection of computing resources only (no storage elements). CEMon should be deployed at all the OSG CE that accept the DZero VO. In the future, as new VOs decide to utilize !ReSS, we may decide to deploy CEMon to all OSG resources.


---++ Server Requirements

CEMon exposes web service interfaces for remote communcation. Typically, 1 GByte or more of memory is required to provide a performant service. CPU speed and disk space, instead, can be "modest".


---++ Packaging

CEMon is deployed as part of the Virtual Data Toolkit, together with OSG-specific configuration scripts. The central resource selection service depends on the CEMon version deployed by VDT v1.3.11


---++ Installation and Configuration

CEMon installation [[CEMonAndGIPInstallationNotes][instructions]].<br>
Information Gatherer installation [[InformationGathererInstallationNotes][instructions]].<br>
See also VDT installation instructioins.

---++ Test Harness

This paragraph discusses a few of simple tests to check that the CEMon services are deployed correctly.

CEMon makes site CEs available to the resource selection service. CEMon provides a description of such CEs to the central resource selection services by *pushing* the information to the Information Gatherer. The resource selection infrastructure does not require that CEMon authorizes any access to its interfaces. However, for testing purposes, it may be useful to configure CEMon to authorize access to the administrators that install the system. This is achieved by mapping the administrator's DN to any user (e.g. nobody) in /etc/grid-security/grid-mapfile. The following tests assume this configuration.

We recommend to perform the following tests

*1.* Instantiate CEMon and check that the servlet engine is running the service. This can be achieved by pointing a browser to the servlet page, typically at !https://&lt;tomcat-host-name&gt;:8443/ce-monitor/services/CEMonitor<br>
You should see a web page displaying test strings such "CEMonitor" and "this is an AXIS service".

*2.* Check that the central resource selection services has a record of your resources. Using the Condor-G clients from VDT, issue the command
<verbatim>
condor_status -pool <Central-ReSS-host> -constraints 'GlueCEInfoHostName=="<your-CE-host>"'
</verbatim>
where &lt;Central-ReSS-host&gt; is TBD<br>
If everything works well, you should see the list of resources advertised from your site.<br>
For example
<small>
<verbatim>
$ condor_status -pool samgfarm1.fnal.gov -constraints 'GlueCEInfoHostName=="fgtest1.fnal.gov"'
 
Name          OpSys       Arch   State      Activity   LoadAv Mem   ActvtyTime
 
LIGO.fgtest1. [?????????] [????] [????????] [???]  [??]   [Unknown]
accelerator.f [?????????] [????] [????????] [???]  [??]   [Unknown]
astro.fgtest1 [?????????] [????] [????????] [???]  [??]   [Unknown]
atlas.fgtest1 [?????????] [????] [????????] [???]  [??]   [Unknown]
auger.fgtest1 [?????????] [????] [????????] [???]  [??]   [Unknown]
cdf.fgtest1.f [?????????] [????] [????????] [???]  [??]   [Unknown]
cdms.fgtest1. [?????????] [????] [????????] [???]  [??]   [Unknown]
cms.fgtest1.f [?????????] [????] [????????] [???]  [??]   [Unknown]
des.fgtest1.f [?????????] [????] [????????] [???]  [??]   [Unknown]
dosar.fgtest1 [?????????] [????] [????????] [???]  [??]   [Unknown]
dzero.fgtest1 [?????????] [????] [????????] [???]  [??]   [Unknown]
fermilab.fgte [?????????] [????] [????????] [???]  [??]   [Unknown]
fmri.fgtest1. [?????????] [????] [????????] [???]  [??]   [Unknown]
gadu.fgtest1. [?????????] [????] [????????] [???]  [??]   [Unknown]
geant4.fgtest [?????????] [????] [????????] [???]  [??]   [Unknown]
glow.fgtest1. [?????????] [????] [????????] [???]  [??]   [Unknown]
grase.fgtest1 [?????????] [????] [????????] [???]  [??]   [Unknown]
gridex.fgtest [?????????] [????] [????????] [???]  [??]   [Unknown]
grow.fgtest1. [?????????] [????] [????????] [???]  [??]   [Unknown]
hypercp.fgtes [?????????] [????] [????????] [???]  [??]   [Unknown]
i2u2.fgtest1. [?????????] [????] [????????] [???]  [??]   [Unknown]
ilc.fgtest1.f [?????????] [????] [????????] [???]  [??]   [Unknown]
ivdgl.fgtest1 [?????????] [????] [????????] [???]  [??]   [Unknown]
ktev.fgtest1. [?????????] [????] [????????] [???]  [??]   [Unknown]
lqcd.fgtest1. [?????????] [????] [????????] [???]  [??]   [Unknown]
miniboone.fgt [?????????] [????] [????????] [???]  [??]   [Unknown]
minos.fgtest1 [?????????] [????] [????????] [???]  [??]   [Unknown]
mipp.fgtest1. [?????????] [????] [????????] [???]  [??]   [Unknown]
mis.fgtest1.f [?????????] [????] [????????] [???]  [??]   [Unknown]
nanohub.fgtes [?????????] [????] [????????] [???]  [??]   [Unknown]
nova.fgtest1. [?????????] [????] [????????] [???]  [??]   [Unknown]
numi.fgtest1. [?????????] [????] [????????] [???]  [??]   [Unknown]
osg.fgtest1.f [?????????] [????] [????????] [???]  [??]   [Unknown]
patriot.fgtes [?????????] [????] [????????] [???]  [??]   [Unknown]
sdss.fgtest1. [?????????] [????] [????????] [???]  [??]   [Unknown]
star.fgtest1. [?????????] [????] [????????] [???]  [??]   [Unknown]
theory.fgtest [?????????] [????] [????????] [???]  [??]   [Unknown]
 
                     Machines Owner Claimed Unclaimed Matched Preempting
 
 
               Total        0     0       0         0       0          0
 
                    (Omitted 37 malformed ads in computed attribute totals)
</verbatim>
</small>

Add option -l to see a detailed description of the resources.

*3.* If the previous test worked, no further test is required. Otherwise, the service may be working properly, but there may be a communication problem with the Information Gatherer (IG). Try querying the service locally using the CEMon clients commands. Note that administrators' DNs must be added to /etc/grid-security/grid-mapfile in order for this test to work. After creating a valid proxy, issue
<verbatim>
CEMonitorGetEvent <path-to-proxy> / https://<tomcat-host>:8443/ce-monitor/services/CEMonitor OSG_CE  OLD_CLASSAD
</verbatim>
You should see the site resources in old classad format.<br>
For example
<small>
<verbatim>
$ CEMonitorGetEvent /tmp/x509up_u7160 / https://samgfarm1.fnal.gov:8443/ce-monitor/services/CEMonitor OSG_CE  OLD_CLASSAD
Message[0]=[
        GlueClusterUniqueID = "samgfarm2.fnal.gov";
        GlueCEUniqueID = "samgfarm2.fnal.gov:2119/jobmanager-condor";
        GlueClusterName = "samgfarm2.fnal.gov";
        GlueSubClusterUniqueID = "samgfarm2.fnal.gov";
        GlueClusterService = "samgfarm2.fnal.gov";
        GlueCEHostingCluster = "samgfarm2.fnal.gov";
        GlueCEAccessControlBaseRule = "VO:CDF,VO:CMS";
        GlueHostProcessorModel = "PIV";
        GlueCEInfoHostName = "samgfarm2.fnal.gov";
        GlueHostProcessorClockSpeed = 3000;
        GlueCEStateWaitingJobs = 0;
        GlueHostApplicationSoftwareRunTimeEnvironment = "CDF-Application_v1_1,CMS-Application_v2_0";
        GlueCEStateTotalJobs = 0;
        GlueHostProcessorVendor = "intel";
        GlueSchemaVersionMajor = 1;
        GlueCEInfoLRMSVersion = "6.7.13";
        GlueInformationServiceURL = "undefined,undefined,undefined";
        GlueSubClusterName = "samgfarm2.fnal.gov";
        GlueCEInfoLRMSType = "condor";
        GlueCEInfoGatekeeperPort = 2119;
        GlueCEName = "samgfarm";
        GlueSchemaVersionMinor = 2;
 
]
Message[1]=[
        GlueClusterUniqueID = "samgfarm1.fnal.gov";
        GlueCEUniqueID = "samgfarm1.fnal.gov:2119/jobmanager-condor";
        GlueClusterName = "samgfarm1.fnal.gov";
        GlueSubClusterUniqueID = "samgfarm1.fnal.gov";
        GlueClusterService = "samgfarm1.fnal.gov";
        GlueCEHostingCluster = "samgfarm1.fnal.gov";
        GlueCEAccessControlBaseRule = "VO:DZero";
        GlueHostProcessorModel = "PIII";
        GlueCEInfoHostName = "samgfarm1.fnal.gov";
        GlueHostProcessorClockSpeed = 1000;
        GlueCEStateWaitingJobs = 0;
        GlueHostApplicationSoftwareRunTimeEnvironment = "DZero-Application_v1_1,DZero-Application_v1_2";
        GlueCEStateTotalJobs = 0;
        GlueHostProcessorVendor = "intel";
        GlueSchemaVersionMajor = 1;
        GlueCEInfoLRMSVersion = "6.7.13";
        GlueInformationServiceURL = "undefined,undefined,undefined";
        GlueSubClusterName = "samgfarm1.fnal.gov";
        GlueCEInfoLRMSType = "condor";
        GlueCEInfoGatekeeperPort = 2119;
        GlueCEName = "jra1_low";
        GlueSchemaVersionMinor = 2;
 
]
</verbatim>
</small>

*4.* If all these tests fail, check the log files of CEMon (in the Tomcat log file area) and the configuration of the GIP.


---++ Validation
The ITB setup of the Resource Selection Service will be used to perform functionality, scalability, and stress tests. These tests are derived from the DZero [[DZeroRequirements][requirements]] on the !ReSS service.

   * Gather feedback from administrators on the CEMon deployment procedure. Improve installation procedure and integrate with VDT, possibly by the OSG v0.6.0 deployment

   * Validate that classad coming from different sites (i.e. different GIP configurations) are well-formed and usable for common resource selection criteria.

   * Study the scalability of the central services handling O(100) classad from the ~13 ITB test sites. In detail, investigate how IG handles O(10) CEMon registrations and O(100) classad processing and transferring to the condor_collector.

   * Stress test study of the IG. Simulate the load of the production environment by increasing 10 times the frequency of classad publication by the O(10) CEMon's. This requires a change in the configuration of all ITB CEMon, thus the collaboration of the ITB system administrators.

   * Stress test the match making infrastructure submitting O(1) job/sec for 1 hour. In particular, evaluate the efficiency of the condor_negotiator call-out code, to match elements of an attribute list.

   * Validate that the machine load remains manageable when GIP are called from multiple clients (CEMon, Ldap, ...)

---++ Contact Information

Gabriele Garzoglio: <a href="mailto:garzoglio@fnal.gov">garzoglio@fnal.gov</a><br>
Tanya Levshina: <a href="mailto:tlevshin@fnal.gov">tlevshin@fnal.gov</a><br>

---++ More Documentation 

VDT: http://vdt.cs.wisc.edu/

CEMon: http://grid.pd.infn.it/cemon/field.php

---------------------

-- Main.GabrieleGarzoglio - 10 Apr 2006