%META:TOPICINFO{author="KyleGross" date="1481048000" format="1.1" version="1.9"}%
---+!! *<noop>%SPACEOUT{ "%TOPIC%" }%*
%TOC%

---++Introduction--Site Fabric Requirements

This page is not directly involved with the installation of the Compute Element and 
should probably be moved to the Site Admins Coordination section of the twiki eventually.
The Site Admins Coordination section began at the August 2006 Consortium meeting in 
Seattle and has now grown to a biannual meeting coordinated by Rob Gardner.
This page is tracking requests from site admins that have been made at these meetings.


---++Desired VDT Installation and Functional Features
   * Alain question--would rpm's help with the worker node client install--yes.  This was promised in August 2006 and we are no closer to getting the rpms now than we were.  (A certificate authority rpms is available, however).
   * Lots of bloat in clients, both user and worker node--oftentimes installs the whole server package just to get the client, should split some packages, can be insecure--to date this has not been addressed. VDT 1.8.1 only installs one Java on the worker node and not two different versions, this is some progress.
   * Need better Condor_G audit trail--remote condor site and job ID in local classad and vice versa--some work has been done with condor team but not deployed everywhere as yet.
   * Need reaper for hung globus-job-manager processes
   * Better cleanup of /home/.globus/.gass_cache, /home/.globus/job areas
   * On both of the two above issues, various sysadmins have come up with their own scripts and there is going to be a subversion repository to store them in the Site Admins area.
   *  Can some vdt configuration be cached outside of VDT_LOCATION (accidental deletes)-- vdt_app_data is intended for this function but not used for all the applications as yet.  VDT has added the feature VDT_OLD_LOCATION to bring most of the information forward from old install.
   * Consensus from this group on pacman updates for VDT seemed to be the following:
   *  For VDT/OSG upgrades, VDT will be set up so that you can install it into a new directory, with one command switch new one on, turn old one off, and reverse the process if necessary.--done since VDT1.6.1
   *  For small patches such as the coming Globus security patch, will make a small patch that can be installed on top of existing VDT directory and rolled back out if necessary--done
   *  Alain will formalize these suggestions and write them up, further discussion in VDT office hours and on mailing lists--done
   *  Best way to handle versioning, make the main directory have a versioned name, such as /usr/local/vdt-1.3.10, /usr/local/vdt-1.3.11, switch between them by making /usr/local/vdt be a soft link to the one you want. --done 

---++Requested clarifications of policy
   * How big of files are allowed to be globus-url-copied into home areas of grid users (LCG interoperability issue, initial tarball)--still no clarification

   * Any policy on how long files can stay in APP, DATA area--no grid-wide policy, depends on site

   * What is policy on users trying to do condor_submit to standard universe, via fork jobmanager--allowed and supported

   * Many have promised that fixed $OSG_WN_TMP area won't be required in OSG 0.5.0 but need to make sure that policy is clear when it isn't--policy is clear, some VO's still can't deal with it, and VDT still wants to do more work to make dynamic $OSG_WN_TMP be transparently implemented especially under Condor job manager.

   * Can there be an OSG-wide policy on the use of pool accounts, length of proxies?  More security than site/fabric--to be addressed in Security session

---++Requested refinements of information services
   * PBS sites don't advertise uniformly, some limit on cpu time, some limit on wall time--no progress
   * Also a time limit could be just a default (and you could request longer) or could be a hard limit--no progress
   * Need easier way to let users know of heterogeneous clusters with different cpu speed--GLUE schema has  subcluster fields but OSG interface has no easy way to select them--The configure-osg.script is fixed for OSG 0.8.0 to easily allow declaration of subclusters.
   * Pre-emption policies are not obvious from GIP, any other monitoring at this point.--In VDT 1.8.1 there is now a Preemption field in the glue schema but its value is just 0 or 1, either you pre-empt or you don't, and it has to be set manually via alter-attributes.conf.
   * Job slot limits at the moment aren't uniform, can be done in Condor, not elsewhere.--can also be done with PBS with proper queue configuration
   * Does some of the monitoring have to be split off to a monitoring box?  Could be hard to do but we should consider.--considered but not done for now.

<!-- Main.StevenTimm - 09 Aug 2006 -->

%BR%
%COMPLETE3% %BR%
%RESPONSIBLE% Main.StevenTimm - 17 Oct 2007 %BR%
%REVIEW%
%REVCOM% 
