%META:TOPICINFO{author="JeffPorter" date="1200934231" format="1.1" version="1.1"}%
%META:TOPICPARENT{name="WSGramValidation"}%
%LINKCSS%

<!-- This is the default OSG Integration template. Please modify it in the sections indicated to create your topic! --> 

<!-- By default the title is the WikiWord used to create this topic !-->
<!-- if you want to modify it to something more meaningful, just replace %TOPIC% below with i.e "My Topic"!-->

---+!! %SPACEOUT{ "%TOPIC%" }%


%TOC%

%STARTINCLUDE%
%EDITTHIS%

---+++ Bulk job summisions

The purpose of this test was to evaluate sources that limit large scale submissions with WS GRAM.   The tests were done for <b>type VII</b> jobs where data was transfered from the submit host and a 3rd site while produced data was transfered to a gridftp serviced storage resource. Tests were done on the ==LBNL_VTB== cluster. Submission via globusrun-ws was done in a loop:

   * <pre class=screen> globusrun-ws -submit -F  osp1.lbl.gov:9443 -Ft PBS -S -f xmlFiles/dc_rsl_0.xml </pre>

No delays were put in the submit loop.

The initial tests submitting ~100 jobs found a fraction of jobs failing with file staging errors previously observed during Condor-G submissions. We found a weak but clear dependence on scale; fraction of jobs failed increase with larger bulk submissions.   In this context, the error messages clearly stated =Server refused GSSAPI authentication= on the destination server.  There exists a new recommendation from the GT gridftp folks to increase the default timeout period between connection and authentication from 30 seconds to 120 seconds.  Additionally we measured the time interval between connection and authorisation using timestamps in the =gridftp-auth.log= file to be ~100s of seconds.  We changed the timeout to 300 seconds by inserting the line <pre class=screen> control_preauth_timeout 300 </pre> into the server's =gridftp.conf= file.  The result was that file staging errors ceased to occur.

As the jobs submissions were scaled up (several 100s), additional errors appeared. The occured at different stages of the process but pointed to a similar source via the common attribute: =Failed sending request= to some service component.  This indicated either a client-side or server-side container timeout.  By independently testing both possibilites it was determined to be a server-container timeout.  This was fixed by updating the =$GLOBUS_LOCATION/etc/globus_wsrf_core/server-config.wsdd= with:

<pre class=screen><verbatim>
    <globalConfiguration>
       ....
       <parameter name="containerTimeout" value="1000000"/>
       ...
    </globalConfiguration>
</verbatim>
</pre>


<b>SUMMARY</b>
   * After these modifcations, bulk submission were tested up to 400 jobs on the small server site.   Subsequent small handful of failures were due to slow processing capacity of the site.  The server itself remained functional without crashing during all of these tests and did not require restarting.  The server was able to process jobs submitted immediately after the largest rate submissions had been processed.


%STOPINCLUDE%

%BOTTOMMATTER%

-- Main.JeffPorter - 21 Jan 2008