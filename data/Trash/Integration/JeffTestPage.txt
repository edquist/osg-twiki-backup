%META:TOPICINFO{author="JeffPorter" date="1174406775" format="1.1" version="1.2"}%
%META:TOPICPARENT{name="MinutesWSGramMar19"}%
%LINKCSS%

<!-- This is the default OSG Integration template. Please modify it in the sections indicated to create your topic! --> 

<!-- By default the title is the WikiWord used to create this topic !-->
<!-- if you want to modify it to something more meaningful, just replace %TOPIC% below with i.e "My Topic"!-->

---+!! %SPACEOUT{ "GT4 testing with Condor-G" }%
%TOC%

%STARTINCLUDE%
%EDITTHIS%

---++ Comparison of GT4 and GT2 using Condor-g 

Shown below are the submit files for running direct gt4/gt2 comparisons. These examples are for =queue 25=.  This current tests were carried out for =queue = 10,25,50,75,100,150,200,400, and 600=.

*Condor submit example file for GT4 tests:*

<pre class="screen"> <b>
 Universe=grid
 Grid_Type = gt4
 Jobmanager_Type = Condor  
 GlobusScheduler=https://osg-itb.ligo.caltech.edu:9443
 executable=/usr2/shared/app/star_app/uptime.pl
 transfer_executable=False
 stream_output = False
 stream_error  = False
 output = test25/test.out.$(Process)
 error  = test25/test.err.$(Process)
 log    = test25/test.log
 notification=Never
 queue 25
</b></pre>

*Condor submit file example for GT2 tests:*
 
<pre class="screen"> <b> 
 Universe=grid
 grid_resource = gt2 osg-itb.ligo.caltech.edu/jobmanager-condor
 executable=/usr2/shared/app/star_app/uptime.pl
 transfer_executable=False
 stream_output = False
 stream_error  = False
 output = gt2_test25/test.out.$(Process)
 error  = gt2_test25/test.err.$(Process)
 log    = gt2_test25/test.log
 notification=Never
 queue 25
</b></pre>
 
---++ Event timing from Condor-g log file

The logfiles produced from running multiple jobs with Condor-g contain 4 separate events types with each event for each job marked by a timestamp. I will use these timestamps to break up the jobs' life cycle into these three time-periods (t1-t0, t2-t1, and t3-t2) for performance comparisons between gt4 and gt2.  An example log file is attached to this page and the event-types are listed here.

| *event kind* |  *Log-file timestamped entry*  |  *my interpretation*   |  
|  0  |  Job submitted from host: <ip-address:port>  |  submission to client submit-host  | 
|  1  |  Job submitted to Globus  |  submission to remote site  |  
|  2  |  Job executing on host:   |  submission successful to worker node  | 
|  3  |  Job terminated  |  job is fully completed and reported back to client submit-host  | 



---++ Timing Measurements

The following two plots show the timing of jobs submitted to globus for =queue 600= and for GT4 and GT2 separately. The x-axis is t1-t0 in seconds.  Here we can see a similar structure in the gt4 and gt2 results where the 600 jobs are submitted over a few thousand seconds and show a sub-structure that indicates a broad clumping by 100 jobs.  However, the gt4 result is more than twice as extended in time as the gt2 test. 


|    <img src="%ATTACHURLPATH%/zero_2_sub_600.gif" alt="zero_2_sub_600.gif" width=305' height='205' />  |       <img src="%ATTACHURLPATH%/zero_2_sub_600_gt2.gif" alt="zero_2_sub_600_gt2.gif" width='305' height='205' />
   | 

In the following two plots, both gt4 and gt2 results are overlayed. The left plot is mean-time between remote-submission and execution plotted against the =queue= sample. The right plot has the mean-time between execution and finish.  In both plots the gt4 result begin comparable to the gt2 results at low =queue= number but rise quickly with increasing number reaching plateaus 2-4 times that of the gt2 result.  The gt2 results are more stable over the entire range. 

I suspect that the increased times from gt4 over these 2 periods are the cause of the extended gt4 period in the first plots (t1-t0 above). That is, I saw little or no difference in the load on the client submit-host between the gt4 and gt2 tests with minute-averaged loads ranging from 1.0 to 2.5. Thus, the longer remote submission times was likely due to the longer completion times experienced during gt4 submission and execution.


|       <img src="%ATTACHURLPATH%/sub_2_exec_time.gif" alt="sub_2_exec_time.gif" width='305' height='205' />
  |       <img src="%ATTACHURLPATH%/exec_2_finis_time.gif" alt="exec_2_finis_time.gif" width='305' height='205' />
  |

---++ Next steps


It seems pretty clear that the plateau region in the above to plots is due to Condor-g's handling of the job submission. The sub-structure in the first plots (6 bumps for queue=600) and the starting of the plateau at =queue = 100= are related and surely due to the submit-host configuration (though just now I don't see which parameters are involved).  The next steps would be:

   * modify Condor-g's submission handling to allow more jobs sent to the remote site  
   * verify that the plateau region turns on at higher =queue= number
   * measure slope to plateau (can do this now) and use slope measurement as a metric for tuning of or feedback to WS-GRAM

These tests are fairly automated now so can be done with relative ease.  The biggest challenges are the time it takes to run the tests (~2 hrs for =queue ~ 600=) and ensuring the load on the test site is not being thrashed by other testing. 



---++ Scaling tests on UC's T2DEV-OSG

These tests included input data (~2MB/job) but no output data and the results seem much more reasonable than on the ligo-itb site. Specifically, there is not that dependence on =queue= seen on the ligo site. However, the gt4 service is still killed with =queue 120=

|       <img src="%ATTACHURLPATH%/sub-2-exec-t2dev.gif" alt="sub-2-exec-t2dev.gif" width='305' height='205' />
  |


%STOPINCLUDE%

-- Main.JeffPorter - 19 Mar 2007

%META:FILEATTACHMENT{name="exec_2_finis_unlimited.gif" attr="" autoattached="1" comment="execution-to-finsh-timing-unlimited" date="1174873984" path="exec_2_finis_unlimited.gif" size="6852" user="Main.JeffPorter" version="1"}%
%META:FILEATTACHMENT{name="condor_config" attr="" autoattached="1" comment="condor config of submit host" date="1174342496" path="condor_config" size="79707" user="Main.JeffPorter" version="1"}%
%META:FILEATTACHMENT{name="zero_2_sub_600_gt2.gif" attr="" autoattached="1" comment="gt2-queue600-sub-timing" date="1174339503" path="zero_2_sub_600_gt2.gif" size="8847" user="Main.JeffPorter" version="1"}%
%META:FILEATTACHMENT{name="sub_2_exec_unlimited.gif" attr="" autoattached="1" comment="submission-to-execution-timing-unlimited" date="1174874026" path="sub_2_exec_unlimited.gif" size="6595" user="Main.JeffPorter" version="1"}%
%META:FILEATTACHMENT{name="sub_2_exec_time.gif" attr="" autoattached="1" comment="submission-to-execution-timing" date="1174340112" path="sub_2_exec_time.gif" size="5242" user="Main.JeffPorter" version="1"}%
%META:FILEATTACHMENT{name="sub_2_exec_datamv.gif" attr="" autoattached="1" comment="submission to exec with data movement" date="1175798984" path="sub_2_exec_datamv.gif" size="7682" user="Main.JeffPorter" version="1"}%
%META:FILEATTACHMENT{name="exec_2_finis_time.gif" attr="" autoattached="1" comment="execution-to-finish-timing" date="1174340142" path="exec_2_finis_time.gif" size="5739" user="Main.JeffPorter" version="1"}%
%META:FILEATTACHMENT{name="gt4_queue25.log.log" attr="" autoattached="1" comment="gt4-queue25-log file" date="1174341261" path="gt4_queue25.log.log" size="28850" user="Main.JeffPorter" version="1"}%
%META:FILEATTACHMENT{name="killer250.tgz" attr="" autoattached="1" comment="log+out+err of condor-g job that killed ws-gram" date="1174503255" path="killer250.tgz" size="15389" user="Main.JeffPorter" version="1"}%
%META:FILEATTACHMENT{name="exec_2_finish_datamv.gif" attr="" autoattached="1" comment="exec-2-finish with data movement" date="1175798956" path="exec_2_finish_datamv.gif" size="7454" user="Main.JeffPorter" version="1"}%
%META:FILEATTACHMENT{name="zero_2_sub_600.gif" attr="" autoattached="1" comment="gt4-queue600-sub-timing" date="1174339447" path="zero_2_sub_600.gif" size="8257" user="Main.JeffPorter" version="1"}%
