%META:TOPICINFO{author="StevenTimm" date="1172098324" format="1.1" version="1.4"}%
%META:TOPICPARENT{name="Integration.ITB_0_5.DocumentationTable"}%
-- Main.StevenTimm - 04 Dec 2006
This page tracks the Site and Fabric issues that were raised at the August 
2006 consortium meeting best practices session.  I have recently (2/21/07) updated
it to track which of the changes that were raised were implemented in VDT 1.6.1 and which were not.
This document is intended to be forwarded on to be the wish list for the next version of OSG whenever
that is.  It is not part of the Installation documentation per se.


---++Desired VDT Installation and Functional Features
   * Alain question--would rpm's help with the worker node client install--yes.  Update:  in VDT 1.6.1a we are no closer to getting rpms for worker node clients.
   * Lots of bloat in clients, both user and worker node--oftentimes installs the whole server package just to get the client, should split some packages, can be insecure--to date this has not been addressed.

   * ATLAS wishlist [[http://osg.ivdgl.org/twiki/bin/view/Integration/AtlasWishList060]]  Their requirements, uberftp in worker node client, done, gLite tools, some are in (voms, myproxy) others are not.  Accounting, in, privilege-enabled storage in. 
   * Need better Condor_G audit trail--remote condor site and job ID in local classad and vice versa--some work has been done with condor team but not deployed everywhere as yet.
   * Need reaper for hung globus-job-manager processes--no progress
   * Better cleanup of /home/.globus/.gass_cache, /home/.globus/job areas--no progress
   *  Can some vdt configuration be cached outside of VDT_LOCATION (accidental deletes)-- vdt_app_data is intended for this function but not used for all the applications as yet.--configuration update now is part of VDT 1.6.x
   * Consensus from this group on pacman updates for VDT seemed to be the following:
   *  %RED% For VDT/OSG upgrades, VDT will be set up so that you can install it into a new directory, with one command switch new one on, turn old one off, and reverse the process if necessary.--done
   *  For small patches such as the coming Globus security patch, will make a small patch that can be installed on top of existing VDT directory and rolled back out if necessary--done
   *  Alain will formalize these suggestions and write them up, further discussion in VDT office hours and on mailing lists--done
   *  Best way to handle versioning, make the main directory have a versioned name, such as /usr/local/vdt-1.3.10, /usr/local/vdt-1.3.11, switch between them by making /usr/local/vdt be a soft link to the one you want. --done %ENDCOLOR%

---++Requested clarifications of policy
   * How big of files are allowed to be globus-url-copied into home areas of grid users (LCG interoperability issue, initial tarball)--still no clarification

   * Any policy on how long files can stay in APP, DATA area--no grid-wide policy, depends on site

   * What is policy on users trying to do condor_submit to standard universe, via fork jobmanager--allowed and supported

   * Many have promised that fixed $OSG_WN_TMP area won't be required in OSG 0.5.0 but need to make sure that policy is clear when it isn't--policy is clear, some VO's still can't deal with it.

   * Can there be an OSG-wide policy on the use of pool accounts, length of proxies?  More security than site/fabric--to be addressed in Security session

---++Requested refinements of information services
   * PBS sites don't advertise uniformly, some limit on cpu time, some limit on wall time--no progress
   * Also a time limit could be just a default (and you could request longer) or could be a hard limit--no progress
   * Need easier way to let users know of heterogeneous clusters with different cpu speed--GLUE schema has  subcluster fields but OSG interface has no easy way to select them
   * Pre-emption policies are not obvious from GIP, any other monitoring at this point.--still true
   * Job slot limits at the moment aren't uniform, can be done in Condor, not elsewhere.--can also be done with PBS with proper queue configuration
   * Does some of the monitoring have to be split off to a monitoring box?  Could be hard to do but we should consider.--considered but not done for now.

-- Main.StevenTimm - 09 Aug 2006