%META:TOPICINFO{author="MichaelThomas" date="1281473438" format="1.1" reprev="1.6" version="1.6"}%
%META:TOPICPARENT{name="WebHome"}%
---+!! *<nop>%SPACEOUT{ "%TOPIC%" }%*
%TOC%

---++Introduction
This tutorial covers the installation of a SE based on !Hadoop and !Bestman Gateway.  At the end of this tutorial you will be able to use srm to copy files into and out of the SE, access files through a local filesystem mount, and know how to add more storage space to Hadoop.

---++Requirements

The participants will need to have a minimum of three servers and root access on both servers, but four or more is ideal.  All servers should have a single public IP address. All servers must have the fuse kernel module and fuse userspace packages installed. All servers must have Sun Java 1.6 installed. A working gums service is required for user mappings on the !GridFTP server; grid-mapfile mappings are not currently supported. One server will run the Hadoop NameNode, Bestman, and Gridftp processes. The NameNode server must have at least 4GB of memory.  The !Bestman+GridFTP server must have a valid host or service certificate installed in /etc/grid-security/{hostcert.pem,hostkey.pem} (for gridftp) and /etc/grid-security/http/{httpcert.pem,httpkey.pem} (for !BestMan). 

If you have only three servers, then one will run the !Hadoop !Datanode, one will run the !NameNode, and the other will run the Secondary !NameNode + !BestMan + !GridFTP

If you have four servers then one will run the !Hadoop !Datanode, one will run the !NameNode, one will run the Secondary !Namenode, and the third will run !BestMan + !GridFTP

It is possible, though highly discouraged, to use only two servers by omitting the Secondary Namenode.

---++More Information

---++Commands

---+++Install Hadoop on both the Namenode and Datanode

On the namenode and datanode, run the same commands as the root user:

<pre class="screen">
rpm -ivh http://vdt.cs.wisc.edu/hadoop/osg-hadoop-1-2.el5.noarch.rpm
yum install hadoop
</pre>

Configure Hadoop on the Namenode by editting =/etc/sysconfig/hadoop=.  Configure Hadoop on the Datanode by editting =/etc/sysconfig/hadoop=.  Configure Hadoop on the Secondary Namenode by editting =/etc/sysconfig/hadoop=.  In general, you should be able to use an identical copy of =/etc/sysconfig/hadoop= on all of your nodes.  The specific settings that you will want to change are listed below.  Descriptions of the settings are in the configuration file itself, and also here:  https://twiki.grid.iu.edu/bin/view/Storage/HadoopInstallation#Edit_etc_sysconfig_hadoop

<pre class="screen">
HADOOP_NAMENODE
HADOOP_REPLICATION_DEFAULT
HADOOP_SECONDARY_NAMENODE
HADOOP_CHECKPOINT_DIRS
HADOOP_CHECKPOINT_INTERVAL
HADOOP_DATADIR
HADOOP_DATA
</pre>

Start Hadoop on the namenode first, then on the datanode second, and finally on the Secondary Namenode using the same set of commands on each:

<pre class="screen">
service hadoop-firstboot start
chkconfig hadoop on
service hadoop start
</pre>

At this point you should be able to point your web browser at =http://namenode:9000/= and see your namenode status page and a single datanode.  You can also copy files into and out of HDFS using the native hadoop commands, such as:

<pre class="screen">
hadoop fs -mkdir /osg
hadoop fs -chown 777 /osg
hadoop fs -copyFromLocal /etc/hosts /osg/hosts.txt
</pre>

Verify that the file was copied with:

<pre class="screen">
hadoop fs -ls /
</pre>

Before you can use the POSIX fuse mount, you need to install the appropriate package:

<pre class="screen">
yum install hadoop-fuse
</pre>

Now you can try mounting the POSIX fuse mount for hadoop by adding the following to =/etc/fstab=

<pre class="screen">
hdfs# /mnt/hadoop fuse server=namenode.host,port=9000,rdbuffer=32768,allow_other 0 0
</pre>

Now mount the filesystem with:

<pre class="screen">
mkdir -p /mnt/hadoop
mount /mnt/hadoop
</pre>

At this point you should be able to ls, cat, cp, and rm files in =/mnt/hadoop=.  Verify that the file you copied earlier with the native hadoop commands appears in the POSIX fuse mount. 

---+++ Install !GridFTP

<pre class="screen">
rpm -ivh http://vdt.cs.wisc.edu/hadoop/osg-hadoop-1-2.el5.noarch.rpm
yum install gridftp-hdfs
</pre>

Modify =/etc/sysconfig/hadoop= appropriately (see above).  Set your gums hostname in =/etc/grid-security/prima-authz.conf=.  Now configure hadoop and restart xinetd so that it recognizes the new service.

<pre class="screen">
service hadoop-firstboot start
service xinetd restart
</pre>

At this point you should be able to use globus-url-copy to copy files into and out of HDFS.  From a host with the osg client installed, run:

<pre class="screen">
globus-url-copy file:////etc/hosts gsiftp://your.srm.host:2811/osg/junk.txt
</pre>

Now use the hadoop commands on any of your hadoop nodes to verify the file:

<pre class="screen">
hadoop fs -ls /osg
hadoop fs -cat /osg/junk.txt
</pre>

---+++Install !BestMan SRM

Since we are installing Bestman on the same node as GridFTP, we don't have to install the =osg-hadoop= setup package again and can proceed directly with the installation of bestman.  Make sure to fix the ownership of your http cert/key pair after bestman is installed:

<pre class="screen">
yum install bestman hadoop-fuse
chown -R bestman: /etc/grid-security/http
</pre>

Make sure the POSIX fuse mount is available, following the directions above.

You should now modify your bestman configuration to point to your gridftp server, set the allowed list of paths that bestman can access, and point to your gums server:

<pre class="screen">
supportedProtocolList=gsiftp://your.gridftp.server1:2811;gsiftp://your.gridftp.server2:2811
GUMSserviceURL=https://your.gums.host:8443/gums/services/GUMSAuthorizationServicePort
localPathListAllowed=/mnt/hadoop;/tmp
</pre>

You also need to run =visudo= to update the =/etc/sudoers= file with settings to allow bestman to access files in HDFS.  Add the following to the end of this file:

<pre class="screen">
Cmnd_Alias SRM_CMD = /bin/rm, /bin/mkdir, /bin/rmdir, /bin/mv, /bin/ls 
Runas_Alias SRM_USR = ALL, !root 
bestman ALL=(SRM_USR) NOPASSWD:SRM_CMD
</pre>

Now you can start the bestman service with:

<pre class="screen">
service bestman start
</pre>

At this point you should be able to use srmcp and srm-copy to copy files into and out of Hadoop.

<pre class="screen">
srmls -2 srm://namenode.host:8443/srm/v2/server?SFN=/mnt/hadoop/osg
srmcp -2 file:////etc/hosts srm://namenode.host:8443/srm/v2/server?SFN=/mnt/hadoop/osg/junk2.txt
srm-copy file:////etc/hosts srm://osg-srm.ultralight.org:8443/srm/v2/server?SFN=/mnt/hadoop/osg/junk3.txt
</pre>

Congratulations!  You now have a working SE using Hadoop/HDFS and !BestMan Gateway.

---++Presentation

<embed src="%ATTACHURL%/Hadoop_OSG-SiteAdmin_August_2010.pdf" width="792" height="612">

---++References

   1 https://twiki.grid.iu.edu/bin/view/Storage/Hadoop
   1 https://twiki.grid.iu.edu/bin/view/Storage/HadoopInstallation
   1 https://twiki.grid.iu.edu/bin/view/Storage/HadoopGridFTP
   1 https://twiki.grid.iu.edu/bin/view/Storage/HadoopSRM

%BR%

---++ *Comments*
%COMMENT{type="tableappend"}%

<!--
   * Set USERSTYLEURL = https://twiki.grid.iu.edu/twiki/pub/ReleaseDocumentation/HandsOn/centerpageborder.css
-->

%BR%
%COMPLETE1% %BR%
%RESPONSIBLE% you %BR%
%REVIEW%
   * [[%ATTACHURL%/Hadoop_OSG-SiteAdmin_August_2010.pdf][Hadoop_OSG-SiteAdmin_August_2010.pdf]]: Hadoop overview

%META:FILEATTACHMENT{name="Hadoop_OSG-SiteAdmin_August_2010.pdf" attachment="Hadoop_OSG-SiteAdmin_August_2010.pdf" attr="" comment="Hadoop overview" date="1281449427" path="Hadoop_OSG-SiteAdmin_August_2010.pdf" size="90302" stream="Hadoop_OSG-SiteAdmin_August_2010.pdf" tmpFilename="/usr/tmp/CGItemp25189" user="MichaelThomas" version="1"}%
