%META:TOPICINFO{author="MarcoMambelli" date="1328756710" format="1.1" version="1.2"}%
%META:TOPICPARENT{name="WebHome"}%
---+ SLAC - OSG meeting

---++ Coordinates
Phone: # 1 866-740-1260, code 8349885#

International participants dial Toll Number: 303-248-0285 or for International Toll-Free Number check: http://www.readytalk.com/intl

Join via Adobe Connect: http://osg.adobeconnect.com/osgmeeting/   

The time is Friday 1/20 11am-12pm West (1-2pm central, 2-3pm east)


---++ Request
Initial message from Steffen Luitz:

Hi All,

In November and December we had meetings with our scientific user community (representatives from FGST, PPA Theory and a few others) to explore how we could better take advantage of the Open Science Grid. While on one hand we need to figure out how we (our scientific users) can use cycles provided by other OSG sites, we will on the other hand need to reciprocate and step up our capabilities as an OSG resource provider. One of the problems seems to be that SLAC is configured differently from "the typical OSG site" (e.g. with a few exceptions no outgoing Internet connectivity for worker nodes), another the lack of a general (non-ATLAS) OSG infrastructure. With all the requirements-gathering for the strategic planning and roadmap processes going on, and after a discussion with Amber on Friday, I think it would be a good time to also consider the OSG requirements across our systems.

As a first step, I'd like to propose a meeting where Gabriele Garzoglio (FNAL, OSG) or someone from the OSG site coordination team would give a (phone) presentation about how "the typical OSG site"  is usually configured, what the requirements are and have a discussion of what needs to be included in the various roadmaps and what the next steps could be.

Given Gabriele's schedule and my travel schedule, the meeting would have to be next week or be delayed until at least mid-February.

Since OSG touches Unix, network, storage and security, it would be great to have representatives from these areas, please let me know who should be invited (the recipients list is just from the top of my head), so please feel free to suggest attendants - I'd be happy to arrange the details.


---++ Minutes (revised)
---+++ Attendees: 
UC: Marco Mambelli , FNAL: Gabriele Garzoglio <garzogli@fnal.gov>,
SLAC: probably "Luitz, Steffen" <luitz@slac.stanford.edu>,  "Yang, Wei" <yangw@slac.stanford.edu>, "Moss, Leonard J." <ljm@slac.stanford.edu>,
    "Bense, Booker" <bbense@slac.stanford.edu>, "Gruber, Shirley" <shirley@slac.stanford.edu>,
    "Ceseracciu, Antonio" <antony@slac.stanford.edu>, "Cottrell, Les" <cottrell@slac.stanford.edu>,
    "Buhrmaster, Gary" <gtb@slac.stanford.edu>, "Nakata, Lance" <lnakata@slac.stanford.edu>,
    "Cowles, Robert D." <rdc@slac.stanford.edu>, "Boehnlein, Amber" <amber@slac.stanford.edu>, "Ringgold, Norm" <norm@slac.stanford.edu>

Minutes sent also to Rob Gardner <rwg@hep.uchicago.edu>


Dear all,
here are some brief notes about last Friday's meeting and attached is the presentation.

In the presentation I covered the requirements for OSG sites and some additional requests from OSG VOs.

SLAC has already an OSG site that satisfies OSG requirements but is interested in making its resources more accessible to a broader set of the SLAC and OSG community.

Many VOs have been relying on features available on most OSG sites
   1. a Linux platform
   2. some opportunistic storage shared across the clusters
   3. outbound network connectivity from the worker nodes
   4. pool accounts (a big number of Unix accounts dedicated to a VO)

1. is not a problem. Pool accounts (4) are required for a limited number of VOs and generally have workarounds.

The most important problem seems outbound connectivity (3) that could eliminate also the need of opportunistic storage (2) because given the good network connectivity and the limited amount of data, jobs could use the local disk and stage the data in and out form VO owned storage elements.

VOs could provide a list of IP and ports that their jobs connect to but in practice they have grown accustomed to outbound connectivity and sometime are not fully aware of their network requirements.

Allowing unrestricted outbound connectivity form the worker nodes, like most sites do, would simplify the task for the VOs and reduce the effort for system administrators that do not have to update the firewall with servers and ports each time there is a change in a VO or a new VO is added.
According to the BDII (OSG information system), out of 227 subclusters in OSG, only 12 subclusters (7 at SLAC, 3 test one and 2 more) do not provide outbound connectivity form the worker nodes


The next step is to have a phone meeting with SLAC and OSG representatives to compare notes on how outbound connectivity is handled and discuss security implications.
SLAC is interested also in hearing how idle time during file transfers is handled to limit the decrease in CPU efficiency (e.g. are jobs over-scheduled?).
For OSG there will be representatives form OSG security and some sites: Fermilab (DOE funded) and MWT2 (NSF funded)

I contacted Rob Gardner (MWT2), in CC, and sent an email to OSG security. Gabriele will provide a Fermilab contact, then Steffen or someone else can schedule the meeting.


---++ More
---+++ Sub-clusters not providing outbound connectivity
Out of 227 subclusters in OSG, 12 subclusters (7 at SLAC, 3 test one and 2 more) do not provide outbound connectivity form the worker nodes

Investigation via ldadsearch, grep and file inspection:
<pre>
[root@fermicloud009 ~]# ldapsearch  -x -l 60 -b mds-vo-name=local,o=grid  -h is-itb.grid.iu.edu -p 2170  "(&(objectClass=GlueClusterTop)(objectClass=GlueHostApplicationSoftware)(objectClass=GlueSubCluster))" > ptp
[root@fermicloud009 ~]# grep GlueHostNetworkAdapterOutboundIP ptp > ptp2
[root@fermicloud009 ~]# wc ptp2
 227  454 8865 ptp2
[root@fermicloud009 ~]# grep TRUE ptp2 | wc
    215     430    8385
[root@fermicloud009 ~]# grep FALSE ptp2 | wc
     12      24     480
</pre>
Subclusters not providing outbound network connectivity:
<pre>
# cms-xen11.fnal.gov-ITB_INSTALL_TEST, cms-xen11.fnal.gov, ITB_INSTALL_TEST,  local, grid
# cms-xen2.fnal.gov-OSG_INSTALL_TEST_2, cms-xen2.fnal.gov, OSG_INSTALL_TEST_2 , local, grid
# cms-xen9.fnal.gov-ITB_INSTALL_TEST_3, cms-xen9.fnal.gov, ITB_INSTALL_TEST_3 , local, grid
# fell-WT2, slac, WT2, local, grid
# bali-WT2, slac, WT2, local, grid
# boer-WT2, slac, WT2, local, grid
# yili-WT2, slac, WT2, local, grid
# kiso-WT2, slac, WT2, local, grid
# dole-WT2, slac, WT2, local, grid
# hequ-WT2, slac, WT2, local, grid
# LIGO_OSG_NEMO-LIGO_UWM_NEMO, osg-nemo-ce.phys.uwm.edu, LIGO_UWM_NEMO, local , grid
# piranha, piranha.ie.lehigh.edu, Lehigh_coral, local, grid
</pre>

---++ Next meeting
http://www.doodle.com/t3qtprphg3z47p8a                                                               


-- Main.MarcoMambelli - 23 Jan 2012
   * [[%ATTACHURL%/slac-osg-meeting.pdf][slac-osg-meeting.pdf]]: slac-osg-meeting.pdf

   * [[%ATTACHURL%/slac-osg-meeting.pptx][slac-osg-meeting.pptx]]: slac-osg-meeting.pptx

%META:FILEATTACHMENT{name="slac-osg-meeting.pdf" attachment="slac-osg-meeting.pdf" attr="" comment="" date="1327351095" path="slac-osg-meeting.pdf" size="56696" stream="slac-osg-meeting.pdf" tmpFilename="/usr/tmp/CGItemp10282" user="MarcoMambelli" version="1"}%
%META:FILEATTACHMENT{name="slac-osg-meeting.pptx" attachment="slac-osg-meeting.pptx" attr="" comment="" date="1327351289" path="slac-osg-meeting.pptx" size="84293" stream="slac-osg-meeting.pptx" tmpFilename="/usr/tmp/CGItemp10411" user="MarcoMambelli" version="1"}%
