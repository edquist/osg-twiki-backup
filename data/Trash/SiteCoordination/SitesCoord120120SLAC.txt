%META:TOPICINFO{author="MarcoMambelli" date="1330372984" format="1.1" version="1.6"}%
%META:TOPICPARENT{name="WebHome"}%
---+!! SLAC - OSG meeting
%TOC%

---++ Coordinates
Phone: # 1 866-740-1260, code 8349885#

International participants dial Toll Number: 303-248-0285 or for International Toll-Free Number check: http://www.readytalk.com/intl

Join via Adobe Connect: http://osg.adobeconnect.com/osgmeeting/   

The time is Friday 1/20 11am-12pm West (1-2pm central, 2-3pm east)


---++ Request
Initial message from Steffen Luitz:

Hi All,

In November and December we had meetings with our scientific user community (representatives from FGST, PPA Theory and a few others) to explore how we could better take advantage of the Open Science Grid. While on one hand we need to figure out how we (our scientific users) can use cycles provided by other OSG sites, we will on the other hand need to reciprocate and step up our capabilities as an OSG resource provider. One of the problems seems to be that SLAC is configured differently from "the typical OSG site" (e.g. with a few exceptions no outgoing Internet connectivity for worker nodes), another the lack of a general (non-ATLAS) OSG infrastructure. With all the requirements-gathering for the strategic planning and roadmap processes going on, and after a discussion with Amber on Friday, I think it would be a good time to also consider the OSG requirements across our systems.

As a first step, I'd like to propose a meeting where Gabriele Garzoglio (FNAL, OSG) or someone from the OSG site coordination team would give a (phone) presentation about how "the typical OSG site"  is usually configured, what the requirements are and have a discussion of what needs to be included in the various roadmaps and what the next steps could be.

Given Gabriele's schedule and my travel schedule, the meeting would have to be next week or be delayed until at least mid-February.

Since OSG touches Unix, network, storage and security, it would be great to have representatives from these areas, please let me know who should be invited (the recipients list is just from the top of my head), so please feel free to suggest attendants - I'd be happy to arrange the details.


---++ Minutes (revised)
---+++ Attendees: 
UC: Marco Mambelli , FNAL: Gabriele Garzoglio <garzogli@fnal.gov>,
SLAC: probably "Luitz, Steffen" <luitz@slac.stanford.edu>,  "Yang, Wei" <yangw@slac.stanford.edu>, "Moss, Leonard J." <ljm@slac.stanford.edu>,
    "Bense, Booker" <bbense@slac.stanford.edu>, "Gruber, Shirley" <shirley@slac.stanford.edu>,
    "Ceseracciu, Antonio" <antony@slac.stanford.edu>, "Cottrell, Les" <cottrell@slac.stanford.edu>,
    "Buhrmaster, Gary" <gtb@slac.stanford.edu>, "Nakata, Lance" <lnakata@slac.stanford.edu>,
    "Cowles, Robert D." <rdc@slac.stanford.edu>, "Boehnlein, Amber" <amber@slac.stanford.edu>, "Ringgold, Norm" <norm@slac.stanford.edu>

Minutes sent also to Rob Gardner <rwg@hep.uchicago.edu>


Dear all,
here are some brief notes about last Friday's meeting and attached is the presentation.

In the presentation I covered the requirements for OSG sites and some additional requests from OSG VOs.

SLAC has already an OSG site that satisfies OSG requirements but is interested in making its resources more accessible to a broader set of the SLAC and OSG community.

Many VOs have been relying on features available on most OSG sites
   1. a Linux platform
   2. some opportunistic storage shared across the clusters
   3. outbound network connectivity from the worker nodes
   4. pool accounts (a big number of Unix accounts dedicated to a VO)

1. is not a problem. Pool accounts (4) are required for a limited number of VOs and generally have workarounds.

The most important problem seems outbound connectivity (3) that could eliminate also the need of opportunistic storage (2) because given the good network connectivity and the limited amount of data, jobs could use the local disk and stage the data in and out form VO owned storage elements.

VOs could provide a list of IP and ports that their jobs connect to but in practice they have grown accustomed to outbound connectivity and sometime are not fully aware of their network requirements.

Allowing unrestricted outbound connectivity form the worker nodes, like most sites do, would simplify the task for the VOs and reduce the effort for system administrators that do not have to update the firewall with servers and ports each time there is a change in a VO or a new VO is added.
According to the BDII (OSG information system), out of 227 subclusters in OSG, only 12 subclusters (7 at SLAC, 3 test one and 2 more) do not provide outbound connectivity form the worker nodes


The next step is to have a phone meeting with SLAC and OSG representatives to compare notes on how outbound connectivity is handled and discuss security implications.
SLAC is interested also in hearing how idle time during file transfers is handled to limit the decrease in CPU efficiency (e.g. are jobs over-scheduled?).
For OSG there will be representatives form OSG security and some sites: Fermilab (DOE funded) and MWT2 (NSF funded)

I contacted Rob Gardner (MWT2), in CC, and sent an email to OSG security. Gabriele will provide a Fermilab contact, then Steffen or someone else can schedule the meeting.


---++ More
---+++ Sub-clusters not providing outbound connectivity
Out of 227 subclusters in OSG, 12 subclusters (7 at SLAC, 3 test one and 2 more) do not provide outbound connectivity form the worker nodes

Investigation via ldadsearch, grep and file inspection:
<pre>
[root@fermicloud009 ~]# ldapsearch  -x -l 60 -b mds-vo-name=local,o=grid  -h is-itb.grid.iu.edu -p 2170  "(&(objectClass=GlueClusterTop)(objectClass=GlueHostApplicationSoftware)(objectClass=GlueSubCluster))" > ptp
[root@fermicloud009 ~]# grep GlueHostNetworkAdapterOutboundIP ptp > ptp2
[root@fermicloud009 ~]# wc ptp2
 227  454 8865 ptp2
[root@fermicloud009 ~]# grep TRUE ptp2 | wc
    215     430    8385
[root@fermicloud009 ~]# grep FALSE ptp2 | wc
     12      24     480
</pre>
Subclusters not providing outbound network connectivity:
<pre>
# cms-xen11.fnal.gov-ITB_INSTALL_TEST, cms-xen11.fnal.gov, ITB_INSTALL_TEST,  local, grid
# cms-xen2.fnal.gov-OSG_INSTALL_TEST_2, cms-xen2.fnal.gov, OSG_INSTALL_TEST_2 , local, grid
# cms-xen9.fnal.gov-ITB_INSTALL_TEST_3, cms-xen9.fnal.gov, ITB_INSTALL_TEST_3 , local, grid
# fell-WT2, slac, WT2, local, grid
# bali-WT2, slac, WT2, local, grid
# boer-WT2, slac, WT2, local, grid
# yili-WT2, slac, WT2, local, grid
# kiso-WT2, slac, WT2, local, grid
# dole-WT2, slac, WT2, local, grid
# hequ-WT2, slac, WT2, local, grid
# LIGO_OSG_NEMO-LIGO_UWM_NEMO, osg-nemo-ce.phys.uwm.edu, LIGO_UWM_NEMO, local , grid
# piranha, piranha.ie.lehigh.edu, Lehigh_coral, local, grid
</pre>

---++ Meeting 2/15/12 - FNAL and OSG, wn connectivity
Attendees: FNAL: Keith Chadwick, Irwin Gaines OSG: Mine, Marco SLAC: Steffen, Wei, Antonio (netw), Booker, Gary (security), Amber

Possible threats discussed:
   * DOS starting from nodes
   * access to confidential internal data
   * use for personal business (VOs not respecting the agreement)
   * export control issues (?Dind? export)
   * difference of worker nodes at FNAL and SLAC and between worker nodes and other computers on-site

Request from SLAC to have a meeting with BNL representatives.

---++ Meeting 2/27/12 - BNL, wn connectivity
Monday 2/27 1pm EST (12pm CST, 10am WST)
   * phone (readytalk): 1 866-740-1260, code 8349885#
   * International participants dial Toll Number: 303-248-0285 or for International Toll-Free Number check: http://www.readytalk.com/intl

Join via Adobe Connect: http://osg.adobeconnect.com/osgmeeting/

---+++ Minutes
*Attendees*: Marco and Gabriele (OSG);
Irwin Gaines (Fermilab);
Steffen Luitz, Wei Yang, Booker Bense, Gary Buhrmaster, Ian (SLAC);
Michael Ernst, John Hover, Alex Wither (BNL)

*Meeting Notes:*

Steffen gave an introduction to the problem: SLAC would like to be a "better citizen" of OSG. Use opportunistic resources outside, allow more outside jobs on SLAC. One of the bigger showstopper is that there is no outgoing access from worker nodes. FNAL gave useful input. Would like to hear from BNL

As far as John and Michael know, BNL provided always outbound connectivity form the worker nodes: they have a public IP, are behind a firewall with inbound connectivity blocked and only few ports are blocked outbound (80, 443, 8443) and must use a proxy server. There is a work in progress to probably replace the need of a proxy with some transparent filtering.

Alex. Tools used to control traffic and mitigate risks: 
   1. mandate that all the node have CS log data
   2. collect flow data. Number of monitoring.
   3. actively collect and log all packets (Solera) on a 3 weeks window
A lot of ssh outbound connections are seen. There is no idea of the content. BNL relies on the collaboration of the other institution. Access to logs and host monitoring provide some data but the other end will help in case of suspect traffic.


Few more questions form SLAC. How do you deal with:
   1. Be a potential DOS source - Home grown application that monitors flows, sends alerts and may also shut down connections at the nearest switch if bad enough
   2. Issues of potential export of non public data (bussines, restricted, …) - Compute nodes are on a separate enclave with different Firewall. Business systems are on separate networks isolated with their own Firewall. Science running there uses no restricted data.
   3. Process for DIMD export issues. ITAR regulation, can include also using resources in a way that can contribute to a restricted resource. - No special control. Control is delegated to the VO authorizing the jobs.
   4. How are batch nodes used? - Local batch submission and grid jobs. No interactive use (it is separate).
   5. Is it possible to get a copy of general CSPP, where talking of risks and mitigation? - Within BNL RICF has a separate security plan. Keith W (BNL) will contact Nens Speirs (SLAC CIS) and most likely share the document on a one-to-one basis.  

*Next step:*

SLAC will do an internal review: do some research, look at risk assessments, decide. 
Gabriele Garzoglio asked for a timeline. SLAC answered that it is difficult because there are some resources involved that are not under the control of the people attending the meeting. Probably few months and less than one year.


---++ Follow-up
   * SLAC will receive CSPP from FNAL and BNL (a sanitized version with no specifics names/IPs is fine)
   * SLAC will complete its internal review
   * SLAC (Steffen) will contact is any further help is needed in the process

%META:FILEATTACHMENT{name="slac-osg-meeting.pdf" attachment="slac-osg-meeting.pdf" attr="" comment="" date="1327351095" path="slac-osg-meeting.pdf" size="56696" stream="slac-osg-meeting.pdf" tmpFilename="/usr/tmp/CGItemp10282" user="MarcoMambelli" version="1"}%
%META:FILEATTACHMENT{name="slac-osg-meeting.pptx" attachment="slac-osg-meeting.pptx" attr="" comment="" date="1327351289" path="slac-osg-meeting.pptx" size="84293" stream="slac-osg-meeting.pptx" tmpFilename="/usr/tmp/CGItemp10411" user="MarcoMambelli" version="1"}%
