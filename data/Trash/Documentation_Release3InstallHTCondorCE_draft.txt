%META:TOPICINFO{author="BrianLin" date="1503677428" format="1.1" version="1.4"}%
<style type="text/css">
code em, pre em { color: red; font-weight: normal; font-style: normal; }
</style>

---+ Installing and Maintaining HTCondor-CE

%TOC{depth="3"}%

---++ About This Guide

The HTCondor-CE software is a _job gateway_ for an OSG Compute Element (CE). As such, HTCondor-CE is the entry point for jobs coming from the OSG — it handles authorization and delegation of jobs to your local batch system. In OSG today, most CEs accept _pilot jobs_ from a factory, which in turn are able to accept and run end-user jobs.

Use this page to learn how to install, configure, run, test, and troubleshoot HTCondor-CE from the OSG software repositories.

---++ Before Starting

Before starting the installation process, consider the following points (consulting [[#ReferenceSection][the Reference section below]] as needed):

   * *User IDs:* If they do not exist already, the installation will create the Linux user IDs =condor= (UID 4716), =tomcat= (UID 91) and =gratia= (UID 42401)
   * *Service certificate:* The HTCondor-CE service uses a host certificate at =/etc/grid-security/host*.pem=
   * *Network ports:* The pilot factories must be able to contact your HTCondor-CE service on ports 9619 and 9620 (TCP)
   * *Host choice:* HTCondor-CE should be installed on a host that already has the ability to submit jobs into your local cluster

As with all OSG software installations, there are some one-time (per host) steps to prepare in advance:

   * Ensure the host has [[Documentation/Release3.SupportedOperatingSystems][a supported operating system]]
   * Obtain root access to the host
   * Prepare [[Documentation/Release3.YumRepositories][the required Yum repositories]]
   * Install [[Documentation/Release3.InstallCertAuth][CA certificates]]


---++ Installing HTCondor-CE

An HTCondor-CE installation consists of the job gateway (i.e., the HTCondor-CE job router) and other support software (e.g., !GridFTP, a Gratia probe, authorization software). To simplify installation, OSG provides convenience RPMs that install all required software with a single command.

<ol>
%INCLUDE{"Documentation/Release3/OSGReleaseSeries" section="Update"}%
  <li>
    <p>If your batch system is already installed via non-RPM means and is in the following list, install the appropriate 'empty' RPM. Otherwise, skip to the next step.</p>
%TABLE{sort="off"}%
| *If your batch system is…* | *Then run the following command…* |
| HTCondor | =yum install empty-condor --enablerepo=osg-empty= |
| PBS | =yum install empty-torque --enablerepo=osg-empty= |
| SGE | =yum install empty-gridengine --enablerepo=osg-empty= |
| Slurm | =yum install empty-slurm --enablerepo=osg-empty= |
  </li>
  <li>
    <p>If your HTCondor batch system is already installed via non-OSG RPM means, add the line below to =/etc/yum.repos.d/osg.repo=. Otherwise, skip to the next step.</p>
    <pre class="file">exclude=condor* empty-condor</pre>
  </li>
  <li>    
    <p>Select the appropriate convenience RPM(s):</p>
%TABLE{sort="off"}%
| *If your batch system is…* | *Then use the following package(s)…* |
| HTCondor | =osg-ce-condor= |
| LSF | =osg-ce-lsf= |
| PBS | =osg-ce-pbs= |
| SGE | =osg-ce-sge= |
| Slurm | =osg-ce-pbs gratia-probe-slurm osg-configure-slurm= |
  </li>
  <li>
    <p>Install the CE software:</p>
    <pre class="rootscreen">%UCL_PROMPT_ROOT% yum install <em>PACKAGE(S)</em></pre>
  </li>
</ol>

%NOTE% To ease the transition from GRAM to HTCondor-CEs, the convenience RPMs install both types of job gateway software. By default, the HTCondor gateway is enabled and the GRAM gateway is disabled, which is the correct configuration for most HTCondor-CE-based sites (but see the gateway configuration section below for more options).

%NOTE% HTCondor-CE version 1.6 or later is required to send site resource information to OSG for matching jobs to resources.


---++ Configuring HTCondor-CE

There are a few required configuration steps to connect HTCondor-CE with your batch system and authorization method. For more advanced configuration, see the section on [[#OptionalConfig][optional configurations]].

---+++ Enabling HTCondor-CE

If you are installing HTCondor-CE on a new host, the default configuration is correct and you can skip this step and continue onto [[#BatchSystem][Configuring the batch system]]! However, if you are updating a host that used a Globus GRAM job gateway (aka the Globus gatekeeper), you must enable the HTCondor job gateway.

   1. <p>Decide whether to disable GRAM (the preferred option) or run both HTCondor and GRAM CEs</p>
   1. <p>Edit the gateway configuration file =/etc/osg/config.d/10-gateway.ini= to reflect your choice</p>\
       <p>To enable HTCondor-CE and disable GRAM&nbsp;CE:</p>\
       <pre class="file">gram_gateway_enabled = False
htcondor_gateway_enabled = True</pre>\
       <p>To enable both HTCondor and GRAM CEs:</p>\
       <pre class="file">gram_gateway_enabled = True
htcondor_gateway_enabled = True</pre>

More information about the Globus GRAM&nbsp;CE can be found [[Documentation/Release3.InstallComputeElement][here]].

#BatchSystem
---+++ Configuring the batch system

Enable your batch system by editing the =enabled= field in the =/etc/osg/config.d/20-<span style="background-color: #FFCCFF;">YOUR BATCH SYSTEM</span>.ini= file:\
<pre class="file">enabled = <span style="background-color: #FFCCFF;">True</span></pre>

---++++ Batch systems other than HTCondor

If you are using HTCondor as your *local batch system* (i.e., in addition to your HTCondor-CE), skip to the [[#ConfiguringAuthorization][configuring authorization]] section. For other batch systems (e.g., PBS, LSF, SGE, Slurm), keep reading.

---+++++ Sharing the spool directory

To transfer files between the CE and the batch system, HTCondor-CE requires a shared file system. The current recommendation is to run a dedicated NFS server (whose installation is beyond the scope of this document) on the *CE host*. In this setup, HTCondor-CE writes to the local spool directory, the NFS server exports the it, and the NFS server shares the it with all of the worker nodes.

%NOTE% If you choose not to host the NFS server on your CE, you will need to turn off root squash so that the HTCondor-CE daemons can write to the spool directory.

By default, the spool directory is =/var/lib/condor-ce= but you can control this by setting =SPOOL= in =/etc/condor-ce/config.d/99-local.conf= (create this file if it doesn't exist). For example, the following sets the =SPOOL= directory to =/home/condor=:

<pre class="file">SPOOL=/home/condor</pre>

%NOTE% The shared spool directory must be readable and writeable by the =condor= user for HTCondor-CE to function correctly.

---+++++ Disable worker node proxy renewal

Worker node proxy renewal is not used by HTCondor-CE and leaving it on will cause some jobs to be held. Edit =/etc/blah.config= on the HTCondor-CE host and set the following two values:

<pre class="file">
blah_disable_wn_proxy_renewal=yes
blah_delegate_renewed_proxies=no
</pre>

%NOTE% There should be no whitespace around the =&#61;=. 

#ConfiguringAuthorization
---+++ Configuring authorization

There are two methods to manage authorization for incoming jobs, edg-mkgridmap and GUMS. edg-mkgridmap is easy to set up and maintain, and GUMS has more features and capabilities. We recommend using edg-mkgridmap unless you have specific needs that require the use of GUMS. Some examples of these specific requirements are:

   * You want to map users based on rules
   * You need to support multiple VO roles
   * You need to support !gLExec for pilot jobs

---++++ Authorization with edg-mkgridmap

To configure your CE to use edg-mkgridmap:

   1. <p>Follow the configuration instructions in [[Documentation/Release3.Edg-mkgridmap][the edg-mkgridmap document]] to define the VOs that your site accepts</p>
   1. <p>Set some critical gridmap attributes by editing the =/etc/osg/config.d/10-misc.ini= file on the HTCondor-CE host:</p>\
      <pre class="file">
authorization_method = gridmap
</pre>
   1. <p>Enable edg-mkgridmap and disable GUMS in the =/etc/lcmaps.db= file</p>\
       <p>In the =authorize_only= section, comment out the =gumsclient= line and uncomment the =gridmapfile= line. The result should be as follows:</p>\
       <pre class="file">
authorize_only:
# gumsclient -> good | bad
gridmapfile -> good | bad
</pre>
   1. <p>Specify the location of your grid mapfile in =/etc/condor-ce/config.d/01-common-auth.conf=:</p>\
       <pre class="file">GRIDMAP = /etc/grid-security/grid-mapfile</pre>\
       <p><strong>Note:</strong> The standard location for the grid mapfile is shown above. Use that location unless you have specific reasons to put the file somewhere else.</p>

---++++ Authorization with GUMS

   1. <p>Follow the instructions in [[Documentation/Release3.InstallGums][the GUMS installation and configuration document]] to prepare GUMS</p>
   1. <p>Set some critical GUMS attributes by editing the =/etc/osg/config.d/10-misc.ini= file on the HTCondor-CE host:</p>\
       <pre class="file">
authorization_method = xacml
gums_host = <span style="background-color: #FFCCFF;">YOUR GUMS HOSTNAME</span>
</pre>

%NOTE% Once gsi-authz.conf is in place, your local HTCondor will attempt to utilize the LCMAPS callouts if enabled in the condor_mapfile.  If this is not the desired behavior, set GSI_AUTHZ_CONF=/dev/null in the local HTCondor configuration.

---+++ Configuring information systems

To split jobs between the various sites of the OSG, information about each site&rsquo;s availability is uploaded to a central collector. The job factories then query the central collector for idle resources and submit pilot jobs to the available sites. To advertise your site, you will need to run the Generic Information Provider and OSG Info Services.

---++++ Generic Information Provider (GIP)

The =GIP= is a service that discovers information about your site resources like the number of available cores and what VO's are allowed to run on your site. Consult the [[Documentation/Release3.GipConfiguration][GIP configuration document]] for instructions on how to set up your =GIP= service.

%NOTE% If you have =gip-1.3.11-4= installed, manual intervention is required for correct reporting to BDII. See [[Documentation/Release3.Release3220#Trash.ReleaseDocumentationKnownIssues][3.2.20 known issues]].

---++++ OSG Info Services

=osg-info-services= takes the information collected from =GIP= and uploads it to OSG's central collector. For =osg-info-services= to communicate with the appropriate servers, it needs a service certificate and key located at =/etc/grid-security/http/httpcert.pem= and =/etc/grid-security/http/httpkey.pem=, respectively. The service certificate and key need to be owned by the appropriate user: =tomcat= (default) or the local user account specified by the =user= option in =/etc/osg/config.d/30-gip.ini=. Enable osg-info-services in =/etc/osg/config.d/30-infoservices.ini=:

<pre class="file">enabled = <em>True</em></pre>

---+++ Applying configuration settings

Making changes to the OSG configuration files in the =/etc/osg/config.d= directory does not apply those settings to software automatically. Settings that are made outside of the OSG directory take effect immediately or at least when the relevant service is restarted. For the OSG settings, use the [[Documentation/Release3.IniConfigurationOptions][osg-configure]] tool to validate (to a limited extent) and apply the settings to the relevant software components. The =osg-configure= software is included automatically in an HTCondor-CE installation.

   1. <p>Make all changes to =.ini= files in the =/etc/osg/config.d= directory</p>\
       <p><strong>Note:</strong> This document describes the critical settings for HTCondor-CE and related software. You may need to configure other software that is installed on your HTCondor-CE host, too.</p>
   1. <p>Validate the configuration settings</p>\
       <pre class="rootscreen">%UCL_PROMPT_ROOT% osg-configure -v</pre>\
       <p>Fix any errors (at least) that =osg-configure= reports.</p>
   1. <p>Once the validation command succeeds without errors, apply the configuration settings:</p>\
       <pre class="rootscreen">%UCL_PROMPT_ROOT% osg-configure -c</pre>
   1. <p>Generate a =user-vo-map= file with your authorization set up:</p>
      i. <p>If you're using edg-mkgridmap, run the following:</p>\
         <pre class="rootscreen">%UCL_PROMPT_ROOT% edg-mkgridmap</pre>
      i. <p>If you're using GUMS, run the following:</p>\
         <pre class="rootscreen">%UCL_PROMPT_ROOT%  gums-host-cron</pre>

#OptionalConfig
---+++ Optional configuration

The following configuration steps are optional and will likely not be required for setting up a small site. If you do not need any of the following special configurations, skip to [[#UsingHTCondorCE][the section on using HTCondor-CE]].

   * [[#JobRoutes][Transforming and filtering jobs]]
   * [[#NetworkInterfaces][Configuring for multiple network interfaces]]
   * [[#LocalUni][Limiting or disabling locally running jobs on the CE]]
   * [[#SuppressNoDnRecords][Accounting with multiple CEs or local user jobs]]
   * [[#AccountingGroups][HTCondor accounting groups]]
   * [[#CeView][Installing the HTCondor-CE View]]
   * [[#WalltimeUnits][Converting walltime units]]

#JobRoutes
---++++ Transforming and filtering jobs

If you need to modify or filter jobs, more information can be found in the [[Documentation/Release3.JobRouterRecipes][Job Router Recipes]] document.

%NOTE% If you need to assign jobs to HTCondor accounting groups, refer to [[#AccountingGroups][this]] section. 

#NetworkInterfaces
---++++ Configuring for multiple network interfaces
If you have multiple network interfaces with different hostnames, the HTCondor-CE daemons need to know which hostname and interface to use when communicating to each other. Set =NETWORK_HOSTNAME= and =NETWORK_INTERFACE= to the hostname and IP address of your public interface, respectively, in =/etc/condor-ce/config.d/99-local.conf= directory with the line:

<pre class="file">
NETWORK_HOSTNAME=<span style="background-color: #FFCCFF;">condorce.example.com</span>
NETWORK_INTERFACE=<span style="background-color: #FFCCFF;">127.0.0.1</span>
</pre>

Replacing <span style="background-color: #FFCCFF;">condorce.example.com</span> text with your public interface&rsquo;s hostname and <span style="background-color: #FFCCFF;">127.0.0.1</span> with your public interface&rsquo;s IP address.

#LocalUni
---++++ Limiting or disabling locally jobs running on the CE

If you want to limit or disable jobs running locally on your CE, you will need to configure HTCondor-CE's local and scheduler universes. Local and scheduler universes are HTCondor-CE&rsquo;s analogue to GRAM&rsquo;s managed fork: they allow jobs to be run on the CE itself, mainly for remote troubleshooting. Pilot jobs will not run as local/scheduler universe jobs so leaving them enabled does NOT turn your CE into another worker node.

The two universes are effectively the same (scheduler universe launches a starter process for each job), so we will be configuring them in unison.

   * *To change the default limit* on the number of locally run jobs (the current default is 20), add the following to  =/etc/condor-ce/config.d/99-local.conf=: <pre class='file'>START_LOCAL_UNIVERSE = <span style="background-color: #FFCCFF;">TotalLocalJobsRunning + TotalSchedulerJobsRunning < &lt;job limit&gt;</span>
START_SCHEDULER_UNIVERSE = $(START_LOCAL_UNIVERSE)</pre>
   * *To only allow a specific user* to start locally run jobs, add the following to  =/etc/condor-ce/config.d/99-local.conf=: <pre class='file'>START_LOCAL_UNIVERSE = <span style="background-color: #FFCCFF;">target.Owner =?= "&lt;username&gt;"</span>
START_SCHEDULER_UNIVERSE = $(START_LOCAL_UNIVERSE)</pre>
   * *To disable* locally run jobs, add the following to  =/etc/condor-ce/config.d/99-local.conf=: <pre class='file'>START_LOCAL_UNIVERSE = <span style="background-color: #FFCCFF;">False</span>
START_SCHEDULER_UNIVERSE = $(START_LOCAL_UNIVERSE)</pre>

%NOTE% RSV requires the ability to start local universe jobs so if you are using RSV, you need to allow local universe jobs from the =rsv= user.

#SuppressNoDnRecords
---++++ Accounting with multiple CEs or local user jobs

%NOTE% For non-HTCondor batch systems only

If your site has multiple CEs or you have non-grid users submitting to the same local batch system, the OSG accounting software needs to be configured so that it doesn't over report the number of jobs. Use the following table to determine which file requires editing:

| *If your batch system is…* | *Then edit the following file on your CE(s)…* |
| LSF | =/etc/gratia/pbs-lsf/ProbeConfig= |
| PBS | =/etc/gratia/pbs-lsf/ProbeConfig= |
| SGE | =/etc/gratia/sge/ProbeConfig= |
| Slurm | =/etc/gratia/slurm/ProbeConfig= |

Then edit the value of =SuppressNoDNRecords= so that it reads:

<pre class="file">
SuppressNoDNRecords="1"
</pre>

#AccountingGroups
---++++ HTCondor accounting groups

%NOTE% For HTCondor batch systems only 

If you want to provide fairshare on a group basis, as opposed to a Unix user basis, you can use HTCondor accounting groups.  They are independent of the Unix groups the user may already be in and are [[http://research.cs.wisc.edu/condor/manual/v8.2/3_4User_Priorities.html#SECTION00447000000000000000][documented in the HTCondor manual]].  If you are using HTCondor accounting groups, you can map jobs from the CE into HTCondor accounting groups based on their UID, their DN, or their VOMS attributes.

   * *To map UIDs to an accounting group,* add entries to =/etc/osg/uid_table.txt= with the following form:\
   <pre class="file">uid GroupName</pre>\
%TWISTY{%TWISTY_OPTS_OUTPUT% showlink="Click to expand an example uid_table.txt&hellip;"}%\
<pre class="file">
uscms02 TestGroup
osg     other.osgedu
</pre>\
%ENDTWISTY%

   * *To map DNs or VOMS attributes to an accounting group,* add lines to =/etc/osg/extattr_table.txt= with the following form:\
   <pre class="file"><span style="background-color: #FFCCFF;">SubjectOrAttribute</span> GroupName</pre>\
The <span style="background-color: #FFCCFF;">SubjectOrAttribute</span> can be a Perl regular expression.</br>\
%TWISTY{%TWISTY_OPTS_OUTPUT% showlink="Click to expand an example extattr_table.txt&hellip;"}%\
<pre class="file">
cmsprio cms.other.prio
cms\/Role=production cms.prod
\/DC=com\/DC=DigiCert-Grid\/O=Open\ Science\ Grid\/OU=People\/CN=Brian\ Lin\ 1047 osg.test
.* other
</pre>\
%ENDTWISTY%

%NOTE% Entries in =/etc/osg/uid_table.txt= are honored over =/etc/osg/extattr_table.txt= if a job would match to lines in both files. 

#CeView
---++++ Install and run the HTCondor-CE View

The HTCondor-CE View is an optional web interface to the status of your CE.  To run the View, 

   1. Begin by installing the package htcondor-ce-view:
   <pre class="rootscreen">%UCL_PROMPT_ROOT% yum install htcondor-ce-view</pre>
   1. Next, uncomment the =DAEMON_LIST= configuration located at =/etc/condor-ce/config.d/05-ce-view.conf=:
   <pre class="file">DAEMON_LIST = $(DAEMON_LIST), CEVIEW, GANGLIAD</pre>
   1. Restart the CE service:
   <pre class="rootscreen">%UCL_PROMPT_ROOT% service condor-ce restart</pre>
   1. Verify the service by entering your CE's hostname into your web browser

The website is served on port 80 by default. To change this default, edit the value of =HTCONDORCE_VIEW_PORT= in =/etc/condor-ce/config.d/05-ce-view.conf=.

#WalltimeUnits
---++++ Converting walltime units

%NOTE% For non-HTCondor batch systems only

HTCondor-CE submits walltime requests to batch systems in seconds. If your batch system requires walltime requests in a different unit of time, you must convert the walltime units in your local blahp configuration file. 

<ol>
  <li>
    <p>Use the table below to find the configuration file that corresponds to your batch system.</p>
%TABLE{sort="off"}%
| *If your batch system is...* | *Edit the following file...* |
| LSF | =/etc/blahp/lsf_local_submit_attributes.sh= |
| PBS | =/etc/blahp/pbs_local_submit_attributes.sh= |
| SGE | =/etc/blahp/sge_local_submit_attributes.sh= |
| Slurm | =/etc/blahp/pbs_local_submit_attributes.sh= |
   </li>
   <li>
     <p>Edit the value of the =Walltime= variable using the shell built-in =let= command. To convert the walltime units to minutes, for example:</p>
     <pre class="file">let Walltime=Walltime/60</pre>
   </li>
</ol>

%TWISTY{%TWISTY_OPTS_OUTPUT% showlink="Click to expand an example pbs_local_submit_attributes.sh&hellip;"}%\
<pre class="file">
#!/bin/sh

# Set walltime according to request; the batch system
# may reject this, of course!
if [ -n "$Walltime" ]; then
  let Walltime=Walltime/60
  echo "#PBS -l walltime=$Walltime"
else
  echo "#PBS -l walltime=24:00:00"
fi
</pre>\
%ENDTWISTY%

#UsingHTCondorCE
---++ Using HTCondor-CE

As a site administrator, there are a few ways in which you might use the HTCondor-CE:

   * Managing the HTCondor-CE and associated services
   * Using HTCondor-CE administrative tools to monitor and maintain the job gateway
   * Using HTCondor-CE user tools to test gateway operations

#ManagingServices
---+++ Managing HTCondor-CE and associated services

In addition to the HTCondor-CE job gateway service itself, there are a number of supporting services in your installation. The specific services are:

%TABLE{sort="off"}%
| *Software* | *Service name* | *Notes* |
| Fetch CRL | On EL 6: =fetch-crl-boot= and =fetch-crl-cron= %BR% On EL 5: =fetch-crl3-boot= and =fetch-crl3-cron= | See [[Documentation/Release3.InstallCertAuth#Start_Stop_fetch_crl_A_quick_gui][CA documentation]] for more info |
| Gratia | =gratia-probes-cron= | Accounting software |
| Your batch system | =condor= or =pbs_server= or &hellip; | |
| OSG Info Services | =osg-info-services= | |
| HTCondor-CE | =condor-ce= | |

Start the services in the order listed and stop them in reverse order. As a reminder, here are common service commands (all run as =root=):

%TABLE{sort="off"}%
| *To &hellip;* | *Run the command &hellip;* |
| Start a service | =service <em>SERVICE-NAME</em> start= |
| Stop a service | =service <em>SERVICE-NAME</em> stop= |
| Enable a service to start during boot | =chkconfig <em>SERVICE-NAME</em> on= |
| Disable a service from starting during boot | =chkconfig <em>SERVICE-NAME</em> off= |

---+++ Using HTCondor-CE tools

Some of the HTCondor-CE administrative and user tools are documented in [[Documentation/Release3.TroubleshootingHTCondorCE][the HTCondor-CE troubleshooting guide]].


---++ Validating HTCondor-CE

There are different ways to make sure that your HTCondor-CE host is working well:

   * Perform automated validation by running [[Documentation/Release3.InstallRSV][RSV]]
   * Manually verify your HTCondor-CE using [[Documentation/Release3.TroubleshootingHTCondorCE][the HTCondor-CE troubleshooting guide]]; useful tools include:
      * [[Documentation/Release3.TroubleshootingHTCondorCE#condor_ce_run][condor_ce_run]]
      * [[Documentation/Release3.TroubleshootingHTCondorCE#condor_ce_trace][condor_ce_trace]]
      * [[Documentation/Release3.TroubleshootingHTCondorCE#condor_submit][condor_submit]]


---++ Troubleshooting HTCondor-CE

For information on how to troubleshoot your HTCondor-CE, please refer to [[Documentation/Release3.TroubleshootingHTCondorCE][the HTCondor-CE troubleshooting guide]].


---++ Registering the CE

To be part of the OSG Production Grid, your CE must be registered in the [[https://oim.grid.iu.edu/ OSG Information Management System]] (OIM). To register your resource:

   1. [[Documentation.CertificateUserGet][Obtain, install, and verify your user certificate]] (which you may have done already)
   1. [[Operations.OIMRegistrationInstructions][Register your site and CE in OIM]]

---++ Getting Help

To get assistance, please use the [[Documentation.HelpProcedure][this page]].


#ReferenceSection
---++ Reference

Here are some other HTCondor-CE documents that might be helpful:

   * [[Documentation/Release3.HTCondorCEOverview][HTCondor-CE overview and architecture]]
   * [[Documentation/Release3.InstallHTCondorBosco][Installing and maintaining HTCondor-CE-Bosco]]
   * [[Documentation/Release3.JobRouterRecipes][Configuring HTCondor-CE job routes]]
   * [[Documentation/Release3.TroubleshootingHTCondorCE][The HTCondor-CE troubleshooting guide]]
   * [[Documentation/Release3.SubmittingHTCondorCE][Submitting jobs to HTCondor-CE]]

---+++ Configuration

The following directories contain the configuration for HTCondor-CE. The directories are parsed in the order presented and thus configuration within the final directory will override configuration specified in the previous directories.

| *Location* | *Comment* |
| =/usr/share/condor-ce/config.d/= | Configuration defaults (overwritten on package updates) |
| =/etc/condor-ce/config.d/= | Files in this directory are parsed in alphanumeric order (i.e., =99-local.conf= will override values in =01-ce-auth.conf=) |

For a detailed order of the way configuration files are parsed, run the following command:

<pre class="screen">
%UCL_PROMPT% condor_ce_config_val -config
</pre>

---+++ Users

%STARTSECTION{"Users"}%
The following users are needed by HTCondor-CE at all sites:

| *User* | *Comment* |
| =condor= | The HTCondor-CE will be run as root, but perform most of its operations as the =condor= user. |
| =gratia= | Runs the Gratia probes to collect accounting data |
| =tomcat= | Default user that runs GIP | 
%ENDSECTION{"Users"}%

---+++ Certificates
| *Certificate* | *User that owns certificate* | *Path to certificate* |
| Host certificate | =root= | =/etc/grid-security/hostcert.pem= <br> =/etc/grid-security/hostkey.pem= |

Find instructions to request a host certificate [[Documentation/Release3.GetHostServiceCertificates][here]].

---+++ Networking

%STARTSECTION{"Firewalls"}%
%INCLUDE{"Documentation/Release3/FirewallInformation" section="FirewallTable" lines="htcondorce,htcondorce_shared"}% 

Allow inbound and outbound network connection to all internal site servers, such as GUMS and the batch system head-node only ephemeral outgoing ports are necessary.</br>

%ENDSECTION{"Firewalls"}%

%META:TOPICMOVED{by="BrianLin" date="1503677428" from="Documentation/Release3.InstallHTCondorCE_draft" to="Trash.Documentation_Release3InstallHTCondorCE_draft"}%
