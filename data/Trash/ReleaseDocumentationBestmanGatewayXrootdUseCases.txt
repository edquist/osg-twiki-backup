%META:TOPICINFO{author="SarahWilliams" date="1251397401" format="1.1" reprev="1.4" version="1.4"}%
%META:TOPICPARENT{name="BestmanGatewayXrootd"}%
---+!! *<nop>%SPACEOUT{ "%TOPIC%" }%*
%TOC%

%STARTINCLUDE%
%BR%
---+ _%INCLUDEHEADING%  %SPACEOUT{ "%TOPIC%" }%_
This document outlines site use cases of the  !BeStMan-gateway/Xrootd software.

%EDITTHIS%
%BR%

---++ MWT2 Feasibility Study
---+++ Background & Motivation
Currently MWT2_IU and UC function as separate clusters, using dCache on the SE.  Our goal is to unify the clusters, to:
   * Provide more storage ( by not having duplicate copies of data at each site),
   * Replace duplicate services with fail-over services
   * Reduce overhead by having only one set of configurations to manage
In a storage, we're looking for:
   * Something easy to manage
   * Good read, write and analysis performance 
   * Doesn’t introduce new stability or reliability issues 
   * Fail-over capability
---+++ Site Description
<img src="https://twiki.grid.iu.edu/twiki/pub/ReleaseDocumentation/BestmanGatewayXrootdUseCases/mwt2-network-uc.png"><img  src="https://twiki.grid.iu.edu/twiki/pub/ReleaseDocumentation/BestmanGatewayXrootdUseCases/mwt2-network-iu.png">

At IU we have 44 regular data servers, and 3 high performance.  At UC we have 37 regular, 3 high performance.  Regular servers are 4-core, 8GB mem, ~3TB storage with 1 core reserved for the storage service.  High performance nodes are 8-core, 32GB mem, 48TB storage. 

In our setup, the network presents several potential issues:
   * Latency between the sites is ~5.3 ms
   * At IU, all nodes have public IP addresses, but the switch implements ACLs to prevent incoming connections based on  a whitelist.
   * At UC, the worker nodes are on a private network with NAT access to the outside. The storage nodes are dual-homed with public and private IPs

<img src="https://twiki.grid.iu.edu/twiki/pub/ReleaseDocumentation/BestmanGatewayXrootdUseCases/mwt2-network-uc-obs.png">
<img src="https://twiki.grid.iu.edu/twiki/pub/ReleaseDocumentation/BestmanGatewayXrootdUseCases/mwt2-network-iu-obs.png">

---+++ Test Setup 1 & 2
In testing, our goal was to answer these questions:
   * Can a private-ip worker node read & write to a public-only dataserver? a public-only redirector? 
   * Does a dual-homed public/private ip dataserver handle requests from public and private ips correctly? Does a public/private ip redirector? 
   * What is read & write speed compared to dCache with dccp? 
      * When connecting to a high-performance storage node? To a combination worker/storage node? 
      * When connecting between sites with xrdcp vs within the site with dccp

We will be benchmarking, so this is designed to be a prototype of a complete cross-site system.  The number of dataservers is kept low in the initial installation, to enable testing of individual read and write speeds. Later tests will add more to measure total throughput.

For the Dataservers, we want at least 1 each of a low- and high-performance node,  1 each of a node with public/private and public-only ips, and one each of a node at IU and UC.

For the Redirector, we want to test once with a public-only node, and once with a public/private node.

*Setup 1*: Public redirector
| *Role* | *Hostname* | *Location* | *Network* | *Speed* |
| Redirector | iut2-s1 | IU | Public | 10G |
| Data Server | iut2-s3 | IU | Public | 10G |
| | iut2-c034 | IU | Public | 1G |
| | uct2-s3 | UC | Public & Private | 10G |
| | uct2-c034 | UC | Public & Private | 1G |
| Worker node | iut2-c042 | IU | Public | 1G |
| | uct2-c035 | UC | Private | 1G | 

*Setup 2*: Public & Private redirector
| *Role* | *Hostname* | *Location* | *Network* | *Speed* |
| Redirector | uct2-s1 | UC | Public & Private | 10G |
| Data Server | iut2-s3 | IU | Public | 10G |
| | iut2-c034 | IU | Public | 1G |
| | uct2-s3 | UC | Public & Private | 10G |
| | uct2-c034 | UC | Public & Private | 1G |
| Worker node | iut2-c042 | IU | Public | 1G |
| | uct2-c035 | UC | Private | 1G | 

See the [[https://twiki.grid.iu.edu/twiki/pub/ReleaseDocumentation/BestmanGatewayXrootdUseCases/mwt2_configs.tar.gz][Config files]] for other settings.

---+++ Results
   *  The private-ip worker nodes were able to read and write in both tests with no adjustment
   *  The public/private data servers and redirector answer requests on the correct interfaces.
   * Since our machines exist in different domains, cms must explicitly allow both, by adding these lines to all xrootd.cfg: <pre class="screen">cms.allow host iut2-*.iu.edu
cms.allow host uct2-*.uchicago.edu</pre>
   * For data servers behind the switch ACLs, xrd must be configured to listen on a static port, using =xrd.port N=, and that port allowed through for & clients.   Because the cmsd cannot be configured for a static port, all ports must be allowed from the redirector.
   * It is possible to have all xrootd instances use the same config file by using if constructs, as documented in the [[http://xrootd.slac.stanford.edu/doc/dev/Syntax_config.htm][Xrootd Config Syntax Guide]].  I didn't use that for the test, and it caused problems in keeping the config files consistent.
   * Compared Xrootd with xrdcp to dCache with dccp
      * Read speed doubled
      * Write speed was doubled for large files.  In Xrootd there is a 5 second delay in creating files, which hurt performance on files <300MB.   The speed stayed within an acceptable range.
   * The difference in speed between  the worker/storage and high-performance nodes was not as high as expected.  The high-performance nodes may need further tuning
   * WAN speed was very bad on first test.   The client machine is running kernel =2.6.9-78.0.17=, which requires manual tuning to good WAN performance. I added these parameters to =/etc/sysctl.conf= and ran =sysctl -p /etc/sysctl.conf=:<pre class="screen">net.ipv4.tcp_rmem = 4096 87380 20000000
net.ipv4.tcp_wmem = 4096 87380 20000000
net.core.rmem_max = 20000000
net.core.wmem_max = 20000000</pre> 

Final speeds were:

| *Direction* | *dCache with dccp* | *Xrootd WAN with untuned client* | *with tuned client* |
| *Read* | 32MB/s | 30MB/s | 73MB/s |
| *Write* | 20MB/s | 20MB/s | 33MB/s |

%STOPINCLUDE%
%BR%
%COMPLETE1% %BR%
%RESPONSIBLE% Main.SarahWilliams - 25 Aug 2009 %BR%
%REVIEW%

---++ *Comments*
%COMMENT{type="tableappend"}%

%META:FILEATTACHMENT{name="mwt2-network-uc.png" attachment="mwt2-network-uc.png" attr="" comment="MWT2_UC Site Diagram" date="1251223740" path="mwt2-network-uc.png" size="24365" stream="mwt2-network-uc.png" tmpFilename="/usr/tmp/CGItemp24371" user="SarahWilliams" version="1"}%
%META:FILEATTACHMENT{name="mwt2-network-iu.png" attachment="mwt2-network-iu.png" attr="" comment="MWT2_IU Site Diagram" date="1251223766" path="mwt2-network-iu.png" size="23329" stream="mwt2-network-iu.png" tmpFilename="/usr/tmp/CGItemp29431" user="SarahWilliams" version="1"}%
%META:FILEATTACHMENT{name="mwt2-network-uc-obs.png" attachment="mwt2-network-uc-obs.png" attr="" comment="MWT2_UC Site Diagram, with notes" date="1251223931" path="mwt2-network-uc-obs.png" size="26937" stream="mwt2-network-uc-obs.png" tmpFilename="/usr/tmp/CGItemp32211" user="SarahWilliams" version="1"}%
%META:FILEATTACHMENT{name="mwt2-network-iu-obs.png" attachment="mwt2-network-iu-obs.png" attr="" comment="MWT2_IU Site Diagram, with notes" date="1251223949" path="mwt2-network-iu-obs.png" size="28155" stream="mwt2-network-iu-obs.png" tmpFilename="/usr/tmp/CGItemp32186" user="SarahWilliams" version="1"}%
%META:FILEATTACHMENT{name="mwt2_configs.tar.gz" attachment="mwt2_configs.tar.gz" attr="" comment="MWT2 Config files" date="1251396919" path="mwt2_configs.tar.gz" size="28414" stream="mwt2_configs.tar.gz" tmpFilename="/usr/tmp/CGItemp31889" user="SarahWilliams" version="1"}%
