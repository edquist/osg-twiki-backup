%META:TOPICINFO{author="DerekWeitzel" date="1360274480" format="1.1" version="1.19"}%
%META:TOPICPARENT{name="BoSCOv1p1"}%
<!-- conventions used in this document
   * Local UCL_HOST = %URLPARAM{"INPUT_HOST" encode="quote" default="bosco"}%
   * Local UCL_USER = %URLPARAM{"INPUT_USER" encode="quote" default="bosco"}%
   * Local UCL_DOMAIN = %URLPARAM{"INPUT_DOMAIN" encode="quote" default="opensciencegrid.org"}%
   * Set TWISTY_OPTS_DETAILED = mode="div" showlink="Show Detailed Output" hidelink="Hide" showimgleft="/twiki/pub/TWiki/TWikiDocGraphics/toggleopen-small.gif" hideimgleft="/twiki/pub/TWiki/TWikiDocGraphics/toggleclose-small.gif" remember="on" start="hide" 
   * Set TOC2 =<div style="float:right; margin-right:-1.015em; padding:0.5em; background-color:white;">%TOC%<p class="twikiClear" /></div>
-->

---+!! BOSCO Multi User
%DOC_STATUS_TABLE%
%TOC{depth="3"}%


---# Introduction 

BOSCO is a job submission manager designed to help researchers manage large numbers (~1000s) of job submissions to 
the different resources that they can access on a campus (initially a PBS cluster running Linux).
This is release 1.1 of BOSCO, if you find any problems or need help installing or running !BoSCO, please email bosco-discuss@opensciencegrid.org .

It offers the following capabilities: 
   * Jobs are automatically resubmitted when they fail. The researcher does not need to babysit their jobs.                                                                                       
   * Job submissions can be throttled to meet batch scheduler settings (e.g. only 10 jobs running concurrently). The researcher does not need to make multiple submissions. BOSCO handles that for them.    
   * BOSCO is designed to be flexible and allows jobs to be submitted to multiple clusters, with different job schedulers (e.g. PBS, LSF, Condor). 
The primary advantage for the researcher is that they only need to learn one job scheduler environment even if the clusters utilize different native environments.                                                                    

---++ BOSCO multi user
This document is a bout BOSCO multi user, a version installed and managed on the submit host by a single user (administrator) and made available to all the users of that host.

Here are some key differences:
| *BOSCO (single user)* | *BOSCO multi user* |
| Installed by user | Installed as administrator (root) |
| User manages BOSCO<br> - BOSCO started as User<br> - Contributing clusters (BOSCO resources) added by User | Administrator manages BOSCO <br> - BOSCO started as root<br> - Contributing clusters added using a single service account |
| User must have SSH access on all BOSCO resources | SSH access via group service account (negotiated by admin) |
| Only User can submit jobs to the HTCondor pool of BOSCO | All the users on the system can submit jobs to the HTCondor pool of BOSCO |
| No choices because it must be easy to install and run for scientists without system administration experience | More flexible because  there may be more customization to add BOSCO in the Campus Grid |





%TWISTY{%TWISTY_OPTS_DETAILED% showlink="Click to see the format conventions used in this document" }%   
%INCLUDE{"Documentation/DocumentationTeam.DocConventions" section="Header"}%
%INCLUDE{"Documentation/DocumentationTeam.DocConventions" section="CommandLine"}%
%ENDTWISTY%


%STARTSECTION{"BoscoRequirements"}%
---# Requirements

   $ *Submit-node*: This is the system that the researcher uses to submit jobs. In general it can be the user's laptop, workstation, or it can be another system that the user logs into for submitting jobs to the cluster. A current requirement is that the submit-node must use the same Linux flavor that the PBS/LSF/Condor cluster is using. *There can not be any Condor collector running on the submit node*, otherwise it will conflict with the Campus Factory.
   $ *Cluster head-node*: This is the node that you normally login to on the PBS, LSF or Condor cluster.
      $ *PBS flavors supportted*: Torque and PBSPro
      $ *Condor flavors supported*: Condor 7.6 or later
      $ *LSF flavors*: no special requirements
   $ *Cluster*: This is the remote cluster that jobs will execute on.  The Cluster head-node is a node belonging to this cluster.  The cluster needs:
      $ *Shared Filesystem*: The Cluster needs a shared home filesystem
      $ *Network Access*: The worker nodes need to have access to the submit host.  The worker nodes can be behind a [[https://en.wikipedia.org/wiki/Network_address_translation][NAT]] between the worker nodes and the submit host.

BOSCO can be used as part of a more complex Condor setup (with flocking or multiple pools). Whatever is the setup:
   * the BOSCO host needs connectivity to the cluster submit nodes
   * the worker nodes (running the jobs, e.g. the nodes in the PBS cluster) must have network connectivity to the jobs submit node (the BOSCO host or a different Condor schedd flocking into it)
%ENDSECTION{"BoscoRequirements"}%

%STARTSECTION{"BoscoInstall"}%
---# How to Install

---## Creating the Bosco User
As =root=, create a =bosco= user and a install directory (e.g. =/opt/bosco=) that all users can see and use (all users should be able to read, =bosco= should be able to write). <pre class="rootscreen">
%UCL_PROMPT_ROOT% useradd bosco
%UCL_PROMPT_ROOT% mkdir -p /opt/bosco
%UCL_PROMPT_ROOT% chown bosco: /opt/bosco
</pre>

---## Download and Install BOSCO
Perform the following steps as the newly created =bosco= user.

   1. Download the BOSCO installer
      * BOSCO comes in multiple flavors depending on your platform and the installer will download and install the correct flavor for you. Right click on [[ftp://ftp.cs.wisc.edu/condor/bosco/latest/boscoinstaller][this link]], select "save as" and save the file in the bosco user home directory (any place is OK as long as you find the installer).
      * Alternatively you can use =wget= and the download link:<pre class="screen">
%UCL_PROMPT% cd ~
%UCL_PROMPT% wget ftp://ftp.cs.wisc.edu/condor/bosco/latest/boscoinstaller
</pre>
      * If you have no =wget=, you can use =curl= to download:<pre class="screen">
%UCL_PROMPT% curl -o ~/boscoinstaller ftp://ftp.cs.wisc.edu/condor/bosco/latest/boscoinstaller
</pre>
   1. Change the file permission and Install BOSCO as =bosco=: <pre class="screen">
%UCL_PROMPT% chmod +x  ~/boscoinstaller 
%UCL_PROMPT% ~/boscoinstaller --prefix=/opt/bosco
</pre>
   1. Remove the installer file: <pre class="screen">
%UCL_PROMPT% rm ~/boscoinstaller
</pre>

%TWISTY{%TWISTY_OPTS_DETAILED% }%   <pre class="screen">
# The local BOSCO user in this example is called uc3
[root@uc3-bosco ~]# mkdir -p /opt/bosco
[root@uc3-bosco ~]# chown uc3 /opt/bosco
[root@uc3-bosco ~]# su - uc3
-bash-3.2$ ./boscoinstaller --prefix=/opt/bosco
Downloading BOSCO from ftp://ftp.cs.wisc.edu/condor/bosco/latest/bosco-beta-x86_64_RedHat5.tar.gz
Installing BOSCO in /opt/bosco
Installing Condor from /tmp/tmp_zACZK/condor-7.9.2-76336-x86_64_RedHat5-stripped to /opt/bosco
Unable to find a valid Java installation 
Java Universe will not work properly until the JAVA 
(and JAVA_MAXHEAP_ARGUMENT) parameters are set in the configuration file!

Condor has been installed into:
    /opt/bosco

Configured condor using these configuration files:
  global: /opt/bosco/etc/condor_config
  local:  /opt/bosco/local.uc3-bosco/condor_config.local

In order for Condor to work properly you must set your CONDOR_CONFIG
environment variable to point to your Condor configuration file:
/opt/bosco/etc/condor_config before running Condor commands/daemons.
Created a script you can source to setup your Condor environment
variables. This command must be run each time you log in or may
be placed in your login scripts:
   source /opt/bosco/bosco_setenv

Congratulations, you installed BOSCO succesfully!
-bash-3.2$
-bash-3.2$ source /opt/bosco/bosco_setenv
</pre>
%ENDTWISTY%

---## Add BOSCO to the default environment
Add BOSCO to the default environment of all your users: <pre class="root">
cp /opt/bosco/bosco.sh /opt/bosco/bosco.csh /etc/profile.d/
</pre>
This is not required but it is recommended, so users don't have to setup the environment each time they login.

%ENDSECTION{"BoscoInstall"}%

%STARTSECTION{"BoscoSetup"}%
---# How to Use

Now BOSCO is installed. To use it:
   1. Setup the environment
   1. Add all the desired clusters (at least one)
   1. Start BOSCO
   1. Submit a test job
   1. Submit a real job

---## Setup environment before using
#SetupEnvironment
If the administrator did not add BOSCO to the default environment (last step in the installation above), then an environment file must be sourced all the times you use BOSCO (start/stop/job submission or query, anything):
<pre class="screen">
%UCL_PROMPT% source /opt/bosco/bosco_setenv
</pre>

---## Starting BOSCO 
#BoscoStart
BOSCO has some persistent services that must be running. You'll have to start it at the beginning and probably after each reboot of your host.
You should stop BOSCO before an upgrade and possibly before a shutdown of your host.
If you will not use BOSCO anymore, uninstall will remove it from your system.


To start BOSCO, as *ROOT*:<pre class="rootscreen">
%UCL_PROMPT_ROOT% bosco_start
</pre>


---## Add a cluster to BOSCO
Follow the following steps as the *BOSCO* user.

%INCLUDE{"BoscoInstall" section="BoscoAddResource"}%


---## Submitting a test job
You can send a simple test job to verify that the cluster added is working correctly.  The following steps are as the *BOSCO* user.

To send a BOSCO test job to the host %RED%username@mycluster-submit.mydomain%ENDCOLOR% (name as listed in the output of =bosco_cluster --list=):
   1. Setup the environment appropriate for your shell as described in the setup environment section (above).
   1. For the cluster %RED%username@mycluster-submit.mydomain%ENDCOLOR% (identical to output of  =bosco_cluster --list=). Replace the parts in red: <pre class="screen">
%UCL_PROMPT% bosco_cluster --test %RED%username@mycluster-submit.mydomain%ENDCOLOR%
</pre> %TWISTY{%TWISTY_OPTS_DETAILED% }%   <pre class="screen">
%UCL_PROMPT% $ bosco_cluster -t dweitzel@ff-grid.unl.edu
dweitzel@ff-grid.unl.edu
Testing ssh to dweitzel@ff-grid.unl.edu...Passed!
Testing bosco submission...Passed!
Checking for submission to remote pbs cluster (could take ~30 seconds)...Passed!
Submission files for these jobs are in /home/dweitzel/bosco/local.localhocentos56/bosco-test
Execution on the remote cluster could take a while...Exiting
</pre> %ENDTWISTY%

---## How to Stop and Remove
To stop BOSCO, as *root* (remember, all the commands with a orange-red background require you to be root):<pre class="rootscreen">
%UCL_PROMPT_ROOT% bosco_stop
</pre>

To uninstall BOSCO:
   * First remove the startup script if you added them: <pre class="rootscreen">%UCL_PROMPT_ROOT% rm /etc/profile.d/bosco.*</pre>
   * To remove everything: installation directory, remote clusters and the BOSCO files in your =.bosco= and =.ssh= directories you can use:<pre class="rootscreen">%UCL_PROMPT_ROOT% bosco_uninstall --all</pre>
   * To remove the remote clusters get the list and remove them one by one: <pre class="screen">%UCL_PROMPT% bosco_cluster --list
# For each remote cluster 
%UCL_PROMPT% bosco_cluster -r %RED%user@cluster_as_spelled_in_list%ENDCOLOR%</pre>
   * To remove only the installation directory:  <pre class="rootscreen">%UCL_PROMPT_ROOT% bosco_uninstall</pre>

%NOTE% Uninstalling BOSCO installation directory removes the software but leaves the files in your =.bosco= and =.ssh= directories with all the information about the added clusters and the SSH keys. Files installed on the remote clusters are not removed either. 

---## How to Update BOSCO
If you want to update BOSCO to a new version you have to follow the following steps.  

%NOTE% Please notice that some commands need to be run by root, and others by the bosco user

   1. setup BOSCO:<pre class="rootscreen">%UCL_PROMPT% source /opt/bosco/bosco_setenv</pre>
   1. stop BOSCO: <pre class="rootscreen">%UCL_PROMPT_ROOT% bosco_stop</pre>
   1. remove the old BOSCO: <pre class="rootscreen">%UCL_PROMPT_ROOT% bosco_uninstall</pre>
   1. download and install the new BOSCO (see install section above)  and re-add all the clusters in your setup:
   1. for each installed cluster (the list is returned by =bosco_cluster --list=):
      1. remove the cluster: <pre class="screen">%UCL_PROMPT% bosco_cluster --remove %RED%username@mycluster-submit.mydomain.org%ENDCOLOR% </pre>
      1. add the cluster: <pre class="screen">%UCL_PROMPT% bosco_cluster --add %RED%username@mycluster-submit.mydomain.org queue%ENDCOLOR% </pre>
   1. start BOSCO: <pre class="rootscreen">%UCL_PROMPT_ROOT% bosco_start</pre>

This will update the local installation and the software on the remote clusters
%ENDSECTION{"BoscoSetup"}%

---# Advanced use

---## Multi homed hosts
Multi homed hosts are hosts with multiple Network Interfaces (aka dual-homed when they have 2 NICs).
BOSCO configuration is tricky on multi-homed hosts. BOSCO requires the submit host to be able to connect back to the BOSCO host, so it must advertise an interface that is reachable from all the chosen submit hosts. E.g. a host with a NIC on a private network and one with a public IP address must advertise the public address if the submit hosts are outside of the private network. 
In order to do that you have to:
   * make sure that the name returned by the command =/bin/hostname -f= is the name resolving in the public address (e.g. =host `hostname -f`= should return the public address). If not you should change it.
   * edit =~/bosco/local.%RED%$HOST%ENDCOLOR%/condor_config.local= (HOST is the short host name) and add a line like =NETWORK_INTERFACE = xxx.xxx.xxx.xxx= , substituting xxx.xxx.xxx.xxx with the public IP address. This will tell BOSCO to use that address.

---## Flocking to the BOSCO submit host
If you have a more complex Campus Grid environment you can flock from your submit hosts to the BOSCO submit host to have access to the resources available through BOSCO.

On the BOSCO submit host:
   * Edit =/opt/bosco/local.*/config/condor_config.factory= to add you submit host (fully qualified domain name or IP address) in the FLOCK_FROM line, e.g.: <pre class="file"># What hosts can run jobs to this cluster.
FLOCK_FROM = %RED%yourname.yourdomain.org%ENDCOLOR%
</pre>

On your Campus Grid submit host add the BOSCO submit host in the FLOCK_TO entry of the Condor configuration, e.g. =/etc/condor/condor_config.local=: <pre class="file"># What hosts can run jobs to this cluster.
FLOCK_TO = %RED%bosco.uchicago.edu%ENDCOLOR%:11000?sock=collector
</pre>

%NOTE% that the BOSCO submit host is running on port 11000 and it is using the single port daemon.

---## Querying the status of BOSCO
If you have a monitoring system and you want to query BOSCO you need to know the following:
   * The BOSCO submit host collector runs under the shared port collector on port 11000: ==bosco.yourdomain.org:11000?sock=collector==
   * The host sending the query needs to be authorized to run the query 

%INCLUDE{"BoscoInstall" section="BoscoJob"}%


%INCLUDE{"BoscoInstall" section="BoscoAdvancedUse"}%

---# Troubleshooting

---## Useful Configuration and Log Files
BOSCO underneath is using Condor. You can find all the Condor log files in =/opt/bosco/local.HOSTNAME/log= (supposing that =/opt/bosco= is the installation directory).

%INCLUDE{"BoscoInstall" section="BoscoTroubleshootingItems"}%


---# Get Help/Support
To get assistance you can send an email to bosco-discuss@opensciencegrid.org


%INCLUDE{"BoscoInstall" section="BoscoReferences"}%


---+ Comments
%COMMENT{type="tableappend"}%

<!-- CONTENT MANAGEMENT PROJECT
############################################################################################################
 DEAR DOCUMENT OWNER
 ===================

 Thank you for claiming ownership for this document! Please fill in your FirstLast name here:
   * Local OWNER = MarcoMambelli

 Please define the document area, choose one of the defined areas from the next line
 DOC_AREA = (ComputeElement|General|Integration|Monitoring|Operations|Security|Storage|Tier3|User|VO)
   * Local DOC_AREA       = General

 define the primary role the document serves, choose one of the defined roles from the next line
 DOC_ROLE = (Developer|Documenter|Scientist|Student|SysAdmin|VOManager)
   * Local DOC_ROLE       = SysAdmin

 Please define the document type, choose one of the defined types from the next line
 DOC_TYPE = (HowTo|Installation|Knowledge|Navigation|Planning|Training|Troubleshooting)
   * Local DOC_TYPE       = Installation
  Please define if this document in general needs to be reviewed before release ( %YES% | %NO% )
   * Local INCLUDE_REVIEW = %YES%

 Please define if this document in general needs to be tested before release ( %YES% | %NO% )
   * Local INCLUDE_TEST   = %YES%

 change to %YES% once the document is ready to be reviewed and back to %NO% if that is not the case
   * Local REVIEW_READY   = %YES%

 change to %YES% once the document is ready to be tested and back to %NO% if that is not the case
   * Local TEST_READY     = %YES%

 change to %YES% only if the document has passed the review and the test (if applicable) and is ready for release
   * Local RELEASE_READY  = %YES%


 DEAR DOCUMENT REVIEWER
 ======================

 Thank for reviewing this document! Please fill in your FirstLast name here:
   * Local REVIEWER       = 
 Please define the review status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local REVIEW_PASSED  = %YES%


 DEAR DOCUMENT TESTER
 ====================

 Thank for testing this document! Please fill in your FirstLast name here:
   * Local TESTER         = 
 Please define the test status for this document to be in progress ( %IN_PROGRESS% ), failed ( %NO% ) or passed ( %YES% )
   * Local TEST_PASSED    = %YES%
############################################################################################################
-->