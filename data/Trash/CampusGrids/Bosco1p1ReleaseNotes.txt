%META:TOPICINFO{author="DerekWeitzel" date="1354762816" format="1.1" reprev="1.1" version="1.1"}%
%META:TOPICPARENT{name="BoSCOv1p1"}%
---+!! BOSCO 1.1 Release Notes

---++!! Abstract

This document describes the major differences between BOSCO versions 1.0 and BOSCO 1.1.

%TOC%

---++ Welcome to BOSCO 1.1


---++ Changes to BOSCO for Users

---+++ Multi-OS Support
The Multi-OS feature is intended to allow users to submit to clusters that may not be the same operating system as the submit host.  This is especially useful when users are running a submit host on their personal computer that is running Debian, while the supercomputer in the next building is running Red Hat 6, a common occurrence.

The Multi-OS components follow a basic process in order to operate:
   1. Detect the remote operating system with the findplatform script.
   1. Download (from the cloud?) the appropriate bosco version for the platform.
   1. Transfer the files needed on the remote cluster.  This includes grabbing the libraries and binaries for the campus factory's glideins.  The glidein creation takes the most time of this process as it needs to compress the libraries and binaries before transferring.
   1. When BOSCO detects jobs idle on the submit host, it will start glideins appropriate for the platform to service the jobs.

The Multi-OS support required modification of the cluster addition and adding both a findplatform script and a glidein_creation script.  


---+++ SSH File Transfer

SSH File Transfer feature improves the method of staging input and output files to the remote cluster.  In 1.0, files are transferred by starting a daemon on the remote cluster that connects back to the submit host over a random port.  This required a lot of open ports on the submit host.  

The new SSH File Transfer will limit the number of ports required on the submit host.  BOSCO will now transfer files over a port that is forwarded over the SSH connection that BOSCO maintains with the remote cluster.  The transfers are inherently secure as they are over the SSH connection, as well as they are authenticated by the Condor daemons on either end of the connection (remote cluster and submit host).   



---+++ !MacOSX Support

BOSCO now supports the !MacOSX 10.7+ operating system as a submit host.  BOSCO does not support !MacOSX for a cluster (+execution host).

---++ Changes to BOSCO for System Administrators

---+++ Single Port Usage
In 1.0 of BOSCO, the submit host needed a lot of ports open for connections originating from the remote clusters.  This was caused by 2 mechanisms:
   1. File transfer from the BOSCO submit host to the cluster login node before issuing the local submit call (qsub, condor_submit...).  This opens ports on the submit host because the cluster would call out to the submit host to initiate transfers.
   1. Connections for control, status, and workflow management between the cluster worker nodes and BOSCO submit host.  This is the Campus Factory, which gives BOSCO the traditional Condor look and feel.

In order for BOSCO to function, the submit host needs a large swath of ports in order to operate correctly.  Also, as you scale, you will need even more ports open.

The file transfers from the submit host to the login node are now being transferred using SSH, see my previous post.

With the new feature of single port usage, all control, status, and workflow management connections are routed through HTCondor's share_port_daemon on port 11000 (which is hardcoded, but is picked at random).


---+++ Multi-User BOSCO

What Is Multi-Cluster?

In BOSCO, Multi-Cluster is the feature that allows for submission to multiple clusters with a single submit file.  A user can submit a regular file, such as: <pre class="file">
universe = vanilla
output = stdout.out
error = stderr.err
Executable = /bin/echo
arguments = hello
log = job.log
should_transfer_files = YES
when_to_transfer_output = ON_EXIT
queue 1
</pre>

When the job is submitted, BOSCO will submit glideins to each of the clusters that are configured in BOSCO.  The glideins will start on the worker nodes of the remote clusters and join the local pool at the submission host, creating an on-demand Condor pool.  The jobs will then run on the remote worker nodes through the glideins. 
