%META:TOPICINFO{author="KyleGross" date="1476284787" format="1.1" reprev="1.2" version="1.2"}%
%META:TOPICPARENT{name="CampusGridMeetings"}%
-- Main.DanFraser - 03 Sep 2010
---+++ The full report with links is available at https://twiki.grid.iu.edu/bin/view/Trash/Trash/CampusGrids/CampusGridMeetings
---+++ Attendees:
   * Derek, David, Brian, Igor, Dan

---+++ Action Items:
   * Derek to start a new Wiki page (on the Campus Grids wiki) for current development
   * Need to interview at least two campuses and see if the security model we are proposing will fly -- Purdue and UConn would be good candidates to discuss this with. 

---+++ Notes:
   * Based on the Campus Grids Trash/Blueprint meeting the first goal is to enable users to submit jobs to their own cluster without losing important capabilities.
      * There was some discussion about what users need, even creating a list of the capabilities that users need.
      * We agreed that we already have some use cases defined and should make sure these are clear and pursue those. 
      * It was noted that we also need to be careful and make sure that what we provide as a first starting point for the users will be useful -- the first user experience is the most important, if it is bad, they may never return. 
   * One item we agreed on for users is that they should *not* need X509 certificates when they are on their own campus. 
      * Users should only need certs when they are bridging between campuses
      * For starters we can assume that if they are going to share resources with another campus, they will do this using the OSG. 
   * The success of glide-ins on the OSG is a good model to try and see if we can extend it to campuses. 
      * Derek already has written a small glide-in factory for use on a single campus cluster and is starting to test it. 
   * Security was raised as one of the most important issues to tackle
      * If all users are mapped to a single account, the Campus Grid Infrastructure may have a short life. 
      * The technology is easy (SUDO), once we have a trust structure in place where this is allowed.
      * The cluster will need to implicitly "trust" the glide-in factory, but there will also need to be a "root" install on the cluster. Will sites allow this? We need to have some discussions and ask. 
   * Since there will be some integration software developed by Derek, we discussed the sustainability model for this software.
      * David noted that he is committed to own and maintain this software at Nebraska. Of course there will eventually need to be some funding to support the code. Currently Derek has some limited funds to support this development. 
      * When/if this code is determined to be "production ready" and used by the OSG, the OSG will need to have an agreement with Nebraska, just like it has for all of its software providers. But we don't need to worry about this now. 
