%META:TOPICINFO{author="KyleGross" date="1476284648" format="1.1" version="1.6"}%
---+++OSG Trash/Blueprint and Technology Meeting Agenda

*Brookhaven National Lab* <br/>
*Birkner Hall*  <br/>
*Conference Room D* <br/>
*January 17-18th, 2012* <br/>
*17th: 9:00AM - 5:00PM* <br/>
*18th: 9:00AM - 2:00PM* <br/>

*Contact: John Hover Cell: 631-682-1803 Office: 631-344-5828* <br/>

---+++ Trash/Blueprint topics.

Topics below are marked with either (N) for "new topic" or (O) for "old topic".

We have attempted to sort the topics in priority order, and plan to tackle them top-to-bottom.

   * (N) Campus Grid plans.  Presented by Dan.

   * (O) Investigation of potential replacement technologies for Information Services:
      * This would include the GLUE data transport (Currently CEMon client and collector)
      * The DB where information is stored (LDAP DB)
      * The data retrieval (OpenLDAP clients).
      * Are we using the right tools, are the stable and robust enough for a growing production environment, what do we want out IS to look like moving into the future?

   * (N) VO software installation at OSG sites. 
      * Inclusion strategies for VO software (CVMFS vs. $OSG_APP), (OSG RPMs vs. VO-maintained RPMs.).
      * Central scheduler/Cross-CE issues and implications.

   * (N) Is it time to revisit the "Grid User" identity concept?
      * The implications of allowing grid users to assume they will always run as the same UNIX user at a site. Recycleable pool accounts vs. permanent mapping? VOMSAdmin 2.6.1 "multi-cert user" feature and its interaction with GUMS. How does this interact with Federated ID schemes?

   * (O) Shared Data 
      * Where are we from a Trash/Blueprint perspective? Any updates on our previous thinking?
      * Definition of "data federation" from the Federated Data Stores meeting in Lyon:
         * "Collection of disparate storage resources managed by co-operating but independent administrative domains transparently accessible via a common name space."

   * (N) Reducing/removing the need for Worker Node host certificates in OSG.  Short topic - present what has already been done.
      * http://jira.opensciencegrid.org/browse/TECHNOLOGY-10

   * (O) Current status of federated identity plans/directions for OSG. 
      * This includes current discussions of collaboration with European grid. 
      * May table this due to lack of the correct folks.

   * (O) Current status of cloud computing plans/directions for OSG. 
      * There is the already expressed concern by Miron about how/whether OSG should be involved in the financial side of Cloud usage.

   * (N) Potential role and coordination with the Internet2/PerfSonar Monitoring Dashboard (Tomasz/BNL). 
      * We looked into integrating this with RSV/Gratia, but there are incompatibilities. These could be worked out with coordination. 

---+++ OSG Technology
   * Quarterly update of the Trash/Blueprint Document 1 week before the Trash/Blueprint meeting.
      * Trash/Blueprint reviewed, and no major updates.  Will do this again post-meeting, especially for the Campus Grids section.
   * Report from Technology Investigations to Trash/Blueprint Group:
      * Results from TI's that are related to previous Trash/Blueprint items.
      * Plans for future TIs ([[TIDrawingBoard][brainstorming area]])
      * Requests from Trash/Blueprint Group for TIs (or vice-versa)?  Requests from Technology:
         * Work on OSG's definition of "data federation".
         * Firm up requirements for HTTP data distribution work.
   * How do we coordinate with XSEDE TIS?
   * How do we provide better guidance to OSG ET on the roadmap for future TI's?

---+++ Wrap-up

At the end of the blueprint meeting, we should reach the following goals:
   1 Have a handful of TI's "queued up".
   1 Accept or reject the writeups for the TIs in "documentation" state.
   1 Accept or reject the OSG Trash/Blueprint document updates.
      * This item delayed post-blueprint to incorporate Campus Grid ideas.

