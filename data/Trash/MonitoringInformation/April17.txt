%META:TOPICINFO{author="ConradSteenberg" date="1145295592" format="1.0" version="1.2"}%
%META:TOPICPARENT{name="WebHome"}%
---+ April 17, 2006
---++ Agenda
	* GUMS Monitoring 

---++ Minutes
	* Attending: Michael, Conrad, Anand, Gabriele, John Roscheck, Leigh

	* What to monitor? Do a mapping? A ping?
	* Monitor probes could be run using VORS, with information reported on the web page. VORS can be adapted to make programmatic access possible
	* How is a new GUMS instance detected? Currently manually reported to operations staff
	* Leigh: CE monitoring can possibly be used to report that GUMS is used.

	* Q: external access to GUMS assumed? How about firewall settings, or if the instance is running on an internal network?
	* Gabriele: Look for common solution with European efforts, which uses entirely different technologies.
	* How should new servers be registered should be discussed?
	* FYI, Leigh compiled a report of GUMS servers several months ago, at http://www.ivdgl.org/~leighg/gums-report.html

	* vdt-1.3.11 needed for Gums memory fix, need to coordinate with VDT/GUMS release teams.

	* GUMS config template file supplied with the distribution, could be used to set up access from a central host.

	* Michael: suggest using discovery service, putting publication code in GUMS itself, rather than using external scripts like in VOMS. Example code exists in JClarens.
	* Anand: suggest using GIPs for information publication

	* John: VORS monitoring display change: monitor.grid.iu.edu

---++ Notes by Gabriele
* How do we monitor GUMS status? We discussed 2 models
(1) GUMS publishes its internal status: requires development
(2) a probe tries to query for a mapping: does not require development, 
example clients are available in the PRIMA distribution (should be checked).

Let's think about model (2).
GUMS status could be probed and published using a combination of the 
following:

- Publication over the web using GridCat (check this). A probe could be 
run periodically. At the beginning, registration of new GUMS services 
could be done manually. The problem is that GUMS is a local site service 
and may not easily allow external access (e.g. it may be running on a 
private network).

- We could have GUMS register with the discovery service. This requires 
adding code to GUMS. When GUMS is up, it registers: this partially 
solves the question of GUMS availability. At the 0th level, we may not 
even need to run a probe to check the mapping periodically if we know 
that GUMS is up. If we want to run an external probe, the registration 
service could publish whether GUMS is externally accessible or not.

- We could use GIP and GLUE (service element) to publish the GUMS 
status. The GIP have access from within the cluster i.e. no external 
accessibility wouold be required to run a probe.

- If we run an external probe, we need to have GUMS authorize the probe 
access. We already distribute a standard (example) GUMS configuration 
file via VDT. We could add the identity of the probe in this 
configuration file.

* GUMS has a memory management problem.
Only 30% of the sites use GUMS for site identity mapping: this low 
deployment rate may be due to this memory leak. [GG: small sites may 
choose to stick to a more simple mapping system (grid-mapfiles) 
anyway... the 30% may not be a good indicator of interest in GUMS ].
See Leigh's GUMS report http://www.ivdgl.org/~leighg/gums-report.html

We are looking into fixing the problem: John Hover is spending all his 
allocated time on GUMS working on this. We may need to get John some 
help, if no progress is made soon. John will work on this with the VDT 
team next week (condor week). It is not clear that this problem can be 
solved by VDT 1.3.11 (due in 3 weeks).

* How do we publish GUMS mapping policies?
The GUMS configuration file is a site-specific representation of the 
policies. The privilege project would like to work with EGEE and 
implement a common representation of the policy and (possibly) 
publication mechanism. EGEE uses a different authorization framework 
(LCAS/LCMAPS) than OSG.






-- Main.ConradSteenberg - 17 Apr 2006

