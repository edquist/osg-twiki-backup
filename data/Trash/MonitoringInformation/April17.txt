%META:TOPICINFO{author="KyleGross" date="1203445225" format="1.1" version="1.4"}%
%META:TOPICPARENT{name="WebHomeOld"}%
---+ April 17, 2006
---++ Agenda
   * GUMS Monitoring 

---++ Minutes
   * Attending: Michael, Conrad, Anand, Gabriele, John Roscheck, Leigh

   * What to monitor? Do a mapping? A ping?
   * Monitor probes could be run using VORS, with information reported on the web page. VORS can be adapted to make programmatic access possible
   * How is a new GUMS instance detected? Currently manually reported to operations staff
   * Leigh: CE monitoring can possibly be used to report that GUMS is used.

   * Q: external access to GUMS assumed? How about firewall settings, or if the instance is running on an internal network?
   * Gabriele: Look for common solution with European efforts, which uses entirely different technologies.
   * How should new servers be registered should be discussed?
   * FYI, Leigh compiled a report of GUMS servers several months ago, at http://www.ivdgl.org/~leighg/gums-report.html

   * vdt-1.3.11 needed for Gums memory fix, need to coordinate with VDT/GUMS release teams.

   * GUMS config template file supplied with the distribution, could be used to set up access from a central host.

   * Michael: suggest using discovery service, putting publication code in GUMS itself, rather than using external scripts like in VOMS. Example code exists in JClarens.
   * Anand: suggest using GIPs for information publication

   * John: VORS monitoring display change: monitor.grid.iu.edu

---++ Notes by Gabriele
* How do we monitor GUMS status? We discussed 2 models
(1) GUMS publishes its internal status: requires development
(2) a probe tries to query for a mapping: does not require development, 
example clients are available in the PRIMA distribution (should be checked).

Let's think about model (2).
GUMS status could be probed and published using a combination of the 
following:

- Publication over the web using GridCat (check this). A probe could be 
run periodically. At the beginning, registration of new GUMS services 
could be done manually. The problem is that GUMS is a local site service 
and may not easily allow external access (e.g. it may be running on a 
private network).

- We could have GUMS register with the discovery service. This requires 
adding code to GUMS. When GUMS is up, it registers: this partially 
solves the question of GUMS availability. At the 0th level, we may not 
even need to run a probe to check the mapping periodically if we know 
that GUMS is up. If we want to run an external probe, the registration 
service could publish whether GUMS is externally accessible or not.

- We could use GIP and GLUE (service element) to publish the GUMS 
status. The GIP have access from within the cluster i.e. no external 
accessibility wouold be required to run a probe.

- If we run an external probe, we need to have GUMS authorize the probe 
access. We already distribute a standard (example) GUMS configuration 
file via VDT. We could add the identity of the probe in this 
configuration file.

* GUMS has a memory management problem.
Only 30% of the sites use GUMS for site identity mapping: this low 
deployment rate may be due to this memory leak. [GG: small sites may 
choose to stick to a more simple mapping system (grid-mapfiles) 
anyway... the 30% may not be a good indicator of interest in GUMS ].
See Leigh's GUMS report http://www.ivdgl.org/~leighg/gums-report.html

We are looking into fixing the problem: John Hover is spending all his 
allocated time on GUMS working on this. We may need to get John some 
help, if no progress is made soon. John will work on this with the VDT 
team next week (condor week). It is not clear that this problem can be 
solved by VDT 1.3.11 (due in 3 weeks).

* How do we publish GUMS mapping policies?
The GUMS configuration file is a site-specific representation of the 
policies. The privilege project would like to work with EGEE and 
implement a common representation of the policy and (possibly) 
publication mechanism. EGEE uses a different authorization framework 
(LCAS/LCMAPS) than OSG.

---++ Notes by John Hover

-I don't think you should ever count on being able to get to GUMS
from off-site. 

-I would resist having GUMS publish its own status for 2 reasons. 

1) it would mean I would have to add code to GUMS. Right now GUMS is very
restricted in what it does, very much in keeping with the UNIX
philosophy. It does one thing and does it well: mapping grid identities
to UNIX accounts. If we add functionality peripheral to its main task,
we take the chance of making it less robust. Also, it is now nicely
encapsulated behind the OSG AuthZ/SAML interface (aside from
administrative tasks). Again, breaking that encapsulation is risky.

2) it still leaves the possibility of the publishing
working, but GUMS not correctly doing mapping. There are lots of error
conditions that result in GUMS being unable to map correctly that
nevertheless leave the container running and able to respond (e.g.
configuration errors, database problems, etc.) It would not be possible
to account for them all directly. So a separately implemented heartbeat
tester would need to do whatever an external mapping request does
anyway. The best definitive test to see if GUMS is mapping is to map a
valid user by essentially the same mechanism that gatekeepers are
actually using.

-The GUMS resource leak problem was only identified in late February, so
I would doubt whether that has affected its deployment. I think it is
more likely that many sites just don't feel they need it. It is really
only necessary for 2 things: VOMS extended attributes, and pool
accounts. BNL uses it because ATLAS production uses Roles, and because
DOE security regulations prohibit using group accounts. Many sites
wouldn't have these requirements. 

-- Main.JohnHover - 17 Apr 2006





-- Main.ConradSteenberg - 17 Apr 2006