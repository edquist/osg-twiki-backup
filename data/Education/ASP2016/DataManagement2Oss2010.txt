%META:TOPICINFO{author="TanyaLevshina" date="1279662575" format="1.1" version="1.5"}%
%META:TOPICPARENT{name="MaterialsOSS2010"}%
---+!!Data Management Exercises (Part II) 
%TOC{depth="3"}%

---++ Introduction
In the second part of our exercises we will continue to work with BLAST application, now adding storage into the picture. Also, we will try to understand where and how you can find out available Storage Elements. At the end of the exercises you will be exposed to plethora of available data transfer and management clients you can choose from.

---++ Exercises 
---+++ Prerequisite 
   * Login on submission node <pre class="screen">
ssh %BLUE%username%ENDCOLOR%@vdt-itb.cs.wisc.edu
</pre>
   * Obtain proxy certificate, if you have not done so already <pre class="screen">
voms-proxy-init -voms osgedu:/osgedu
Enter GRID pass phrase: 
</pre>
   * Make a directory for these exercises <pre class="screen">
cd
mkdir storage-2
cd storage-2
</pre>

---+++ Running BLAST 
We will try to built on exercises you have been doing for the last two days. You have already submitted a simple script to the GRID that ran BLAST [[https://twiki.grid.iu.edu/bin/view/Education/CondorBLASTOSS2010][see exercise]]. In this case BLAST application and databases were already pre-deployed on osg-edu cluster.  Let's consider the following problem: you still would like to run your job on osg-edu cluster and you have application pre-deployed on the worker nodes of this cluster, unfortunately the data are not accessible from  the worker nodes. The only place from where you can get the data is a SE at OSG-EDU site. You you have to figure out how to solve this problem. Can you do it on your own? 
---++++ Solution
We can write a simple script that will do the following:
   1. Setup GRID environment
   1. Create a temporary space on the worker node under ==$OSG_WN_TMP==, move to this directory
   1. Find all the files related to the database you want to search (e.g ==yeast==)  at  SE OSG-EDU(SURL: ==srm://osg-edu.cs.wisc.edu:10443==) . The directory path to all BLAST databases is ==/srmcache/osgedu/blast/db-1/==. (Try to do ==srm-ls== command and verify that they are actually there).
   1. Download all the files associated with ==yeast== to the worker node
   1. Run BLAST executable with required parameters (database name, sequence query and log file)
The Condor-G submission file should describe input and output  files you want to  transfer with these two scripts.

You can try to solve this problem on your own. If you need help you can check my examples.
   * ==/home/tanya/exercises/dm_2/blast.sh== (slightly modified script provided by Alain [[https://twiki.grid.iu.edu/bin/view/Education/CondorBLASTOSS2010][here]]). <pre class="file">
more blast.sh
%TWISTY%
#!/bin/sh

if [ $# -ne 3 ]; then
    echo "Usage: ./blast.sh db_name query logfile "
    exit 1
fi


appdir=$OSG_APP/osgedu/blast/
dbdir=$OSG_DATA/osgedu/blast_dbs

# Get our environment set up
. $appdir/setup.sh

# Run the query
blastp -db $dbdir/$1 -query $2  >>$3  2>&1
%ENDTWISTY%
</pre>
   * Wrapper script ==/home/tanya/exercises/dm_2/blast2.sh==.<pre class="file">
more blast2.sh
%TWISTY%
  #!/bin/bash
################################################################################
#  blast2 - download specific blast databases from a particular Storage Element  #
#          execute blast query for a particular query                           #
#          do cleanup                                                           #
#################################################################################
usage ()
{
     log "Usage: ./blast2.sh surl endpath db_name query_file logfile"
}
log ()
{
if [ x$logname == x ]
then
        echo $1
else
        echo $1 >>$logfile
fi
}
# test if we have four arguments on the command line
if [ $# -lt  4 ]
then
    usage
    exit 1
fi
surl=$1
endpath=$2
dbname=$3
query=$4
logname=""
cwd=`pwd`
if [ $# -eq 5 ]
then
        logname=$5
        logfile=$cwd/$logname
        #just in case create a logfile
        touch $logfile
fi
retVal=0
log "Start blast2.sh"
#setup grid enviroment
. $OSG_GRID/setup.sh
#create temporary directory
export TMPDIR=$OSG_WN_TMP
tmpDir=`mktemp -d -t osgedu.XXXXXX`
cd $tmpDir
log "Current directory is $tmpDir"
#move and change the permission of the uploaded script
mv $cwd/blast.sh .
chmod 755 blast.sh
mv $cwd/$query .
mkdir db-1
#get all the databases we need to download
log "Executing: srm-ls srm://$surl/srm/v2/server\?SFN=$endpath|grep  SRM-CLIENT|grep yeast"
srm-ls srm://red-srm1.unl.edu:8443/srm/v2/server?SFN=/mnt/hadoop/user/engage/scienceportal/databases/blast/db-1/ |grep SRM-CLIENT|grep $dbname|awk -F'db-1/' '{print $2}'|while read name
do
        log "Executing: srm-copy srm://$surl/srm/v2/server\?SFN=$endpath/$name file:///$PWD/db-1/$name "
        srm-copy srm://$surl/srm/v2/server\?SFN=$endpath/$name file:///$PWD/db-1/$name
        curRetVal=$?
        log "Return value $curRetVal"
        if [ $curRetVal -ne 0 ]
        then
                retVal=$curRetVal
                log "New Return value $curRetVal"
        fi
done
log "Return value $retVal"
if [ $retVal -eq 0 ]
then
        #move word_counter script
        option=""
        if [ x$logname != x ]
        then
                option=$logfile
        fi
        log "Executing: ./blast.sh $dbname $query $option"
        ./blast.sh $dbname $query  $option
        retVal=$?
        log "Return value $retVal"
fi
cd $OSG_WN_TMP
rm -rf $tmpDir
log "End blast2.sh"
exit $retVal
%ENDTWISTY%
</pre>
   * Condor-G submission file ==/home/tanya/exercises/dm_2/test2.submit==: <pre class="file">
more test2.submit
%TWISTY%
universe=grid
grid_resource = gt2 osg-edu.cs.wisc.edu:/jobmanager-condor
Executable = blast2.sh
Log = test2.$(Cluster).$(Process).log
Output = test2.$(Cluster).$(Process).out
Error = test2.$(Cluster).$(Process).err
transfer_executable = true
transfer_input_files = blast.sh,yeast.query1
WhenToTransferOutput = ON_EXIT_OR_EVICT
transfer_output_files = test2.out.$(Cluster).$(Process)
should_transfer_files   = YES
Arguments =  osg-edu.cs.wisc.edu:10443 /srmcache/osgedu/blast/db-1/ yeast.aa yeast.query1  test2.out.$(Cluster).$(Process)
queue
%ENDTWISTY%
</pre>
   * Submit this Condor-G job. The logfile should look similar to this: <pre class="file">
more test2.log.62398.0
%TWISTY%
Start blast2.sh
Current directory is /tmp/osgedu.rY3298
Executing: srm-ls srm://red-srm1.unl.edu:8443/srm/v2/server\?SFN=/mnt/hadoop/user/engage/scienceportal/databases/blast/db-1/|grep SRM-CLIENT|grep yeast
Executing: srm-copy srm://red-srm1.unl.edu:8443/srm/v2/server\?SFN=/mnt/hadoop/user/engage/scienceportal/databases/blast/db-1//yeast.aa file:////tmp/osgedu.rY3298/db-1/yeast.aa
Return value 0
Executing: srm-copy srm://red-srm1.unl.edu:8443/srm/v2/server\?SFN=/mnt/hadoop/user/engage/scienceportal/databases/blast/db-1//yeast.aa.phr file:////tmp/osgedu.rY3298/db-1/yeast.aa.phr
Return value 0
Executing: srm-copy srm://red-srm1.unl.edu:8443/srm/v2/server\?SFN=/mnt/hadoop/user/engage/scienceportal/databases/blast/db-1//yeast.aa.pin file:////tmp/osgedu.rY3298/db-1/yeast.aa.pin
Return value 0
Executing: srm-copy srm://red-srm1.unl.edu:8443/srm/v2/server\?SFN=/mnt/hadoop/user/engage/scienceportal/databases/blast/db-1//yeast.aa.pnd file:////tmp/osgedu.rY3298/db-1/yeast.aa.pnd
Return value 0
Executing: srm-copy srm://red-srm1.unl.edu:8443/srm/v2/server\?SFN=/mnt/hadoop/user/engage/scienceportal/databases/blast/db-1//yeast.aa.pni file:////tmp/osgedu.rY3298/db-1/yeast.aa.pni
Return value 0
Executing: srm-copy srm://red-srm1.unl.edu:8443/srm/v2/server\?SFN=/mnt/hadoop/user/engage/scienceportal/databases/blast/db-1//yeast.aa.psd file:////tmp/osgedu.rY3298/db-1/yeast.aa.psd
Return value 0
Executing: srm-copy srm://red-srm1.unl.edu:8443/srm/v2/server\?SFN=/mnt/hadoop/user/engage/scienceportal/databases/blast/db-1//yeast.aa.psi file:////tmp/osgedu.rY3298/db-1/yeast.aa.psi
Return value 0
Executing: srm-copy srm://red-srm1.unl.edu:8443/srm/v2/server\?SFN=/mnt/hadoop/user/engage/scienceportal/databases/blast/db-1//yeast.aa.psq file:////tmp/osgedu.rY3298/db-1/yeast.aa.psq
Return value 0
Return value 0
Executing: ./blast.sh yeast.aa yeast.query1 /nfs/osgedu/gram_scratch_kFmkKIBmUW/test2.log.62398.0
BLASTP 2.2.23+


Reference: Stephen F. Altschul, Thomas L. Madden, Alejandro A.
Schaffer, Jinghui Zhang, Zheng Zhang, Webb Miller, and David J.
Lipman (1997), "Gapped BLAST and PSI-BLAST: a new generation of
protein database search programs", Nucleic Acids Res. 25:3389-3402.



Reference for composition-based statistics: Alejandro A. Schaffer,
L. Aravind, Thomas L. Madden, Sergei Shavirin, John L. Spouge, Yuri
I. Wolf, Eugene V. Koonin, and Stephen F. Altschul (2001),
"Improving the accuracy of PSI-BLAST protein database searches with
composition-based statistics and other refinements", Nucleic Acids
Res. 29:2994-3005.



Database: yeast.aa
           6,298 sequences; 2,974,038 total letters



Query=  
Length=80
                                                                      Score     E
Sequences producing significant alignments:                          (Bits)  Value

ref|NP_009511.1|  uridine permease; Fui1p                              170    4e-44
ref|NP_012677.1|  dolichyl phosphate-D-mannose:protein O-D-mannos...  23.9    4.6  
ref|NP_015305.1|  Smt3-processing enzyme; Ulp1p                       23.9    4.8  
ref|NP_011691.1|  Squalene monooxygenase; Erg1p                       23.9    5.1  
ref|NP_009545.1|  putative repressor protein homologous to yeast ...  23.1    7.3  


>ref|NP_009511.1| uridine permease; Fui1p
Length=639

 Score =  170 bits (430),  Expect = 4e-44, Method: Composition-based stats.
 Identities = 80/80 (100%), Positives = 80/80 (100%), Gaps = 0/80 (0%)

Query  1   MPVSDSGFDNSSKTMKDDTIPTEDYEEITKESEMGDATKITSKIDANVIEKKDTDSENNI  60
           MPVSDSGFDNSSKTMKDDTIPTEDYEEITKESEMGDATKITSKIDANVIEKKDTDSENNI
Sbjct  1   MPVSDSGFDNSSKTMKDDTIPTEDYEEITKESEMGDATKITSKIDANVIEKKDTDSENNI  60

Query  61  TIAQDDEKVSWLQRVVEFFE  80
           TIAQDDEKVSWLQRVVEFFE
Sbjct  61  TIAQDDEKVSWLQRVVEFFE  80


>ref|NP_012677.1| dolichyl phosphate-D-mannose:protein O-D-mannosyltransferase; 
Pmt4p
Length=762

 Score = 23.9 bits (50),  Expect = 4.6, Method: Composition-based stats.
 Identities = 10/39 (25%), Positives = 21/39 (53%), Gaps = 0/39 (0%)

Query  18   DTIPTEDYEEITKESEMGDATKITSKIDANVIEKKDTDS  56
            D   + +++E  K+S +   +K  +  D   I+ +DTD+
Sbjct  311  DAFMSAEFQETLKDSPLSVDSKTVNYFDIITIKHQDTDA  349


>ref|NP_015305.1| Smt3-processing enzyme; Ulp1p
Length=621

 Score = 23.9 bits (50),  Expect = 4.8, Method: Compositional matrix adjust.
 Identities = 15/35 (42%), Positives = 22/35 (62%), Gaps = 1/35 (2%)

Query  31   ESEMGDATKITSKIDANVIEKKDTDSENNITIAQD  65
            ESE G  T  TS I +   +K + DS+N+IT ++D
Sbjct  173  ESE-GVGTPSTSPISSLASQKSNCDSDNSITFSRD  206


>ref|NP_011691.1| Squalene monooxygenase; Erg1p
Length=496

 Score = 23.9 bits (50),  Expect = 5.1, Method: Composition-based stats.
 Identities = 9/23 (39%), Positives = 15/23 (65%), Gaps = 0/23 (0%)

Query  9    DNSSKTMKDDTIPTEDYEEITKE  31
            D + K ++D TI  +DYE+  +E
Sbjct  121  DGNDKVLEDSTIHIKDYEDDERE  143


>ref|NP_009545.1| putative repressor protein homologous to yeast Tup1p and mammalian 
retinal transducin; contains nuclear targeting signal; 
Hir1p
Length=840

 Score = 23.1 bits (48),  Expect = 7.3, Method: Compositional matrix adjust.
 Identities = 12/25 (48%), Positives = 18/25 (72%), Gaps = 1/25 (4%)

Query  45   DANVIEKKDTDSENNITIAQDDEKV  69
            +A V +KKD D EN + + Q+D+KV
Sbjct  294  NAGVKQKKDDDPENAL-VGQNDDKV  317



Lambda     K      H
   0.304    0.123    0.327 

Gapped
Lambda     K      H
   0.267   0.0410    0.140 

Effective search space used: 74103176


  Database: yeast.aa
    Posted date:  May 4, 2010  9:00 PM
  Number of letters in database: 2,974,038
  Number of sequences in database:  6,298



Matrix: BLOSUM62
Gap Penalties: Existence: 11, Extension: 1
Neighboring words threshold: 11
Window for multiple hits: 40
Return value 0
End blast2.sh
%ENDTWISTY%
</pre>

---++++ On your own
   * Can you make four-node DAG that will upload data from SE to the worker node, run several queries, create a tar file and upload data back to a SE?
---+++ Storage Discovery
You should know by now enough about storage to be able to try to figure out how to use it on your own. The problem is that we didn't give any tools to figure out what Storage Element will support your VO. Also, how you would find the  surl and endpath of a SE. You can always use ==condor_status== and various constraints to try to figure out this information, but it is not a trivial task. The OSG has a  [[http://is.grid.iu.edu/cgi-bin/status.cgi][BDII service]] which aggregates LDAP information provided by sites. The information reported by each site describes static and dynamic resources available at that site and VOs that are authorized to use these resources. The [[https://twiki.grid.iu.edu/bin/view/ReleaseDocumentation/OSGStorageDiscoveryTool][OSG Discovery Tools]] allow users to discover what SE supports thier VO and how to access it.

   1. Setup GRID environment
   1. See all the get_commands available for information discovery: <pre class="screen"> ls $VDT_LOCATION/discovery/bin/get_*
/opt//osg-client/discovery/bin/get_gridftp_storage_element_id  /opt//osg-client/discovery/bin/get_site_name              /opt//osg-client/discovery/bin/get_srm_sp_reserve_cmd
/opt//osg-client/discovery/bin/get_gridftp_url                 /opt//osg-client/discovery/bin/get_site_name_for_seid     /opt//osg-client/discovery/bin/get_srm_storage_element_id
/opt//osg-client/discovery/bin/get_mount_path                  /opt//osg-client/discovery/bin/get_srm_copy_cmd           /opt//osg-client/discovery/bin/get_storage_element_id
/opt//osg-client/discovery/bin/get_os_versions                 /opt//osg-client/discovery/bin/get_srmcp_cmd              /opt//osg-client/discovery/bin/get_surl
/opt//osg-client/discovery/bin/get_runtime_versions            /opt//osg-client/discovery/bin/get_srm_reserve_space_cmd
</pre>
   1.  Check what SEs are available for OSGEDU and what are endpoints: <pre class="screen">
/opt//osg-client/discovery/bin/get_surl --vo osgedu --show_storage_element_id  
STORAGE ELEMENT ID            SURL                                                                                                
bsrm-1.t2.ucsd.edu            srm://bsrm-1.t2.ucsd.edu:8443/srm/v2/server?SFN=/hadoop/osgedu/TESTFILE                             
cit-se.ultralight.org         srm://cit-se.ultralight.org:8443/srm/v2/server?SFN=/mnt/hadoop/osg/osgedu/TESTFILE                  
dcsrm.usatlas.bnl.gov         srm://dcsrm.usatlas.bnl.gov:8443/srm/managerv2?SFN=/pnfs/usatlas.bnl.gov/osg/osgedu/TESTFILE        
ff-se.unl.edu                 srm://ff-se.unl.edu:8443/srm/v2/server?SFN=/panfs/panasas/CMS/data/osgedu/TESTFILE                  
iut2-dc1.iu.edu               srm://iut2-dc1.iu.edu:8443/srm/managerv2?SFN=/pnfs/iu.edu/TESTFILE                                  
iut2-grid8.iu.edu             srm://iut2-grid8.iu.edu:63443/srm/v2/server?SFN=/xrdfs/TESTFILE                                     
osg-east.hms.harvard.edu      srm://osg-east.hms.harvard.edu:10443/srm/v2/server?SFN=/osg/storage/data/osgedu/TESTFILE            
osg-edu.cs.wisc.edu           srm://osg-edu.cs.wisc.edu:10443/srm/v2/server?SFN=/space/bestman/osgedu/TESTFILE                    
osg-se.sprace.org.br          srm://osg-se.sprace.org.br:8443/srm/managerv2?SFN=/pnfs/sprace.org.br/data/TESTFILE                 
red-srm1.unl.edu              srm://red-srm1.unl.edu:8443/srm/v2/server?SFN=/mnt/hadoop/public/osgedu/TESTFILE                    
se.grid.unesp.br              srm://se.grid.unesp.br:8443/srm/v2/server?SFN=/store/osgedu/TESTFILE                                
se1.phys.uconn.edu            srm://se1.phys.uconn.edu:8443/srm/managerv2?SFN=/osgedu/TESTFILE                                    
uct2-dc1.uchicago.edu         srm://uct2-dc1.uchicago.edu:8443/srm/managerv2?SFN=/pnfs/uchicago.edu/TESTFILE      
</pre>
It means that you can use ==srm://red-srm1.unl.edu:8443/srm/v2/server?SFN=/mnt/hadoop/public/osgedu/%BLUE%TESTFILE%ENDCOLOR%== to upload/download  files to/from  Nebraska (==red-srm1.unl.edu==) SE.

---++++On your own
Try other commands and see if they are useful. 

----+++SRM clients
There are various implementations of data transfer and data management tools. Each implementation has its own pros and cons. The following clients are widely used in OSG:
   1. SRM clients
      * [[https://twiki.grid.iu.edu/bin/view/ReleaseDocumentation/LCGUtils][LCG SRM Client]] (==lcg-cp== and others)
      * [[https://twiki.grid.iu.edu/bin/view/ReleaseDocumentation/LBNLSrmClient][LBNL SRM Client]] (==srm-copy== and others)
      * [[https://twiki.grid.iu.edu/bin/view/ReleaseDocumentation/FermiSrmClientCommands][FNAL SRM Client]] (==srmcp== and others) 
   1. !GridFTP client
      * [[http://www.globus.org/toolkit/docs/4.0/data/gridftp/rn01re01.html][Globus GridFTP client]] (==globus-url-copy==)
      * [[http://dims.ncsa.illinois.edu/set/uberftp/userdoc.html][UberFTP]], another command-line client for !GridFTP; covers a wider variety of the !GridFTP protocol than just copying 

All of them are available on the submission and worker nodes.

-- Main.TanyaLevshina - 15 Jul 2010