%META:TOPICINFO{author="LincolnBryant" date="1438184249" format="1.1" reprev="1.14" version="1.14"}%
%META:TOPICPARENT{name="UserSchool15Materials"}%
<style type="text/css">
pre em { font-style: normal; background-color: yellow; }
pre strong { font-style: normal; font-weight: bold; color: #008; }
</style>

---+ !!HTCondor File Transfer
%TOC%

The objective of this exercise is to refresh yourself on the basic techniques for transferring data on OSG.

Recall that OSG does not have a shared filesystem! With that in mind, we'll show how to transfer input data for a sample application. 

We'll also look at how compression and archival can be used to effectively transfer files.

---++ Setup

<center>
<img src="%ATTACHURLPATH%/data_tranfer_1.jpg " alt="data_tranfer_1.jpg " width='400' height='150'/>
</center>

In this exercise we'll use NAMD, a popular molecular dynamics package, to perform a simulation on OSG. We'll write a job that loads NAMD from the OSG Distributed Environment Modules and transfers its input data from the OSG Connect login host via the HTCondor File Transfer mechanism. 

First, you'll login to OSG Connect with the credentials you made on Tuesday:
<pre class="screen">
%UCL_PROMPT_SHORT% ssh username@login.osgconnect.net
</pre>

Once logged in, you'll need to copy the NAMD directory to your home directory. 

<pre class="screen">
%UCL_PROMPT_SHORT% cp -a /stash/public/userschool2015/namd ~
%UCL_PROMPT_SHORT% cd namd
</pre>

You should see a number of files in the =~/namd= directory, as in the table below:
| *File* | *Description* |
| =par_all27_prot_lipid.inp= | NAMD parameter file | 
| =ubq_gbis_eq.conf= | NAMD input configuration file |
| =ubq.pdb= | Protein structure file |
| =ubq.psf= | Protein topology file |

For this exercise, the details of the NAMD input files are unimportant. Simply keep in mind that NAMD needs all of the files to run.

---++ Creating the job wrapper script

To load the NAMD program, we use the OSG Distributed Environment Modules. You should be familiar with them from Tuesday's OSG Connect exercise, but you may refer [[https://support.opensciencegrid.org/support/solutions/articles/5000634394-accessing-software-using-distributed-environment-modules][here]] for additional details. 

With that in mind, our wrapper script for NAMD should look something like this:
<pre class="file">
#!/bin/bash
echo "Files in the current directory:" $(ls)
source /cvmfs/oasis.opensciencegrid.org/osg/modules/lmod/current/init/bash
module load namd/2.9
namd2 ubq_gbis_eq.conf > ubq_gbis_eq.log
</pre> 

Save the wrapper as =namd_run.sh= and remember to make it executable with =chmod +x namd_run.sh=.

For reference, here is a line-by-line breakdown of the script:
| *Line* | *Description* | 
| =#!/bin/bash= | Invokes the BASH shell |
| =echo "Files in the current directory:" $(ls)= | List the files in the current directory |
| =source /cvmfs/oasis.opensciencegrid.org/osg/modules/lmod/current/init/bash= | Loads the module system into the shell's environment |
| =module load namd/2.9= | Loads the NAMD program, version 2.9 |
| =namd2 ubq_gbis_eq.conf > ubq_gbis_eq.log= | Runs NAMD, reading =ubq_gbis_eq.conf= for configuration and redirecting output to =ubq_gbis_eq.log= | 



---++ Create and submit the job

We've started a submit script for you below, but you will need to fill out the =transfer_input_files= section. For NAMD to successfully run, you'll need all four input files.

*HINT*: =transfer_input_files= accepts a comma separated list of files.

<pre class="file">
universe = vanilla
executable = namd_run.sh
transfer_input_files = 
output  = job.out
error = job.error
log = job.log
requirements = (HAS_CVMFS_oasis_opensciencegrid_org =?= TRUE)
queue
</pre>

Remember to include =HAS_CVMFS_oasis_opensciencegrid_org= to *only* match against worker nodes with the OASIS software repository mounted.

Once you have finished creating the submit file, go ahead and submit the job.
<pre class="screen">
%UCL_PROMPT_SHORT% condor_submit namd_run.submit
</pre>

The job should take around 5 minutes to complete. Once finished, look at the job output (in our case, =job.out=) and look for the line starting with "Files in the current directory".  It may be easiest to use the =grep= tool, like so:

<pre class="screen">
%UCL_PROMPT_SHORT% grep "Files in the current directory" job.out
</pre>

Did the files successfully transfer? You should see something like this:

<pre class="screen">
Files in the current directory: _condor_stderr _condor_stdout condor_exec.exe par_all27_prot_lipid.inp ubq.pdb ubq.psf ubq_gbis_eq.conf
</pre>

*Question*: What do =_condor_stderr=, =_condor_stdout=, and =condor_exec.exe= correspond to in the submit file? 

---++ Compressed input files

Sometimes when you have a lot of input files it makes more sense to compress them before sending them with a job. For this exercise, we want to compress our four NAMD input files and send them to the remote worker node. 

For this part of the exercise, you will need to:

   1. Compress the input files using the =tar= command
   1. Modify =transfer_input_files= in the file =namd_run.submit= to transfer your compressed file
   1. Edit =namd_run.sh= and add a line to decompress the input files.

*HINT*: Here's a pattern for the =tar= command:
<pre class="screen">
%UCL_PROMPT_SHORT% tar -cvzf [compressed filename] [list of files]
</pre>

Replace =-c= with =-x= to decompress. Refer to the slides if you get confused.

%BR%
-- Main.BalamuruganDesinghu - 23 Jul 2015

%META:FILEATTACHMENT{name="data_tranfer_1.jpg" attachment="data_tranfer_1.jpg" attr="" comment="Transfer input files. Condor transfers the wrapper script by default." date="1437761680" path="data_tranfer_1.jpg" size="24319" stream="data_tranfer_1.jpg" tmpFilename="/usr/tmp/CGItemp9889" user="BalamuruganDesinghu" version="1"}%
%META:TOPICMOVED{by="LincolnBryant" date="1438184167" from="Education.UserSchool15Thu31DataJob" to="Education.UserSchool15Thu12DataJob"}%
