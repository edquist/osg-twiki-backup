%META:TOPICINFO{author="ForrestChristian" date="1174764297" format="1.1" version="1.6"}%
%META:TOPICPARENT{name="LectureOneTutorial"}%
<link rel="stylesheet" type="text/css" href="%PUBURL%/%WEB%/WorkshopTutorialModules/exercises.css">

---+!! Immediate (fork) and Batch (scheduled) Job managers

%STARTINCLUDE%
%EDITTHIS%

Notice that we follow the system name that you want to run the command on with the qualifier =/jobmanager-fork=. GRAM, the Globus protocol for running remote jobs, supports the concept of a "job manager" as an adapter to local job management environments.  Each "Grid site" - or collection of resources - can support one or more such job managers. The "fork" job manager runs an immediate job through the UNIX fork() interface. Another job manager we have installed on the workshop hosts, =jobmanager-condor= acts as an interface to the Condor batch scheduling system.

Which do you think will be faster?  Lets find out: use the command =time= to test which jobmanager is faster.

To time a command, just enter =time <em>commandname</em>=:

<pre class="screen">
%LOGINHOST%$ <userinput>time sleep 3</userinput>
</pre>

Use this to time a few trvial Grid jobs to compare =jobmanager-fork= and =jobmanager-condor=.

The "fork" job manager is very fast - it has rather low "scheduling latency".  It runs trivial commands very quickly.  But it also has no compute power - its usually just a single CPU on a cluster-controlling computer called the _gatekeeper_ or _headnode_.  A batch job manager, on the other hand, has a higher scheduling overhead.  But it gives you access to all computers in a cluster, and the opportunity to do real parallel computing.

It turns out that each of our workshop machines is just an ordinary single-processing machine. We've just "tricked" Condor onto thinking that it had a real "cluster" there with a set of CPUs. (We configured each of the workshop hosts with 16 such virtual CPUS).

While our four workshop hosts use the Condor scheduler, and thus =jobmanager-condor=, other systems use other schedulers. For example, systems using _PBS_ (Portable Batch System) require that you use =jobmanager-pbs=.  You'll get a chance to try this later in this lab.

Now try running a few jobs at a remote grid site which does have a real cluster:

<pre class="screen">
%LOGINHOST%$ <userinput>globus-job-run skynet-login.isi.edu:/jobmanager-pbs /bin/hostname</userinput>
</pre>

Next try starting five such jobs on the skynet cluster at once: put an "&" at the end of the line, and either use cut-and-past, or shell command history, or a simple shell script to run five of these commands at once.  

Can you see multiple hostnames being used?  Are any of these the skynet-login "gatekeeper" hostname?


%STOPINCLUDE%
<!--                                                                            
      * Set LOGINHOST = workshop1.lac.uic.edu
      * Set LOGINIP = 131.193.181.56
      * Set GRIDHOST = tg-login.sdsc.teragrid.org
      * Set OTHERHOST = workshop2.lac.uic.edu
      * Set CERTSUBJECT = /O=Grid/OU=OSG/CN=Training User 99
      * Set LOGINNAME = train99
      * Set HOMEDIR = /home/%LOGINNAME%
--> 

%BOTTOMMATTER%

-- Main.ForrestChristian - 29 Jan 2007: edited from original  %BR%
-- Main.ForrestChristian - 24 Mar 2007 - Added VARIABLES      %BR%