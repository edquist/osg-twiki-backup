%META:TOPICINFO{author="LaurenMichael" date="1438012999" format="1.1" version="1.4"}%
%META:TOPICPARENT{name="UserSchool15Materials"}%
<style type="text/css">
pre em { font-style: normal; background-color: yellow; }
pre strong { font-style: normal; font-weight: bold; color: #008; }
</style>

---+ Friday Exercise 1.1: Learn about Joe's Desired Computing Work

Joe Biologist studies the influence of genetic differences (genotypes) on the growth traits (phenotypes) of a common crop. Joe has come to you with some computing work he’d like to automate as a workflow, so that he can scale out his research and run it on the Open Science Grid. He has used HTCondor to manually submit individual jobs (never used a DAG), but has only run jobs on a smaller, dedicated HTC cluster where he doesn’t have to request CPU, disk, or RAM, and he’s not familiar with DAGman. He's getting annoyed by how many manual job submissions and summary scripts he has to run, especially as he's thinking of scaling out his work in a way that would be much more cumbersome - so he's asking you to help him organize all the steps into an optimized DAG workflow. 

---+++ After asking Joe many questions, you realize the following things:

*A) Joe starts with a file called =input.csv= that was made on his desktop.* When you open this file in excel, Joe shows you that each row corresponds to an individual plant. For each individual, the first three columns are phenotype measurements for each of three different growth _traits_ (T240, T300, T360), and the remaining columns contain the genotype (A or B) of that individual across multiple genes (columns).

*B) At present, Joe does the following manual steps (for each of the three traits!)* to achieve a meaningful result from the data in =input.csv=:
   * 1. Joe first submits a job that calculates a large number of hypothetical permutations of phenotype-genotype combinations for the trait.
   * 2. Joe then runs a script for each trait, to create a gzipped tar file of the results of the _permutation_ job to be used in the next "QTL mapping" job.
   * 3. Joe submits a second job for each trait, which performs a _QTL mapping_ calculation to determine which genes were most important for the phenotype, relative to other possible genes exemplified in the random permutations.
   * 4. As a final step for each trait, Joe runs a script that creates a gzipped tar file of all of the _permutation_ and _QTL mapping_ data, so that he can take it back to his desktop computer for final processing.

*C) Joe uses a special _wrapper_ to run the _permutation_ and _QTL mapping_ calculations, which are otherwise written as R scripts.* For each step this perl script, =runR.pl=, first installs R using files from Joe's proxy server and then sets up the R environment before running whatever R script has been indicated as an argument to =runR.pl=. Therefore, the =runR.pl= wrapper script is run as the HTCondor executable with the name of either R program indicated as an argument to the wrapper (along with arguments to the R program, itself).

*D) The two tar steps are shell scripts simply containing a relevant =tar= command,* and can be run on the submit server because they create little CPU load and finish very quickly.

---++++ More on each step:

*1) The permutation step

*2) Joe performs two steps _for each trait_: a "Permutation preparation" step and a “QTL mapping” step that each need only 1 CPU core.*
   * For each trait, Joe usually runs a "Permutation" condor job that uses one column of phenotype data and all the genotype information from input.csv for all individuals. This step, which calculates some input number of random permutations of the data, is carried out by an R program, =run_perm.R=, and the number of permutations performed is passed as an argument to the program. Joe needs to run a total of 10,000 total permutations per trait, but these can be achieved by running multiple condor job processes of fewer permutations for a total of 10,000.
   * A g-zipped tarball of all of the permutation output for a trait is then created to be used in the second step.
   * In the second step, which is a "QTL" mapping step, a program called =qtl.R= takes in the data from =input.csv=, data from a tarball of the trait-specific permutation output, and an argument indicating the input.csv column number for the trait. 
   * The QTL step produces multiple output files that Joe then needs to tar and compress so he can copy the final data back to his own computer.

*4) Joe has brought all of his inputs, outputs, and submit files for you to see.* (You’ll see these in the exercises and should only need to modify the submit files as specifically indicated.)

*5) When Joe runs all 10,000 permutations as one condor job, it will run for days (too long for _your_ cluster, which only runs jobs for up to a 4 hours each).* He has cut the permutations of a single condor job up into multiple, shorter HTCondor processes of fewer permutations before, but he doesn’t remember the details.


---+++ Joe’s Job Summaries

Based upon Joe’s description and submit files you determine the following details for each step:

---++++ *Permutation Step* (example if permutation1.submit)

execution: 	
   * =./runR.pl 1_$(Process) run_perm.R 1 $(Process) 10000=

arg descriptions:	
   * =1_$(Process)=, used by =runR.pl= to name its log file
   * =1=, trait column in =input.csv= (i.e. this is 3 for permutation3.submit)
   * =$(Process)=,	used by =run_perm.R= for naming the permutation output
   * =10000=,	indicates that 10,000 permutations should be done for this single job process

input: 		
   * =run_perm.R=, =input.csv=, =RLIBS.tar.gz=

 output: 	
   * =runR.1_0.out=, log file for =runR.pl=, where "1_0" is from arg
   * =perm_part.1_0.Rdat=, output from =run_perm.R=, "1" and "0" are from args

*Note:* =tarit.sh= is run after each trait's Permutation step (with the column number as an argument) to compress =perm_part.1_0.Rdat= for the QTL step. Execution: =tarit.sh 1=, where "1" is the trait column number.
		
---++++ *QTL Mapping Step* (example if =qtl1.submit=)

execution:	
   * =./runR.pl qtl_1 qtl.R 1=

arg descriptions:	
   * =qtl_1=, used by =runR.pl= to name its log file
   * =1=, trait column in =input.csv=

input:		
        =qtl.R, input.csv=, =RLIBS.tar.gz=, =perm_combined.tar.gz= (created by =tarit.sh=)

output:	
   * =runR.qtl_1.out=, log file for =runR.pl=, where "qtl_1" is from arg
   * =perm_combined_1.Rdat=,	"1" is from =qtl.R= arg
   * =perm_summary_1.txt=, “”
   * =sim_geno_results_1.Rdat=, “”
   * =qtl_1.Rdat=, “”
   * =refined_qtl_summary_1.txt=, “”
   * =refined qtl_1.Rdat=, “”
   * =fit_qtl_results_1.Rdat=, "”

*Note:* =results_1.tar.gz= is made by running =taritall.sh= (with the column number as an argument) after the QTL step for each trait finishes, where "1" reflects the trait column number in the output above. Execution: =taritall.sh 1=, where "1" is the trait column number.




-- Main.LaurenMichael - 23 Jul 2015

%META:TOPICMOVED{by="LaurenMichael" date="1438007647" from="Education.UserSchool15Fri1Background" to="Education.UserSchool15Fri11LearnJoesWork"}%
