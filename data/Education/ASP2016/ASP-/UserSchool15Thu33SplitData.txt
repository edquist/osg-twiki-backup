%META:TOPICINFO{author="BalamuruganDesinghu" date="1437755884" format="1.1" reprev="1.1" version="1.1"}%
%META:TOPICPARENT{name="UserSchool15Materials"}%
<style type="text/css">
pre em { font-style: normal; background-color: yellow; }
pre strong { font-style: normal; font-weight: bold; color: #008; }
</style>


---+ Exercise 3.3 : Multiple query files

In the previous exercises (Exercise 3.1  and 3.2), we focused on how to do blast search with split data base for a given query file. We want to generalize this approach for a set of query file.  We do the query for two but the idea is applicable to several query files. 

We have two query files, namely, HLA.txt and BRAC1.txt. The database is split into 18 files. So we need to perform 36  jobs. This is a classic case that fits into high throughput computing for large number of query files. 

Our job submission files are generated through ==blast_gen.bash== script. Basically it loops over the number of data chunks. Add another loop and generalize it for multiple query files.

<pre>
Understand blast_exe.bash script
modify the script to generate job files for HLA.txt and BRAC1.txt.
</pre> 

---++Additional information

In the blast search example, we are utilizing the bash script to take care of submitting multiple jobs. A better alternative is to utilize the workflow manager such as DAGMan or Pegasus. You have learned a lot about DAGMan already. Pegaus is a workflow manager built on top of DAGMan functionalities. To check it works for our blast example: https://github.com/OSGConnect/tutorial-pegasus-blast

-- Main.BalamuruganDesinghu - 24 Jul 2015
