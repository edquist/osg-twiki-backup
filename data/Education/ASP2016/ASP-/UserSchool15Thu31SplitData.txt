%META:TOPICINFO{author="BalamuruganDesinghu" date="1438085090" format="1.1" version="1.10"}%
%META:TOPICPARENT{name="UserSchool15Materials"}%
<style type="text/css">
pre em { font-style: normal; background-color: yellow; }
pre strong { font-style: normal; font-weight: bold; color: #008; }
</style>

---+!! Thursday  Exercise 3.1: Splitting input data up
%TOC%

---++ Goal
Some computations require large amounts of input data.  Having a single job download large amounts of data and then process may result in a job that takes a long time to analyze it's inputs and which uses a lot of RAM while doing so.  In these situations, it's often advantageous to break the inputs up and use multiple jobs to instead of a single job.   This exercise looks at how to do this using a BLAST job that works uses a 20GB reference database.

<center>
<img src="%ATTACHURLPATH%/DataChunk_1.jpg" alt="DataChunk_1.jpg" width='400' height='300'/>
</center>

---++ Data chunks and workflow
As mentioned before the BLAST database used for this exercise has a total size of 20GB. We've already split into 18 chunks using the standard tools that comes with blast package. The files are located at 
<pre class="screen">
%UCL_PROMPT_SHORT% <strong>ls /stash/public/blast/database/nt.5-30-2014/*.gz </strong>
-rw-rw-r-- 1 dbala @OSG-Staff 801M Jan 27 14:44 /stash/public/blast/database/nt.5-30-2014/nt.00.tar.gz
-rw-rw-r-- 1 dbala @OSG-Staff 825M Jan 27 14:44 /stash/public/blast/database/nt.5-30-2014/nt.01.tar.gz
-rw-rw-r-- 1 dbala @OSG-Staff 769M Jan 27 14:44 /stash/public/blast/database/nt.5-30-2014/nt.02.tar.gz
-rw-rw-r-- 1 dbala @OSG-Staff 778M Jan 27 14:45 /stash/public/blast/database/nt.5-30-2014/nt.03.tar.gz
-rw-rw-r-- 1 dbala @OSG-Staff 690M Jan 27 14:45 /stash/public/blast/database/nt.5-30-2014/nt.04.tar.gz
-rw-rw-r-- 1 dbala @OSG-Staff 769M Jan 27 14:45 /stash/public/blast/database/nt.5-30-2014/nt.05.tar.gz
-rw-rw-r-- 1 dbala @OSG-Staff 743M Jan 27 14:46 /stash/public/blast/database/nt.5-30-2014/nt.06.tar.gz
-rw-rw-r-- 1 dbala @OSG-Staff 636M Jan 27 14:46 /stash/public/blast/database/nt.5-30-2014/nt.07.tar.gz
-rw-rw-r-- 1 dbala @OSG-Staff 617M Jan 27 14:46 /stash/public/blast/database/nt.5-30-2014/nt.08.tar.gz
-rw-rw-r-- 1 dbala @OSG-Staff 524M Jan 27 14:47 /stash/public/blast/database/nt.5-30-2014/nt.09.tar.gz
-rw-rw-r-- 1 dbala @OSG-Staff 722M Jan 27 14:47 /stash/public/blast/database/nt.5-30-2014/nt.10.tar.gz
-rw-rw-r-- 1 dbala @OSG-Staff 733M Jan 27 14:47 /stash/public/blast/database/nt.5-30-2014/nt.11.tar.gz
-rw-rw-r-- 1 dbala @OSG-Staff 708M Jan 27 14:48 /stash/public/blast/database/nt.5-30-2014/nt.12.tar.gz
-rw-rw-r-- 1 dbala @OSG-Staff 202M Jan 27 14:48 /stash/public/blast/database/nt.5-30-2014/nt.13.tar.gz
-rw-rw-r-- 1 dbala @OSG-Staff 426M Jan 27 14:48 /stash/public/blast/database/nt.5-30-2014/nt.14.tar.gz
-rw-rw-r-- 1 dbala @OSG-Staff 766M Jan 27 14:48 /stash/public/blast/database/nt.5-30-2014/nt.15.tar.gz
-rw-rw-r-- 1 dbala @OSG-Staff 810M Jan 27 14:49 /stash/public/blast/database/nt.5-30-2014/nt.16.tar.gz
-rw-rw-r-- 1 dbala @OSG-Staff 652M Jan 27 14:49 /stash/public/blast/database/nt.5-30-2014/nt.17.tar.gz
-rw-rw-r-- 1 dbala @OSG-Staff 285M Jan 27 14:49 /stash/public/blast/database/nt.5-30-2014/nt.18.tar.gz
</pre>

We want to perform blast analysis for a given query file on these smaller chunks. Blast search takes the sequence in the query file and  matches with the sequences in database.   For a given query file, we want to perform blast search on these chunks.   We'll give an example of this and your task will be to create a submit script that will perform a different query.

---++ Get and explore example files
On the OSG submit node, copy the required files to your home directory. 
<pre class="screen">
%UCL_PROMPT_SHORT% <strong>cp /stash/public/userschool2015/BlastSplitSearch ~   </strong>
</pre>

<pre class="screen">
%UCL_PROMPT_SHORT% <strong>cd  BlastSplitSearch  </strong>
%UCL_PROMPT_SHORT% <strong> ls  </strong>
generate_job_files.bash   # Helper script  to set up jobs
StartUpFiles/  # Contains input files and scripts for the job
QueryFiles/    # Contains query files
</pre>

Let us see what is inside the directory ==StartUpFiles==
<pre class="screen">
%UCL_PROMPT_SHORT% <strong>ls StartUpFiles/  </strong>
HLA.txt    # query input file
blast_exe.bash    # Job wrapper script
blast_gen.bash    #  Generates job submit file for a list of data chunks using the file "blast.submit.template" as a template
blast.submit.template    # The template file used to create job submission files
</pre>

---++ Generate job files and submit

We utilize  the helper script  ==generate_job_files.bash== to set up the job. 
<pre class="screen">
%UCL_PROMPT_SHORT% <strong>  chmod +x generate_job_files.bash  </strong>
%UCL_PROMPT_SHORT% <strong> ./generate_job_files.bash  </strong>
</pre>
would produce the following output on the screen
<pre class="screen">
..........
To submit all condor jobs 
cd JobDirectory 
./jobsubmit.bash 
..........
</pre>
and creates a directory ==JobDirectory== for job submissions.  Inside ==JobDirectory==, we see the following list of files
<pre class="file">
blast_00.submit, blast_01.submit, ...   # 18 job script files for 18 data chunks
HLA.txt    # query input file
blast_exe.bash    # Job wrapper script
jobsubmit.bash    # script to submit all jobs
Log/    # directory to store the standard output, log and error files
</pre>

To submit the jobs 
<pre class="screen">
%UCL_PROMPT_SHORT% <strong> ./jobsubmit.bash  </strong>
</pre>
OR
<pre class="screen">
%UCL_PROMPT_SHORT% <strong> condor_submit blast*.submit  </strong>
</pre>




%BR%
-- Main.BalamuruganDesinghu - 23 Jul 2015

%META:FILEATTACHMENT{name="DataChunk_1.jpg" attachment="DataChunk_1.jpg" attr="" comment="Transfer data chunks to the worker machines" date="1437758266" path="DataChunk_1.jpg" size="32138" stream="DataChunk_1.jpg" tmpFilename="/usr/tmp/CGItemp7108" user="BalamuruganDesinghu" version="1"}%
