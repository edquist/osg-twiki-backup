%META:TOPICINFO{author="CraigPrescott" date="1172195244" format="1.1" reprev="1.2" version="1.2"}%
%META:TOPICPARENT{name="Sandbox.TierThreePrerequisiteDocument"}%
-- Main.CraigPrescott - 22 Feb 2007
---++Introduction
PBS stands for "Portable  Batch System".  It is a popular networked subsystem for submitting, monitoring, and controlling a work load of batch jobs on one or more systems.  PBS has a long history, and is available nowadays in three flavors: 
   * OpenPBS - the original PBS developed for NASA in the early to mid-1990s, available as open source
   * PBS Pro - a commercial version of PBS from Altair Engineering
   * Torque - the open source successor to OpenPBS - http://clusterresources.com/downloads/torque

OpenPBS still works, and you can use it, but you should be aware that the focus of the open source development effort has moved on to Torque for some time now.  If you want to run OpenPBS and support is important to you, you may purchase it from Altair Engineering.  Personally, I am not aware of a technical argument to prefer OpenPBS to Torque.  

PBS Pro is a fine product.  It is reasonably priced compared to competing commercial batch systems and has dedicated support from Altair Engineering should you desire it.  We use it where I work, and I have no serious complaints.  The most recent releases of PBS Pro (versions 7.x and later) have features that OpenPBS and Torque do not, as well as a more flexible resource specification than its open source counterparts.  If I recall correctly, you should be able to get a trial version of PBS Pro before you buy - contact Altair for info.

As mentioned previously, Torque is the open source PBS project which is being actively developed, and the user community has followed suit.  Iin its current 2.x versions, it has also matured into a quality product and should be more than capable of scaling to typical Tier3 cluster sizes.

The above are my personal opinions.  In this document, I will specifically describe deployment and configuration of Torque as the batch system backing an an OSG computing element.  The configuration steps outlined below, however, should apply nearly equally well to OpenPBS or PBS Pro.

---+++Useful Links
It is always handy to have a few reference links at your fingertips, so I enclose a few here.  As always, Google is your friend and a wealth of information.

   * Cluster Resource's Torque page page: http://www.clusterresources.com/pages/products/torque-resource-manager.php
   * Altair's PBS Pro front page: http://www.altair.com/software/pbspro.htm
   * OpenPBS versus PBS Pro - "Which PBS is for you?": http://www.openpbs.org/which_pbs.html
   * OpenPBS Mini-HOWTO: http://dcwww.camp.dtu.dk/pbs.html

---++Downloading Torque

Point your browser to http://clusterresources.com/downloads/torque.  Select the most recent version and save it to a file (at the time of this writing, version 2.1.7 is just released).  Copy it to the node you intend to use as your OSG computing element headnode.  Unpack it:


<verbatim>
cd torque-2.1.7
Now we are ready to deploy some packages on our head node.  If you didn't create RPMs in the steps above, you need to *become root* on the head node and type <code>make install</code> from the top level of the Torque source tree.  Everything will be installed into <code>/usr/local</code> unless you specified an alternate installation path at <code>configure</code> time.
---++Installing Torque
---++ Installing Torque on the Compute Nodes
PBS_DAEMON="/usr/sbin/pbs_server -h <hostname> -S <hostname> -M <hostname>"
where <hostname> is the same hostname you used when you created the server instance.  Once this is done, you can restart the <code>pbs_server</code> from the <code>init.d</code> script:

<verbatim>
/etc/init.d/pbs_server restart
</verbatim>
d189 2
where <code>&lt;hostname&gt;</code> is the same hostname you used when you created the server instance.

We can now configure the server.  This is done with the <code>qmgr</code> command.  If <code>qmgr</code> is executed without any options, it will put you in an interactive shell from which you can just type in PBS commands.  But you can also feed commands to <code>qmgr</code> with the <code>-c</code> option.  Let's turn on scheduling, create a routing queue and an execution queue, and take care of some defaults:

<verbatim>
qmgr -c 'set server scheduling=true'
qmgr -c 'create queue defaultq'
qmgr -c 'set queue defaultq queue_type = route'
qmgr -c 'create queue batchq'
qmgr -c 'set queue batchq queue_type = execution'
qmgr -c 'set queue defaultq started = true'
qmgr -c 'set queue defaultq route_destinations = batchq'
qmgr -c 'set queue batchq queue_type = execution'
qmgr -c 'set queue defaultq enabled = true'
qmgr -c 'set server resources_default.nodes = 1
qmgr -c 'set queue batchq started = true'
qmgr -c 'set queue batchq enabled = true'
qmgr -c 'set server resources_default.nodes = 1'


where <code>&lt;hostname&gt;</code> is the same hostname you used for the <code>pbs_server</code> setup.  This is a dirty trick.  But the fact is that the built-in Torque scheduler will only listen on the interface that corresponds to the output of <code>gethostname</code>, so the gloves may have to come off.
/etc/init.d/pbs_mom start
</verbatim>
qmgr -c 'create node <fqdn> np=<ncpus>' 
set server node_check_rate = 150
The <code>qstat</code> command is used to display queue and job status.  By itself, if will print out the list of jobs that are in the queue, and their status.  <code>qstat</code> has a number of interesting options - see <code>man qstat</code> for more info.  Since we don't have any jobs running yet, <code>qstat</code> won't show us anything too interesting.
---+++ Submitting a Job

You use the <code>qsub</code> command to submit the job to the batch system; just give qsub the name of your job script, like so:

<verbatim>
---+++ Querying a Job
---++ Final Words

Hopefully this note will help you get your Torque batch system up and running, and give you a bit of familiarity with the typical procedures and tools available.  If you have further questions, I highly recommend to look at the Admin Manual and numerous man pages included with the Torque packages, and to consult the <code>torqueuser</code> mailing list (archives at http://www.supercluster.org/pipermail/torqueusers/).  Torque is highly configurable; in this short tutorial, we have only done enough to get you started.  While what we've done so far may be perfectly adequate for many environments, you should be aware that configuration options exist to add user and group ACLs, resource attributes handy for heterogenous environments, optimizations for job output relay, multiple execution queues with their own scheduling priorities, considerations for running parallel jobs, dropping in of powerful third party schedulers such as Maui, etcetera.  Good luck!

%META:TOPICMOVED{by="CraigPrescott" date="1172188993" from="Education.PBSSetup" to="Education.PbsSetup"}%
