%META:TOPICINFO{author="TanyaLevshina" date="1278984007" format="1.1" reprev="1.8" version="1.8"}%
%META:TOPICPARENT{name="MaterialsOSS2010"}%
---+!!Data Management Exercises (Part I) 
%TOC{depth="2"}%

---++ Introduction
The goals of these exercises are...
---++ Exercises 
---+++ Prerequisite 
   * Login on submission node <pre class="screen">
<verbatim>
ssh <username>@vdt-itb.cs.wisc.edu
</verbatim>
</pre>
   * Setup grid enviroment<pre class="screen">
 . /opt/osg-client/setup.sh
</pre>
   * Obtain proxy certificate<pre class="screen">
voms-proxy-init -voms osgedu:/osgedu
Enter GRID pass phrase: 
</pre>

---+++ Classic Storage
A Classic Storage is represented by a stand-alone [[http://www.globus.org/toolkit/data/gridftp][!GridFTP]] server installed  on a Compute Element. It allows access to several specific data directories available on all OSG sites.    The storage space allocated under ==OSG_DATA== directory is intended as the space for applications to write input and output relatively small data files with persistency that must exceed the lifetime of the job which created it.

In order to upload data to ==OSG_DATA== you will need to use ==globus-url-copy== command. The basic syntax for globus-url-copy is:

==globus-url-copy [optional command line switches] Source_URL Destination_URL==

You will need to use the following URL prefixes to specify local file and file on the remote node:
   * file:// (on a local machine only)
   * gsiftp://

   * What is the path to OSG_DATA?<pre class="screen">
globus-job-run osg-edu.cs.wisc.edu:/jobmanager-fork /usr/bin/env|grep OSG_DATA
OSG_DATA=/nfs/osg-data
</pre>
   * Let's create your directory there<pre class="screen">
globus-job-run osg-edu.cs.wisc.edu:/jobmanager-fork /bin/mkdir /nfs/osg-data/osgedu/${USER}
</pre>
   * We will use ==Complete-Prose-Works-by-Walt-Whitman.txt== located in ~/tanya. The file size is 1.4 MB and contain works by Walt Whitman.  The file is downloaded from [[http://fliiby.com/file/221825/jodjt2p6sb.html][this site]], see also [[http://gutenberg.net][information about Gutenberg Project ]].  Let's use ==globus-url-copy== to upload the file<pre class="screen">
globus-url-copy file:///home/tanya/Complete-Prose-Works-by-Walt-Whitman.txt gsiftp://osg-edu.cs.wisc.edu:2811/nfs/osg-data/osgedu/${USER}/testfile
 globus-job-run osg-edu.cs.wisc.edu:/jobmanager-fork /bin/ls -l /nfs/osg-data/osgedu/${USER}
total 1416
-rw-r--r--  1 osgedu users 1445762 Jul 12 13:17 Complete-Prose-Works-by-Walt-Whitman.txt
</pre>
   * Run simple condor-g jobs that handle data file differently:
    1. Transfer data with condor job. First, create a submission file ==test1==  <pre class="file">
universe=grid
grid_resource = gt2 red.unl.edu:/jobmanager-fork
Executable=word_counter
Log = /home/tanya/whitman_logs/wordcounter.$(Cluster).$(Process).log
Output = /home/tanya/whitman_logs/wordcounter.$(Cluster).$(Process).out
Error = /home/tanya/whitman_logs/wordcounter.$(Cluster).$(Process).err
WhenToTransferOutput = ON_EXIT
transfer_input_files =  Complete-Prose-Works-by-Walt-Whitman.txt
transfer_output_files = wordcounter.out.$(Cluster).$(Process)
Arguments =  Complete-Prose-Works-by-Walt-Whitman.txt grass
queue
</pre> This submission file requests to submit the python script ==word_counter== that counts the number of  encounters of the specified word in the text. The file will be  transferred with condor job. Now, we can submit job that is using file from ==$OSG_DATA/osgedu/${USER}== directory: <pre class="file">
universe=grid
grid_resource = gt2 red.unl.edu:/jobmanager-fork 
Executable=word_counter
Log = /home/tanya/whitman_logs/wordcounter.$(Cluster).$(Process).log
Output = /home/tanya/whitman_logs/wordcounter.$(Cluster).$(Process).out
Error = /home/tanya/whitman_logs/wordcounter.$(Cluster).$(Process).err
Arguments =  /nfs/osg-data/osgedu/tanya/Complete-Prose-Works-by-Walt-Whitman.txt grass
queue
</pre>

  

---++++Challenges 
   *  !GridFTP allows to do  third-party transfer. Try to initiate a data transfer from a client running on vtb-itb to transfer data from Wisconsin to Nebraska
   * You can speed !GridFTP transfers: try to use bigger tcp window, memory buffer and parallel streams
---+++ Storage Element 
An OSG site may offer a Storage Element (SE) - a physical storage system where data are stored and managed according authorization policies. A SE could be represented by a physical file system, disk caches or hierarchical mass storage system.  A Storage Resource Manager (SRM) is a component that is usually associated with a Storage Element. A SRM optimizes the use of a SE by providing file caching, staging of files from hierarchical storage, and/or allowing managing the space by using space reservation and lifetime of the file. Storage Elements manage storage and enforce authorization policies on who is allowed to create, delete and access physical files. See [[https://twiki.grid.iu.edu/bin/view/ReleaseDocumentation/Storage][this document]] for details.
All OSG Storage Elements support the gsiftp protocol and the full or limited implementation of [[https://sdm.lbl.gov/srm-wg/doc/SRM.v2.2.html][ Storage Resource Manager (SRM) specification. In some cases the Storage Element and the shared file system may use the same underlying distributed file system, providing local access from the worker nodes and external access through the gsiftp protocol, or the SRM specification. 

During this exercise we will pre-stage data on the specific SE and then run a job on worker node that access the file directly.

What you have to know before you start:
   * Storage url (surl) of Storage Elements available for OSGEDU VO members:
   1. Nebraska srm://red-srm1.unl.edu:8443/srm/v2/server?SFN=/mnt/hadoop/public/osgedu (!BeStMan-gateway/HDFS; data available from the worker node with the path /mnt/hadoop/public/osgedu)
   1. OSG_EDU  srm://osg-edu.cs.wisc.edu:10443/srm/v2/server?SFN=/srmcache/osgedu/ (!BeStMan-fullmode/disk)

There are many [][implementations] of srm client. You can choose the one you like the most. Examples that are shown here are for [][srm-lbnl-client]].

---++++ First steps
   * Verify that you can access storage<pre class="screen">
srm-ping srm://osg-edu.cs.wisc.edu:10443
%TWISTY%
srm-ping   2.2.1.3.12  Tue Apr 27 13:13:24 PDT 2010
BeStMan and SRM-Clients Copyright(c) 2007-2010,
Lawrence Berkeley National Laboratory. All rights reserved.
Support at SRM@LBL.GOV and documents at http://sdm.lbl.gov/bestman

SRM-CLIENT: SURL does not contains ?SFN 
SRM-CLIENT: serviceHandle /srm/v2/server is taken from the srmclient.conf 
SRM-CLIENT: SFN is assumed as 
SRM-CLIENT: Connecting to serviceurl httpg://osg-edu.cs.wisc.edu:10443/srm/v2/server

SRM-PING: Mon Jul 12 16:45:54 CDT 2010  Calling SrmPing Request...
versionInfo=v2.2

Extra information (Key=Value)
backend_type=BeStMan
backend_version=2.2.1.3.13
backend_build_date=2010-04-28T18:55:52.000Z 
gsiftpTxfServers[0]=gsiftp://osg-edu.cs.wisc.edu
clientDN=/DC=org/DC=doegrids/OU=People/CN=Tanya Levshina 508821
localIDMapped=osgedu
%ENDTWISTY%
</pre>

   * Verify that you can upload file. First, create a directory <pre class="screen">
srm-mkdir  srm://red-srm1.unl.edu:8443/srm/v2/server?SFN=/mnt/hadoop/public/osgedu/tanya
%TWISTY%
srm-mkdir   2.2.1.3.12  Tue Apr 27 13:13:24 PDT 2010
BeStMan and SRM-Clients Copyright(c) 2007-2010,
Lawrence Berkeley National Laboratory. All rights reserved.
Support at SRM@LBL.GOV and documents at http://sdm.lbl.gov/bestman
SRM-CLIENT: Connecting to serviceurl httpg://red-srm1.unl.edu:8443/srm/v2/server

SRM-DIR: Mon Jul 12 17:26:02 CDT 2010 Calling SrmMkdir
SRM-DIR: DirectoryPath(0)=srm://red-srm1.unl.edu:8443/srm/v2/server?SFN=/mnt/hadoop/public/osgedu/tanya
        status=SRM_SUCCESS
        explanation=null
%ENDTWISTY%
</pre> Copy file to this SE directory: <pre class="screen">
srm-copy file:///home/tanya/Complete-Prose-Works-by-Walt-Whitman.txt srm://red-srm1.unl.edu:8443/srm/v2/server?SFN=/mnt/hadoop/public/osgedu/tanya/Complete-Prose-Works-by-Walt-Whitman.txt 
%TWISTY%
srm-copy   2.2.1.3.12  Tue Apr 27 13:13:24 PDT 2010
BeStMan and SRM-Clients Copyright(c) 2007-2010,
Lawrence Berkeley National Laboratory. All rights reserved.
Support at SRM@LBL.GOV and documents at http://sdm.lbl.gov/bestman
SRM-CLIENT: Mon Jul 12 17:47:28 CDT 2010 Connecting to httpg://red-srm1.unl.edu:8443/srm/v2/server

SRM-CLIENT: Mon Jul 12 17:47:29 CDT 2010 Calling SrmPrepareToPutRequest now ...
request.token=put:754867
Request.status=SRM_SUCCESS
explanation=null

SRM-CLIENT: RequestFileStatus for SURL=file:///home/tanya/Complete-Prose-Works-by-Walt-Whitman.txt is Ready.
SRM-CLIENT: received TURL=gsiftp://red-gridftp9.unl.edu:2811//mnt/hadoop/public/osgedu/tanya/Complete-Prose-Works-by-Walt-Whitman.txt

SRM-CLIENT: Mon Jul 12 17:47:38 CDT 2010 start file transfer
SRM-CLIENT:Source=file:////home/tanya/Complete-Prose-Works-by-Walt-Whitman.txt
SRM-CLIENT:Target=gsiftp://red-gridftp9.unl.edu:2811//mnt/hadoop/public/osgedu/tanya/Complete-Prose-Works-by-Walt-Whitman.txt

SRM-CLIENT: Mon Jul 12 17:47:43 CDT 2010 end file transfer for file:///home/tanya/Complete-Prose-Works-by-Walt-Whitman.txt

SRM-CLIENT: Mon Jul 12 17:47:43 CDT 2010 Calling putDone for srm://red-srm1.unl.edu:8443/srm/v2/server?SFN=/mnt/hadoop/public/osgedu/tanya/Complete-Prose-Works-by-Walt-Whitman.txt
Result.status=SRM_SUCCESS
Result.Explanation=null

SRM-CLIENT: Request completed with success

SRM-CLIENT: Printing text report now ...

SRM-CLIENT*REQUESTTYPE=put
SRM-CLIENT*TOTALFILES=1
SRM-CLIENT*TOTAL_SUCCESS=1
SRM-CLIENT*TOTAL_FAILED=0
SRM-CLIENT*REQUEST_TOKEN=put:754867
SRM-CLIENT*REQUEST_STATUS=SRM_SUCCESS
SRM-CLIENT*SOURCEURL[0]=file:///home/tanya/Complete-Prose-Works-by-Walt-Whitman.txt
SRM-CLIENT*TARGETURL[0]=srm://red-srm1.unl.edu:8443/srm/v2/server?SFN=/mnt/hadoop/public/osgedu/tanya/Complete-Prose-Works-by-Walt-Whitman.txt
SRM-CLIENT*TRANSFERURL[0]=gsiftp://red-gridftp9.unl.edu:2811//mnt/hadoop/public/osgedu/tanya/Complete-Prose-Works-by-Walt-Whitman.txt
SRM-CLIENT*ACTUALSIZE[0]=0
SRM-CLIENT*FILE_STATUS[0]=SRM_SUCCESS
SRM-CLIENT*EXPLANATION[0]=SRM-CLIENT: PutDone is called successfully
%ENDTWISTY%
</pre>
   * Check the file is actually there: <pre class="screen">
srm-ls  srm://red-srm1.unl.edu:8443/srm/v2/server?SFN=/mnt/hadoop/public/osgedu/tanya/Complete-Prose-Works-by-Walt-Whitman.txt
%TWISTY%
srm-ls   2.2.1.3.12  Tue Apr 27 13:13:24 PDT 2010
BeStMan and SRM-Clients Copyright(c) 2007-2010,
Lawrence Berkeley National Laboratory. All rights reserved.
Support at SRM@LBL.GOV and documents at http://sdm.lbl.gov/bestman
SRM-CLIENT: Connecting to serviceurl httpg://red-srm1.unl.edu:8443/srm/v2/server

SRM-DIR: Mon Jul 12 20:18:38 CDT 2010 Calling srmLsRequest

SRM-DIR: ..........................
        Status    : SRM_SUCCESS
        Explanation : null
        Request token=null

        SURL=/mnt/hadoop/public/osgedu/tanya/Complete-Prose-Works-by-Walt-Whitman.txt
        Bytes=1445762
        FileType=FILE
        StorageType=null
        Status=SRM_SUCCESS
        Explanation=Read from disk..
        OwnerPermission=null
        LifetimeLeft=null
        LifetimeAssigned=null
        CheckSumType=null
        CheckSumValue=null
        FileLocality=null
        OwnerPermission=null
        GroupPermission=null
        OtherPermission=null
        ArrayOfSpaceTokens=null
        RetentionPolicyInfo=null
        LastModificationTime=null
        CreatedAtTime=null

SRM-DIR: Printing text report now ...
SRM-CLIENT*REQUEST_STATUS=SRM_SUCCESS
SRM-CLIENT*SURL=/mnt/hadoop/public/osgedu/tanya/Complete-Prose-Works-by-Walt-Whitman.txt
SRM-CLIENT*BYTES=1445762
SRM-CLIENT*FILETYPE=FILE
SRM-CLIENT*FILE_STATUS=SRM_SUCCESS
SRM-CLIENT*FILE_EXPLANATION=Read from disk..
%ENDTWISTY%
</pre>


---+++ Running job on the Grid with SE
 Run simple condor-g job that access this data from the worker node at Nebraska site: <pre class="file">
universe=grid
grid_resource = gt2 red.unl.edu:/jobmanager-fork 
Executable=word_counter
Log = /home/tanya/whitman_logs/wordcounter.$(Cluster).$(Process).log
Output = /home/tanya/whitman_logs/wordcounter.$(Cluster).$(Process).out
Error = /home/tanya/whitman_logs/wordcounter.$(Cluster).$(Process).err
Arguments =  /mnt/hadoop/public/osgedu/tanya/Complete-Prose-Works-by-Walt-Whitman.txt grass
queue
</pre>

---++++ Challenges:
   * Construct your DAG that first stage data from OSGEDU SE to the worker node and then run ==word_counter== script
   * What will you do in case of failures (e.g What can you do if file doesn't exist in OSGEDU SE)?
   








-- Main.TanyaLevshina - 09 Jul 2010
