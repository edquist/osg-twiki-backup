%META:TOPICINFO{author="BalamuruganDesinghu" date="1437998694" format="1.1" reprev="1.10" version="1.10"}%
%META:TOPICPARENT{name="UserSchool15Materials"}%
<style type="text/css">
pre em { font-style: normal; background-color: yellow; }
pre strong { font-style: normal; font-weight: bold; color: #008; }
</style>

---+ Using data from AWS webserver

Now, we'll look at running jobs that get their input from a remote web server, using HTCondor's HTTP plugin. Again we'll use NAMD, but this time we will download the input data from Amazon S3, which is a public cloud service. 

<center>
<img src="%ATTACHURLPATH%/data_tranfer_aws.jpg" alt="data_tranfer_aws.jpg" width='400' height='300'/>
</center>



First, =cd= to our working directory for this exercise and list the directory contents.
<pre class="screen">
%UCL_PROMPT_SHORT% <strong>cd namd/namd-ct-web </strong>
%UCL_PROMPT_SHORT% <strong>ls </strong>
namd_run.sh    # Job wrapper script to execute namd job
</pre>

As you can see, we only have the NAMD wrapper here. We'll want to create a submit file and transfer the input data from AWS. 

The input files you need for this exercise are located here:
| http://s3-us-west-2.amazonaws.com/osg-user-school/namd/par_all27_prot_lipid.inp |
| http://s3-us-west-2.amazonaws.com/osg-user-school/namd/ubq_gbis_eq.conf |
| http://s3-us-west-2.amazonaws.com/osg-user-school/namd/ubq.pdb |
| http://s3-us-west-2.amazonaws.com/osg-user-school/namd/ubq.psf |

As in the previous exercise, we need to tell HTCondor where to find the input files. Fortunately for us, we can just paste the HTTP links into =transfer_input_files=. For this exercise, fill out the template submit file:

<pre class="file">
universe = vanilla
executable = namd_run.sh

transfer_input_files = 

output =
error = 
log = 

requirements = (HAS_CVMFS_oasis_opensciencegrid_org =?= TRUE)

queue
</pre>

Then submit the job
<pre class="screen">
%UCL_PROMPT_SHORT% <strong>condor_submit namd_run.submit </strong>
</pre>

Once the job finished (may take 3-5 minutes  run time) you will see bunch of output files (trajectory, log file with energy, velocity and so on), run
<pre class="screen">
%UCL_PROMPT_SHORT% <strong> tail -n 1 ubq_gbis_eq.log   </strong>
</pre>

and if you see the following line
<pre>
Program finished.
</pre> 
your job was successful. 


This kind of data transfer may also be useful to download, say, reference data from the Protein Databank (PDB) or the National Institute for Standards and Technology (NIST)

---++ Copying data from Stash

Stash is OSG Connect's data service. Copying data from Stash (stash.osgconnect.net) is much the same as copying data from any other HTTP server. For this example, we'd like you to copy data to a worker node from your public directory on OSG Connect.

<center>
<img src="%ATTACHURLPATH%/data_tranfer_stash.jpg" alt="data_tranfer_stash.jpg" width='400' height='300'/>
</center>

The example files are located under the directory ==namd-ct-stash==.

<pre class="screen">
%UCL_PROMPT_SHORT% <strong>cd ~/namd/namd-ct-stash </strong>
%UCL_PROMPT_SHORT% <strong>ls </strong>
namd_run.sh    # Job wrapper script to execute namd job
</pre>

As before, we have our namd_run.sh and our input files. For this exercise, first copy the input data files to =~/public=. (Recall that =~= is an alias for =/home/your_username=), and create a job submit script that transfers the files from =http://stash.osgconnect.net/+your_username/path/to/files=



-- Main.BalamuruganDesinghu - 23 Jul 2015

%META:FILEATTACHMENT{name="data_tranfer_aws.jpg" attachment="data_tranfer_aws.jpg" attr="" comment="Data transfer from AWS server" date="1437761750" path="data_tranfer_aws.jpg" size="38912" stream="data_tranfer_aws.jpg" tmpFilename="/usr/tmp/CGItemp9882" user="BalamuruganDesinghu" version="1"}%
%META:FILEATTACHMENT{name="data_tranfer_stash.jpg" attachment="data_tranfer_stash.jpg" attr="" comment="" date="1437768432" path="data_tranfer_stash.jpg" size="40123" stream="data_tranfer_stash.jpg" tmpFilename="/usr/tmp/CGItemp6502" user="LincolnBryant" version="1"}%
