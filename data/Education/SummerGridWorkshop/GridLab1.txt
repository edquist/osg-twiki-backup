%META:TOPICINFO{author="MichaelWilde" date="1150411459" format="1.0" version="1.1"}%
%META:TOPICPARENT{name="SummerGridSyllabus2006"}%
Exercises for Lecture 1:

Introduction to the Grid

(revision 5)

 

This exercise explores some simple Grid operations to start developing a few very basic techniques for distributed computing.

We assume you're using the default “bash” shell set up on your logins on the laptops and lab servers. We don’t recommend this, but if you’ve changed to a csh-based shell, you'll need to slightly modify the examples. We’ll assume you know how to do this.
Table of Contents

1.	  Getting to know your Mac Laptop

2.	  Getting set up on the Lab Linux System

3.	  Submitting jobs with Globus Commands

4.	  Explore the Lab Grid

5.	  Digging Deeper
1.					Getting to know your Mac Laptop

You will be working for the week in teams of two, which have been pre-assigned and are listed on a handout titled Team List.  Please find your partner, and locate (from the handout) the laptop that you have been assigned to.

You and your partner will share the same userid on the laptop, and use the same userid to log into the Linux lab systems that we will be using.  These IDs are of the form “trainingN” – listed on the Class Team Roster. You’ll need to work on the laptop with the same number – that’s where your login has been established. These numbers are also marked on stickers on the bottom of the laptop, and on each desk in the lab.

You will be using the following tools on your laptop:

-			“Terminal” tool to connect to the Linux lab systems.

-			“FireFox” browser.  Since some things require FireFox and don’t work well with Safari or Internet Explorer, its best to stay in FireFox and keep all your bookmarks in this one browser.

-			Occasionally, a simple text editor.

Please take a moment and learn how to start these tools from the MacOS “Dock” – the tool selector at the bottom of the laptop. To create a new Terminal window from within Terminal, use File -> New Shell.

A handy tip: you can use the Apple-Key (has an “Apple” and “Propeller” symbol – just to the left of the space bar) for fast cut and paste. Apple-C = “copy the text selected by the cursor”, Apple-V = “paste text selected by the cursor”, Apple-X = “delete text selected by the cursor”.

Set a bookmark in your FireFox browser to the Workshop Syllabus page:

http://osg.ivdgl.org/twiki/bin/view/SummerGridWorkshop/SummerGridSyllabus2005

 

General Information about the workshop will be posted at:

http://osg.ivdgl.org/twiki/bin/view/SummerGridWorkshop/WebHome

 

Now, start a “Terminal” window from the desktop Dock at the bottom of your screen (it may have been moved to the sides or even the top, though…). The icon for Terminal is a black screen with the characters “>_” on it.

 

Note the conventions for command-line dialogs that will be used throughout these exercises:

What you type is in bold

The system’s responses are in regular weight text

Our comments to you (which you should NOT enter) are:  #  italics after a "#"

 

training42$ pwd			  # You type "pwd" but NOT this comment!

/home/training42			 # the system's response

training42$					# the system's command prompt

 

 

Practice cutting text from the browser to run a command or set of commands: cut the “pwd” command from the box above and paste it into your terminal window to execute it.

This is a good way to avoid making typos while entering commands from the examples (also a good way to replicate our typos precisely – please let us know when you find errors in the exercise handouts! :) 

 
2.					Getting set up on the Lab Linux System

You will be doing almost all of lab exercises this week from a Linux computer (“host”) named “gk1” (its “fully qualified host name” is “gk1.phys.utb.edu”).  From this machine, we will run Grid jobs, transfer files, and explore Grid sites.

To access this machine, from your laptop Terminal window, we will use the “secure shell” utility, ssh, to do a “remote login” from your laptop to the gk1 Linux server:

CCT-Training14s-Computer:~ training14$ ssh gk1.phys.utb.edu

The authenticity of host 'gk1.phys.utb.edu (206.76.233.104)' can't be established.

RSA key fingerprint is 36:74:78:a8:ed:6b:38:96:63:20:01:df:46:9b:59:3b.

Are you sure you want to continue connecting (yes/no)? yes

Warning: Permanently added 'gk1.phys.utb.edu,206.76.233.104' (RSA) to the list of known hosts.

training14@gk1.phys.utb.edu's password: training14 # not echoed !!!

[training14@gk1 training14]$	  # Now you’re on the gk1 server!

After the first time you do this, you won’t get the “Are you sure…” prompt. Some of you will never see this, as your computers were used for testing this material, and the “yes” reply was already supplied by a tester.  So it will look like:

CCT-Training14s-Computer:~ training14$ ssh gk1.phys.utb.edu

Password: training14 <enter trainingN here, same as your laptop name>

[training14@gk1 training14]$

For the rest of this exercise, we will use simpler prompts: $ for your laptop and gk1$ for the gk1 lab server.

Check that various important variables are set correctly in your environment:

 

gk1$ echo $GLOBUS_LOCATION

/opt/vdt/globus

gk1$ echo $VDT_LOCATION

/opt/vdt

gk1$ echo $CONDOR_LOCATION

/opt/vdt/condor

gk1$

 

Next, create a Grid security proxy for this tutorial.	(A proxy is like a temporary ticket to use the Grid – in this case, for the next 12 hours.  This will be explained in Lecture 2.)

You will need to obtain your passphrase from the Team List handout. Use the passphrase from the Team List for the team member listed in the “Your Identity” prompt, as illustrated below.

 

$ grid-proxy-init

Your identity: /C=US/O=Globus/O=University of Wisconsin/OU=Computer Sciences Department/CN=Alan De Smet

Enter GRID pass phrase for this identity: YourPassPhrase

Creating proxy ........................................... Done

Your proxy is valid until Thu Jul 10 16:06:13 2003

$ 

 
3.					Submitting jobs with Globus Commands

Now, if everything is set correctly, you should be able to run “Grid jobs” (here, mostly “commands”) on the lab Grid. First, check that the gatekeeper “knows” you – has your Grid identity authorized to run jobs:

gk1$ globusrun –a –r gk2/jobmanager-fork

 

GRAM Authentication test successful

gk1$

Look for the “test successful” message. This means you are “authorized” to use the gk2 “resource”. If this still fails, there is a problem with your Grid certificate, so contact an instructor.

Now, run your first very simple Grid job with the command “globus-job-run”:

 

gk1$ globus-job-run gk2 /bin/hostname

gk2

gk1$

You’ve just submitted a “job” (the command “hostname”) to the GRAM gatekeeper on gk2, from the “submit host” gk1! Trivial, perhaps, but a building block to more powerful capabilities.

What else can you learn with this? E.g, how can you find what user ID your job ran under?	Also try /usr/bin/env (real important!), uptime, pwd, ls? (Note: you must use full paths!)

Try running a shell command:

/bin/sh –c 'cmd here'				 (use this, e.g. to find your $PATH with echo!)

try this on gk2 as well

 
4.					Explore the Lab Grid

Now lets see how many “sites” are in the “lab” Grid that we set up for this workshop:

gk1$ gsites

dartmouth-physics	

dartmouth-pbs		 

uchicago-compsci	 

utb-summergrid		

dartmouth-math		

uchicago-chemistry  

uchicago-sociology  

uchicago-education  

uchicago-astronomy  

uchicago-business	

gk1$

The “gsites” command is part of the “gstar” package – a small set of prototype tools to make Grid usage easier. These are already proving useful, so we’ll apply them in our exercises.  These tools are briefly described at: http://osg.ivdgl.org/twiki/bin/view/GriphynMainTWiki/GstarToolkit

Here we will use the two commands gsites and grun. You can get info on their arguments and usage by using the --help option for each.

The gsites command serves as a simple interface to the GridCat Grid Information System – one of the GIS systems used in Grid3 and the OpenScienceGrid. We have set up a GridCat system for our lab, so we can get a list of all the GRAM “gatekeeper” hosts in the lab Grid with gsites:

[training14@gk1 training14]$ gsites -g

Site					 Gatekeeper						  Job-Managers		  

---------------------------------------------------------------------

dartmouth-physics	phys-01.grid.dartmouth.edu	 fork,condor			

dartmouth-pbs		 pbs-01.grid.dartmouth.edu	  fork,sge				

uchicago-compsci	 evitable.uchicago.edu			fork,condor			

utb-summergrid		gk2.phys.utb.edu				  fork,condor			

dartmouth-math		math-01.grid.dartmouth.edu	 fork,condor			

uchicago-chemistry  terminable.uchicago.edu		 fork,condor			

uchicago-sociology  ept.uchicago.edu				  fork,condor			

uchicago-education  chalant.uchicago.edu			 fork,condor			

uchicago-astronomy  gainly.uchicago.edu			  fork,condor			

uchicago-business	sheveled.uchicago.edu			fork,condor			

[training14@gk1 training14]$

To dig deeper, try the various other gsites options to learn more about these sites.

Now, try running some simple jobs on a remote machine:

gk1$ grun –s uchicago-compsci –c /bin/hostname

See what happens if the command name to run (-c option) is not fully qualified.  (i.e., just “-c hostname”)

To make things easier, set up aliases. You’ll need to make a “.gstar” directory in your home directory. You can paste the commands from “cat” through the line containing just “END”:

gk1$ cd

gk1$ mkdir .gstar # Note the "."!

gk1$ cat > $HOME/.gstar/aliases <<END

dmphys dartmouth-physics

dmpbs dartmouth-pbs	

uccs uchicago-compsci

lab utb-summergrid

dmmath dartmouth-math

ucchem uchicago-chemistry

ucsoc uchicago-sociology

ucedu uchicago-education

ucastro uchicago-astronomy

ucbus uchicago-business

END

gk1$

Now try using the aliases:

 [training14@gk1 training14]$ grun -s lab -c /bin/hostname

 

# processing utb-summergrid, 101 CPUs

utb-summergrid: globus-job-run gk2.phys.utb.edu/jobmanager-fork /bin/hostname

gk2

[training14@gk1 training14]$

(Note that if you give grun a bad alias, it fails silently, since no hosts matched. It’s a prototype…)

Here’s the same command run under a shell:

[training14@gk1 training14]$ grun -s lab -c '/bin/sh -c hostname'		  

 

# processing utb-summergrid, 101 CPUs

utb-summergrid: globus-job-run gk2.phys.utb.edu/jobmanager-fork /bin/sh -c hostname

gk2

[training14@gk1 training14]$

Note that here we did not need to specify a full path for hostname – so running /bin/sh on the remote site gives you a PATH.  Can you find out what it is? (Hint: run echo $PATH…)

If you’re careful with single and double quotes, you can also pass a list of commands:

gk1$ grun -s lab -c '/bin/sh -c "ls /etc | grep cron"'

 

# processing utb-summergrid, 101 CPUs

utb-summergrid: globus-job-run gk2.phys.utb.edu/jobmanager-fork /bin/sh -c "ls /etc | grep cron"

anacrontab

cron.d

cron.daily

cron.hourly

cron.monthly

cron.weekly

crontab

gk1$

Try using the grun –f option to put your scripts in a file.

Now, you can explore the remote execution environment.  Learn what you can about remote environment  variable settings (env command), local directory (pwd), and what files are out there (ls).  Can you create and remove a file in the remote directory?  Can you cd to /tmp and do the same?

To run a command on all Grid sites, try grun with no “-s” option.  The sites in a Grid are seldom all “up” at any given time, and out lab Grid is no exception!	Try to find out which sites are responding correctly.  What different GRAM errors do you get?

Then, make an include (or an exclude) list to run a command only on the “good” sites. An include-list is a simple file of site names, placed in a file ending in “.i”.  An exclude list is similar but ends in “.x”. (NOTE: you need to use full site names in these lists – not aliases).  For example:

gk1$ cat >sites.i <<END

sitename1 # Put the real, *full* site names here (not aliases)

sitename2

END

 

Try running the simple “numerical application” bc to see how fast the different processors are out in the Grid:

 

echo 1234^50000 | time bc >/dev/null

 

Try this on several of the “working” sites.

Gg1$ grun -S sites.i -c '/bin/sh -c "echo 1234^50000 | time bc >/dev/null"'

 

# processing uchicago-compsci, 50 CPUs

uchicago-compsci: globus-job-run evitable.uchicago.edu/jobmanager-fork /bin/sh -c "echo 1234^50000 | time bc >/dev/null"

4.00user 0.00system 0:04.15elapsed 96%CPU (0avgtext+0avgdata 0maxresident)k

0inputs+0outputs (152major+306minor)pagefaults 0swaps

 

# processing utb-summergrid, 101 CPUs

utb-summergrid: globus-job-run gk2.phys.utb.edu/jobmanager-fork /bin/sh -c "echo 1234^50000 | time bc >/dev/null"

4.15user 0.02system 0:04.58elapsed 90%CPU (0avgtext+0avgdata 0maxresident)k

0inputs+0outputs (160major+307minor)pagefaults 0swaps

gk1$

5.					Digging Deeper

 

Look into “RSL” –  the Globus GT2 GRAM “Resource Specification Language” – Google for more info. Try a simple globus-job-run with the option “–dumprsl”, then try globusrun with your own RSL. 

o		  globusrun – r gk1 –o '&(executable=/bin/pwd)'

o		  Write a small shell script to dump more about your environment in one command. Try it locally.

§			#!/bin/bash

§			date

§			hostname -f

§			uptime

§			env

§			cat /etc/issue

Then: globus-job-run gk1 –s my-scriptname

Extra extra credit: Try “staging” a binary – copying it from your job submission host to the execution host (such as the local /bin/date)

·			What RSL does globus-job-run create?

·			Submit a simple job such as /bin/hostname to the Condor jobmanager using globus-job-run and globusrun.	The “contact string” is gk2/jobmanager-condor rather than just “gk1” (which is a default name for gk2/jobmanager-fork)

Create a new program in your favorite language. C, Bourne shell, Perl, and Python are reasonable choices. This program should take one argument, and integer, and return the square of that argument. Run this program on our local grid for value. You'll need to stage the executable--see the -s command for globus-job-run. (What RSL do you get now?) Run this program for n in [10, 30], and collect the results in distinct files. Better yet, make a script to do all of this for you.

