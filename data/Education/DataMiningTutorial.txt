%META:TOPICINFO{author="ForrestChristian" date="1174603657" format="1.1" reprev="1.2" version="1.2"}%
%META:TOPICPARENT{name="MidwestSyllabus"}%
%LINKCSS%

---+!! Tutorial: Data Mining
%TOC%


---++ Getting set up

Check that you have a valid proxy.

<pre class="screen">
gridlab$ <userinput>grid-proxy-init</userinput>
Your identity: /O=GridNCDM/OU=GlobusNCDM.simpleCA/OU=lac.uic.edu/CN=GlobusGrossman
Enter GRID pass phrase for this identity:
Creating proxy ...................................... Done
Your proxy is valid until: Fri Mar 23 00:20:40 2007
</pre>

Now, make a working directory for this exercise. For the rest of this exercise, all your work should be done in there.

<pre class="screen">
gridlab$ <userinput>mkdir dmex</userinput>
gridlab$ <userinput>cd dmex</userinput>
</pre>

Now, make the required directories on the target machine.  You will need the following directories on each machine: data, analysis, and models.

<pre class="screen">
gridlab$ <userinput>globusrun-ws -F node-4.globusncdm -submit -c "/bin/mkdir" "/home/globusgrossman/data" </userinput>
Submitting job...Done.
Job ID: uuid:63bf25c6-d895-11db-a43b-00e081749872
Termination time: 03/23/2007 16:50 GMT
Current job state: Active
Current job state: CleanUp
Current job state: Done
Destroying job...Done.
</pre>

The other directories are created in a similar fashion.



<a name="Computing Clusters on a Local Machine"></a>
---++ Computing Clusters on a Local Machine

It is always a good idea to make sure you can do the computation first on a local machine that you can log on to. 
d76 3
<pre class="screen">
gridlab$ <userinput>> library(pmml)</userinput>
Loading required package: XML
> <userinput> data(iris)</userinput>
> <userinput> a.data &lt;- iris </userinput>
> <userinput> summary(a.data)</userinput>
<userinput>> data(iris)</userinput>
<userinput>> a.data <- iris </userinput>
<userinput>> summary(a.data)</userinput>
 Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   
 Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  
 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  
 Median :5.800   Median :3.000   Median :4.350   Median :1.300  
 Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  
 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  
 Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  
       Species  
 setosa    :50  
 versicolor:50  
 virginica :50  
<userinput>> a.data.1 <- a.data[, c("Sepal.Length", "Sepal.Width", "Petal.Length", "Petal.Width")]</userinput>
<userinput>> m1 <- kmeans(a.data.1, centers=3) </userinput>
<userinput>>  m1$centers </userinput>
  Sepal.Length Sepal.Width Petal.Length Petal.Width
1     5.901613    2.748387     4.393548    1.433871
2     5.006000    3.428000     1.462000    0.246000
3     6.850000    3.073684     5.742105    2.071053
<userinput>>  p1 <- pmml(m1) </userinput>
<userinput>> saveXML(p1, file="iris-clusters.pmml") </userinput>
<userinput>>> quit() </userinput>

</pre>

In this example, we use the Iris data that is part of the R distribution and available through the data() function.  We compute three k-means clusters for the four features: 
   * Sepal.Length
   * Sepal.Width
   * Petal.Length
   * Petal.Width 
and save the resulting model as a PMML file. To make sure that this works, you should examine the PMML file and it should look like the following:

<pre class="programlisting">
&lt;?xml version="1.0"?&gt;
&lt;PMML version="3.1" xmlns="http://www.dmg.org/PMML-3_1" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"&gt;
 &lt;DataDictionary numderOfFields="4"&gt;
  &lt;DataField name="Sepal.Length" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="Sepal.Width" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="Petal.Length" optype="continuous" dataType="double"/&gt;
  &lt;DataField name="Petal.Width" optype="continuous" dataType="double"/&gt;
 &lt;/DataDictionary&gt;
 &lt;ClusteringModel modelName="KMeans_Model" functionName="clustering" algorithmName="KMeans" mo
delClass="centerBased" numberOfClusters="3"&gt;
  &lt;MiningSchema&gt;
   &lt;MiningField name="Sepal.Length" usageType="active"/&gt;
   &lt;MiningField name="Sepal.Width" usageType="active"/&gt;
   &lt;MiningField name="Petal.Length" usageType="active"/&gt;
   &lt;MiningField name="Petal.Width" usageType="active"/&gt;
  &lt;/MiningSchema&gt;
  &lt;ComparisonMeasure kind="distance"/&gt;
  &lt;Cluster name="1" size="62"&gt;
   &lt;Array n="4"&gt;5.90161290322581 2.74838709677419 4.39354838709678 1.43387096774194&lt;/Array&gt;
  &lt;/Cluster&gt;
  &lt;Cluster name="2" size="50"&gt;
   &lt;Array n="4"&gt;5.006 3.428 1.462 0.246&lt;/Array&gt;
  &lt;/Cluster&gt;
  &lt;Cluster name="3" size="38"&gt;
   &lt;Array n="4"&gt;6.85 3.07368421052632 5.74210526315789 2.07105263157895&lt;/Array&gt;
  &lt;/Cluster&gt;
 &lt;/ClusteringModel&gt;
&lt;/PMML&gt;
</pre>


<a name="Computing Clusters Using R and Globus"></a>
---++ Computing Clusters Using R and Globus 

Once you can use R to compute clusters locally on a node that you can login to and invoke R directly, it is relatively easy to invoke the script on a remote node.  Here is an example.  First, we invoke the script directly on a local machine:
d148 1
<pre class="screen">
$ <userinput>R &lt; angle-analysis.r --no-save </userinput>
<userinput>R &lt; r-analysis-4.r --no-save </userinput>

R version 2.4.0 Patched (2006-11-25 r39997)
Copyright (C) 2006 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> a.data.file &lt;- "data/angle-4.csv"

...etc...
d171 1
</pre>

Next, we perform the following steps. We assume that we have a coordinating node and one or more compute nodes.
Next, we perform the following steps:

<ol>
<li> Copy a segment of the data to a compute.
<li> Copy the corresponding analysis script.
<li> Invoke R, with the input coming from the analysis script.
<li> Copy the resulting PMML model back to the coordinating node.
</ol>

Here is a Python script which will do this:

<pre class="programlisting">
cmds = "globus-url-copy file:///home/globusgrossman/data/angle-data-4.csv " 
cmds = cmds + "gsiftp://node-4.globusncdm/home/globusgrossman/data/angle-data.csv" 
from os import system                             
 
# copy local data file to remote machine 
cmds = "globus-url-copy file:///home/globusgrossman/angle-analysis.r " 
cmds = cmds + "gsiftp://node-4.globusncdm/home/globusgrossman/angle-analysis.r" 
system(cmds) 
 
# copy r script to compute clusters to remote machine 
cmds = "globus-url-copy file:///home/%LOGINNAME%/angle-analysis.r " 
cmds = cmds + " /bin/sh -c '/usr/bin/R < /home/globusgrossman/angle-analysis.r --no-save' " 
system(cmds) 
 
# invoke R script on remote machine 
cmds = "globus-url-copy gsiftp://node-4.globusncdm/home/globusgrossman/models/angle-model.pmml " 
cmds = cmds + "file:///home/globusgrossman/collect/angle-model-4.pmml" 
system(cmds) 
 
# collect PMML file 
cmds = "globus-url-copy gsiftp://node-4.globusncdm/home/%LOGINNAME%/models/angle-model.pmml " 
cmds = cmds + "file:///home/%LOGINNAME%/collect/angle-model-4.pmml" 
system(cmds) 
</pre>

Here is the R script that is being run on the node:
a.data.file <- "data/angle-data.csv" 
<pre class="programlisting">
library(pmml) 
a.model.file <- "models/angle-model.pmml" 
# data file 
a.col <- list(ts=0,  
 
# output file 
a.model.file &lt;- "models/angle-model.pmml" 
 
a.col &lt;- list(ts=0,  
  src="",  
  sprt=0,  
  sCOUNTRY="",  
  dst="",  
  dprt=0,  
  dCOUNTRY="",  
  ip.4min=0,  
  ip.2min=0,  
  ip.1min=0,  
  ipprt.4min=0,  
a.raw <- scan(file=a.data.file, what=a.col, skip=1, sep=',') 
a.data <- as.data.frame(a.raw) 
  clusters="" 
a.data.1 <- a.data[,c('ip.4min', 'ip.2min', 'ip.1min',  
 
a.raw &lt;- scan(file=a.data.file, what=a.col, skip=1, sep=',') 
a.data &lt;- as.data.frame(a.raw) 
m1 <- kmeans(a.data.1, centers=10) 
a.data.1 &lt;- a.data[,c('ip.4min', 'ip.2min', 'ip.1min',  
p1 <- pmml(m1) 
 
 
m1 &lt;- kmeans(a.data.1, centers=10) 
 
p1 &lt;- pmml(m1) 
saveXML(p1, file=a.model.file) 
</pre>


<a name="Hints"></a>
---++ Hints

Here are some hints to keep in mind.
<ul>
<li>Make sure that your analysis program (for example, your R script) works on your login machine first. </li>
<li>Make sure Globus script works on your login machine first, before trying it on another machine. </li>
--
      * Set GRIDHOST = tg-login.sdsc.teragrid.org
-- Main.MichaelWilde - 22 Mar 2007

Main.MichaelWilde - 22 Mar 2007
Main.ForrestChristian - 24 Mar 2007 - Added VARIABLES

-->
