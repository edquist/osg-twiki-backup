%META:TOPICINFO{author="ChristinaKoch" date="1469582303" format="1.1" reprev="1.2" version="1.2"}%
%META:TOPICPARENT{name="UserSchool16Materials"}%
<style type="text/css">
pre em { font-style: normal; background-color: yellow; }
pre strong { font-style: normal; font-weight: bold; color: #008; }
</style>

---+ Friday Exercise 1.1: Learn about Joe's Desired Computing Work

Joe Biologist studies the influence of genetic differences (genotypes) on the growth traits (phenotypes) of a common crop. Joe has come to you with some computing work he’d like to automate as a workflow, so that he can scale out his research and run it on a much larger HTC compute system. He has used HTCondor to manually submit individual jobs (never used a DAG), but has only run jobs on a smaller, dedicated HTCondor cluster where he doesn’t have to request CPU, disk, or RAM, and he’s not familiar with DAGman. He's getting annoyed by how many manual job submissions and summary scripts he has to run, especially as he's thinking of scaling out his work in a way that would be much more cumbersome - so he's asking you to help him organize all the steps into an optimized DAG workflow. 

(As you learn more details below, it might be helpful to draw a diagram that describes the steps of his workflow.)

---++ After asking Joe many questions, you realize the following things:

*A) Joe starts with a file called =input.csv= that was made on his desktop.* When you open this file in excel, Joe shows you that each row corresponds to an individual plant. For each individual, the first three columns are phenotype measurements for each of three different growth _traits_ (T240, T300, T360), and the remaining columns contain the genotype (A or B) of that individual across multiple genes (columns).

*B) At present, Joe does the following manual steps (for each of the three traits!)* to achieve a meaningful result from the data in =input.csv=:
   * 1. Joe first submits a job that calculates a large number of hypothetical permutations of phenotype-genotype combinations for the trait.
   * 2. Joe then runs a script for each trait, to create a gzipped tar file of the results of the _permutation_ job to be used in the next "QTL mapping" job.
   * 3. Joe submits a second job for each trait, which performs a _QTL mapping_ calculation to determine which genes were most important for the phenotype, relative to other possible genes exemplified in the random permutations.
   * 4. As a final step for each trait, Joe runs a script that creates a gzipped tar file of all of the _permutation_ and _QTL mapping_ data, so that he can take it back to his desktop computer for final processing.

*C) Joe uses a special _wrapper_ to run the _permutation_ and _QTL mapping_ calculations, which are otherwise written as R scripts.* For each step this perl script, =runR.pl=, first installs R using files from Joe's proxy server and then sets up the R environment before running whatever R script has been indicated as an argument to =runR.pl=. Therefore, the =runR.pl= wrapper script is run as the HTCondor executable with the name of either R program indicated as an argument to the wrapper (along with arguments to the R program, itself).

*D) The two tar steps are shell scripts simply containing a relevant =tar= command,* and can be run on the submit server because they create little CPU load and finish very quickly.

*E) When Joe has previously run all 10,000 permutations as one condor job, the job runs for hours on his own small cluster.* He has cut the permutations of a single condor job up into multiple, shorter HTCondor processes of fewer permutations before, but he doesn’t remember the details how many jobs of how many total permutations worked well. Furthermore, Joe would like to scale up to *100,000* permutations per trait this time. Even with 10,000 permutations completed for each trait, the _QTL_ step completes within several minutes.

---+++ View Joe's files
*(but don't do anything with them until the next Exercise, where you'll plan necessary developments of a workflow for Joe.)*

Log in to osg-ss-submit.chtc.wisc.edu and move to a desired location in your home directory. Enter the following commands to copy and decompress/untar Joe’s job ingredients, which Lauren has stored in her home directory.

<pre class="screen">
%UCL_PROMPT_SHORT% <strong>wget http://proxy.chtc.wisc.edu/SQUID/osgschool16/WorkflowExercise.tar.gz</strong>
%UCL_PROMPT_SHORT% <strong>tar xvzf WorkflowExercise.tar.gz</strong>
</pre>

You can now navigate into the =WorkflowExercise= directory to view the full ingredients for Joe’s Computing work. Review all of these files based upon the information below and refer back to it as you proceed through the remaining exercises (1.2-1.4).


---+++ Joe’s Job Summaries

Based upon Joe’s description and submit files you determine the following details for each step:

---++++ *Permutation Step* (explanation for =permutation1.submit=)

Execution: 	
   * =./runR.pl 1_$(Process) run_perm.R 1 $(Process) 10000=

Argument descriptions:	
   * =1_$(Process)=, used by =runR.pl= to name its log file
   * =1=, trait column in =input.csv= (i.e. this is 3 for permutation3.submit)
   * =$(Process)=,	used by =run_perm.R= for naming the permutation output
   * =10000=,	indicates that 10,000 permutations should be done for this single job process

input: 		
   * =run_perm.R=, =input.csv=, =RLIBS.tar.gz=

 output: 	
   * =runR.1_0.out=, log file for =runR.pl=, where "1_0" is from arg
   * =perm_part.1_0.Rdat=, output from =run_perm.R=, "1" and "0" are from args

*Note:* =tarit.sh= is run after each trait's Permutation step (with the column number as an argument) to compress =perm_part.1_0.Rdat= (or potentially multiple such files named according to "perm_part.1_*.Rdat") for the QTL step. Execution: =tarit.sh 1=, where "1" is the trait column number.
		
---++++ *QTL Mapping Step* (explanation for =qtl1.submit=)

execution:	
   * =./runR.pl qtl_1 qtl.R 1=

arg descriptions:	
   * =qtl_1=, used by =runR.pl= to name its log file
   * =1=, trait column in =input.csv=

input: 
   * =qtl.R=, =input.csv=, =RLIBS.tar.gz=, =perm_combined.tar.gz= (created by =tarit.sh=)

output:	
   * =runR.qtl_1.out=, log file for =runR.pl=, where "qtl_1" is from arg
   * =perm_combined_1.Rdat=, =perm_summary_1.txt=, =sim_geno_results_1.Rdat=, =qtl_1.Rdat=,	=refined_qtl_summary_1.txt=, =refined qtl_1.Rdat=, and =fit_qtl_results_1.Rdat=,  where "1" is from =qtl.R= arg

*Note:* =results_1.tar.gz= is made by running =taritall.sh= (with the column number as an argument) after the QTL step for each trait finishes, where "1" reflects the trait column number in the output above. Execution: =taritall.sh 1=, where "1" is the trait column number.
