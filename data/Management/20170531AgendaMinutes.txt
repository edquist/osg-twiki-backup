%META:TOPICINFO{author="TimCartwright" date="1496420927" format="1.1" reprev="1.3" version="1.3"}%
%META:TOPICPARENT{name="AreaCoordinator"}%
---+ OSG Area Coordinators Meeting &mdash; 31 May 2017


---++ Meeting Coordinates

%TABLE{}%
| When: | Wednesday, 2:00 p.m. Central Time |
| Online: | https://IU.zoom.us/j/320940886 |
| Phone (toll): | +1 (408) 638-0968 &nbsp;<em>or</em>&nbsp; +1 (646) 558-8656 &nbsp; &rarr; &nbsp; PIN 320-940-886 |


---++ Top of Meeting Business
   1. Review the [[https://indico.fnal.gov/categoryDisplay.py?categId=86][OSG calendar]]
   1. Talk about [[NewsletterList][upcoming newsletter articles]]

*Note for presenters:* Please report on updates to the area goals we had established at the staff retreat; these goals are available at https://osg-docdb.opensciencegrid.org:440/cgi-bin/ShowDocument?docid=1232. Remember that the next OSG annual report for each area will explicitly state the goals and the results.


---++ Production Support, by Ken Herner
[[%ATTACHURL%/053117-osg-ac.pdf][053117-osg-ac.pdf]]: Production Support Update


---++ Minutes

*Attendees:* Brian Bockelman, Brian Lin, Emelie Harstad, Ken Herner, Rob Quick, Scott Teige, Shawn !McKee, Tim Cartwright, Tim Theisen, Zalak Shah

---+++ Research Highlights
Just a reminder from Rob&nbsp;Q. that Kyle is always looking for new Research Highlight ideas.

---+++ Production Support

   * Pilot hours are steady and the distribution among experiments is similar to the past.

   * For opportunistic sites, the 3-month rankings were a little different: #1 was FNAL USCMS Tier 1, Syracuse was a bit lower than recent past, and UCSD did pretty well. !Mu2E had some problems but seems OK now.

   * For opportunistic usage, things were fairly good, including a strong peak (over 35K flock jobs) through the long Memorial Day weekend.

   * Project usage was a little different, too, with !IceCube taking the top spot at almost 10M hours; SPLINTER was #2 at about 6M hours. There were some strong bursts (!) of LIGO activity, which is retroactively understandable in light of their announcement on Thursday.

   * Overall, the recent trends are good. There was the downturn in the October through December (2016) period, but things have rebounded nicely. But, there is a lot of stuff coming within about a year, so there is still good reason to continue pushing to add more sites.

   * Some sites are moving to Enterprise Linux 7 (EL7). Containers are hiding a lot of this from users, but the time will come when EL6 is no longer supported. What is being done to address this (far off) situation? Tim&nbsp;C. offered to connect Ken with the folks at UW&ndash;Madison who are working to actively migrate users to EL7.

   * For new site activity, DUNE is now running at Sheffield, Imperial (UK), and FZU (Czech Republic); it took only 2 hours to get them running at FZU (due to a pre-existing configuration). They are working on getting access at the CERN Tier 0&nbsp;&mdash; the use of CILogon Basic certificates is still an issue, but at least production work should be OK. Still pushing on getting other VOs to run at Utah, Puerto Rico, and Ole Miss, and getting DUNE to those places may help with demand.

   * There is continued progress in using the Hosted CE at JLab/UConnecticut.

   * The GPU situation is a little less rosy than last time. Tusker at HCC has been working well, but now BNL is not looking good&nbsp;&mdash; local use is heavy and there are questions about opportunistic use and funding. Nonetheless, there is strong interest within FIFE (at least) for GPUs, based on a survey that was recently conducted. On the positive side, Syracuse is still promising, and Ken will follow up with them soon to see if they are close to opening up their GPUs to opportunistic use.

   * Overall, the last couple of months have been going pretty well, and there are new pushes from non-LHC VOs.

   * Ken suggested that a year from now there will be a big strain on the existing infrastructure. He clarified that this means on computing resources plus data&nbsp;&mdash; lots of experiments will be pushing lots of data around. Brian&nbsp;B. said that GPUs are an order-of-magnitude concern and that even HEPCloud probably cannot provide enough.

   * There was a question about the Globus Toolkit transition to closed source. Brian&nbsp;B. said that OSG will continue to carry the open-source code as long as needed.

---+++ Concerns
   * Always concerned about getting enough opportunistic resources; right now we are OK, but the future will be challenging (and see above).
   * Trying to maintain pressure on HPC and GPU access without getting annoying&nbsp;&mdash; are there other resources to look into?
   * The change to EL7 (see above).

---+++ Action items
None.

%META:FILEATTACHMENT{name="053117-osg-ac.pdf" attachment="053117-osg-ac.pdf" attr="" comment="Production Support Update" date="1496256817" path="053117-osg-ac.pdf" size="604167" stream="053117-osg-ac.pdf" tmpFilename="/usr/tmp/CGItemp56339" user="KennethHerner" version="1"}%
