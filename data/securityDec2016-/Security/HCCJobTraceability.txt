%META:TOPICINFO{author="AnandPadmanabhan" date="1409629677" format="1.1" reprev="1.1" version="1.1"}%
%META:TOPICPARENT{name="SecurityTeamWorkingArea"}%
---+ Submitting jobs from HCC VO without having end user credentials 

   * What is the architecture of the glidein setup at your VO. A simple architecture diagram would be useful? 
      * The architecture of the glidein setup is very simple.  Just 1 host, glidein.unl.edu.  Additionally, only 1 host ‘flocks’ into glidein, cpass.unl.edu.

   * If you have more submit nodes (for e.g. portal submit nodes, PI owned submit nodes) from which the jobs get flocked to frontend, provide information on how do you trace jobs from these submit nodes to frontend?
      * Cpass submitted jobs are logged into our accounting system.  From the accounting system, it is clear that the jobs originated from Cpass.

   * How long are the logs associated with frontend stored (condor logs, system logs (specifically authentication logs), glidein logs)? Are condor audit logs on submit nodes and frontends stored at least for 3 months?
      * Condor logs: They are rotated frequently due to size, probably hourly when a user is running.
      * System logs: logrotate is set to 12 weeks retention.  This includes /var/log/secure…

   * Do you have a centralized system for collecting logs?
      * No

   * Are jobs information being forwarded to a central Gratia collector. How can you use this for tracing jobs back to user?
      * Yes.  Records are sent to the global collector at Fermilab.  These records include ‘LocalUserId’ which is the local user name on our glidein machine.

   * Are there submit nodes that do not meet the traceability requirements (and hence should not be submitted to Fermilab) from where the jobs are being flocked to the front end? If so, what controls (e.g. separate queues in glidein frontend) are in place to ensure that these jobs are handled appropriately, please provide technical details?
      * No, just the 1 frontend I described above, glidein.unl.edu.

   * Please provide a policy/procedure page (could be an existing URL) outlining: (a) registration procedure in place for how a user can get access to submit nodes/portal account and/or ssh access to the glidein frontend (if provided); (b) process of vetting user identity, and (c) procedures in place a new submit nodes/portal may gain access to submit to a glidein frontend (please note that when a new submit node is added it will need to be carefully evaluated for meeting traceability needs). Are login account authentication on submit nodes and/or portals local or do they inherit from a University wide services. (e.g. LDAP, Kerberos)?
      * URL: https://hcc.unl.edu/grid-nebraska 
      The UNL Research Computing (HCC) hosts their own user database in LDAP.  The glidein allowed users is a subset of the users in LDAP.  The users must contact us, and sit down in person with us, in order to gain access to the glidein node.

   * Would it be feasible for your VO to provide the traceability information (tracing a specific job to a VO member) within 24 hours during security incidents?
      * Yes.

   * Would it be possible for your VO easily generate the list of users who belong to the VO and who have access to FNAL and other OSG resources. Please provide technical details.
      * Yes.  We have the list of users in the HCC VO from VOMS.  Additionally, the glidein node is white listed, therefore we can provide a specific list of users that have access to the glidein submit host.

   * Do you have a list of staff members who have privileged access to the job submission and frontend services. If there is any granularity in the privileges granted, please outline them or provide links to VO policy documentation.
      * Staff members are also white listed along with users.  A select group of staff is granted root permissions.  

   * What is the policy of revoking user access to job submission services? Specifically does your VO policy and procedure to determine a) when a user should be banned or suspended from the VO due to security concerns; b) the length of time for the VO to perform the removal process from the time it receives a request for banning; c) how to re-instantiate a previously banned user; and d) the process to announce such actions (banning, unbanning) to the grid resource owners. Any VO policy on user removal a link to that would be useful.
      * There is no formal policy.  
      * The user is banned immediately if we notice any suspicious behavior, or if suspicious behavior is reported by resource owners.  We ban and ask questions later.
      * Since submissions are centrally managed on a single node, banning a user is immediate (un-whitelist), and their jobs are removed immediately.  
      * Reinstating a user is as simple as adding them back onto the whitelist.
      * To date, as a resource owner, I have never seen a user ban announcement.  I presume it would go out to the OSG_SITES mailing list, but again, I’ve never seen one.  Certainly, an osg security ticket at the GOC would be appropriate, and they would assist on the announcement.

   * Please provide any pertinent details on how the glidein infrastructure (includes all architecture pieces, e.g. frontend, submit nodes, portal nodes) is secured (e.g. firewalls, logging, monitoring,
patching).
      * The glidein host has a very open firewall, necessitated by the architecture of GlideinWMS.  
      * Logging is described above in #3.  
      * Monitoring is done by ganglia.
      * Regular updates to the glidein node are applied along with our other infrastructure. 

---++ Followup Questions 1

   * 1-2: Please elaborate how you will trace a job back to an individual user for jobs that were flocked from cpass using information condor/Gratia logs available on your side.
      * Cpass jobs are marked as from CPASS in the accounting database.  The originator of the job will be in the ProbeName column, which in the case of Cpass will be condor:cpass.unl.edu.  In addition to the ProbeName column, each record has the original job id from from the submitter.  The Job Id can be correlated with the cpass submission host to determine the original owner of the job, which is kept in the condor history.  The Condor history has no limit on size.
   * 3. Would it be possible to make configuration changes to ensure condor logs are kept for a longer period. Specifically would it be possible to ensure that atleast ensure some critical logs like condor audit logs and Gratia logs are maintained for 3 months.
      * Yes, we could configure condor audit logs to be maintained for 3 months.  Gratia raw job records (records with LocalJobId, LocalUsername... attributes) are kept for 3 months by default.
   * 7. Do these requirements also apply to getting access to the cpass submit node?
      * Cpass has a much more loose requirements for access.  You must have a academic email address, and the lead UNL researcher must approve access.  But, it's a science gateway, and can only run 1 application, cpass.  Users provide limited input parameters to the application, and it is run. 

---++ Followup Questions 2

   * What controls are there in place to make sure they can only run that application with limited input parameters.
   * Do these users have ssh access to cpass machine or is the access restricted to a portal
   * If a portal is in place, for jobs submitted on behalf of a portal user, can you confirm a trace is kept (e.g. in accounting database) as to which Cpass gateway user originated a particular job.

-- Main.AnandPadmanabhan - 02 Sep 2014
