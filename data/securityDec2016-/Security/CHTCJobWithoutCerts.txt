%META:TOPICINFO{author="AnandPadmanabhan" date="1393540680" format="1.1" reprev="1.4" version="1.4"}%
---++ Submitting jobs from CHTC/Glow VO without having end user credentials

This effort aims to understand the setup of glidein framework at Condor High Throughput Computing (CHTC) group and Glow VO with on goal of considering if jobs may be submitted from CHTC to OSG sites (including FNAL) without X.509 credentials. Specifically we hope to learn the architecture of the CHTC and what kind of security controls/policies/logging are in place before a user a granted access or have access revoked following an incident.

---+++ CHTC Architecture

CHTC submits jobs to the glidein pool on glidein.chtc.wisc.edu.   CHTC directly manage 2 submit nodes who use the glidein. There are however numerous departmental submit nodes which also submit directly to glidein.  All nodes are running htcondor, that is the job framework.  CHTC do not use pilots like ATLAS and CMS, the users manage their own job submission systems via dagman or local scripts.

In order for a user to get access to a CHTC machine they have to go through a formal registration process with the CHTC where they take down their information, department and PI.  Then CHTC makes an account for the user on their submit nodes.  For non chtc controled submit nodes access is granted by the owner of the node, typically a department head/PI or an admin appointed by one to control access.

There is no policy on long term maintaining logs, condor logs are kept until they fill up then they roll over, so typically only a few days/hours of logs are stored for who ran what jobs when, depending on the usage volume.  CHTC do track usage for pools, tracking daily, weekly, monthly and yearly usage for all users submitting to the pools here: [[http://monitor.chtc.wisc.edu/uw_condor_usage/usage1.shtml ]]

Overall, the architecture at CHTC has a frontend (FE) node that accepts flocked jobs from submit nodes. The FE then submits jobs to OSG factory at both GOC and SDSC. Few of the submit nodes are managed by CHTC team while others are managed by individual PIs/admins. For nodes managed by CHTC there is a formal registration process for the users but for nodes maintained by individual PIs there is no such guarantees. 

Based on this it was decided that only jobs submitted to node that have formal user registration requirement (e.g. CHTC managed nodes) might submit to FNAL or other OSG sites that wish be able to track individuals.


---++++ Status Update
---+++++ 1/20/14
   1. CHTC have been working on a new glidein server to replace their old aging one and run with fermi. They don't currently have a way to lock jobs based on submit nodes where they originated. 
   1. The new plan hence is to migrate users to the new glidein who met the tracability requirement requirements. This means that new frontend will only accept jobs from "trusted" servers 
   1. For tracing user jobs, CHTC proposed using condor audit logs for traceability between frontend and submit node. The log shows the ip and user name of commands made to edit the queue on the submit node (anonymized example below).
<verbatim>
Example entry:
01/19/14 18:00:08 (pid:yyy) (cid:xxx) Command=QMGMT_WRITE_CMD, peer=<a.b.c.d:p>
01/19/14 18:00:08 (pid:yyy) (cid:xxx) AuthMethod=FS, AuthId=username, CondorId=username@hostname
01/19/14 18:00:08 (pid:yyy) (cid:xxx) Set Attribute for job nnn.0, DAG_NodesTotal = 8000
01/19/14 18:00:08 (pid:yyy) (cid:xxx) Set Attribute for job nnn.0, DAG_NodesDone = 2255
01/19/14 18:00:08 (pid:yyy) (cid:xxx) Set Attribute for job nnn.0, DAG_NodesPrerun = 0
01/19/14 18:00:08 (pid:yyy) (cid:xxx) Set Attribute for job nnn.0, DAG_NodesQueued = 2058
01/19/14 18:00:08 (pid:yyy) (cid:xxx) Set Attribute for job nnn.0, DAG_NodesPostrun = 5
01/19/14 18:00:08 (pid:yyy) (cid:xxx) Set Attribute for job nnn.0, DAG_NodesReady = 3
01/19/14 18:00:08 (pid:yyy) (cid:xxx) Set Attribute for job nnn.0, DAG_NodesFailed = 3679
01/19/14 18:00:08 (pid:yyy) (cid:xxx) Set Attribute for job nnn.0, DAG_NodesUnready = 0
01/19/14 18:00:08 (pid:yyy) (cid:xxx) Set Attribute for job nnn.0, DAG_Status = 2
01/19/14 18:00:08 (pid:yyy) (cid:xxx) Set Attribute for job nnn.0, DAG_InRecovery = 0
</verbatim>
      * Follow up question on audit logs:  From the log snippet it is unclear how one would associate a jobid across frontend and submit nodes using one of these entries. For example if factory gives you a time range and a glidein ID would it be possible to associate a job on remote site with an entry in this log. 
         * This has been addressed later to show how Factory and audit logs can be used to trace individuals. 
      * How reliable is the information in this log. In other words how easy or difficult would it be for the attacker to fake this information in 2 cases (1) submit node has been compromised  but the front end is not; (2) neither node is compromised but attacker tries a man-in-middle kind of attack, is this possible. Condors security mechanism likely addresses (2), but we need to understand for sire. It is a;so likely that if there is a root compromise on either the submit or the frontend nodes we will be unable to use the information reliably. If so we need to clearly understand what is the level of traceability that might be possible case of such compromises. 
         * In the glidein environment, the communication is between the condor sub systems. So logs coming form any nodes where root (or condor user account) has been compromised cannot be trusted.

---++++++ Concerns Raised and Potential Solutions

   * HTCondor logs on the Frontend get deleted too quickly after being rotate. This is esspecially true if the front end is fairly busy as well as they are independently managed. Addressing this issue, is fairly easy to resolve since newer versions of htcondor will allow admins to specify number of days to keep the logs (See Challenge 3 in [[https://osg-docdb.opensciencegrid.org:440/cgi-bin/RetrieveFile?docid=1149;filename=JobTraceability_Glidein_v7-2.pdf;version=2][tractability document]]). We want to ensure on every submit  host logs are atleast maintained for one week. CHTC has agreed to get a weeks audit config added to the external nodes, using the following config:

<verbatim>
       user@host ~ $ cat /etc/condor/config.d/99-chtc-log.conf
       SCHEDD_AUDIT_LOG = $(LOG)/AuditLog
       MAX_SCHEDD_AUDIT_LOG = 1d
       MAX_NUM_SCHEDD_AUDIT_LOG = 7 
</verbatim>

   * The use of flocking to submit jobs that might have originated on non CHTC machines. This is a bit more challenging, specifically the traceability study we conducted specifically did not address flocking. We need to understand how an individual user who submitted the jobs can be traced using htcondor logs when jobs are flocked to the submit site. A main concern is the possibility that jobs get flocked to the frondend from non CHTC submit nodes (that might not have formal registration process) and get submitted to OSG sites that require high degree of traceability (e.g. FNAL). We discussed 3 ways
      * Require a more formal registration process from non CHTC nodes that are flocking into frontend, this was however deemed infeasible since CHTC does not control the individual PI submit node and did not want to raise the bar of joining their collaboration.
      * Set up an new FE that accepts jobs only from CHTC or approved submit nodes. This approach is more expensive in terms of administration and we decided against pursuing it at this stage.
      * Set up a technical control on the frontend where by only jobs submitted on CHTC managed submitted nodes (or other specifically approved nodes) get matched to glidein running at FNAL or other sites which need traceability to individual level. This is the option we have chosen to pursue and we will be investigating how such a configuration may be implemented on the frontend.
 
---+++++ 1/28/14
   * Completed very basic setup and testing of the new glidein2 frontend today.   The new frontend only accepts jobs from submit nodes that are controlled by CHTC and/or meet the security requirements.  
---+++++ 2/6/14
   *  Had meeting with Nate and team at CHTC, CHTC has set up a new glidein frontend that is accepting jobs only from trusted submit nodes.
   * Received log files (glidein job's stdout and stderr) from factory of jobs that originated from the new frontend. The .err logs has the startd and started logs encoded which can be decoded using glideinwms/factory/tools/cat_StartdLog.py and glideinwms/factory/tools/cat_StarterLog.py respectively/ CHTC team will look into these logs to see if they can trace it back to a particular user on a submit node
   * Below is the email (from Becky) that outlines the process of tracing the job
<verbatim> 
I have successfully completed a job trace using information in the logs you provided.


This snippet from job.1573306.out is what I used:

=== Stats of main ===
01/29/14 12:49:13 Starting job 192648.0 from 128.104.55.9:9618?sock=12207_af89_116174
01/29/14 12:59:13 Terminated job 192648.0 from 128.104.55.9:9618?sock=12207_af89_116174 status 0 duration 600

Using the IP (128.104.55.9), I determined this job was submitted from submit-2.chtc.wisc.edu

on submit-2.chtc.wisc.edu I looked through the AuditLogs to find the job:

$> grep 192648 AuditLog.*
AuditLog.20140128T180000:01/29/14 14:47:50 (pid:12207) (cid:12971393) Submitting new job 192648.0


There is additional information in the AuditLog.20140128T180000 that correlates the job id with a pid, then the pid maps to the AuthId and CondorId.  I found my username bgietzel as the submitter.

01/29/14 14:47:50 (pid:12207) (cid:12971393) Submitting new job 192648.0
01/29/14 15:00:38 (pid:12207) (cid:12973682) Command=QMGMT_WRITE_CMD, peer=<128.104.55.9:42762>
01/29/14 15:00:38 (pid:12207) (cid:12973682) AuthMethod=FS, AuthId=bgietzel, CondorId=bgietzel@submit.chtc.wisc.edu

</verbatim> 

---+++++ 2/11/14
Following is a list of questions from Anand and response from Becky regarding the setup at CHTC

   * Were the AuditLogs on the frontend or the submit nodes?
      * Auditlogs are on the submit nodes.
   * Are these audit logs maintained atleast for a week?
      * Yes, they are kept for a week.
   * Is there any setup in place (e.g. syslog-ng) to store the logs at a central place?
      * We are working on setup of a syslog-ng server.
   * Have you started using the new frontend in production for OSG sites other than FNAL? 
      * The new frontend is still in the testing phase.   We have run test jobs on some OSG sites using the new frontend as part of this process.  Once we get this audit resolved and perform further validation we'll move it into production.
   * Currently, which submit nodes are allowed to access this frontend?
      * The nodes I have enabled for glidein2 are submit-2 and another test submit node under CHTC control. (Nate: chtc submit nodes submit-1 2 and and 3. )
   * I understand only CHTC controlled submit nodes are allowed to submit jobs to the new frontend. Is this correct? 
      * No, the submit nodes will be a mix of those under CHTC management and other research groups.
   * If other submit nodes are allowed on the frontend what are the controls in place that will ensure that only trusted nodes submit jobs to FNAL.
      * I am setting up a separate frontend queue for schedds that are managed by CHTC, so only jobs from these schedds will use FNAL resources. 
   * A simple policy/procedure page (could be an existing URL) outlining 
      * Registration procedure in place for how a user can get access to submit nodes that are enabled on the frontend
         * http://chtc.cs.wisc.edu/get-started.shtml
         * http://aci.wisc.edu/large-scale-request/
      * how a submit node may gain access to submit to this new frontend.
         * Any submit nodes added to the frontend are added by CHTC staff.  If the submit node is not managed by CHTC, we will add it to the queue that does not have access to FNAL resources.  If the submit node is set up and managed by CHTC, we will add it to the queue that  has access to FNAL resources.

---+++ 2/21/2014
Following is a list of questions from Anand and response from Becky regarding the CHTC environment.

   * When do you estimate the syslog-ng server will be operational and used by submit nodes.
      * We're working out some rate-limiting problems with our syslog-ng server.
   * You said you are submitting queues for schedds so only CHTC managed resource will go to fermilab. Could you provide me little bit more technical detail of how this is done in condor and may be provide pointers to relevant condor documentation.
      * I'm using the frontend.xml to set up queues, using a regexp to match the submit node name and filter out machines that are maintained by CHTC.  The CHTC submitters are named as submit-{1,2,3,x}.chtc.wisc.edu. 
   * Would it be feasible for GLOW to provide the traceability information (tracing a specific job to a VO member) within 24 hours during security incidents?
      * We can provide a response within 1 business day.
   * Can you easily generate the list of users who below to the VO and who have access to FNAL and other OSG resources.
      * Yes, we can easily generate this list of users.
   * Do you have a list of CHTC staff members who have privileged access to the job submission and frontend services. If there is any granularity in the privileges granted, please outline them or provide links to VO policy documentation.
      * Yes, we also have a list of CHTC staff with access.  Privilege includes sudo for each staff member.
   * What is the policy of revoking user access to job submission services? Specifically does GLOW VO policy and procedure to determine a) when a user should be banned or suspended from the VO due to security concerns; b) the length of time for the VO to perform the removal process from the time it receives a request for banning; c) how to re-instantiate a previously banned user; and d) the process to announce such actions (banning, unbanning) to the grid resource owners. If there is any VO policy on user removal a link to that would be useful.
      * Fortunately we have not had the need to ban any users from our systems due to security concerns. We could remove a user within one business day.
   * Are login account authentication on submit nodes local or so they inherit from University wide services. (e.g. LDAP, Kerberos)?
      * Traditionally this was not the case.  We are migrating towards using UW-Madison-issued netids for access to CHTC, and auditing existing users who are not using UW-Madison netids yet.
   * Would it  at all be feasible to additionally keep the audit logs on CHTC managed submit nodes for 3 months?
      * We can look into storage of audit logs for 3 months.  

-- Main.AnandPadmanabhan - 13 Jan 2014
