%META:TOPICINFO{author="BrianBockelman" date="1238551257" format="1.1" version="1.1"}%
%META:TOPICPARENT{name="Hadoop"}%
---+!! *<noop>%SPACEOUT{ "%TOPIC%" }%*
%TOC%

---+ Understanding and Planning Your Hadoop Install

---++ Hadoop Introduction

Hadoop is a data processing framework.  It is an open-source Apache Foundation project, and the main contributor is Yahoo!  The framework has two main parts - job scheduling and a distributed file system, the Hadoop Distributed File System (HDFS).  We currently utilize HDFS as a general-purpose file system.  For this document, we'll use the words "Hadoop" and "HDFS" interchangeably, but it's nice to know the distinction.

[[http://hadoop.apache.org/core/docs/r0.19.1/hdfs_design.html][HDFS has a wonderful architecture document; we recommend starting there.]]

Please do read through this.  We will assume you have read this, or at least the important architectural portions.  The file system is block-oriented; each file is broken up into 64 MB or 128 MB chunks (user configurable).  These chunks are stored on data nodes and served up from there; the central namenode keeps track of the block locations, the namespace information, and block placement policies.  HDFS provides POSIX-like semantics; it provides fully random-access reads and non-random-access writes.  Currently, fsync and appends (after the file has been initially closed) are experimental.

---++ Hadoop SE Components

We broadly break down the server components of the Hadoop SE into three categories: HDFS core, Grid extensions, and HDFS auxiliary.  The components in each of these categories are outlined below:

   * HDFS Core:
      * Namenode: The core metadata server of Hadoop.  This is the most critical piece of the system, and there can only be one of these.  This stores both the file system image and the file system journal.  The namenode keeps all of the filesystem layout information (files, blocks, directories, permissions, etc) and the block locations.  The filesystem layout is persisted on disk and the block locations are kept solely in memory.  When a client opens a file, the namenode tells the client the locations of all the blocks in the file; the client then no longer needs to communicate with the namenode for data transfer.
      * Datanode: This node stores copies of the blocks in HDFS.  They communicate with the namenode to perform "housekeeping" such as creating new replicas, transferring blocks between datanodes, and deleting excess blocks.  They also communicate with the clients to transfer data.  To reach the best scalability, there should be as many datanodes as possible.
   * Grid extensions
      * BeStMan SRM: A generic SRM server that can be run on top of any POSIX-like filesystem.  This is run in "gateway" mode, which limits the amount of the SRM protocol implemented.  To date, this has been sufficient to LHC VOs.
      * Globus GridFTP: The standard GridFTP from Globus.  We use a plug-in module (using the Globus Direct Storage Interface) that allows the GridFTP process to use the HDFS C-bindings directly.
   * HDFS auxiliary:
      * "Secondary Namenode": Perhaps more aptly called a "checkpoint server".  This server downloads the file system image and journal from the namenode, merges the two together, and uploads the new file system image up to the namenode.  This is done on a different server in order to reduce the memory footprint of the namenode.
      * Hadoop Balancer: This is a script (unlike the others, which are daemons) that runs on the namenode.  It requests transfers of random blocks between the datanodes.  This works until all datanodes have approximately the same percentage of free space.  Well-balanced datanodes are necessary for having a healthy cluster.

In addition to the server components, there are two client components:

   * FUSE: This allows HDFS to be mounted as a filesystem on the worker nodes.  FUSE is a Linux kernel module that allows kernel I/O calls to be translated into a call to a userspace program.  In this case, a program called fuse_dfs translates the POSIX calls into HDFS C-binding calls.
   * Hadoop Command Line Client: This command line client exposes a lot of the Unix-like calls without mounting FUSE, plus access to the non-POSIX calls (such as setting quotas and file replication levels).  For example, "hadoop fs -ls /" is equivalent to "ls /mnt/hadoop" if /mnt/hadoop is the mount point of HDFS.

---++ Recommended Hardware

-- Main.BrianBockelman - 01 Apr 2009