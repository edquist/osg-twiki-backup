%META:TOPICINFO{author="BrianBockelman" date="1250275419" format="1.1" reprev="1.8" version="1.8"}%
%META:TOPICPARENT{name="StorageForum"}%
---+ Hadoop Distributed File System

The Hadoop Distributed File System (!HDFS) is a highly scalable, very reliable distributed file system developed by the Apache project as a part of the Hadoop data processing system.  The primary contributor (and largest user) is Yahoo.  !HDFS is based on the design of the Google File System.  !HDFS's strengths is in its ability to use commodity hard drives in worker nodes; it can turn a large amount of semi-reliable hardware into a system which is very reliable.

To find out more information about HDFS, [[http://hadoop.apache.org/hdfs/][visit its home page]].  If you are thinking about installing Hadoop, we also recommend reading the [[http://hadoop.apache.org/common/docs/current/hdfs_design.html][HDFS architecture page]].

This page covers the OSG's usage of Hadoop, and includes instructions for installing a grid-enabled HDFS system.

---++ Information for Site Admins

---+++ Preparation
This is the best area for site admins to start.  If you plan on installing a Hadoop SE on the OSG, we recommend [[HadoopUnderstanding][starting off with the planning document]].

---+++ Installation
Once you have read the planning document and feel you understand the general architecture, follow these guides (in order).
   * [[HadoopInstallation][Hadoop and FUSE]].  This guide covers installation of the core HDFS components, including the FUSE-based mounts.  Once completed, you will be able to store files and interact with the file system locally.
   * [[HadoopGridFTP][GridFTP]].  This guide covers installation of the HDFS-aware !GridFTP server.  Once completed, you should be able to copy files in and out of HDFS through the grid-standard WAN protocol, !GridFTP.
   * [[HadoopSRM][SRM]].  This covers the installation of a BeStMan SRM server on top of HDFS.  Once completed, you should be able to interact with HDFS via SRM, a grid-standard webservices protocol for doing metadata operations remotely.
   * [[HadoopGratia][Gratia Probe]].  The Gratia probe instruments the !GridFTP servers running on HDFS; it uses their log files to send records of all completed transfers to a central server.  Once completed, you should see transfers at your site show up in the central OSG accounting.

---+++ Validation

Oh no!  No one has written validation guides yet.

---+++ Operations and Troubleshooting
HDFS, while relatively easy to administrate, is not completely headache free!  The pages below offer tips and tricks for operating and maintaining HDFS.
   * [[HadoopOperations][Operations]].  How to operate a stable HDFS instance.  Keep this page handy.
   * [[HadoopDebug][Troubleshooting]].
   * [[HadoopUpgrade][Upgrades]].  This page has not yet been written.
   * [[HadoopRecovery][Recovery]].  This page has not yet been written.
   * [[HadoopMonitoring][Monitoring]].
   * [[HadoopPhedex][Phedex Agent Tips]].  CMS-specific tips to getting their transfer application working optimally with HDFS.

---++ Information for developers 

   * Development
      * [[HadoopTodo][TODO]]
      * [[HadoopRelease][Building a release]]
      * [[HadoopRSV][RSV]].  Made obsolete with the release of RSV v3 (!OSG 1.2)
   * Talks and workshops
      * [[HdfsWorkshop][HDFS Workshop]] (UCSD, 2009.03.11)
      * [[CmsSeRequirements][CMS-specific requirements tracking]]

---++ Get Involved!  Contact Us!

   $ Mailing list: [[mailto:osg-hadoop@fnal.gov][osg-hadoop@fnal.gov]]
   $ Chat: =uscms-t2@conference.fnal.gov= (Jabber Multi-User Chat)
