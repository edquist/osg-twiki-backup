%META:TOPICINFO{author="MichaelThomas" date="1255735926" format="1.1" reprev="1.8" version="1.8"}%
%META:TOPICPARENT{name="Hadoop"}%
---+!! *<noop>%SPACEOUT{ "%TOPIC%" }%*
%TOC%

---+ Installation

---++ Quick Start

Quickstart for the impatient.  This assumes you already have [[HadoopInstallation][Hadoop and FUSE]] installed on the Xrootd server.

 <verbatim>
rpm -ivh http://newman.ultralight.org/repos/hadoop/4/x86_64/caltech-hadoop-4-1.noarch.rpm
yum install xrootd
cp /etc/xrootd/xrootd_sample.cfg /etc/xrootd/xrootd.cfg # ...and edit appropriately (see below)
vi /etc/xrootd/Authfile # Edit appropriately (see below)
service xrootd start
</verbatim>

---++ Prerequisites

The Xrootd server has the following prerequisites:

   1 You must also have already [[HadoopInstallation][installed and mounted]] Hadoop using FUSE.

Xrootd is preconfigured to look for the host certificate and key in =/etc/grid-security/xrd/xrd*.pem=.
These files must exist and be readable by the xrootd user.  Using certificates in a different directory or with different names will require modifying =/etc/xrootd/xrootd.cfg=.  Make sure =/etc/grid-security/xrd/xrdcert.pem= exists with mode 644, and =/etc/grid-security/xrd/xrdkey.pem= exists with mode 400 (not 600!)

The installation includes the latest CA Certificates package from the OSG as well as the fetch-crl CRL updater.

It is highly recommended that you make sure your CRLs in =/etc/grid-security/certificates= exist and are up to date by running fetch-crl manually before starting xrootd the first time.  Otherwise xrootd will attempt to download CRLs itself when it starts up.

The rpm/yum installation will create a 'xrootd' system account and group (uid,gid < 500) on the host system for running the xrootd process. If you would like to control the uid/gid that is used, then you should create the 'xrootd'' user and group manually before installing the rpms.

---++ YUM Installation

Remember, in order to use xrootd, you must have the [[HadoopInstallation][Hadoop and the FUSE kernel module]] already installed on your system in order to use the yum installer.

To configure your local installation for the yum repository, [[HadoopInstallation#Yum_install][follow the advice here]] to install the correct =caltech-hadoop= package for your site.

After installing the caltech-hadoop yum configuration package, you can install the xrootd server with:

<verbatim>
yum install xrootd
</verbatim>

Updates can be installed with:

<verbatim>
yum upgrade xrootd
</verbatim>

---+ Configuration (NEEDSWORK)

Write the following into xrootd.cfg:

<verbatim>
xrd.port any
xrd.port 1094 if xrootd.unl.edu

xrootd.fslib /usr/lib/libXrdOfs.so
ofs.osslib /usr/lib/libXrdHdfs.so
ofs.authorize 1

oss.localroot /mnt/hadoop
all.export /hello_world forcero
all.export /user
ofs.trace all
xrd.trace all

all.role server
all.role manager if xrootd.unl.edu

all.manager xrootd.unl.edu:1213

cms.allow host *

xrootd.seclib /usr/lib/libXrdSec.so

sec.protocol /usr/lib gsi -certdir:/etc/grid-security/certificates -cert:/etc/grid-security/xrd/xrdcert.pem -key:/etc/grid-security/xrd/xrdkey.pem -crl:3

acc.authdb Authfile
acc.audit deny grant

all.adminpath /var/run/xrootd
</verbatim>


For now, write the following into Authfile:
<verbatim>
u * /store lr
</verbatim>
This allows anyone to read from /store.


---++ Running Xrootd

Start the xrootd and cmsd servers with one command

<verbatim>
service xrootd start
</verbatim>

To start xrootd automatically at boot time:

<verbatim>
chkconfig xrootd on
</verbatim>

---++ Validation and debugging (NEEDSWORK)


Now, test the clients:

<verbatim>
xrdcp root://xrootd.unl.edu//some/path/in/your/HDFS
</verbatim>

Note that you give a path in your HDFS, but you use xrootd.unl.edu as the server.  This is because xrootd will form a global network of servers.

If xrootd won't start, try invoking xrootd manually with the '-d' flag at the end of the command:

<verbatim>
runuser -s /bin/bash - xrootd -c "/usr/bin/xrootd.sh -d"
runuser -s /bin/bash - xrootd -c "cmsd -c /etc/xrootd/xrootd.cfg -d"
</verbatim>

---+ TODO:

   * LFN-to-PFN translation for each site based on the CMS TFC
   * Better authorization.  Currently, your username in the Authfile is HASH.0 where HASH is the output of <verbatim>openssl x509 -noout -hash -in ~/.globus/usercert.pem</verbatim>.  This is really weird - it should integrate with PRIMA.
      * Have the authfile method complemented by native HDFS permissions.

-- Main.BrianBockelman - 14 Oct 2009

%META:FILEATTACHMENT{name="xrootd_make.diff" attachment="xrootd_make.diff" attr="" comment="" date="1255538500" path="xrootd_make.diff" size="801" stream="xrootd_make.diff" tmpFilename="/usr/tmp/CGItemp10439" user="BrianBockelman" version="2"}%
