%META:TOPICINFO{author="WillMaier" date="1237562474" format="1.1" reprev="1.2" version="1.2"}%
%META:TOPICPARENT{name="Hadoop"}%
---+!! *<noop>%SPACEOUT{ "%TOPIC%" }%*
%TOC%

---++ Building Hadoop

Note: You DO NOT need to use this page if you are only deploying Hadoop.

We currently use the NMI build and test system to trigger builds for a variety of platforms.

   1. Prereqs: Java 1.6, ant, svn client on the build system
   1. Download and unpack the Hadoop source code.
      * We currently use the 0.19.1 tag:
      <verbatim> svn co http://svn.apache.org/repos/asf/hadoop/core/tags/release-0.19.1/ hadoop </verbatim>
   1. Source an existing VDT install which includes Ant and JDK (do a "ls" on the $VDT_LOCATION and make sure there are "ant" and "jdk1.5" directories).
   1. Set the following variables:
         1. HADOOP_HOME=freshly unpacked source
         1. CLASSPATH variables:

            <verbatim>export CLASSPATH=$HADOOP_HOME/hadoop-0.19.0-core.jar:$HADOOP_HOME/lib/commons-logging-1.0.4.jar:$HADOOP_HOME/lib/commons-logging-api-1.0.4.jar:$HADOOP_HOME/lib/log4j-1.2.15.jar:$CLASSPATH</verbatim>

         1. Library variables:

            <verbatim>export LD_LIBRARY_PATH=$HADOOP_HOME/build/libhdfs:$VDT_LOCATION/jdk1.5/jre/lib/amd64/server:$LD_LIBRARY_PATH</verbatim>

         1. Path variables:

            <verbatim>export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/src/contrib/fuse-dfs/src:$PATH</verbatim>

   1. Patch Hadoop as necessary.  The patches we use are listed below.
   1. (Only on 64-bit nodes).  Edit $HADOOP_HOME/src/c++/libhdfs/Makefile; replace all occurrences of -m32 with -m64.
   1. Export misc. build variables:

      <verbatim>
      export PERMS=1
      export FUSE_HOME=$VDT_LOCATION/fuse
      </verbatim>
 
      Otherwise, fuse-dfs will not build.
   1. Build Hadoop:

      <verbatim>ant compile-contrib -Dlibhdfs=1 -Dfusedfs=1 jar</verbatim>

      This requires automake >= 1.9.5, which IS NOT AVAILABLE on RHEL4 (for Nebraska builders: this is located in /usr on node001.  Build there.).  I had to download and install it from source, then add /usr/local/bin to the PATH and /usr/local/lib to the LD_LIBRARY_PATH.  You can test your automake version with "automake --version".
   1. Fix link, build/libhdfs/libhdfs.so, to not be absolute.  I 'cd' to the directory $HADOOP_HOME/build/libhdfs, rm the existing libhdfs.so, then perform 'ln -s libhdfs.so.1 libhdfs.so'
   1. cd $HADOOP_HOME/..   Then, make a copy of the entire directory, hadoop-0.x.x/, to hadoop/.  Finally, issue the tar command:

      <verbatim>tar zcf hadoop-0.x.x-RHELy-zzz.tar.gz hadoop/</verbatim>

      Replace x.x with the Hadoop version number; replace y with the RHEL release (4 or 5), and zzz with the platform (i686 or x86_64).
   1. Copy the resulting tarball into t2.unl.edu:/var/www/html/cache.


---+++ Patches we apply to Hadoop

   * HADOOP-4368: http://osg-test4.unl.edu/store/patches/HADOOP-4368.patch
   * HADOOP-4675: http://osg-test4.unl.edu/store/patches/HADOOP-4675.patch
   * HADOOP-5222: http://osg-test4.unl.edu/store/patches/HADOOP-5222.patch

---++ Building GridFTP-HDFS
Again, we build GridFTP-HDFS using the NMI build and test system to build for all the supported variants.

   1. Pre-requisites:
         1. Valid Hadoop, preferably installed via the UNL pacman cache.
         1. subversion RPM package providing the standard svn client.
   1. Use pacman to pull in the Globus GridFTP SDK:

      <verbatim>
      pacman -get http://vdt.cs.wisc.edu/vdt_1101_cache:Globus-Base-Data-Server
      pacman -get http://vdt.cs.wisc.edu/vdt_1101_cache:Globus-Base-SDK
      </verbatim>

   1. Source the VDT's setup.sh.
          * Make sure $VDT_LOCATION exists in the following steps!
   1. Check out the GridFTP-HDFS sources:
      <verbatim>svn co svn://t2.unl.edu/brian/gridftp_hdfs</verbatim>
   1. Make a backup copy of the makefiles:

      <verbatim>
      cp makefile_header makefile_header.bkp
      cp Makefile Makefile.bkp
      </verbatim>

      This is so the original makefiles can be preserved during the next step.
   1. Replace MAGIC_VDT_LOCATION with the actual contents of $VDT_LOCATION.

      <verbatim>
      sed -i s:MAGIC_VDT_LOCATION:$VDT_LOCATION:g Makefile
      sed -i s:MAGIC_VDT_LOCATION:$VDT_LOCATION:g makefile_header
      </verbatim>

   1. Run make to build the GridFTP module.

      <verbatim>make</verbatim>

   1. Copy the original makefiles back:

      <verbatim>
      cp Makefile.bkp Makefile
      cp makefile_header.bkp makefile_header
      </verbatim>

   1. Create a tarball, and place it in the pacman cache.


-- Main.BrianBockelman - 20 Mar 2009
