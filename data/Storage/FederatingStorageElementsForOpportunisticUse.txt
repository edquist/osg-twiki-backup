%META:TOPICINFO{author="TedHesselroth" date="1274807156" format="1.1" reprev="1.8" version="1.8"}%
%META:TOPICPARENT{name="OpportunisticStorage"}%
---+*%SPACEOUT{ "%TOPIC%" }%*
%TOC%

The proposal is to allow users to access all opportunistic storage on OSG via a grid centralized storage element. The motivation is to hide from the user the current necessity of making the storage available and to provide the mechanisms of discovery, etc, as a backend service. Technical feasibility of a few software implementations are discussed.

---++IRODS

One of the main drivers of IRODS is the federation of heterogeneous data management technologies. 

It should be noted that federation in IRODS terminology is across Multiple IRODS instances, or zones. Federation allows access to other IRODS instances from an IRODS instance. The IRODS zone hosting the file is the root of the logical path of the file. Therefore federation as defined in IRODS does not in itself make the instances transparent. That may be acceptable, but it seems to defeat the purpose of having logical vs physical names. Furthermore, it would nominally require an IRODS instance at each site, though it is conceivable that a central host could run an IRODS instance for each site.

The logical name does hide the specific storage resource that the file is on. Logical names are mapped to physical names in the iCAT database. An ftp server can be a storage resource, and with SRM support it should be possible to put distributed SRM resources into one zone. So federation of OSG resources would be the creation of an IRODS zone with distributed storage resources. File transfers would be done through the one IRODS server, acting as a cache for files moved to or from the storage resources. It would take several iclient commands to move a file. Alternatively, these might be written in the form of a rule which could be invoked by one client command.  It may be possible to overload some of the existing iclient commands to invoke direct transfer between user and storage resource rather than using the IRODS server as a proxy. At a lower level, the native IRODS transfer mechanism does use direct data channels, but only to and from IRODS servers.
 
That allows flexible file location, though further catalog operations will be necessary to, for example, make sure collections of files are co-located. Support exists in IRODS for the use of custom scripts to execute various file operations, through the Universal Mass Storage System driver. Into these scripts might be placed to perform additional operations as needed.

Another option is to use only the iCAT portion of IRODS, to form a logical namespace and to define collections. Data could then be moved using using the presently-used clients such as globus-url-copy. File transfers would involve additional steps of catalog reading and file registration. Such a use could potentially pose difficulties, since it is not the canonical way of using IRODS. FTS (see below) may be a better fit for this model. 

---+++Directing a collection to a resource

One can use iclient commands to specify the resource to which a file should go. According to the default iCAT schema, a resource may be associated with a file, but not for a collection. This allows a collection to be spread over several resources. One can use rules, such as these from ARGO, to guide an iput to a resource according to the destination collection.

<pre>
1	#ARGO rules
2	acSetRescSchemeForCreate|"$objPath" like "/ARCS/projects/IMOS/*/ARGO/*"|msiSetDefaultResc(emii.resource.tpac.org.au,preferred)|nop
3	
4	acSetRescSchemeForCreate|"$objPath" like "/ARCS/projects/IMOS/staging/SOOP/*"|msiSetDefaultResc(emii.resource.tpac.org.au,preferred)|nop
5	acSetRescSchemeForCreate|"$objPath" like "/ARCS/projects/IMOS/staging/SOTS/*"|msiSetDefaultResc(emii.resource.tpac.org.au,preferred)|nop
6	acSetRescSchemeForCreate|"$objPath" like "/ARCS/projects/IMOS/staging/ANFOG/*"|msiSetDefaultResc(arcs-df.ivec.org,preferred)|nop
7	acSetRescSchemeForCreate|"$objPath" like "/ARCS/projects/IMOS/staging/AUV/*"|msiSetDefaultResc(arcs-df.vpac.org,preferred)|nop
8	acSetRescSchemeForCreate|"$objPath" like "/ARCS/projects/IMOS/staging/ANMN/*"|msiSetDefaultResc(emii.resource.tpac.org.au,preferred)|nop
9	acSetRescSchemeForCreate|"$objPath" like "/ARCS/projects/IMOS/staging/ACORN/*"|msiSetDefaultResc(arcs-df.vpac.org,preferred)|nop
10	acSetRescSchemeForCreate|"$objPath" like "/ARCS/projects/IMOS/staging/AATAMS/*"|msiSetDefaultResc(arcs-df.vpac.org,preferred)|nop
11	acSetRescSchemeForCreate|"$objPath" like "/ARCS/projects/IMOS/staging/FAIMMS/*"|msiSetDefaultResc(arcs-df.vpac.org,preferred)|nop
12	acSetRescSchemeForCreate|"$objPath" like "/ARCS/projects/IMOS/staging/eMII/*"|msiSetDefaultResc(emii.resource.tpac.org.au,preferred)|nop
13	acSetRescSchemeForCreate|"$objPath" like "/ARCS/projects/IMOS/staging/SRS/*"|msiSetDefaultResc(arcs-df.ivec.org,preferred)|nop
</pre> 

---+++ A distributed iRODS zone of gridftp storage resources

---++++ Start iRODS.

<pre>
    3  cd /opt/iRODS/
    4  ./irodssetup 
    5  ./irodssetup 
    6  ./irodssetup 
    7  ls
    8  ./irodsctl start
    9  MSS universal driver
</pre>

---++++ Make a resource group with local cache and gridftp server resources.

<pre>
   10  export PATH=$PATH:/opt/iRODS/clients/icommands/bin
   11  iadmin mkresc gwdca03 "MSS universal driver" compound gwdca03.fnal.gov /pnfs/fnal.gov/data
   12  iadmin atrg rg gridworks
   13  iadmin atrg rg data1
   14  iadmin mkresc gridworks "unix file system" cache gw014k1.fnal.gov /data1
   15  iadmin atrg rg gridworks
   16  iadmin atrg rg gwdca03
</pre>

---++++ Add users and user groups

<pre>
   35  iadmin mkuser gwadmin rodsadmin
   36  iadmin mkuser tdh rodsuser
   38  iadmin mkuser testuser rodsuser
   40  iadmin mkgroup gwgroup
   41  iadmin atg gwgroup tdh
   42  iadmin atg gwgroup testuser
</pre>

---++++ Add more resources to the resource group

<pre>
</pre>

---++++ Make a collection

A collection may be thought of as a directory in the logical namespace.

<pre>
</pre>





---++++ 

<pre>
</pre>

---+++ OSG iRODS Model

Discovery, Transfer, Catalog, Management

*Within iRODS framework, or iRODS as a component in another framework?*

Minimize the disparity in alternate client software for direct submission to sites.

---++++Discovery
   
Provide for automatic selection of storage element. Support data-driven computation.

   * On directory creation, assign a storage element to it
      * Schema requires it to be stored in a data object
      * Should have expected size of directory
         * May need to move the files to another storage element
      * Space reservation option
      * Storage use profile option
   * Use discovery service to return TURL or SURL to user.
   * Associate a compute element with a storage element via data objects
      * Compute use profile option
         * Influences where data is placed
   * Use RSV probe to identify authorized sites
   * Allow for operation with OSGMM

---++++Transfer

Desire direct transfer between storage element and user based on non-iRODS storage services. 

   * Use irods standard transfer with extension microservices
      * gridftp -does not invoke policy rules.
      * SRM?
      * Must hop through OSG irods server
   * Use irods transfer with Universal Mass Storage Driver
      * Storage resources registered as such
      * Use regular transfer microservices, which will invoke policy rules
      * Must stage through OSG irods server
   * Use irods as a shadow storage service
      * Actual transfers in external framework
         * Using same clients as for non-opportunistic storage.        
      * Get TURL directly or via SURL and make the transfer in the next step
         * Override microservice to provide info rather than transfer data
            * Essential that iRODS automatic policy functions are still invoked.
            * Policy functions are invoked before and after invocation of drivers
               * Custom driver using rcExecCmd (same as UMSD)
               * Additional cmd within workflow with msiExecCmd
         * UMSD functions to return information rather than do transfers
            * Must avoid false registration
               * Must have a way to block until file completion
            * Currrent nop for file transfer (stage only).  Could extend?
         * Possibly use microservice-wrapped web service for callbacks
            * Start of globus.org-type service
            * Facilitate future integration with Java-based iRODS microservices
            * May do GUMS call
            * gsoap, complicated, recompile for each added web service
   * Robustly register file and metadata information.

---++++Catalog

Database registration should be transparent to the user.

   * Trigger job on completion of pre-defined file set.
   * Add FITS data to metadata (LSST)
      * Database searchability
   * Monitor data movement status
   * Leverage existing iRODS GUIs and web interfaces.
   * Support Storage Management functions, see below 

---++++Management

   * Trigger deletion of expired data collections.
   * Maintain space and availability information.
   * Replication
   * Relocation
   * Aggregation

---++globus.org

---++FTS

-- Main.TedHesselroth - 19 May 2010
