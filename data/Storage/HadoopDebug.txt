%META:TOPICINFO{author="WillMaier" date="1238183984" format="1.1" version="1.3"}%
%META:TOPICPARENT{name="Hadoop"}%
---+!! *<noop>%SPACEOUT{ "%TOPIC%" }%*
%TOC%



---++ Debugging your Hadoop Instance

This twiki is setup to help diagnose and solve some typical Hadoop issues. 

---++ Running the Gridftp server in standalone mode

Sometimes diagnosing gridftp server or hadoop errors require you to run the standalone gridftp server which runs in a debug mode. 

*On the Server* 

<verbatim>
source  $VDT_LOCATION/setup.sh
cd $VDT_LOCATION/gridftp_hdfs
./standalone_starter.sh
</verbatim>

*On the Client, note the use of port 5002*


<verbatim>
source  $VDT_LOCATION/setup.sh
dd if=/dev/zero of=testfile.zero count=10000 bs=1024
globus-url-copy file://localhost/`pwd`/testfile.zero gsiftp://gridftpserver.fqdn:5002/your/path/testfile.zero
</verbatim>

After running the command on the client check the console on the server for any error messages in the transfer that could help diagnose your gridftp server problem. 

---++ Errors and Their Solutions

---+++ Incompatible Versions between the Datanode and Namenode

---++++ Problem

Hadoop is very sensitive about the versions and build tags between the different parts of the system. When upgrading hadoop you may get errors of the form.

<verbatim>
2009-03-23 14:06:50,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = cabinet-7-7-28.t2.ucsd.edu/169.228.130.190
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.19.2-dev
STARTUP_MSG:   build =  -r ; compiled by 'mockbuild' on Mon Mar 23 15:50:31 EDT 2009
************************************************************/
2009-03-23 14:06:50,263 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Incompatible build versions: namenode BV = 748415; datanode BV =
2009-03-23 14:06:50,370 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: java.io.IOException: Incompatible build versions: namenode BV = 748415; datanode BV=
        at org.apache.hadoop.hdfs.server.datanode.DataNode.handshake(DataNode.java:416)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:265)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:206)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1239)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1194)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:1202)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:1324)

2009-03-23 14:06:50,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
</verbatim>

---++++ Solution

Generally you want to upgrade the name node and data nodes at the same time to limit these kinds of version problems. Check the versions of your namenode and datanode to make sure you are running the same build tag of hadoop. 

---+++ Gftp Client Errors 

---++++ 500 500-Command failed. :

<verbatim>
Source URL for copy: file:/data/sam2/.same/SRMv2/testFile.txt
Destination URL:
gsiftp://cithep250.ultralight.org:5000//mnt/hadoop/store/user/test/SAM-cit-itb-se.ultralight.org/lcg-util/testfile-user-20090325-222131.txt
# streams: 1
# set timeout to  0 (seconds)
            0 bytes      0.00 KB/sec avg      0.00 KB/sec
instglobus_ftp_client: the server responded with an error
500 500-Command failed. :
globus_gridftp_server_hdfs.c:globus_l_gfs_hdfs_recv:916:
500-Failed to open file in HDFS.
500 End.
</verbatim>

---++++ Solution(s)

These errors can be a bit vague, more information may be available however in the gridftp log itself. For example the above may be a permissions problem that can be verified in the Gridftp log. 

If the log is not helpful it might be necessary to run the gridftp server on standalone mode on port 5002. 

-- Main.TerrenceMartin - 23 Mar 2009