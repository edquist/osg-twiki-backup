%META:TOPICINFO{author="TerrenceMartin" date="1238611839" format="1.1" reprev="1.4" version="1.4"}%
%META:TOPICPARENT{name="Hadoop"}%
---+!! *<noop>%SPACEOUT{ "%TOPIC%" }%*
%TOC%



---++ Debugging your Hadoop Instance

This twiki is setup to help diagnose and solve some typical Hadoop issues. 

---++ Running the FUSE mount in Debug mode

It is often useful to run the FUSE mount in debug mode to identify specific errors and problems with the FUSE mount.

<verbatim>
/usr/bin/hdfs -o server=namenode.fqdn,port=9000,rdbuffer=131072,allow_other -d /mnt/hadoop/
</verbatim>
 
Note the use of the -d switch to put the mount in debug mode. CTRL-C to quit the mount after testing. 

---++ Running the Gridftp server in standalone mode

Sometimes diagnosing gridftp server or hadoop errors require you to run the standalone gridftp server which runs in a debug mode. 

*On the Server* 

<verbatim>
source  $VDT_LOCATION/setup.sh
cd $VDT_LOCATION/gridftp_hdfs
./standalone_starter.sh
</verbatim>

*On the Client, note the use of port 5002*


<verbatim>
source  $VDT_LOCATION/setup.sh
dd if=/dev/zero of=testfile.zero count=10000 bs=1024
globus-url-copy file://localhost/`pwd`/testfile.zero gsiftp://gridftpserver.fqdn:5002/your/path/testfile.zero
</verbatim>

After running the command on the client check the console on the server for any error messages in the transfer that could help diagnose your gridftp server problem. 

---++ Errors and Their Solutions

---+++ Incompatible Versions between the Datanode and Namenode

---++++ Problem

Hadoop is very sensitive about the versions and build tags between the different parts of the system. When upgrading hadoop you may get errors of the form.

<verbatim>
2009-03-23 14:06:50,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = cabinet-7-7-28.t2.ucsd.edu/169.228.130.190
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.19.2-dev
STARTUP_MSG:   build =  -r ; compiled by 'mockbuild' on Mon Mar 23 15:50:31 EDT 2009
************************************************************/
2009-03-23 14:06:50,263 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Incompatible build versions: namenode BV = 748415; datanode BV =
2009-03-23 14:06:50,370 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: java.io.IOException: Incompatible build versions: namenode BV = 748415; datanode BV=
        at org.apache.hadoop.hdfs.server.datanode.DataNode.handshake(DataNode.java:416)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:265)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:206)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1239)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1194)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:1202)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:1324)

2009-03-23 14:06:50,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG:
</verbatim>

---++++ Solution

Generally you want to upgrade the name node and data nodes at the same time to limit these kinds of version problems. Check the versions of your namenode and datanode to make sure you are running the same build tag of hadoop. 

---+++ Gftp Client Errors 

---++++ 500 500-Command failed. :

<verbatim>
Source URL for copy: file:/data/sam2/.same/SRMv2/testFile.txt
Destination URL:
gsiftp://cithep250.ultralight.org:5000//mnt/hadoop/store/user/test/SAM-cit-itb-se.ultralight.org/lcg-util/testfile-user-20090325-222131.txt
# streams: 1
# set timeout to  0 (seconds)
            0 bytes      0.00 KB/sec avg      0.00 KB/sec
instglobus_ftp_client: the server responded with an error
500 500-Command failed. :
globus_gridftp_server_hdfs.c:globus_l_gfs_hdfs_recv:916:
500-Failed to open file in HDFS.
500 End.
</verbatim>

---++++ Solution(s)

These errors can be a bit vague, more information may be available however in the gridftp log itself. For example the above may be a permissions problem that can be verified in the Gridftp log. 

If the log is not helpful it might be necessary to run the gridftp server on standalone mode on port 5002. 


---+++ GFTP Server Errors

---++++  500-Allocated all 200 memory buffers; aborting transfer.

This error which may appear in the gftp/srmcp client or the server is caused by clients that use multiple streams consuming all of the 200 available GFTP server buffers. The default is 200 which is a bit low. To help alleviate this problem you can add the following environment variable to the gridftp server. 

In file $VDT_LOCATION/vdt/etc/vdt-local-setup.sh

add the following line

<verbatim>
export VDT_GRIDFTP_BUFFER_COUNT=500
</verbatim>

This increases the available buffers to 500 which should allow more flexibility in how many streams the gftp server will support before it drops the connection to save memory. 

---++ Authors

-- Main.TerrenceMartin - 23 Mar 2009
