%META:TOPICINFO{author="MichaelThomas" date="1249360713" format="1.1" reprev="1.4" version="1.4"}%
%META:TOPICPARENT{name="Hadoop"}%
---+!! *<noop>%SPACEOUT{ "%TOPIC%" }%*
%TOC%


---+    Installation

There used to be two choices for installation method - RPM-based or Pacman-based.  From feedback we have received from site admins, we are moving forward only with the RPM-based installs.  The Pacman install is documented below for posterity.


---++   Quick Start

Quickstart for the impatient.  This assumes you already have the *jdk* 1.6.0 RPM installed on all relevant nodes.

 <verbatim>
rpm -ivh http://newman.ultralight.org/repos/hadoop/4/i386/caltech-hadoop-4-1.noarch.rpm
yum install gridftp-hdfs
vi /etc/sysconfig/hadoop # Edit appropriately.
service hadoop-firstboot start
vi /etc/grid-security/prima-authz.conf # Add gums hostname
service xinetd restart
</verbatim>

---++ Prerequisites and Assumptions

The installation assumes you are already familiar with the [[HadoopInstallation][Hadoop installation instructions]], notably the installation and configuration of the Hadoop FUSE mount.

The Hadoop RPMs require Sun Java jdk 1.6.0 or later. You can download this from http://java.sun.com.

GUMS must be used for grid user mappings.  While a grid-mapfile may be used, the configuration of its use is not currently tested or supported.

While you can run gridftp on the same node as other hadoop services, this is not recommended.  The Gridftp server for hadoop can be very memory-hungry and should run on a dedicated server.

The installation includes the latest CA Certificates package from the OSG as well as the fetch-crl CRL updater.

---++ RPM/YUM Install method

Hadoop and gridftp-hdfs RPMs for RHEL4 and RHEL5 are available from:

<verbatim>
http://newman.ultralight.org/repos/hadoop/4/x86_64
http://newman.ultralight.org/repos/hadoop/4/i386
http://newman.ultralight.org/repos/hadoop/5/x86_64
http://newman.ultralight.org/repos/hadoop/5/i386
</verbatim>

While it is possible to download and install the RPMs directly, it is recommended that you install the yum repository configuration and install gridftp-hdfs with yum.  This will ensure that all of the required dependant packages are also installed and configured.  To configure your local installation for the yum repository, you should install the caltech-hadoop package from the relevant package:

RHEL4 (32 and 64-bit):

<verbatim>
rpm -ivh http://newman.ultralight.org/repos/hadoop/4/x86_64/caltech-hadoop-4-1.noarch.rpm
</verbatim>

RHEL5 (32 and 64-bit):

<verbatim>
rpm -ivh http://newman.ultralight.org/repos/hadoop/5/x86_64/caltech-hadoop-5-1.noarch.rpm
</verbatim>

Remember, in order to use both Hadoop and gridftp-hdfs, you must have the fuse kernel module already installed on your system in order to use the yum installer.

After installing the caltech-hadoop yum configuration package, you can install the gridftp-hdfs server with:

<verbatim>
yum install gridftp-hdfs
</verbatim>

Updates can be installed with:

<verbatim>
yum upgrade gridftp-hdfs
</verbatim>

---++ Configuration

The installation of gridftp-hdfs and its dependencies creates several directories.  In addition to the Hadoop installation files, you will also find:

| Log files | =/var/log/gridftp-auth.log=, =/var/log/gridftp.log= |
| xinetd files | =/etc/xinetd.d/gridftp-hdfs= |
| runtime config files | =/etc/gridftp-hdfs/*= |
| System binaries | =/usr/bin/gridftp-hdfs*= |
| System libraries | =/usr/lib64/libglobus_gridftp_server_hdfs_gcc64dbg.so*= |
| prima auth configuration | =/etc/grid-security/prima-authz.conf= |
| CA certificates | =/etc/grid-security/certificates/*= |

gridftp-hdfs reads the hadoop configuration file to learn how to talk to Hadoop.  As per the [[HadoopInstallation][Hadoop install instructions]], edit =/etc/sysconfig/hadoop= and run =service hadoop-firstboot start=.  It is *not* necessary (or even recommended) to start any hadoop services with =service hadoop start=.

In =prima-authz.conf= you will need to enter the url for your gums server, as well as the path to your host certificate and key:

<verbatim>
imsContact https://your.gums.host:8443/gums/services/GUMSAuthorizationServicePort
...
serviceCert /etc/grid-security/hostcert.pem
serviceKey  /etc/grid-security/hostkey.pem
</verbatim>

The default settings in =/etc/gridftp-hdfs/*.conf= should be ok for most installations.  The file =gridftp-inetd.conf= is used by the xinetd service for starting up the gridftp server.  The file =gridftp.conf= is used by =/usr/bin/gridftp-hdfs-standalone= for starting up the gridftp server in a testing mode.  =gridftp-hdfs-local.conf= contains additional site-specific environment variables that are used by the gridftp-hdfs dsi module in both the xinetd and standalone gridftp server.  Some of the environment variables that can be used in =gridftp-hdfs-local.conf= include:

| GRIDFTP_HDFS_REPLICA_MAP | File containing a list of paths and replica values for setting the default # of replicas for specific file paths |
| GRIDFTP_BUFFER_COUNT | The number of 1MB memory buffers used to reorder data streams before writing them to Hadoop |
| GRIDFTP_FILE_BUFFER_COUNT | The number of 1MB file-based buffers used to reorder data streams before writing them to Hadoop |
| TMPDIR | The temp directory where the file-based buffers are stored.  Defaults to /tmp |

---++ Running gridftp-hdfs

If you were not already running the xinetd service (by default it is not installed on RHEL5), then you will need to start it with the command =service xinetd restart=.  Otherwise, the gridftp-hdfs service should be configured to run automatically as soon as the installation is finished.  If you would like to test the gridftp-hdfs server in a debug standalone mode, you can run the command:

<verbatim>
/usr/bin/gridftp-hdfs-standalone
</verbatim>

The standalone server runs on port 5002, handles a single gridftp request, and will log output to stdout/stderr.

---+ Pacman installation

*Beware: The pacman installation method is deprecated!  Do not use for new installs.*

---++  Prerequisites and Assumptions

The !GridFTP server for HDFS is based upon the stock Globus server
with a new loadable module to interact with Hadoop.

Make sure that the =xinetd= RPM is installed on your system.

The installation process is based on
[[ReleaseDocumentation.PacmanBestPractices][Pacman]]; 
see the [[ReleaseDocumentation.WebHome][release documentation]] for
help on [[ReleaseDocumentation.PacmanInstall][installing Pacman]] if
you do not have it already.

Now, create your install directory; we will refer to this as
=$VDT_LOCATION= in this documentation.

<verbatim>
cd $VDT_LOCATION
echo "http://t2.unl.edu/store/cache" > trusted.caches
echo "http://vdt.cs.wisc.edu/vdt_1101_cache" >> trusted.caches
export VDTSETUP_AGREE_TO_LICENSES=y
export VDTSETUP_INSTALL_CERTS=l
export VDTSETUP_CA_CERT_UPDATER=n
export VDTSETUP_ENABLE_BESTMAN=n
export VDTSETUP_ENABLE_ROTATE=n
export VDTSETUP_ENABLE_GRIDFTP=n
export VDTSETUP_EDG_CRL_UPDATE=n
export VDT_GUMS_HOST=<host for your GUMS install>
pacman -get http://t2.unl.edu/store/cache:GridFTP_HDFS
ln -s /etc/grid-security/certificates $VDT_LOCATION/globus/TRUSTED_CA
</verbatim>

If your site does not use GUMS, replace the =VDT_GUMS_HOST= line with

<verbatim>
export VDT_NO_PRIMA=1
</verbatim>

Currently supported platforms include RHEL-4 and RHEL-5, both in
32-bit and 64-bit.

The installation automatically enables the !GridFTP server in
=/etc/xinetd.d=. This means that =GridFTP_HDFS= must be installed
using the root account. The !GridFTP server uses port 5000 (as
opposed to 2811, the default port).

---+    Configuration
---++    CA Certificates

Please refer to the [[ReleaseDocumentation.WebHome][release documentation]]
for instructions on how to
[[ReleaseDocumentation.ComputeElementPostInstall#Choosing_and_Installing_a_CA_Dis][install the proper CA certificates]].

---++    Authentication

There are two ways to configure authentication:


---+++    PRIMA/GUMS

This approach integrates well with larger sites. First, install the
PRIMA configurations:

<verbatim>
cp $VDT_LOCATION/post-install/*-authz.conf /etc/grid-security
</verbatim>

Then edit the line starting with =imsContact= in =/etc/grid-security/prima-authz.conf= 
to point to your GUMS installation.


---+++    grid-mapfile

This approach is not recommended.

Create =/etc/grid-security/grid-mapfile=. For each user at your
site, add a line to the file mapping the user's DN to their user
name:

<verbatim>
"<DN>" <user>
</verbatim>

For example:

<verbatim>
"/DC=org/DC=doegrids/OU=People/CN=Will Maier 286302" osg_uscms01
</verbatim>

---++    HDFS

Unfortunately, !GridFTP-HDFS does not yet integrate naturally into
the Hadoop configuration system.  You must specify the following
environment variables for the !GridFTP server:

   $ =VDT_GRIDFTP_HDFS_REPLICAS=: integer number of replicas for each saved file (default: =3=).
   $ =VDT_GRIDFTP_HDFS_NAMENODE=: hostname of the Hadoop namenode (default: =hadoop-name=).
   $ =VDT_GRIDFTP_HDFS_PORT=: port number of the Hadoop namenode (default: =9000=).
   $ =VDT_GRIDFTP_HDFS_MOUNT_POINT=: FUSE mount point on the SRM node (default: =/mnt/hadoop=). This
     allows the !GridFTP server to convert from SRM filenames (which include the
     FUSE mount path) and the native Hadoop filenames (which do not include the
     FUSE mount path).
   $ =VDT_GRIDFTP_LOAD_LIMIT=: maximum number of active transfers (default:
     =20=). If the system load is above this integer value, then the gridftp
     server will accept new transfers, but not allow them to actually start
     movement.
   $ =VDT_GRIDFTP_BUFFER_COUNT=: integer number of buffers that the gridftp server will be allowed to use (default: =200=).

In order to set these variables, you can export the variables appropriately in
the files =$VDT_LOCATION/vdt/etc/vdt-local-setup.sh= and
=$VDT_LOCATION/vdt/etc/vdt-local-setup.csh=.

---++    Add to SRM

Any [[HadoopSRM][BestMan SRM]] server must be told of the location of the new
!GridFTP server before it can use it. Add this new server to the =bestman.rc= of
the SRM server and restart the server.

---++    Enable Gratia Probe

See the [[HadoopGratia][Gratia probe installation instructions]] for more information.

---+    Running the server

Now, simply turn on the server:

<verbatim>
vdt-control --enable gridftp-hdfs
vdt-control --enable vdt-rotate-logs # DO NOT FORGET THIS ONE!
vdt-control --on
</verbatim>

Make sure you turn on log rotation.

-- Main.WillMaier - 19 Mar 2009
