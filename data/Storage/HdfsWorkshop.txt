%META:TOPICINFO{author="WillMaier" date="1236820333" format="1.1" version="1.16"}%
%META:TOPICPARENT{name="StorageForum"}%
---+ HdfsWorkshop, March 11-13, UCSD


---++ Logistics

Information concerning travel and accommodations can be found at the webpage for the recent
[[http://hepuser.ucsd.edu/twiki2/bin/view/UCSDTier2/SandCweekApril2009][Software and Computing]] meeting at UCSD.
   * UCSD will host a hands-on workshop focused on integration of hdfs (the Hadoop file system) at the USCMS Tier2s from March 11 to March 13, 2009.
   * Most attendees will be arriving around noon on Wednesday.  Most will be at the Sheraton La Jolla.

---++ Agenda

   * Meet Wednesday noon at Mayer Hall 5517 (Terrence's office). 
      * start with lunch, in case either Will or Brian are delayed with their flights.
      * Followed by the TODO as it is below.

---++ TODO
   * Wednesday: Overview
      * Introductory remarks from Ken Bloom (30 min)
      * Reality check: Time to ask upfront questions and let sites define any goals they have for the meeting. (30 min)
         * Small roundtable of "what we want to do with Hadoop (and why)" from each site.
      * Detailed outline of Hadoop components (logfiles, what's installed where, etc). (1 hr)
         * Demonstration and outline of the Nebraska system

   * Thursday: Practical
      * Installation
         * Help folks install small evaluation testbeds.
         * Get all the important components going (HDFS, FUSE, GridFTP, SRM)
         * Demonstrate file transfers and CMSSW usage
      * Management and transition notes from UNL (1 hr)
      * Packaging and documentation (30 min)
      * Rocks integration (1 hr)
         * RPMs of hadoop, fuse packages
         * Rocks kickstart xml fragments
         * Hands-on help integrating Hadoop with existing Rocks clusters
         * Todo: build hadoop rpm from source
         * Todo: integration bestman/gridftp (RPMS + kickstart xml)
      * Upgrade (30 min)
      * Monitoring
         * JMX.  Make sure everyone can run JMX console.
         * Ganglia.  Make sure everyone's HDFS cluster gets integrated into Ganglia
         * Nagios.  Share Nebraska probes and offer advice from Nerbaska.
         * Monalisa. Share custom monalisa+ganglia module from Caltech

   * Friday: Verification
      * SE tests and configuration
      * Demonstrate reliability of HDFS in various circumstances: (30 min)
         * restart of namenode
         * restoration from checkpoint/backup
         * client behavior during namenode restart
         * log atomicity during namenode failure (=kill -9=)
      * Test Scalability / Inter-site PhEDEx transfers?  (1 hr)
      * Plan a "storage challenge" to be held before data taking?
     * Develop best practices:
        * Replication policy
        * Service layout
        * Monitoring
        * Namenode checkpointing/backup policy
        * Logging (?)

---++ Coordination

   * Jabber/XMPP: uscms-t2@conference.fnal.gov (multi-user chat)

-- Main.WillMaier - 06 Mar 2009

%META:FILEATTACHMENT{name="Hadoop_Overview.pdf" attachment="Hadoop_Overview.pdf" attr="" comment="" date="1236802800" path="Hadoop Overview.pdf" size="68191" stream="Hadoop Overview.pdf" tmpFilename="/usr/tmp/CGItemp12475" user="BrianBockelman" version="1"}%
%META:FILEATTACHMENT{name="Hadoop_UCSD_Mar11_2009.pdf" attachment="Hadoop_UCSD_Mar11_2009.pdf" attr="" comment="HDFS + Rocks integration" date="1236803096" path="Hadoop_UCSD_Mar11_2009.pdf" size="54651" stream="Hadoop_UCSD_Mar11_2009.pdf" tmpFilename="/usr/tmp/CGItemp7265" user="MichaelThomas" version="1"}%
