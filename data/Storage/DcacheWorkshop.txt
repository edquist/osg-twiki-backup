%META:TOPICINFO{author="FkW" date="1153174335" format="1.0" version="1.25"}%
%META:TOPICPARENT{name="WebHome"}%
---+!! DcacheWorkshop for storage admins (July 17th 2006, FNAL)

%TOC%

---++ Where?
FCC2, i.e. second floor conference room in Feynman computing center @ FNAL.
Or to join virtually, follow these instructions:

If you will be joining by video, we will be using 
the ESnet ECS Ad-hoc bridge.
The number to dial in to connect by video is
88322243 for 88dcache at 348kps.

If you need to dial in by phone only, 
call 510-883-7860 then enter the Ad-hoc number 
88322243 for 88dcache followed by the # sign.

If you need to join by VRVS see instructions at
http://www-staff.es.net/~mikep/adhoc/vrvsecs.htm

'Storm' VRVS room has been reserved.

There's also a web page at the main OSG events calendar:
http://www.opensciencegrid.org/index.php?option=com_content&task=view&id=146

---++ Agenda

---+++ Intro of Attendees
Please feel free to edit this twiki by adding in your site name, and dCache infrastructure deployed today, and planned for the future, say one year from now.

d85 12
 <b>Abhishek Singh Rana & Frank Wuerthwein - UCSD </b>
	* <b>[[%ATTACHURL%/UCSD-dCache-topology-diagram.jpg][UCSD dCache Topology Diagram]]</b>
	* USCMS T2, dCache/SRM in production usage since early 2004.
	* 80+ worker nodes, 70+ have dCache pools, 0.2 - 1.7 TB per pool.
	* ~42TB currently, phased growth ongoing. 
	* ~11 dCache infrastructure nodes with various hardware configs.
	* 1 Core + 1 PNFS server & Mgr (DB) + 1 Replica Mgr (DB) + 1 DCap + 1 SRM (DB) + 6 GFTP.
	* <u>Only</u> Nodes on WAN (dual-homed): 1 Core + 1 SRM (DB) + 6 GFTP.
	* PNFS mounted <u>only</u> on infrastructure nodes, not mounted on worker nodes.
	* Multiple mover queues on pools - default LAN (dCap) + WAN (SRM & GFTP).
	* Network: 6 GFTP nodes on 10GbE, 2 of which with 2 GFTP doors each. 
	* Version: dcache-1.6.6-5 with April 2006 jar update from FNAL.
	* <nowiki>PostgreSQL 7.4.6, jdk1.5.0_01</nowiki>
	* Implicit Space reservation enabled (mid 2005). 
	* Replica Mgr in production usage (early 2004) - all pools are resilient. 
	* ext3 as filesystem. 
	* gPlazma non-GUMS RBAC mode in production usage (mid 2005).
	* Download transfer milestone - 13 TB/day FNAL->UCSD, 3rd party SRM, by <nowiki>PhEdEx</nowiki>.

 <b>Suresh Singh, Michael Thomas - Caltech</b>
	* USCMS Tier2 site, dCache used in production
	* ~60 worker nodes, all but a few are dCache pool nodes
	* 34 Tb, growing to ~60 later this year
	* 2 dCache infrastructure nodes
	* all workers on public address space
	* replication on (2 copies?)
	* second, smaller 4-node dCache installation used for development with <nowiki>LambdaStation</nowiki>

 <b>Preston Smith - Purdue</b>
	* USCMS Tier-2, dCache used in production
	* Version: dcache-1.6.6-5 with May10 2006 jar update from FNAL.
	* 28 TB currently
	* Pools live on large blocks of RAID storage (6 pool nodes).
	* 3 GridFTP doors
	* All nodes reside on public network 
	* No replication currently.
	* Upcoming expansion will add pools on worker nodes (with replication), in addition to additional RAID storage. 
	* 2 infrastructure nodes (pnfs on one node, srm/dcap/admin on 2nd)

<b>Zhengping(Jane) Liu, Yingzi(Iris) Wu --- Brookhaven National Lab</b>
   * USATLAS Tier1 site, dCache used in production
   * 150TB currently, phased growth ongoing
   * 350+ worker nodes (dCache pools)
	* [[%ATTACHURL%/dcacheIntro-7-17-2006][dCache Introduction]]
	  Goal here is to present a layperson's view of how dCache works.
   * Network: 5 GFTP nodes with 2GFTP doors each on 10GbE, 
   * Version: dcache-1.6.6.5
   * ProsgreSQL 8.1.4, jdk 1.5.0_05
   * file system: ext3 in admin and read pool, xfs in write pool
   * Transfer - 7 TB/day 
	* [[%ATTACHURL%/dCache-ROCKS.ppt][dCache on Rocks]]
 <b> Attendees: Please continue with details .. </b>
---+++ dCache performance tuning
	* [[%ATTACHURL%/ASR-dCache-tuning-p1.ppt][Basics of Tuning]]
	* [[%ATTACHURL%/ASR-dCache-admin-p2.ppt][Basics of Admin Interface]]
   * [[%ATTACHURL%/dcacheIntro-7-17-2006][dCache Introduction]]
     Goal here is to present a layperson's view of how dCache works.

---+++ Walkthrough of dCache installation (moved to afternoon)
[[http://www.atlasgrid.bnl.gov/workshop_dcache/install_note][Installation Instructions]]

---+++ dCache on Rocks
   * [[%ATTACHURL%/dCache-ROCKS.ppt][dCache on Rocks]]
	* Using the replica manager:
---+++ dCache performance tuning and basics of admin interface
   * [[%ATTACHURL%/ASR-dCache-tuning-p1.ppt][Basics of Tuning]]
   * [[%ATTACHURL%/ASR-dCache-admin-p2.ppt][Basics of Admin Interface]]

---+++ dCache FAQ and discussion
Here comes your input. Ask whatever questions you want to from off the dCache people.

---++++ How to drain a pool?
You can either use the replicaManager or the CopyManager.
The latter is a relatively new feature.

   * Using the replica manager:
http://cmsdcam2.fnal.gov/dcache/resilient/Resilient_dCache_TroubleShooting.html

The replicaManager is repsonsible for managing desired number of replicas. It can be used ot drain a pool as follows:

Use dcache admin interface on the node that has the admin cell.
Then do something like:
<pre>
dcache> set dest replicaManager
dcache> set pool <pool name 1 > drainoff
dcache> set pool <pool name 2 > drainoff
</pre>

You then need to wait, and occasionally check progress:
<pre>
dcache> set dest replicaManager
dcache> ls unique <pool name 1>
dcache> ls unique <pool name 2>
</pre>

This returns the # of files that are not yet replicated, and thus still unique to pool 1 and pool 2. The pnfsid's of the files that are still unique to the pool(s) are listed in the replicaManager logfile.

Note: "ls unique" looks for files only in pools that are in the 
online state. E.g. other pools in drainoff state are not considered when
checking for uniqueness. You can thus put multiple pools into drainoff state at once without worrying about "ls unique" giving misleading answers.
 
If there are no unique files in the pools then you can take the pool out as follows:

<pre>
	* provide a suggested hardware deployment scenario, or two, three.
	* provide a (complete) list of components, and a one paragraph description of what they do, and what hardware resources they stress.
	* provide a (complete) list of how each of us deploys dcache.

If this doesn't work, complain to support@dcache.org .
Please refer in your email to this twiki page and OSG. 

---++++ What do all of the cells and domains do?
When  trying to debug dcache it is often very confusing because there are so many components. Without knowing what all these components do,
and what hardware resources they stress (cpu, memory, disk, etc.) it is hard to even know which logfile to look at when trying to debug something, and how to improve performance.

Action items:
   * provide a suggested hardware deployment scenario, or two, three.
   * provide a (complete) list of components, and a one paragraph description of what they do, and what hardware resources they stress.
   * provide a (complete) list of how each of us deploys dcache.

	* http://hepuser.ucsd.edu/twiki/bin/view/Main/PnfsChecker
	* Brian's pnfschecker (fkw will check and link it in here)
	* there are scripts in use at fnal.

---++++ Is there a way to configure dcap to have a timeout?
Yes there is. It's an option that has to be specified with dcap,
(dccp -o). This could also be hardcoded into libdcap.so and thus fixed
as a site characteristic. Ideally, one would want to have this as a serverside rather than a clientside timeout such that the admins deploying the server control it. As of now, a serverside timeout is not possible. Rob K. finding out more about this from DESY.

---++++ PNFS checking
There are various people who have developed scripts for either searching for lost files, or chksumming all files. There are at least three such systems:

   * http://hepuser.ucsd.edu/twiki/bin/view/Main/PnfsChecker
   * Brian's pnfschecker (fkw will check and link it in here)
   * there are scripts in use at fnal.

---++++ Billing
There is detailed information about "billing" in the dCache book:
http://www.dcache.org/manuals/Book/cb-accounting.shtml

This is implemented as a cell in dCache, and we all have this installed by default. Unfortunately, none of us knows what to do with it.

	* [[%ATTACHURL%/gPlazma-Presentation.pdf][Deploying gPlazma dCache cell.]]

	* [[%ATTACHURL%/SRMTalk-DCache-Workshop-June17-2006.pdf][SRMTalk-DCache-Workshop-June17-2006.pdf]]: SRM V2.2 Implementation Status

---+++ New features coming within the next 6 months

---++++ gPLAZMA
   * [[%ATTACHURL%/gPlazma-Presentation.pdf][Deploying gPlazma dCache cell.]]
---++++ SRM v2.2
   * [[%ATTACHURL%/SRMTalk-DCache-Workshop-June17-2006.pdf][SRMTalk-DCache-Workshop-June17-2006.pdf]]: SRM V2.2 Implementation Status
---++++ other dCache features 

---+++ Operations Support Tools
Discussion of things people need, and what rudiments of these exist today.
Ideally, we'd "self-organize", and commit to contributing some tools,
and have others that we ask for from OSG Extensions.

---++++ OSG Registration
CMS Tier2 sites are currently required to register their storage elements with the GOC.  This allows them to appear in the GridCat catalog.  It would be nice if more OSG storage elements were registered with the GOC.  Registration is as simple as filling out a web form:

http://www.opensciencegrid.org/index.php?option=com_wrapper&Itemid=68&elMenu=Grid%20Support

---++++ Alarms
Nagios setup for dCache monitoring (BNL, Wisconsin).
	* [[%ATTACHURL%/dcacheIntro-7-17-2006.ppt][dcacheIntro-7-17-2006.ppt]]: Layperson intro to dcache

	* [[%ATTACHURL%/SRMTransferExplained.pdf][SRMTransferExplained.pdf]]: Various Types SRM Transfers from Network Point of View

%META:FILEATTACHMENT{name="dcacheIntro-7-17-2006" attr="" comment="Layperson intro to dcache" date="1153145213" path="dcacheIntro-7-17-2006" size="407040" user="FkW" version="1.1"}%
%META:FILEATTACHMENT{name="ASR-dCache-tuning-p1.ppt" attr="" comment="" date="1153170527" path="ASR-dCache-tuning-p1.ppt" size="64000" user="AbhishekSinghRana" version="1.4"}%
%META:FILEATTACHMENT{name="ASR-dCache-admin-p2.ppt" attr="" comment="" date="1153170515" path="ASR-dCache-admin-p2.ppt" size="97792" user="AbhishekSinghRana" version="1.4"}%
%META:FILEATTACHMENT{name="SRMTalk-DCache-Workshop-June17-2006.pdf" attr="" comment="SRM V2.2 Implementation Status" date="1153152912" path="SRMTalk-DCache-Workshop-June17-2006.pdf" size="76357" user="TimurPerelmutov" version="1.1"}%
%META:FILEATTACHMENT{name="dcacheIntro-7-17-2006.ppt" attr="h" comment="Layperson intro to dcache" date="1153153475" path="dcacheIntro-7-17-2006.ppt" size="411136" user="FkW" version="1.1"}%
%META:FILEATTACHMENT{name="dCache-ROCKS.ppt" attr="" comment="" date="1153154025" path="dCache-ROCKS.ppt" size="443904" user="JorgeRodriguez" version="1.1"}%
%META:FILEATTACHMENT{name="SRMTransferExplained.pdf" attr="" comment="Various Types SRM Transfers from Network Point of View" date="1153154636" path="SRMTransferExplained.pdf" size="88832" user="TimurPerelmutov" version="1.1"}%
%META:FILEATTACHMENT{name="UCSD-dCache-topology-diagram.jpg" attr="" comment="" date="1153154666" path="UCSD-dCache-topology-diagram.jpg" size="66668" user="AbhishekSinghRana" version="1.1"}%
%META:FILEATTACHMENT{name="gPlazma-Presentation.pdf" attr="" comment="Ted Hesselroth: Deploying gPlazma dCache cell" date="1153163627" path="gPlazma-Presentation.pdf" size="316082" user="TedHesselroth" version="1.2"}%

   * [[%ATTACHURL%/SRMTransferExplained.pdf][SRMTransferExplained.pdf]]: Various Types SRM Transfers from Network Point of View

%META:FILEATTACHMENT{name="gPlazma-Presentation.pdf" attr="" autoattached="1" comment="" date="1153163628" path="gPlazma-Presentation.pdf" size="316082" user="UnknownUser" version=""}%
%META:FILEATTACHMENT{name="SRMTransferExplained.pdf" attr="" autoattached="1" comment="" date="1153154636" path="SRMTransferExplained.pdf" size="88832" user="UnknownUser" version=""}%
%META:FILEATTACHMENT{name="ASR-dCache-tuning-p1.ppt" attr="" autoattached="1" comment="" date="1153445759" path="ASR-dCache-tuning-p1.ppt" size="67072" user="Main.AbhishekSinghRana" version="5"}%
%META:FILEATTACHMENT{name="ASR-dCache-admin-p2.ppt" attr="" autoattached="1" comment="" date="1153445683" path="ASR-dCache-admin-p2.ppt" size="119296" user="Main.AbhishekSinghRana" version="5"}%
%META:FILEATTACHMENT{name="SRMTalk-DCache-Workshop-June17-2006.pdf" attr="" autoattached="1" comment="" date="1153152912" path="SRMTalk-DCache-Workshop-June17-2006.pdf" size="76357" user="UnknownUser" version=""}%
%META:FILEATTACHMENT{name="dcacheIntro-7-17-2006.ppt" attr="" autoattached="1" comment="" date="1153153475" path="dcacheIntro-7-17-2006.ppt" size="411136" user="UnknownUser" version=""}%
%META:FILEATTACHMENT{name="dcacheIntro-7-17-2006" attr="" autoattached="1" comment="" date="1153145214" path="dcacheIntro-7-17-2006" size="407040" user="UnknownUser" version=""}%
%META:FILEATTACHMENT{name="dCache-ROCKS.ppt" attr="" autoattached="1" comment="" date="1153154025" path="dCache-ROCKS.ppt" size="443904" user="UnknownUser" version=""}%
%META:FILEATTACHMENT{name="UCSD-dCache-topology-diagram.jpg" attr="" autoattached="1" comment="" date="1153445738" path="UCSD-dCache-topology-diagram.jpg" size="66668" user="Main.AbhishekSinghRana" version="2"}%
