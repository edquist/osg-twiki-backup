 DZero / ATLAS collaboration on Resource Selection on OSG

*Date: March 14, 2006

*Attendees:
Gabriele Garzoglio (GG), Shaowen Wang (SW), Marco Mambelli (MM), 
Sergio Andreozzi (SA), Sudhamsh Reddy (SR), Torre Wenaus (TW)

*Summary and relevant observations:
- ATLAS is interested in the collaboration with DZero on Resource Selection for
  OSG. Using ReSS can make the ATLAS infrastructure more generic and improve 
  the job submission process.  We are going to meet at the end of April to
  explore in practice the use of ReSS for ATLAS pilot jobs.
- Resource attribute of interest for resource selection in ATLAS include
  memory, software releases, network connectivity, data movers at a subcluster
  (gridftp, etc.), max batch system wall clock time (see minutes for a
  discussion on these). ATLAS currently is not interested in the selection of
  storage resources using ReSS.
- The DZero requirements on ReSS seem to apply for ATLAS as well, with the
  possible exception on the number of jobs submitted per day.

*Minutes:
GG: discuss ReSS scope and architecture.

MM: We are not covering selection of storage element. We are only considering a
Computing elements.
TW: OK for ATLAS

TW: Is ReSS like the LCG resource broker?
GG: ReSS is currently completely based on Condor. People submit jobs using
their personal condor-g (condor_schedd), as they do today. They add 1 line to
the configuration of condor_schedd so that it points to the resource selection
service (condor_negotiator/collector).  The first deliverable is building an
end-to-end system for Dzero. Second deliverable is providing ReSS as a generic
service for VOs that have requirements on job management similar to DZero.

MM: what if the requirements select more than one site?
GG: A user can break the tie with a ranking function. Condor from ReSS will
return only one resource. If no ranking is provided, condor will break the tie
returning the first element in its array.

TW: in panda we use condor_schedd to submit pilot jobs. Once the pilot runs,
it pulls one job from the VO queue and executes it, before exiting. We could
use ReSS to select worker nodes with appropriate memory requirements, software
release, etc. for the pilot jobs. Panda also checks that the data needed by
the job is pre-staged at the site.

MM: today, all sites are considered equivalent as far as requirements are
concerned (e.g. software releases, etc.). The pilot can certainly benefit, but
there could be benefit also in the atlas job dispatcher.
TW: how could we integrate the panda job dispatcher and ReSS?
MM: can condor return a list of resources that meet a certain set of
requirements? This info couold be used by the panda dispatcher. This could be
a replacement of the select query to find the right site.
GG: condor can give you a list of classad by using the condor_status command.

TW: another advantage of the integration with ReSS/condor is making the
infrastucture more generic. This would lead to using a common job description
language in OSG. Also, currently in panda, we don't have much automation in the
resource selection system: this could be improved by ReSS.

GG:
Summary: atlas is interested in investigating
- interested in ReSS for pilot jobs
- potentially interested in ReSS for panda job dispatcher

TW: Characteristics of a resource interesting for matching pilot jobs
- memory requirements
- outbound network connectivity (http outbound also through a proxy). (SA) In
  GLUE it is a property of the subcluster: boolean outbound and inbound
  attributes.
- data mover on the worker (e.g. gridftp): (SA) we don't have the attribute in
  GLUE. In LCG the VO can ask sites to add tags to the Information System.
  (SW) We could do this also in OSG, even if we haven't started the process
  yet. (SA) In LCG people are discussing how to do this automatically and
  securely e.g. a user that can install software could also affect how to
  propagate this information from the site to the information system.
- altlas releases: location attribute: for resource selection, only location id
  and version are relevant, not the path info. (GG) How is this different from
  GlueHostApplicationSoftwareRunTimeEnvironment that GLUE v1.2 have already? We
  should look into it.
- max wall clock time: (SA) it is in GLUE as GlueCEPolicyMaxWallclockTime
  (attribute of CE). (SW) we configure that already. (GG) I can check.

All: ATLAS requirements on resource selection
Performance: are the requirements considered for DZero valid for ATLAS
(pilot jobs) as well? One by one...
- "The ReSS will support a community of 100 users, submitting jobs to 10 job
  schedulers": OK.
- "ReSS should support 10,000 jobs per day, with bursts of 2,000 per hour.": NO.
  (TW) In atlas, we expect 200,000 jobs per day in the US (10^6 overall), if we
  include analysis. This may be overestimated. Note that in the current panda
  implementation, 1 pilot job executes 1 vo job then exit (it does not pull the
  job, it advertises its present).
  To implement scalability, we should be able to replicate the info for
  resource selection, each dealing with a fraction of the job. The same
  mechanism would work for ReSS.
- "ReSS should support 100 clusters": OK
  (SW) we envision to have a few hundred clusters.
  (MB) Currently: Number of CE 12,000; number of Cluster 187.
  There are so many CE because, in GLUE v1.2 we had 1 queue per VO: this was
  the only way to publish different policy parameters for a VO. Now in v1.2,
  using the VO view element, we can have single CE for every VO.
  (SA) In the batch systme (priorities), policies are implemented having
  different UID groups. The system maps different VO to the proper VO group.
  We plan to have the same in OSG (privilege project), even if for
  interoperability with LCG we were supporting one queue per VO. (SW) this is
  still in place.
  (GG) Using VO view and a single CE will have the same multiplicity of
  classads as we had with 1 CE per VO (within a factor 2-3 i.e. the average
  number of vo roles).
- "RSS should support a job and resource descriptions (e.g. in classad format)
  with 200 attributes and 5 Kbytes of information." OK.
  This requirement is influenced by the GLUE schema, more than by ATLAS.
  Currently in GLUE there are in the order of 50-60 attributes.

GG: We agree to meet to discuss resource selection for pilot jobs at the end of
April. In April we'll have classads in the ITB (probably will not use VO views
yet). ATLAS can look at it and get a feeling for it. As a second phase, we can
meet to understand resource selection for vo jobs and decide if ReSS is useful
at all.



