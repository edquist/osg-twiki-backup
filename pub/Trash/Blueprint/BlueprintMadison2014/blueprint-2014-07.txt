2014-07-07 Wisconsin Institutes for Discovery
9:00am Miron, John, Chander

Note: Condor chosen as CERN batch system 

==========================================================
-- How to manage the XD-OSG head node? 
  -- data staged through the head node
  -- sysadmin: mats
  -- miron: *policy* before management?  
     -- e.g. users must submit local tasks as jobs rather than running uncontrolled. 
  -- chander: get more users, then deal with issues
  ?? how do we want to manage osg-xd node. 

    1) remote condor_submit, what about returning data?
    2) run schedd locally?
  -- Key issue is input and output sandbox movement. Condor currently has 3rd-location input and output parameters. But a home box may not have the file transfer service available. 

9:35 Brian arrives. 
  
Todd: 10:44 arrives
 -- OSG-XD problem: 100k files from home, run, get output?
 -- Condor sandbox protocols?  curl http ftp 
 -- Initial easy step: separate login node from schedd node. 
     -- Second host already ordered. 
      
 Brian: cgroup partitioning of IO on login node
    -- priority vs. shares?
   3 priorites: 1: condor transfers
                2: tar/untar
                3: interactive
 User work flow:
    -- ftp in large file
    -- check queue
    -- untar, processes more condor submits
    -- every couple days 
    
Action: Todd & Brian work out details
        split schedd & login
        cgroups for priority (condor sandbox transfers vs. everything else). 
        tar/untar -> transparent managed-tar/managed-untar with batch queueing?
        

================================================================================         
For Todd:  BNL Issue with partitionable slots vs. pre-emption
 
  -- Miron: Once a schedd has a claim on a node, the schedd should handle all on-node resource allocation. If the matchmaker wants to re-grab the node, that's OK, but the matchmaker/CM shouldn't micro-manage slots (just nodes). 
     Todd: STARTD-RANK?
  -- Miron: implement whole-node-preemption for golden user, optimize later...

Action: Statement of BNL policy goal (John) -> Miron, Todd
        Fast-track simple implementation of schedd-based preemption (Todd). 
        
===============================================================================
 User & Host Certificates
 
 Path toward eliminating x509 for users. Already there with various OSG overlays. Site access is already authorized by a small set of privileged identities, rather than end-user identities. 
 No paths away from host certificates. 
 Certify as local CA management?

Action: Determine how many host certificates are *required* to run OSG?
        What are the practical pros and cons of switching to non X509 solutions. 
        (Mine)

===============================================================================
OASIS

-- overview of caching hierarchy
  Miron: what is the consequence/timeline of changes at a repo. 
  
  Difficulties:
  -- nested catalogs
  -- reverse mapping. 
  -- Need Stratum 1 catalog traversal tool 
  ?? Miron: monitoring of cache levels, especially cache misses (which pollute the caches). 
 
 Long OASIS discussion...
  
 Chander depart 4:11pm
 
 Miron: In general agrees to SSL-based autoconfig. 
 
 Actions: 
       -- Formalize relationship with CVMFS developers, directly OSG -> devs. (ET?) 
       -- Workplan to do client autoconfig via automount script. (John)
       -- Workplan for auditing S1 content. (Jose)
       -- Rationalize monitoring in general timeline graph of GB per day.  
         file size histogram, per repo, from stratum one after each snapshot. (Jose, others) 
       -- Test SSL file download (John)  
       -- Rebuild repo from scratch ( along with other fire-drill tests). 
       
==============================================================================
Tuesday 7/8:
 
OASIS continued...

  -- Why do we need human signed repo keys? 

Action: 
  -- Security document regarding PKI vs RSA for CVMFS repo keys. 
 
GUMS
 -- No need for complex policy engine and voms caching in world of overlays. 
   -- M: auth and mapping should have been separate. Global identity should have been preserved farther into the system. 
   -- Can we avoid paying attention to the UID of the submitter. e.g. and run a slotX on wn.   
   -- No UID at the sites per VO, just one 'OSG' UID. Tracing/auditin handled within applications/system rather than via UNIX.  
 
?? general question of global information availability for OSG?     

global vs. local namespaces
self-signed certificates throughout OSG? in  a world of overlays. 

Action: 
   -- Document assessing the feasibility of internal OSG-specific self-signed user certificates for all overlay functionality. (Mine)

================================================================================

