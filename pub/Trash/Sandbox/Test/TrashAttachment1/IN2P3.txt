Dans le cadre de ce projet, nous proposons de mener, en collaboration avec les équipes de l'IN2P3 et de RENATER une recherche innovante permettant :-	d'une part de mettre les équipes françaises au niveau des derniers travaux théoriques et expérimentaux menés au niveau international.-	de développer, d'expérimenter et de diffuser une solution logicielle flexible et optimisée pour le transfert des données massives du LHC.-	de participer à la définition d'un standard pour un service de transfert des données adapté aux  grilles de données.Ces travaux s'appuieront sur une  approche expérimentale innovante, basée sur l'émulation haut débit pour le calibrage des équipements d'extrémités et l'expérimentation en vraie grandeur avec le trafic réel  (volumes et contraintes temporelles) des grilles de données de physique sur une véritable infrastructure de production transcontinentale. Cette méthode a pour objectif de permettre l'étude réaliste des comportements aux limites des protocoles et des capacités des équipements actuels et de les valider dans un contexte réel très exigeant.L'émulation offre un environnement matériel stable et bien maîtrisé permettant le contrôle précis des conditions d'expériences.  Cet outil exploite une grappe de 200 PC du projet national GRID5000, interconnectant de nombreux équipements réels (commutateurs, émulateurs matériel, routeurs et systèmes d'extrémités) et active des composants logiciels et matériels qui émulent des latences, des taux de pertes de liens ainsi que des topologies d'infrastructures variées. Validation des modèles développésL'environnement du LHC fournit déjà  un ensemble de données scientifique simulées très fidèles par rapport à la réalité qui permet de tester et de valider les modèles développés en vraie grandeur. Il sera possible par exemple, de produire un lot de données de plusieurs centaines de Téraoctets dans l'un des Tiers-1, de le répliquer dans un autre Tier-1 en utilisant les protocoles de transfert spécifiquement optimisés dans le cadre de ce projet, et finalement de valider l'ensemble de la chaîne en exécutant des tâches d'analyse de physique sur ces données avec retour des résultats vers l'utilisateurs. L'intérêt ici est de pouvoir tester la chaîne complète de traitement sur un lot de données substantiel et de valider l'ensemble.Durant la phase 2006-2007, la validation se fera essentiellement sur des lots de données simulées. A partir de fin 2007-2008 des données réelles des quatre expériences LHC seront disponibles pour tester le système dans un environnement soumis à la pression des utilisateurs. Comme le montre le diagramme ci-dessous, une tache complète pour une expérience est de procéder aux 3 facettes de l'analyse de physique : la simulation, la reconstruction et l'analyse proprement dite qui gère les algorithmes d'identification des objets que le physicien souhaite étudier ou découvrir. Ces taches mettent en jeu diverses parties d'un logiciel ayant une architecture fort développée pour à la fois gérer les entrées sorties des données (données réelles ou simulées), les stocker et classer dans des bases de données les méta-données, soumettre les taches, permettre des visualisations en temps réel etc. .... La validation du logiciel de l'expérience et de la chaîne complète d'analyse de physique nécessite un apprentissage du logiciel sur les systèmes d'exploitation mis à sa disposition, une compréhension de la gestion « automatique » des données des deux côtés (Tier-1 Tier1), un apprentissage du support utilisateur, un réglage fin du calcul et l'apprentissage progressif des physiciens et de l'interaction entre la communauté des physiciens utilisateurs et des fournisseurs du service calcul dans son ensemble.Les équipes participant au projetLe projet présenté ici fait intervenir trois équipes françaises et un partenaire aux Etats-Unis.Le Centre de calcul de l'IN2P3 et du DAPNIA (CCIN2P3)Représenté par son directeur Dominique Boutigny, le CCIN2P3 pilote le présent projet. Il héberge le Tier-1 pour le calcul des quatre expériences LHC en France. Après une première expérience européenne dans le domaine de grille de calcul dans le cadre du projet DataGRID, le CCIN2P3 s'est fortement impliqué dans les développements liés aux grilles de calcul en France à travers les projets EGEE et LCG. Il possède une très grande expérience dans le domaine de l'exploitation des ressources informatiques et de la mise en place des grandes architectures de calcul.Le CC-IN2P3 bénéficie d'un contexte particulièrement favorable au développement d'une expertise dans le domaine des grilles de calcul. Avec ses experts en administration système, en télécommunications, en stockage de données, et en gestion de la production du calcul scientifique, il réunit le panel de compétences nécessaires à l'appréhension et à l'intégration des technologies de grille. La richesse et la diversité de son infrastructure technique, que ce soit en termes de CPUs (plusieurs milliers), de stockage (plusieurs To de disque et de l'ordre du Po en stockage de masse), ou de réseau, donne les moyens au CC d'être un acteur significatif des projets de grille.L'objectif de ces deux projets consiste à mettre en place une infrastructure de grille de production à l'échelle mondiale et couvre donc tous les aspects de ce domaine. Ils fournissent ainsi au CC-IN2P3 l'opportunité d'exploiter tout son savoir-faire, tout en se forgeant une sérieuse expertise dans le déploiement et l'exploitation d'une infrastructure de grille. Dans ce cadre, le CC intervient aussi bien au niveau organisationnel que technique.D'un point de vue organisationnel, la participation du CC-IN2P3 se traduit par une contribution importante à la coordination de l'exploitation de plus de 130 centres de ressource. Concrètement, le CC assure, d'une part,  la direction technique au niveau français pour le projet LCG, et d'autre part, les rôles de « regional operations center » (ROC) et de « core infrastructure center » (CIC) pour le projet EGEE. Les missions de ces deux derniers sont respectivement la coordination de la production des sites français (9 actuellement) et la mise en place de l'exploitation globale de la grille, en étroite collaboration avec 4 autres centres européens. Pour répondre à ses différentes missions, le CC-IN2P3 a du mettre en place une structure adaptée à un travail de coordination distribuée. D'un point de vue technique, il met actuellement à disposition de la grille LCG/EGEE, aussi bien ses ressources de calcul et de stockage que des services clefs nécessaires aux communautés d'utilisateurs pour exploiter les ressources de la grille. Ce travail a permis de  placer le CC dans les 10 sites les plus importants de la grille EGEE/LCG qui compte plus de 130 sites repartis sur toute la planète.Le site possède une grande expérience des transferts de données à  très grande vitesse. Les besoins de la physique des hautes énergies ont nécessités le  développement d'outils de transferts très performants et l'utilisation de nouveaux protocoles. Un débit de transferts de données de production de l'ordre de 300Mbps maintenu sur plusieurs heures est actuellement courant entre les Etats-Unis et le CCIN2P3. Dernièrement sa participation aux Service Challenge LCG a montré sa capacité à mettre en place une infrastructure  _permettant un débit de transferts de données provenant du CERN/Genève de 800Mbps de moyenne en continu pendant plus de 10 jours; soit un transfert de prés de 80Toctets de données. (http://www2.cnrs.fr/presse/communique/667.htm)Le CCIN2P3 hébergera le matériel nécessaire pour mener à bien le projet (serveurs, matériel réseau spécifique, etc.)Le CCIN2P3 met à la disposition du projet son infrastructure et ses équipes techniques. Le GIP RENATER (www.renater.fr)Représenté par son directeur Dany Vandrommele GIP RENATER apportera au projet les infrastructures de communications nécessaires aux échanges avec le CERN et les autres Tier-1, en particulier le Fermi Lab. Le GIP RENATER assure la maîtrise d'ouvrage du réseau national de télécommunications pour la technologie, l'enseignement et la recherche. Ce réseau est une infrastructure mutualisée qui interconnecte toutes les universités et les centres de recherche publique de France. Il fournit également l'accès à tous les autres réseaux recherche dans le reste du mande, via le réseau Pan-européen GEANT. Dany Vandromme est également membre du directoire de la société DANTE (qui assure la maîtrise d'ouvrage du réseau GEANT) et membre du comité exécutif du projet GN2. Pour répondre au mieux aux attentes de la communauté HEP, RENATER installe, dans le cadre du déploiement de RENATER-4, une fibre optique entre le CC-IN2P3 et le CERN. Par ailleurs, des fibres seront également déployées entre Lyon et Paris, où se trouve également le nœud français de GEANT2. Toutes ces fibres seront illuminées par RENATER, ce qui permettra de déployer autant de circuits que nécessaires, sur le même support optique. Chaque circuit, correspondant à une longueur d'onde (lambda), aura une capacité de transmission de 10 Gb/s. Les connexions du Tier-1 de Lyon seront dont assurées prioritairement par la liaison Lyon-Genève, et secondairement par GEANT, qui assurera également la connectivité inter-Tier-1 (y compris avec le Fermi Lab).L'équipe RESO du Laboratoire de l'Informatique du Parallélisme (LIP) RESO est une équipe du laboratoire de l'Informatique du Parallélisme (LIP) UMR N°5568 de l'Ecole Normale Supérieure de Lyon.RESO s'intéresse aux protocoles et services des réseaux très haut débit courtes et longues distances. L'objectif de RESO est d'étudier et de proposer des solutions de transport de bout en bout originales et innovantes visant à répondre aux besoins spécifiques des applications de grille et aptes à passer à l'échelle de plus hauts débits et de flux plus hétérogènes et exigeants.Les travaux fondamentaux sont articulés selon les deux axes de recherche suivants:    * Les architectures Logicielles Optimisées  pour communications efficaces dans les systèmes de type grappe, serveur ou équipements d'accès.    * Les protocoles et traitements pour le transport performant  de flux hétérogènes.Les études et les résultats sont appliqués au domaine des Grilles de calcul et de données Haute-Performance. RESO développe des solutions de « Services réseau » pour les grilles.Le Fermi National Accelerator laboratory (FNAL)Intervient dans le projet en tant que partenaire étranger. Il héberge l'infrastructure du Tier-1 de l'expérience CMS aux Etats-Unis. Le FNAL est l'un des laboratoires leader mondial en physique des hautes énergies, il héberge en particulier l'accélérateur actuellement  le plus puissant au monde (Tevatron) et les expériences CDF et D0. L'expérience D0 dans laquelle la France participe, exploite déjà le concept des grilles de calcul et pourra servir de banc d'essai pour les tests d'interopérabilité.Le FNAL, par l'intermédiaire de son centre de calcul, est fortement impliqué dans les développements informatiques pour le LHC ainsi que dans le développement de la grille américaine Open Science Grid.Collaboration entre les différentes équipesLa collaboration entre les différentes équipes est cruciale pour la réussite du projet. _	Le CCIN2P3 apporte l'infrastructure de calcul avec des capacités de stockage sur disque de plusieurs centaines de Téraoctets maintenant et plusieurs Pétaoctets en 2008. _	RENATER apporte l'infrastructure réseau avec la possibilité de contrôler et d'ajuster la configuration des matériels. La possibilité de tester le réseau international avec des flux de données importants pendant de longues périodes permet comprendre le comportement des réseaux dans des situations extrêmes. _	L'équipe RESO du LIP apporte son expertise dans le domaine des protocoles réseau et bénéficie, à travers le présent projet, à la fois de l'infrastructure réseau mise en place et  d'applications réelles pour tester en vraie grandeur les performances atteintes par ses développements.Retombées attenduesLes retombées du projet consisteront en plusieurs publications dans des journaux scientifiques dans le domaine des STIC ainsi que des communications dans des conférences internationales. Nous attendons également du projet qu'il permette aux équipes françaises qui développent la grille de calcul pour le LHC d'acquérir une position de leader dans ce domaine et d'être ainsi dans les meilleures conditions pour participer pleinement à l'exploitation scientifique des données du LHC dès la mise en route de l'accélérateur. Ce rôle est crucial, puisqu'on attend des découvertes majeures (boson de Higgs, Supersymétrie...) dès les premiers mois d'exploitation des données.Calendrier du projet et jalonsLes différentes étapes du projet protocoles réseaux seront les suivantes:- Une première partie  (T0 à T24)consistera en une analyse des besoins de transport des applications physiques déployées sur LHC. Pour cela, un outil de capture de la signature de communication d'une application conçu par l'équipe RESO sera validé sur des applications réelles et les données acquises seront analysées pour modéliser les trafics émis et reçus.  (RESO + IN2P3)- Parallèlement une étude des spécificités de l'infrastructure étudiée, débouchera sur une modélisation de l'interconnexion réseau d'une grille et de ses sources d'indéterminisme (systèmes d'extrèmités, réseau local, routeur d'accès, firewall, coeur...) qui sera validée ensuite par les travaux expérimentaux (RESO +  RENATER). - La deuxième partie sera une étude comparative expérimentale des nouveaux protocoles de transport vis à vis des besoins identifiés et des propriétés attendues.  On cherchera à définir un benchmark de service et de protocoles de transport pour les grilles de données. (RESO) ( T0 à T24)-	La troisième partie comprendra le développement, la validation et l'évaluation expérimentale d'un prototype de service transport dans l'environnement eWAN puis sur l'infrastructure réelle avec un échantillon de trafics type (T12 à T36) (RESO + IN2P3)Propositions d'experts et confidentialité_	Chaque porteur de projet devra fournir une liste de 3 à 5 noms d'experts français ou étrangers (avec coordonnées complètes : adresse postale et adresse électronique) susceptibles d'évaluer le projet avec lesquels il n'a ni conflit d'intérêt, ni collaborations en cours._	Les membres du Comité d'évaluation et du Comité stratégique sont astreints à la confidentialité.Programme non thématique 2005C - Moyens financiers et humains demandés par chaque équipe partenaire du projetChaque équipe partenaire remplira une fiche de demande d'aide selon les modèles proposés ci-dessous (laboratoire public ou fondation ; entreprise ou association) en fonction de son appartenance.On présentera une brève justification scientifique des moyens demandés pour chacune des équipes impliquées dans le projet.Ressources nécessairesLes ressources nécessaires pour mener le projet à bien sont de trois types :Matériel_	X serveurs de type y équipé de ...._	Matériel réseau...._	Disque....Ressources humainesRESO : 1 bourse de thèse (3ans) (environ 30Keuros /an)1 ingénieur expert pendant 3 ans ( environ 40K euros /an)15K euros de fonctionnement par an 15K euros d' équipement par an (cartes 10Gb/s, serveur haute performance, analyseur de trames...)Soit un total de 100K euros par an.L'embauche sur CDD de trois ( ???) personnes est indispensable à la réussite du projet, le profil de ces personnes est le suivant :_	Deux ingénieurs en informatique niveau IR pour mener bien les développements liés à l'interopérabilité des grilles de calculs. Ceux-ci travailleront en étroite collaboration avec les équipes de développements LCG et EGEE de l'IN2P3 et du CERN. L'un travaillera sur l'aspect purement logiciel du projet et l'autre sur l'aspect exploitation._	Un ingénieur en informatique niveau IR pour travailler sur la partie réseau du projet, cette personne devra développer la collaboration entre le CCIN2P3 et RENATER, il sera également chargé d'implémenter et de tester les protocoles et les applications réseaux développées par l'équipe RESO du LIP.Pour RENATER, un ingénieur Réseau tel que défini dans le second alinéa du paragraphe précédent.Missions et frais d'accueil de chercheurs étrangersPour assurer la parfaite coordination des développements, il faudra prévoir 2 mois par an de missions cumulées aux Etats-Unis et 2 mois de prise en charge de frais de séjours de collaborateurs américains en France (les voyages étant à la charge du FNAL). Programme non thématique 2005Fiche de demande d'aide - Laboratoire public / FondationAcronyme ou titre court du projetResponsable scientifique (coordinateur ou partenaire) (nom, prénom) : Estimation du coût marginal du projet pour le laboratoire :Les valeurs obtenues dans les cellules du tableau P à W serviront à renseigner le tableau « estimation du coût complet » ci-dessousAnnée 1Année 2Année 3Total (Euros)Nbre h/mCoût h/mCoût totalNbre h/mCoût h/mCoût totalNbre h/mCoût h/mCoût totalDépenses de personnel (1)(catégorie 1)(catégorie 2)...(P)Equipements (2),(4)(Q)Achats de petits matériels, de consommables etc (2)(R)Prestations de service(2),(3)(S)Frais de missions (2)(T)Frais généraux (4 % des dépenses)(U)Total (Euros)(V)Aide demandée (Euros)(W)(1)	Personnel non statutaire directement affecté au projet exprimé en hommes mois. Les dépenses éligibles se limitent aux salaires et aux charges sociales. Pour cet appel les doctorants ne doivent pas être pris en compte. Exemple : post-doc (catégorie 1), ingénieur d'études (catégorie 2)(2)	Y compris TVA non récupérable.(3)	Le montant des prestations de service est limité à 50% du montant global du fonctionnement demandé. (4)	Matériel dont la valeur unitaire est supérieure à 4000 euros HTEvaluation (pour information) du coût complet du projet pour le laboratoireEQUIPEMENT (1)  (2)FONCTIONNEMENTTOTALEquipement + fonctionnementDépenses de personnelPrestations de service (1)Autres dépenses de fonctionnement (1)Total fonctionnement(a)(b)(c)(d)(e) = (b) + (c) + (d)(f) = (a) + (e)  = (Q) ci-dessus= somme (P) x (4)+ (3) x (4)= (S) ci-dessus= somme (R+T+U) ci-dessus  (X)(1)	Coût HT majoré le cas échéant de la TVA non récupérable(2) 	Équipement : matériel dont la valeur unitaire est supérieure à 4 000 euros HT(3)	Dépense du personnel rémunéré par d'autres sources de financement (charges sociales comprises) affecté au projet, au prorata de leur implication dans le projet  (y compris les doctorants)(4)	Taux d'environnement de l'établissementProgramme non thématique 2005Fiche de demande d'aide - Entreprise / AssociationAcronyme ou titre court du projetResponsable scientifique (coordinateur ou partenaire) (nom, prénom) : Estimation (en coûts complets H.T.) du projet pour l'entreprise :Année 1Année 2Année 3Total (Euros)Nbre h/mCoût h/mCoût totalNbre h/mCoût h/mCoût totalNbre h/mCoût h/mCoût totalAmortissements d'équipements de R&DDépenses de personnel (1)(catégorie 1)(catégorie 2)...Prestations de service (2) :- Information scientifique et technique- Propriété industrielle- Faisabilité technique - Conception, analyse de la valeur- Essais, tests, caractérisation- Prototypage - Etudes économiques- Autres prestationsFrais de missionAutres dépenses de fonctionnementDépenses liées à l'utilisationd'autres équipements de R&Dque ci-dessus (3)Autres dépenses (3)Frais (assistance, encadrement, coût de structure)  (4)Total H.T. (Euros)(X)Aide demandée (Euros)(W)(1)	Personnel directement affecté au projet, chiffré en hommes mois par catégories de personnel.(2)	Chiffré par  types de prestations(3)	Justifiées selon une procédure de facturation interne(4)	Ces frais seront remboursés jusqu'à un plafond défini par les règles propres à l'ANR. Ce plafond est calculé en fonction des éléments donnés dans le tableau (frais de personnel, équipement, ...)Note : En cas de décision de financement de ce projet, le porteur de projet devra alors fournir un dossier complémentaire comportant un planning de déroulement du projet et des documents administratifs et financiers (entreprises, laboratoires et/ou associations) dont la liste lui sera précisée. Programme non thématique 2005D - Récapitulatif global de la demande financière pour le projet Acronyme ou titre court du projet :a-Total de l'aide demandée (reporter les valeurs (W) des fiches des différents partenaires)Aide demandéeCoordinateur (Partenaire 1)Partenaire 2......Total à reporter sur la première page du dossierb-Estimation (pour information) du coût complet de cette demande(reporter les valeurs (X) des fiches des différents partenaires)Coût completCoordinateur (Partenaire 1)Partenaire 2......Total à reporter sur la première page du dossierContrats sur les trois dernières années (effectués et en cours)Nom du membre participant à cette demande% d'implicationIntitulé de l'appel à projetsSource de financementMontant attribuéTitre du projetNom du coordinateurDate début -Date finDemandes de contrats en cours d'évaluation Nom du membre participant à cette demande% d'implicationIntitulé de l'appel à projetsSource de financementMontant demandéTitre du projetNom du coordinateurSecteurs disciplinaires¬	Sciences et technologies de l'information et de la communication (STIC),¬	Sciences pour l'ingénieur,¬	Chimie,¬	Physique,¬	Mathématiques et interactions,¬	Sciences de l'univers et géo-environnement,¬	Sciences agronomiques et écologiques,¬	Biologie et santé,¬	Sciences humaines et sociales
